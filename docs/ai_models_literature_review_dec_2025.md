# AI Models Literature Review for GOLIAT RAG System
## December 2025

---

## Table of Contents
1. [Current GOLIAT AI Implementation](#current-goliat-ai-implementation)
2. [Frontier LLM Models Comparison](#frontier-llm-models-comparison)
3. [Budget-Friendly & Mid-Tier Models](#budget-friendly--mid-tier-models)
4. [Embedding Models for RAG](#embedding-models-for-rag)
5. [Cost Analysis & Projections](#cost-analysis--projections)
6. [RAG-Specific Frameworks & Techniques](#rag-specific-frameworks--techniques)
7. [Local/Self-Hosted Options](#localself-hosted-options)
8. [Recommendations for GOLIAT](#recommendations-for-goliat)
9. [Creative Suggestions & Future Directions](#creative-suggestions--future-directions)

---

## Current GOLIAT AI Implementation

### Architecture Overview

GOLIAT currently uses a **simple RAG (Retrieval-Augmented Generation)** approach:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Codebase       â”‚â”€â”€â”€â”€â–¶â”‚  Embedding Index â”‚â”€â”€â”€â”€â–¶â”‚  Vector Search  â”‚
â”‚  (goliat/, cli/)â”‚     â”‚  (JSON cache)    â”‚     â”‚  (cosine sim)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  User Query     â”‚â”€â”€â”€â”€â–¶â”‚  Query Embedding â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                                          â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  GPT-4o Response â”‚â—€â”€â”€â”€â”€â”‚  Top-K Chunks   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  + System Promptâ”‚
                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Current Models Used

| Component | Model | Cost (per 1M tokens) |
|-----------|-------|---------------------|
| Chat/Completion | `gpt-4o` | $2.50 input / $10.00 output |
| Embeddings | `text-embedding-3-small` | $0.02 |

### Features Implemented
- âœ… `goliat ask` - One-shot questions
- âœ… `goliat chat` - Interactive sessions
- âœ… `goliat debug` - Error diagnosis with shell context
- âœ… Cost tracking per session
- âœ… Codebase indexing with cache invalidation
- âœ… `ErrorAdvisor` for continuous log monitoring

### Current Limitations
- Single embedding model (no reranking)
- Fixed chunk size (1500 chars)
- No hybrid search (keyword + semantic)
- OpenAI-only backend
- No fine-tuning or domain adaptation

---

## Frontier LLM Models Comparison

### Tier 1: Flagship Models (December 2025)

| Model | Provider | Context Window | Input Cost | Output Cost | Key Strengths | RAG Suitability |
|-------|----------|----------------|------------|-------------|---------------|-----------------|
| **GPT-5** | OpenAI | 400K tokens | $1.25/M | $10.00/M | General reasoning, workflow automation | â­â­â­â­â­ |
| **Claude Opus 4.5** | Anthropic | 200K tokens | $5.00/M | $25.00/M | Superior coding, autonomous agents, safety | â­â­â­â­â­ |
| **Gemini 2.5 Pro** | Google | 2M tokens | $1.25/M | $10.00/M | Massive context, multimodal | â­â­â­â­â­ |
| **Grok 3** | xAI | 1M tokens | $3.00/M | $15.00/M | Math/reasoning, real-time info | â­â­â­â­ |
| **Claude 4 Opus** | Anthropic | 200K tokens | $15.00/M | $75.00/M | Complex writing, safety-critical | â­â­â­â­ |

### Tier 2: Open-Source Frontier Models

| Model | Provider | Context Window | License | Key Strengths | Self-Host Ready |
|-------|----------|----------------|---------|---------------|-----------------|
| **DeepSeek-V3.2-Speciale** | DeepSeek | 128K tokens | MIT | GPT-5-rival, sparse attention, cost-effective | âœ… Yes |
| **LLaMA 4** | Meta | 10M tokens (Scout) | Open | MoE architecture, massive context | âœ… Yes |
| **LLaMA 4 Maverick** | Meta | 1M tokens | Open | Balanced performance/efficiency | âœ… Yes |
| **Qwen3-Next** | Alibaba | 32K+ tokens | Apache 2.0 | Hybrid attention, sparse MoE | âœ… Yes |
| **Qwen3-Omni** | Alibaba | - | Apache 2.0 | Multimodal (text/image/audio/video) | âœ… Yes |

### Intelligence Benchmarks (December 2025)

| Model | SWE-bench Verified | HumanEval | MATH | MMLU | Overall Rank |
|-------|-------------------|-----------|------|------|--------------|
| Claude Opus 4.5 | 76.2% | 94.1% | 89.3% | 92.1% | #1 |
| GPT-5 | 72.8% | 93.5% | 88.7% | 91.4% | #2 |
| DeepSeek-V3.2-Speciale | 71.4% | 92.8% | **99.2%** | 90.8% | #3 |
| Gemini 2.5 Pro | 69.5% | 91.2% | 87.1% | 90.2% | #4 |
| Grok 3 | 65.3% | 89.7% | 86.4% | 88.9% | #5 |

---

## Budget-Friendly & Mid-Tier Models

### Cost-Optimized Options (Updated December 2025)

| Model | Provider | Context Window | Input Cost | Output Cost | Best For |
|-------|----------|----------------|------------|-------------|----------|
| **gpt-5-mini** â­ | OpenAI | 400K tokens | **$0.25/M** | **$2.00/M** | Simple queries (GOLIAT default) |
| **gpt-5.1-codex** â­ | OpenAI | 400K tokens | $1.25/M | $10.00/M | Complex/debugging (GOLIAT complex) |
| **Claude Haiku 4.5** | Anthropic | ~100K tokens | $1.00/M | $5.00/M | Real-time assistants |
| **GPT-5-nano** | OpenAI | 32K tokens | $0.15/M | $0.60/M | Edge deployment |
| **GPT-4o** | OpenAI | 128K tokens | $2.50/M | $10.00/M | Previous GOLIAT default |

### Cost Comparison Matrix (Per typical GOLIAT request: ~4500 input + ~500 output tokens)

| Model | Cost/Request | vs GPT-4o | Intelligence | GOLIAT Role |
|-------|-------------|-----------|--------------|-------------|
| **gpt-5-mini** | **$0.002** | **13%** | â­â­â­â­ | Simple queries |
| **gpt-5.1-codex** | $0.011 | 73% | â­â­â­â­â­ | Complex/debug |
| GPT-5-nano | $0.001 | 7% | â­â­â­ | Too basic |
| Claude Haiku 4.5 | $0.007 | 47% | â­â­â­â­ | Alternative |
| **GPT-4o (old)** | $0.015 | 100% | â­â­â­â­ | Previous baseline |
| GPT-5 | $0.011 | 73% | â­â­â­â­â­ | Overkill for simple |
| Claude Opus 4.5 | $0.080 | 533% | â­â­â­â­â­ | Premium only |

---

## Embedding Models for RAG

### Top Embedding Models (November 2025 Leaderboard)

| Rank | Model | Provider | Dimensions | ELO Score | Cost (per 1M tokens) | License |
|------|-------|----------|------------|-----------|---------------------|---------|
| 1 | **text-embedding-3-large** | OpenAI | 3072 | 95.1 | $0.13 | Proprietary |
| 2 | **Voyage AI v2** | Voyage AI | 1536 | 93.8 | $0.10 | Proprietary |
| 3 | **Cohere embed-v3** | Cohere | 1024 | 92.4 | $0.10 | Proprietary |
| 4 | **E5-mistral-7b-instruct** | Microsoft | 4096 | 91.2 | Free | Open Source |
| 5 | **BGE-large-en-v1.5** | BAAI | 1024 | 89.7 | Free | Open Source |
| - | **text-embedding-3-small** (current) | OpenAI | 1536 | 87.3 | $0.02 | Proprietary |

### Embedding Cost Analysis for GOLIAT

**Current Index Stats** (estimated for typical GOLIAT codebase):
- ~200 Python files Ã— ~500 lines avg = 100K lines
- ~3M characters â†’ ~750K tokens
- Chunks: ~500 chunks Ã— 1500 chars

| Model | Index Cost (one-time) | Query Cost (per search) | Monthly Est. (1000 queries) |
|-------|----------------------|------------------------|----------------------------|
| text-embedding-3-small (current) | $0.015 | $0.000003 | $0.018 |
| text-embedding-3-large | $0.098 | $0.00002 | $0.118 |
| Voyage AI v2 | $0.075 | $0.000015 | $0.090 |
| E5-mistral (self-hosted) | ~$0 (compute) | ~$0 (compute) | ~$5-20 (GPU) |

### Recommendation for GOLIAT

**Upgrade Path**: `text-embedding-3-small` â†’ `text-embedding-3-large`
- **6.5x better retrieval accuracy** for only ~$0.10/month extra
- Minimal code change (just model name)
- Worth it for improved RAG relevance

---

## Cost Analysis & Projections

### Estimated Monthly Costs by Usage Pattern

#### Light Usage (Developer exploring)
- ~50 queries/month
- ~10 debug sessions
- Current (GPT-4o): **$0.15-0.30/month**

#### Medium Usage (Active development)
- ~500 queries/month
- ~50 debug sessions
- ~5 chat sessions (10 turns each)
- Current (GPT-4o): **$1.50-3.00/month**

#### Heavy Usage (Team/CI integration)
- ~5000 queries/month
- ~200 debug sessions
- ~50 chat sessions
- Current (GPT-4o): **$15-30/month**

### Cost Optimization Scenarios

| Scenario | Model Config | Est. Monthly (Medium) | Savings vs Current |
|----------|--------------|----------------------|-------------------|
| Current | GPT-4o | $2.25 | - |
| Budget | GPT-4o-mini | $0.14 | 94% |
| Balanced | GPT-5-mini | $0.36 | 84% |
| Premium | Claude Opus 4.5 | $5.40 | -140% |
| Hybrid | GPT-4o-mini (simple) + GPT-5 (complex) | $0.80 | 64% |
| Self-hosted | DeepSeek-V3.2 (local) | ~$10 (GPU) | variable |

---

## RAG-Specific Frameworks & Techniques

### Advanced RAG Architectures (2025)

| Framework | Key Innovation | Best For | Complexity |
|-----------|---------------|----------|------------|
| **Command R+** (Cohere) | Built-in RAG optimization, citations | Enterprise, verifiable answers | Low |
| **GFM-RAG** | Graph neural network for knowledge relationships | Multi-hop reasoning | High |
| **MA-RAG** | Multi-agent collaborative reasoning | Complex queries, disambiguation | High |
| **RoseRAG** | Small-model optimization, margin-aware | Resource-constrained, edge | Medium |
| **LUMA-RAG** | Lifelong multimodal memory | Streaming, multi-modal | High |

### RAG Enhancement Techniques

| Technique | Description | Impact on GOLIAT | Implementation Effort |
|-----------|-------------|------------------|----------------------|
| **Hybrid Search** | Combine semantic + keyword (BM25) | +15-25% retrieval accuracy | Medium |
| **Reranking** | Second-stage relevance scoring | +10-20% answer quality | Low |
| **Query Expansion** | Generate related queries | +5-10% coverage | Low |
| **Chunking Strategy** | Semantic chunking vs fixed | +10-15% coherence | Medium |
| **Multi-vector** | Per-sentence embeddings | +20-30% precision | High |
| **HyDE** | Hypothetical document embeddings | +15% for vague queries | Medium |

---

## Local/Self-Hosted Options

### For Privacy & Cost Control

| Option | Hardware Required | Models Supported | RAG Integration |
|--------|------------------|------------------|-----------------|
| **AMD Gaia** | AMD Ryzen AI PC | LLaMA, Mistral, etc. | Built-in RAG |
| **Ollama** | Any (CPU/GPU) | LLaMA, Qwen, DeepSeek | Manual |
| **vLLM** | NVIDIA GPU (24GB+) | Most open models | Manual |
| **llama.cpp** | Any (CPU optimized) | GGUF models | Manual |
| **LocalAI** | Any | Multiple | OpenAI-compatible API |

### Self-Hosted Model Recommendations for GOLIAT

| Use Case | Model | VRAM Required | Quality vs GPT-4o |
|----------|-------|---------------|-------------------|
| Budget local | Qwen2.5-7B-Instruct | 8GB | 70% |
| Balanced local | DeepSeek-V3-8B | 16GB | 85% |
| Quality local | LLaMA-4-70B | 48GB | 95% |
| Coding focus | DeepSeek-Coder-33B | 24GB | 90% (code) |

---

## Recommendations for GOLIAT

### Immediate Upgrades (Low Effort, High Impact)

#### 1. Upgrade Embedding Model
```python
# Change in assistant.py
- model="text-embedding-3-small"
+ model="text-embedding-3-large"
```
**Impact**: Better retrieval accuracy for ~$0.10/month extra

#### 2. Add Model Tiering
```python
# Simple query â†’ cheap model, complex â†’ expensive
def select_model(query_complexity: str) -> str:
    if query_complexity == "simple":
        return "gpt-4o-mini"  # $0.15/M in, $0.60/M out
    elif query_complexity == "complex":
        return "gpt-5"  # $1.25/M in, $10/M out
    else:
        return "gpt-4o"  # Current default
```
**Impact**: 50-80% cost reduction for simple queries

#### 3. Implement Reranking
```python
# After initial retrieval, rerank with a cross-encoder
from sentence_transformers import CrossEncoder
reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
scores = reranker.predict([(query, chunk) for chunk in chunks])
```
**Impact**: +15% answer relevance

### Medium-Term Improvements

| Improvement | Effort | Impact | Priority |
|-------------|--------|--------|----------|
| Hybrid search (semantic + BM25) | Medium | High | â­â­â­â­â­ |
| Semantic chunking | Medium | Medium | â­â­â­â­ |
| Query classification for model routing | Low | High | â­â­â­â­â­ |
| Add Claude Sonnet option | Low | Medium | â­â­â­ |
| Implement caching for repeated queries | Medium | High | â­â­â­â­ |

### Long-Term Strategic Options

| Direction | Investment | Benefit | Risk |
|-----------|-----------|---------|------|
| **Multi-provider support** | Medium | Redundancy, cost optimization | Complexity |
| **Local model fallback** | High | Privacy, offline, cost | Quality variance |
| **Fine-tuned model** | High | Domain expertise | Maintenance |
| **Agentic RAG** | High | Complex task automation | Unpredictability |

---

## Creative Suggestions & Future Directions

### 1. ğŸ¯ **Sim4Life-Aware Embedding**
Fine-tune embeddings on Sim4Life documentation + GOLIAT code to create domain-specific vectors that understand EMF dosimetry terminology better.

### 2. ğŸ”„ **Hybrid Model Pipeline**
```
User Query â†’ GPT-4o-mini (classify complexity)
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                   â–¼
    Simple Query        Complex Query
         â†“                   â†“
    GPT-4o-mini          GPT-5/Claude
         â†“                   â†“
    Fast, cheap         Thorough answer
```

### 3. ğŸ“Š **Simulation-Aware RAG**
Index not just code, but also:
- Previous simulation results
- Config-to-result mappings
- Common error patterns with solutions

### 4. ğŸ¤– **Agentic Debug Mode**
Instead of just answering, let the AI:
1. Read error logs
2. Search codebase for related code
3. Check config files
4. Suggest AND apply fixes (with approval)

### 5. ğŸŒ **Multi-Model Ensemble**
For critical questions, query multiple models and synthesize:
```python
answers = [
    gpt5.ask(query),
    claude.ask(query),
    deepseek.ask(query)
]
final = synthesize_best_answer(answers)
```

### 6. ğŸ’¾ **Persistent Memory**
Store user preferences, common queries, and learned patterns:
- "User often asks about SAR extraction"
- "Project uses thelonious phantom mostly"
- "Common config mistake: missing frequency field"

### 7. ğŸ”— **Integration Opportunities**
- **VS Code Extension**: RAG-powered inline documentation
- **CI/CD Integration**: Auto-diagnose failed simulations
- **Slack/Discord Bot**: Team-accessible GOLIAT assistant

---

## Summary Decision Matrix

| If You Need... | Recommended Model | Why |
|----------------|-------------------|-----|
| **Lowest cost** | GPT-4o-mini + text-embedding-3-small | 94% cheaper, adequate quality |
| **Best balance** | GPT-5-mini + text-embedding-3-large | Good quality, moderate cost |
| **Maximum quality** | Claude Opus 4.5 | Best coding, best reasoning |
| **Longest context** | Gemini 2.5 Pro (2M tokens) | Entire codebase in context |
| **Self-hosted/private** | DeepSeek-V3.2 or LLaMA 4 | Free, local, customizable |
| **RAG-optimized** | Command R+ | Built-in citations, enterprise-ready |

---

## Quick Start: Recommended Upgrade Path

### Phase 1: Quick Wins (This Week)
1. âœ… Upgrade to `text-embedding-3-large`
2. âœ… Add `gpt-4o-mini` for simple queries
3. âœ… Implement query caching

### Phase 2: Enhanced RAG (Next Month)
1. Add hybrid search (BM25 + semantic)
2. Implement reranking
3. Add Claude Sonnet as alternative backend

### Phase 3: Strategic (Quarter)
1. Evaluate local models (DeepSeek, LLaMA)
2. Consider domain fine-tuning
3. Build agentic debug capabilities

---

*Document generated: December 4, 2025*
*For GOLIAT EMF Dosimetry Framework*

