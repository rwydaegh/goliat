{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to GOLIAT","text":"<p>GOLIAT is an automated Python framework for near-field and far-field dosimetric assessments using the Sim4Life simulation platform. It streamlines EMF exposure simulations for research and compliance.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li> <p> Installation</p> <p>Two installation methods: PyPI for users, editable install for developers.</p> <p> Install Guide</p> </li> <li> <p> Quick Start</p> <p>Run your first simulation in minutes. No manual setup required.</p> <p> Get Started</p> </li> <li> <p> User Guide</p> <p>Understand near-field and far-field workflows. Step-by-step explanations with practical insights.</p> <p> Read Guide</p> </li> <li> <p> Tutorials</p> <p>Interactive notebooks from basics to cloud execution. Learn by doing.</p> <p> View Tutorials</p> </li> <li> <p> Technical Guide</p> <p>Architecture, components, and system design. For developers extending or maintaining GOLIAT.</p> <p> Technical Guide</p> </li> <li> <p> Advanced Features</p> <p>GUI architecture, profiling, caching, phantom rotation. Advanced capabilities explained.</p> <p> Advanced Features</p> </li> <li> <p> Configuration</p> <p>All JSON configuration parameters with examples. Flexible and powerful.</p> <p> Configure</p> </li> <li> <p> Analysis system</p> <p>Process results, generate plots, and create publications. User guide and developer documentation.</p> <p> Analysis Guide</p> </li> <li> <p> oSPARC</p> <p>Cloud batch execution via oSPARC platform. Scale to hundreds of simulations with true parallel GPU execution.</p> <p> oSPARC Guide</p> </li> <li> <p> Monitoring Dashboard</p> <p>Web-based interface for monitoring distributed studies across multiple workers. Track progress, view logs, coordinate super studies.</p> <p> Monitoring Guide</p> </li> <li> <p> Cloud Setup</p> <p>Deploy GPU instances and run simulations in the cloud. Automated setup included.</p> <p> Cloud Guide</p> </li> <li> <p> Coloring Rules</p> <p>Terminal output coloring guidelines. Makes logs easier to scan and debug.</p> <p> Coloring Rules</p> </li> <li> <p> Troubleshooting</p> <p>Common issues and solutions. Sim4Life setup, execution, and configuration.</p> <p> Troubleshooting</p> </li> <li> <p> Full List of Features</p> <p>Every feature organized by category. See what GOLIAT can do.</p> <p> View Features</p> </li> <li> <p> API Reference</p> <p>All classes, methods, and functions. Generated from code documentation.</p> <p> API Docs</p> </li> <li> <p> Sim4Life API snippets</p> <p>Practical code examples for Sim4Life Python API tasks. Extracted from GOLIAT usage patterns.</p> <p> View snippets</p> </li> <li> <p> Project Info</p> <p>Research project background, funding, partners, and consortium information.</p> <p> Project Info</p> </li> <li> <p> AI Assistant</p> <p>Query the codebase and documentation using natural language. Get instant answers to your questions.</p> <p> Use Assistant</p> </li> </ul>"},{"location":"#overview","title":"Overview","text":"<p>GOLIAT automates dosimetric assessments for the GOLIAT project, calculating SAR and SAPD in digital human phantoms from device or environmental EMF exposure. Key features:</p> <ul> <li>Modular scene building (phantoms, antennas, plane waves).</li> <li>Local or cloud execution (iSolve/oSPARC).</li> <li>Results extraction and analysis (SAR and SAPD metrics, plots).</li> <li>GUI for progress tracking.</li> <li>Automatic disk space management for serial workflows.</li> </ul> <p>Start with the Quick Start to run your first simulation.</p>"},{"location":"#why-goliat","title":"Why GOLIAT?","text":"<ul> <li>Efficiency: Handles setup, runs, and analysis in one tool.</li> <li>Reproducible: Config-driven for consistent results.</li> <li>Scalable: Local parallel or cloud batching for large studies.</li> <li>Accessible: Plain-language docs for newcomers.</li> </ul> <p>For issues, see Troubleshooting. Contribute via Technical Guide.</p>"},{"location":"#results","title":"Results","text":"<p>Check out the auto-generated first draft paper (only results): - Results PDF - Download the compiled PDF - Results LaTeX Source - Download the LaTeX source</p> <p>For a complete list of all available features, see the Full List of Features.</p>"},{"location":"installation/","title":"Installation","text":"<p>GOLIAT supports two installation methods. Use PyPI if you just want to run simulations. Use editable install if you need to modify code or access repository tools.</p>"},{"location":"installation/#pypi-installation","title":"PyPI installation","text":"<p>Install from PyPI and run from any directory. No repository cloning needed.</p> <p>You need Sim4Life 8.2 or 9.2 with valid license, Sim4Life Python interpreter, and Windows.</p> <p>Create a virtual environment with Sim4Life Python:</p> <pre><code>source .bashrc\npython -m venv venv --system-site-packages\nsource venv/Scripts/activate\n</code></pre> <p>Your <code>.bashrc</code> should have the Sim4Life Python path configured. Use <code>goliat config set-version</code> to change it if needed, once installed.</p> <p>The <code>--system-site-packages</code> flag allows the venv to access Sim4Life's packages (like <code>s4l_v1</code>).</p> <p>Install GOLIAT:</p> <pre><code>python -m pip install goliat\n</code></pre> <p>This installs the latest released version from PyPI. For unreleased features or bug fixes, use editable installation.</p> <p>Navigate to your project directory and initialize:</p> <pre><code>cd /path/to/your/project\ngoliat init\n</code></pre> <p>Creates <code>configs/</code> and <code>data/</code> directories and downloads required models. Then run simulations:</p> <pre><code>goliat study near_field_config\n</code></pre> <p>Works from any directory. Upgrade with <code>python -m pip install --upgrade goliat</code>. You can't modify source code or access repository scripts. PyPI installs only include code from published releases, not the latest repository commits.</p>"},{"location":"installation/#editable-installation","title":"Editable installation","text":"<p>Clone repository and install in editable mode. Required for development, testing, or contributing.</p> <p>You need Git, Sim4Life 8.2 or 9.2 with valid license, and Sim4Life Python interpreter.</p> <p>Clone repository:</p> <pre><code>git clone https://github.com/rwydaegh/goliat.git\ncd goliat\n</code></pre> <p>Set up Sim4Life Python environment:</p> <pre><code>source .bashrc\n</code></pre> <p>Adds Sim4Life Python to PATH. GOLIAT prompts to copy <code>.bashrc</code> to home directory.</p> <p>Install in editable mode (or in a venv):</p> <pre><code>python -m pip install -e .\n</code></pre> <p>Code changes are immediately available without reinstalling.</p> <p>Initialize:</p> <pre><code>goliat init\n</code></pre> <p>Downloads models and sets up directories in repository root.</p> <p>Gives you full repository access (scripts, tests, docs) and better IDE support. Use this if you're modifying code, running tests, or contributing.</p>"},{"location":"installation/#post-installation","title":"Post-installation","text":"<p>Both methods require running <code>goliat init</code> once. It verifies Sim4Life Python interpreter, downloads phantom and antenna models, and creates <code>configs/</code> and <code>data/</code> directories.</p> <p>Takes 5-10 minutes depending on internet speed. If you delete parts of the setup, <code>goliat init</code> repairs incomplete installations.</p>"},{"location":"installation/#choosing-between-options","title":"Choosing between options","text":"<p>Use PyPI if you just want to run simulations and don't need to modify code. Use editable install if you're developing, modifying code, running tests, or contributing.</p> <p>For installation issues, see troubleshooting guide.</p>"},{"location":"project_info/","title":"Project Information","text":""},{"location":"project_info/#about-projectgoliat","title":"About #ProjectGOLIAT","text":"<p>GOLIAT (5G expOsure, causaL effects, and rIsk perception through citizen engAgemenT) is a research project that aims to characterize and monitor RF-EMF exposure, in particular 5G, provide novel insights into potential causal neuropsychological and biological effects, and understand risk perception and communication through citizen engagement using an integrative and transdisciplinary pan-European approach.</p> <p>The primary objectives of the project include:</p> <ul> <li>Transfer function matrix: Creating a transfer function (from input powers of phones to impinging field values) to SAR values inside humans, in a large array (or matrix) of conditions.</li> <li>Child Phantom Analysis: Performing simulations on detailed child phantoms, such as \"Thelonious\" and \"Eartha,\" to understand age-dependent effects.</li> <li>SAR Analysis: Calculating Specific Absorption Rate (SAR) metrics, including whole-body, head, trunk, and peak spatial-average SAR (psSAR10g) in sensitive tissues like the skin, eyes, and brain. Also supports Surface Absorbed Power Density (SAPD) extraction for high-frequency (&gt; 6 GHz) assessments.</li> <li>Varied Exposure Scenarios: Investigating numerous exposure conditions, including different frequencies, antenna types, and device positions (e.g., by the cheek, in front of the eyes, near the belly).</li> </ul> <p>Check out the GOLIAT website!</p>"},{"location":"project_info/#funding-and-acknowledgements","title":"Funding and acknowledgements","text":"<p>This work is part of the GOLIAT project, which has received funding from the European Union's Horizon Health program under the call HORIZON-HEALTH-2021-ENVHLTH-02-01 - Exposure to electromagnetic fields (EMF) and health. GOLIAT is part of the CLUE-H consortium with ETAIN, NextGEM and SEAWave.</p> <p>Check out the CLUE-H website!</p>"},{"location":"project_info/#project-partners","title":"Project partners","text":"<p>The GOLIAT consortium consists of 22 partners from across Europe and the United States:</p> <ul> <li>Barcelona Institute for Global Health (ISGlobal), ES (Coordinator)</li> <li>Ghent University (UGent) and IMEC, BE (lead subtask 1.5)</li> <li>Telecom Paris (TP), FR</li> <li>Consiglio Nazionale delle Ricerche (CNR), IT</li> <li>Swiss Tropical and Public Health Institute (SwissTPH), CH</li> <li>Nofer Institute of Occupational Medicine (NIOM), PL</li> <li>University of Bristol (UNIVBRIS), UK</li> <li>Universit\u00e0 degli Studi di Torino (UNITO), IT</li> <li>Academisch Medisch Centrum (AMC), NL</li> <li>Centre National de la Recherche Scientifique (CNRS), FR</li> <li>National Institute of Industrial Environment and Risks (INERIS), FR</li> <li>University La Sapienza (UNIROMA1), IT</li> <li>University of Bologna (UNIBO), IT</li> <li>National Public Health Center (NPHC), HU</li> <li>University of P\u00e9cs (UP), HU</li> <li>University of Exeter Medical School (UNEXE), UK</li> <li>University of Vienna (UNIVIE), AT</li> <li>Science for Change (SfC), ES</li> <li>Norwegian University of Life Sciences (NMBU), NO</li> <li>Massachusetts General Hospital (MGH), US</li> <li>Harvard School of Public Health (HSPH), US</li> <li>University of Michigan (UMich), US</li> </ul>"},{"location":"project_info/#developer-lab","title":"Developer lab","text":"<p>The main developer, Robin Wydaeghe, is from the WAVES Research group at Ghent University and IMEC.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>This section addresses common issues encountered when using GOLIAT. Issues are grouped by category, with steps to resolve them.</p>"},{"location":"troubleshooting/#sim4life-setup-issues","title":"Sim4life setup issues","text":""},{"location":"troubleshooting/#sim4life-not-found-or-python-path-error","title":"Sim4life not found or python path error","text":"<ul> <li>Symptom: \"iSolve.exe not found\" or import errors for s4l_v1.</li> <li>Cause: Sim4Life Python not in PATH or wrong Python interpreter being used.</li> <li>Solution:</li> </ul> <p>For PyPI installs: Use Sim4Life Python interpreter directly:   1. Use the Python executable from Sim4Life installation (e.g., <code>C:\\Program Files\\Sim4Life_8.2.0.16876\\Python\\python.exe</code>)   2. Or create a virtual environment using Sim4Life Python   3. Verify: <code>python -c \"import s4l_v1; print('OK')\"</code> - should print \"OK\"</p> <p>For editable installs: Set up Sim4Life Python in PATH:   1. Locate Sim4Life installation (default: C:\\Program Files\\Sim4Life_8.2.0)   2. Edit <code>.bashrc</code> in repository root with your path:         <pre><code>export PATH=\"/path/to/Sim4Life/Python:$PATH\"\n</code></pre>   3. Source: <code>source .bashrc</code>   4. Verify: <code>python -c \"import s4l_v1; print('OK')\"</code> - should print \"OK\"</p>"},{"location":"troubleshooting/#linuxcloud-execution-environment","title":"Linux/Cloud execution environment","text":"<ul> <li>Symptom: Sim4Life interpreter check fails in AWS/Linux environments.</li> <li>Cause: Platform detection not recognizing cloud execution environment.</li> <li>Solution:</li> <li>GOLIAT automatically detects AWS/Linux environments and bypasses Windows-specific checks.</li> <li>If issues persist, ensure you're using the Sim4Life Python interpreter provided in the cloud environment.</li> <li>The system automatically adapts file locking mechanisms for cross-platform compatibility.</li> </ul>"},{"location":"troubleshooting/#sim4life-web-sim4lifescience-limitations","title":"Sim4Life Web (sim4life.science) limitations","text":"<ul> <li>Symptom: GUI unavailable, phantom licensing issues, or iSolve.exe not found when running in Sim4Life Web environment (available at sim4life.science, built on the oSPARC platform).</li> <li>Cause: Sim4Life Web (sim4life.science) has different capabilities compared to desktop installations.</li> <li>Limitations:</li> <li>GUI: The graphical interface is not available in JupyterLab environments. Set <code>\"use_gui\": false</code> in your configuration.</li> <li>Phantom Licensing: Most phantoms require licensing through \"The Shop\". The <code>duke_posable</code> phantom is available without additional licensing. Other phantoms may require linking to a license server, which is not supported in this repository.</li> <li> <p>iSolve.exe: The solver executable is not present in the JupyterLab app environment. The solver path points to a non-existent executable.</p> </li> <li> <p>Workaround for setup-only runs:   For proof-of-concept setup-only runs in Sim4Life Web, use a configuration similar to <code>configs/far_field_sim4life_web.json</code>:</p> <pre><code>```json\n{\n  \"extends\": \"far_field_config.json\",\n  \"use_gui\": false,\n  \"execution_control\": {\n    \"do_setup\": true,\n    \"do_run\": false,\n    \"do_extract\": false\n  },\n  \"phantoms\": [\n    \"duke_posable\"\n  ]\n}\n```\n</code></pre> </li> </ul> <p>This configuration enables scene setup and project file creation without requiring solver execution or result extraction. To run simulations, use a different Sim4Life app (such as the Framework or Python runner app) or process the generated project files through other means.</p>"},{"location":"troubleshooting/#sim4life-license-or-phantom-download-fails","title":"Sim4life license or phantom download fails","text":"<ul> <li>Symptom: \"License error\" or phantom download prompt fails.</li> <li>Cause: Missing license or invalid email.</li> <li>Solution:</li> <li>Ensure Sim4Life is licensed (check by opening the S4L GUI), or when running from Sim4Life Web (sim4life.science), that you have purchased the license seats.</li> <li>Update <code>download_email</code> in <code>configs/base_config.json</code> to the email of the person acquiring Sim4Life for your org.</li> <li>Rerun study - GOLIAT retries download.</li> <li>Manual alternative: Download phantoms yourself, place in <code>data/</code>.</li> </ul>"},{"location":"troubleshooting/#phantom-download-rate-limit-error","title":"Phantom download rate limit error","text":"<ul> <li>Symptom: <code>gdown</code> package error indicating \"file has been accessed too many times\" when downloading phantoms.</li> <li>Cause: Google Drive rate limiting on frequently accessed files.</li> <li>Solution:</li> <li>Wait a few minutes and try again. The rate limit is temporary.</li> <li>Retry the download: GOLIAT will attempt to download again on the next run.</li> <li>Note: This issue will be fixed in a future release.</li> </ul>"},{"location":"troubleshooting/#project-and-file-issues","title":"Project and file issues","text":""},{"location":"troubleshooting/#lock-files-prevent-access","title":"Lock files prevent access","text":"<ul> <li>Symptom: \"File locked\" or \"Project corruption\" error.</li> <li>Cause: A previous run crashed, leaving a lock file behind. This is a hidden file with a <code>.s4l_lock</code> extension.</li> <li>Solution:</li> <li>Close all Sim4Life instances.</li> <li>Manually delete the lock file. It will be in the same directory as the <code>.smash</code> file.</li> <li>Rerun the simulation. If the issue persists, restarting your machine may be necessary.</li> </ul>"},{"location":"troubleshooting/#corrupted-project-file-smash","title":"Corrupted project file (.smash)","text":"<ul> <li>Symptom: \"HDF5 format error\" or \"Could not open project\".</li> <li>Cause: Incomplete save or disk issue.</li> <li>Solution:</li> <li>Set <code>\"do_setup\": true</code> in your configuration file. GOLIAT will automatically overwrite the corrupted file with a new one.</li> <li>Check disk space/logs for hardware issues.</li> </ul>"},{"location":"troubleshooting/#execution-issues","title":"Execution issues","text":""},{"location":"troubleshooting/#simulation-run-fails-isolveexe","title":"Simulation run fails (iSolve.exe)","text":"<ul> <li>Symptom: \"iSolve.exe failed with return code\" or no output.</li> <li>Cause: Path, kernel (Acceleware/CUDA), or input file issue.</li> <li>Solution:</li> <li>Verify iSolve path in code (goliat/simulation_runner.py).</li> <li>Try <code>\"kernel\": \"Software\"</code> in config for CPU fallback.</li> <li>Check <code>logs/*.log</code> for solver errors (e.g., grid too fine).</li> <li>Ensure <code>manual_isolve: true</code> in config.</li> </ul> <p>Blackwell GPUs (RTX 5090, B100)</p> <p>Sim4Life 9.2.1.19976 does not support aXware on Blackwell cards. Use CUDA kernel instead.</p>"},{"location":"troubleshooting/#parallel-execution-limitations","title":"Parallel execution limitations","text":"<ul> <li>Symptom: Running <code>goliat parallel</code> with multiple splits, but simulations take as long as sequential runs.</li> <li>Cause: iSolve can only run one simulation at a time on a single GPU. When multiple parallel processes try to use iSolve, they queue sequentially.</li> <li>Explanation:</li> <li>Setup and extract phases can run in parallel (CPU-based)</li> <li>Run phase (iSolve) cannot run in parallel on a single GPU machine</li> <li> <p>Multiple processes will queue for GPU access, effectively running one at a time</p> </li> <li> <p>Solution:</p> </li> <li>For true parallel run phases: Use oSPARC batch execution (<code>batch_run: true</code>), where each cloud job gets its own GPU</li> <li>For multiple local machines: Set up GOLIAT on multiple Windows PCs as described in Cloud Setup</li> <li>Accept limitation: Understand that local parallel execution only speeds up setup and extract phases, not the run phase</li> </ul> <p>When parallel execution helps: Setup and extract phases benefit from parallelization even on single-GPU machines. The run phase will still be sequential, but overall time can be reduced if setup/extract phases are significant.</p>"},{"location":"troubleshooting/#osparc-batch-submission-fails","title":"oSPARC batch submission fails","text":"<ul> <li>Symptom: \"Invalid API key\" or \"Job failed\".</li> <li>Cause: .env missing/invalid or quota exceeded.</li> <li>Solution:</li> <li>Verify <code>.env</code> in root (OSPARC_API_KEY etc.; see User Guide).</li> <li>Test keys: Run a single cloud sim first.</li> <li>Check quotas in oSPARC dashboard (max ~61 jobs).</li> <li>For \"RETRYING\": Code auto-retries 3 times; check logs/osparc_submission_logs/.</li> <li>Cancel stuck jobs: <code>python scripts/cancel_all_jobs.py --config your_config.json</code>.</li> </ul>"},{"location":"troubleshooting/#no-results-extracted","title":"No results extracted","text":"<ul> <li>Symptom: Empty JSON/PKL or \"No SAR data\".</li> <li>Cause: <code>do_extract: false</code> or simulation failed.</li> <li>Solution:</li> <li>Set <code>\"do_extract\": true</code> in config.</li> <li>Verify simulation completed and has deliverables (check for warnings in the logs)</li> <li>Rerun extraction: <code>\"do_setup\": false, \"do_run\": false, \"do_extract\": true</code>.</li> </ul>"},{"location":"troubleshooting/#configuration-issues","title":"Configuration issues","text":""},{"location":"troubleshooting/#manual-grid-size-exceeds-3-mm-limit","title":"Manual grid size exceeds 3 mm limit","text":"<ul> <li>Symptom: Error message: \"Manual grid size of X mm exceeds the 3 mm maximum. GOLIAT refuses to continue...\"</li> <li>Cause: Manual gridding configuration specifies a grid size larger than 3 mm.</li> <li>Explanation: GOLIAT enforces a 3 mm maximum for manual grid sizes, even though coarser grids (e.g., 5 mm) may be acceptable from an FDTD standpoint at low frequencies. This restriction exists because:</li> <li>Coarser grids lead to poor voxelization quality, affecting simulation accuracy</li> <li>Downstream GOLIAT features like peak SAR cube computation require adequate voxelization resolution</li> <li> <p>Testing with coarse grids can mask issues that appear later in production runs</p> </li> <li> <p>Solution:</p> </li> <li>Reduce <code>manual_fallback_max_step_mm</code> in your config to 3.0 or smaller</li> <li>If using per-frequency gridding, ensure all values in <code>global_gridding_per_frequency</code> are \u2264 3.0 mm</li> <li>The default fallback value is now 3.0 mm in base configs</li> <li>For now, you could use an Automatic Coarse (or Default at low frequencies) grid since GOLIAT does not yet support checking if the automatic grid is too coarse for its liking</li> </ul>"},{"location":"troubleshooting/#config-loading-error","title":"Config loading error","text":"<ul> <li>Symptom: \"File not found\" or \"Unknown study_type\".</li> <li>Cause: Invalid path or missing <code>study_type</code>.</li> <li>Solution:</li> <li>Use full path: <code>--config near_field_config.json</code>.</li> <li>Ensure <code>study_type</code>: \"near_field\" or \"far_field\".</li> <li>Validate your JSON syntax. For a detailed guide on the configuration options, see the Configuration Documentation.</li> </ul>"},{"location":"troubleshooting/#placement-or-antenna-not-found","title":"Placement or antenna not found","text":"<ul> <li>Symptom: \"Could not find component\" or invalid placement.</li> <li>Cause: Custom config mismatch.</li> <li>Solution:</li> <li>Use default configs first.</li> <li>For custom, match <code>placement_scenarios</code> keys exactly.</li> <li>Antenna: Ensure freq in <code>antenna_config</code> keys.</li> </ul>"},{"location":"troubleshooting/#antenna-file-not-found-fallback-behavior","title":"Antenna file not found (fallback behavior)","text":"<ul> <li>Symptom: Warning message \"Exact antenna file for X MHz not found, using Y MHz instead.\"</li> <li>Cause: No antenna CAD file exists for the exact frequency in your config.</li> <li>Behavior: GOLIAT automatically falls back to the nearest available frequency. The simulation proceeds with the closest match.</li> <li>Solution: This is usually fine for testing. For production, ensure you have the correct antenna files or accept the frequency mismatch.</li> </ul>"},{"location":"troubleshooting/#multi-sine-frequency-extraction-fails","title":"Multi-sine frequency extraction fails","text":"<ul> <li>Symptom: Warning message \"Failed to extract SAR for frequency X MHz\" with traceback in verbose logs.</li> <li>Cause: DFT extraction at a specific frequency failed, possibly due to insufficient simulation time or dispersion fitting issues.</li> <li>Solution:</li> <li>Check the verbose logs for the full traceback to identify the specific error.</li> <li>Ensure frequencies are widely spaced (&gt; 200 MHz apart) for optimal multi-sine performance.</li> <li>Increase <code>simulation_time_multiplier</code> if beat period requirements aren't being met.</li> <li>Other frequencies in the group may still extract successfully - check results.</li> </ul>"},{"location":"troubleshooting/#sapd-extraction-fails-or-returns-no-data","title":"SAPD extraction fails or returns no data","text":"<ul> <li>Symptom: Warning \"No skin entities found for SAPD extraction\" or \"Could not extract peak SAPD value.\"</li> <li>Cause: Missing skin entity configuration or Sim4Life API compatibility issues.</li> <li>Solution:</li> <li>Ensure <code>skin_group</code> is defined in <code>material_name_mapping.json</code> under <code>_tissue_groups</code> for your phantom.</li> <li>Check that skin entities (e.g., \"Skin\", \"Ear_skin\") exist in the model.</li> <li>Review verbose logs for detailed error messages.</li> <li>SAPD requires the peak SAR location to be computed first - ensure SAR extraction succeeds.</li> </ul>"},{"location":"troubleshooting/#gui-and-logging-issues","title":"GUI and logging issues","text":""},{"location":"troubleshooting/#gui-freezes-or-no-progress","title":"GUI freezes or no progress","text":"<ul> <li>Symptom: Window unresponsive.</li> <li>Cause: Multiprocessing issue or long computation.</li> <li>Solution:</li> <li>Run headless: Set <code>\"use_gui\": false</code> in your config and run <code>goliat study your_config.json</code>.</li> <li>Check <code>logs/*.progress.log</code> for updates.</li> <li>Reduce grid size for faster tests.</li> </ul>"},{"location":"troubleshooting/#disk-space-issues","title":"Disk space issues","text":""},{"location":"troubleshooting/#running-out-of-disk-space","title":"Running out of disk space","text":"<ul> <li>Symptom: \"No space left on device\" or simulation failures.</li> <li>Cause: Large simulation output files accumulating.</li> <li>Solution:</li> <li> <p>Enable automatic cleanup for serial workflows:</p> <pre><code>```json\n\"execution_control\": {\n  \"auto_cleanup_previous_results\": [\"output\"]\n}\n```\n</code></pre> </li> <li> <p>Manually delete old <code>*_Output.h5</code>, <code>*_Input.h5</code> files from <code>results/</code> directories.</p> </li> <li>Archive completed studies to external storage.</li> <li>See Configuration Guide for cleanup options.</li> </ul>"},{"location":"troubleshooting/#general-tips","title":"General tips","text":"<ul> <li>Always check <code>logs/</code> and console for errors.</li> <li>Rerun phases individually using <code>execution_control</code>.</li> <li>For cloud: Monitor oSPARC dashboard for job details.</li> <li>For disk space: Use <code>auto_cleanup_previous_results</code> in serial workflows.</li> <li>Still stuck? Open GitHub Issue with log snippet.</li> </ul> <p>See User Guide for workflows. For a complete reference of all available features, see the Full List of Features.</p>"},{"location":"GPU_speeds/fdtd_measurements/","title":"FDTD Performance Measurements","text":"<p>Personal measurements from TensorDock GPU rentals</p>"},{"location":"GPU_speeds/fdtd_measurements/#simulation-configurations","title":"Simulation Configurations","text":""},{"location":"GPU_speeds/fdtd_measurements/#phantoms","title":"Phantoms","text":"<ul> <li>Thelonious: Smaller phantom</li> <li>Eartha: Larger phantom</li> </ul>"},{"location":"GPU_speeds/fdtd_measurements/#simulation-regions","title":"Simulation Regions","text":"<ul> <li>by cheek: Phone near cheek (smaller bounding box)</li> <li>by belly: Phone near belly (medium bounding box)  </li> <li>front of eyes: Phone in front of eyes (different bounding box)</li> </ul>"},{"location":"GPU_speeds/fdtd_measurements/#frequencygrid-relationship","title":"Frequency/Grid Relationship","text":"<p>From <code>configs/far_field_FR3_barebones.json</code>: | Frequency (MHz) | Cell Size (mm) | Notes | |-----------------|----------------|-------| | 7,000 | 0.6 | | | 9,000 | 0.5 | | | 11,000 | 0.5 | | | 13,000 | 0.45 | | | 15,000 | 0.4 | ~2 BCells grid |</p>"},{"location":"GPU_speeds/fdtd_measurements/#main-measurements-table","title":"Main Measurements Table","text":"GPU Cell Size (mm) Phantom MCells/s VRAM Used (GB) VRAM Max (GB) Price ($/hr) RTX 4000 2.5 Thelonious 3,000 6 16 $0.32 RTX 4090 1.4 Thelonious 6,700 15 24 $0.50 RTX 4090 1.0 Thelonious 8,356 17 24 $0.50 RTX 6000 Ada 2.5 Eartha 4,367 10 48 $0.50 RTX 6000 Ada 1.4 Eartha 5,319 14 48 $0.50 L40S 1.0 Eartha 5,000 26 46 $0.75 <p>Note: Grid sizes vary by simulation region (cheek: 420M, 750M noted)</p>"},{"location":"GPU_speeds/fdtd_measurements/#multi-gpu-measurements","title":"Multi-GPU Measurements","text":"# GPUs GPU Config MCells/s VRAM Used (GB) VRAM Max (GB) Price ($/hr) Notes 5 H100 by belly, 1mm, Eartha 16,000 26 82 $2.00 Needs env var in Windows+bash, ECC off! 2 A100 by cheek 8,500 20 80 $1.00"},{"location":"GPU_speeds/fdtd_measurements/#measurements-single-gpu-comparison","title":"Measurements Single GPU Comparison","text":"# GPUs GPU Cell Size (mm) Phantom MCells/s 0 RTX 4090 2.5 Thelonious 7,000 1 A100 1.5 Thelonious 9,200 2 H100 1.3 Thelonious 18,000 3 RTX 4090 2.5 Eartha 7,000 4 A100 1.5 Eartha - 5 H100 1.3 Eartha -"},{"location":"GPU_speeds/fdtd_measurements/#key-observations","title":"Key Observations","text":""},{"location":"GPU_speeds/fdtd_measurements/#multi-gpu-scaling","title":"Multi-GPU Scaling","text":"<ul> <li>6\u00d7 H100 on 15 GHz (0.4mm, ~2 BCells): ~49k MCells/s</li> <li>This is only ~\u00bd of perfect 6\u00d7 parallelism (would expect ~108k MCells/s if linear)</li> <li>Communication overhead becomes significant at this scale</li> </ul>"},{"location":"GPU_speeds/fdtd_measurements/#vram-limitations","title":"VRAM Limitations","text":"<ul> <li>4\u00d7 RTX 4090 (24GB each = 96GB total): Not enough memory for 15 GHz/0.4mm simulation</li> <li>3\u00d7 RTX 4090: Speed increase 6K\u219213K MCells/s, but not at full utilization often</li> <li>RTX 4090 memory: Tops out around Thelonious at ~10 GHz</li> </ul>"},{"location":"GPU_speeds/fdtd_measurements/#grid-size-scaling-cubic","title":"Grid Size Scaling (Cubic!)","text":"<p>Cell size reduction scales cubically: <pre><code>2.5mm \u2192 1.0mm = 2.5\u00b3 = 15.6\u00d7 more cells\n2.5mm \u2192 0.4mm = 6.25\u00b3 = 244\u00d7 more cells!\n</code></pre> Note that the CFL condition adds another scaling OOM on the number of timesteps.</p>"},{"location":"GPU_speeds/fdtd_measurements/#gpu-specs-reference","title":"GPU Specs Reference","text":"GPU Memory BW (GB/s) VRAM Price ($/hr) RTX 4000 ~416 16GB $0.32 RTX 4090 1,008 24GB $0.33 RTX 6000 Ada 960 48GB $0.70 L40S 864 48GB $0.65 A100 80GB 2,039 80GB $0.75 H100 3,350 80GB ~$2.00"},{"location":"GPU_speeds/tensordock_gpus/","title":"TensorDock GPU Availability","text":"<p>Last updated: January 2026</p>"},{"location":"GPU_speeds/tensordock_gpus/#enterprise-gpus","title":"Enterprise GPUs","text":"GPU VRAM Type Available Price ($/hr) A100 80GB SXM4 1 unit $0.850 A100 80GB PCIe 2 units $0.750 L40S 48GB PCIe 2 units $0.650 A40 48GB PCIe 1 unit $0.400 Tesla V100 32GB SXM3 15 units $0.290 Tesla V100 16GB SXM2 8 units $0.190"},{"location":"GPU_speeds/tensordock_gpus/#workstation-rtx-gpus","title":"Workstation RTX GPUs","text":"GPU VRAM Type Available Price ($/hr) RTX 6000 Ada 48GB PCIe 6 units $0.700 RTX 5000 Ada 32GB PCIe 1 unit $0.550 RTX 5090 32GB PCIe 4 units $0.520 RTX A6000 48GB PCIe 6 units $0.390 RTX 4090 24GB PCIe 6 units $0.330 RTX A4000 16GB PCIe 4 units $0.220 RTX A5000 24GB PCIe 1 unit $0.210 RTX 3090 24GB PCIe 4 units $0.200"},{"location":"GPU_speeds/tensordock_gpus/#notes","title":"Notes","text":"<ul> <li>H100: Sometimes available but not currently listed</li> <li>Prices shown are minimum rates (\"From\")</li> <li>All workstation RTX GPUs are PCIe type</li> </ul>"},{"location":"cloud/cloud_setup/","title":"Cloud GPU setup","text":"<p>Don't have a GPU or sufficient resources on your local machine? For approximately \u20ac0.17-1.80 per hour (depending on GPU model), you can rent GPU instances from cloud providers to run GOLIAT simulations. This guide walks you through setting up a cloud Windows VM with GPU support.</p>"},{"location":"cloud/cloud_setup/#overview","title":"Overview","text":"<p>This setup allows you to:</p> <ol> <li>Deploy a Windows VM with GPU support (from RTX 4090 to H100) via cloud providers</li> <li>RDP into the machine remotely</li> <li>Automatically install and configure everything needed to run GOLIAT</li> <li>Launch simulations with minimal manual intervention</li> </ol> <p>The entire setup process takes approximately 10 minutes and is fully automated once you copy the setup script to the VM.</p>"},{"location":"cloud/cloud_setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>A cloud provider account (this guide uses TensorDock as an example, but the process is similar for other providers)</li> <li>Basic familiarity with Remote Desktop Protocol (RDP)</li> <li>Access to Sim4Life installer and license (these are downloaded automatically or can be provided manually)</li> </ul>"},{"location":"cloud/cloud_setup/#step-1-deploy-a-gpu-instance","title":"Step 1: Deploy a GPU instance","text":""},{"location":"cloud/cloud_setup/#option-a-using-the-web-interface","title":"Option A: Using the web interface","text":"<ol> <li>Visit TensorDock Dashboard</li> <li>Select your GPU model (e.g., RTX 4090)</li> <li>Configure resources:</li> <li>CPU: 8+ cores recommended</li> <li>RAM: 32 GB+ recommended</li> <li>Storage: 250 GB+ recommended</li> <li>OS: Windows 10 or Windows 11</li> <li>Prefer Dedicated IP if available</li> <li>Set a secure password for the VM</li> <li>Deploy the instance</li> </ol>"},{"location":"cloud/cloud_setup/#option-b-using-the-python-script","title":"Option B: Using the Python script","text":"<p>A Python script is provided in <code>cloud_setup/deploy_windows_vm.py</code> to automate VM deployment via the TensorDock API:</p> <pre><code># Edit deploy_windows_vm.py and set your credentials:\nAPI_TOKEN = \"YOUR_TENSORDOCK_API_TOKEN\"\n# ... other configuration ...\n\n# Then run:\npython deploy_windows_vm.py\n</code></pre> <p>Note: The template script (<code>deploy_windows_vm.py</code>) contains placeholders. Copy it to <code>my_deploy_windows_vm.py</code> and fill in your actual credentials. The <code>my_*.py</code> files are gitignored.</p>"},{"location":"cloud/cloud_setup/#step-2-connect-via-rdp","title":"Step 2: Connect via RDP","text":"<p>Once your VM is deployed:</p> <ol> <li>Find the public IP address in your provider's dashboard</li> <li>Use Windows Remote Desktop Connection (or any RDP client)</li> <li>Connect using:</li> <li>IP: The public IP from the dashboard</li> <li>Username: Usually <code>Administrator</code> or <code>user</code> (check provider docs)</li> <li>Password: The password you set during deployment</li> </ol>"},{"location":"cloud/cloud_setup/#step-3-run-the-setup-script","title":"Step 3: Run the setup script","text":"<p>The <code>cloud_setup/</code> directory contains a unified setup script that handles both fresh installation and reconnection scenarios.</p>"},{"location":"cloud/cloud_setup/#what-the-script-does","title":"What the script does","text":"<p>The <code>setup.bat</code> script automatically detects whether GOLIAT has already been installed by checking if the <code>goliat/</code> folder exists in the user's home directory.</p>"},{"location":"cloud/cloud_setup/#fresh-installation-goliat-not-found","title":"Fresh installation (goliat/ not found)","text":"<p>If this is a new machine, the script runs the full setup flow:</p> <ol> <li>Checks computer name and administrator privileges</li> <li>Downloads and installs OpenVPN</li> <li>Downloads and installs Python 3.11</li> <li>Installs gdown utility for Google Drive downloads</li> <li>Downloads and installs Sim4Life</li> <li>Downloads VPN configuration files</li> <li>Connects to VPN (if required for Sim4Life license access)</li> <li>Installs Git and clones the GOLIAT repository</li> <li>Automatically configures Sim4Life license (enters license server, validates, and completes installation)</li> <li>Git Bash automatically runs initialization commands (pip install, git config, goliat init)</li> </ol>"},{"location":"cloud/cloud_setup/#reconnection-goliat-found","title":"Reconnection (goliat/ found)","text":"<p>If the setup has already been completed, the script runs the reconnection flow:</p> <ol> <li>Connects to VPN</li> <li>Opens File Explorer at the goliat/ directory</li> <li>Launches Git Bash with automatic commands:</li> <li>Sets git safe.directory</li> <li>Configures git user.email and user.name</li> <li>Runs <code>git pull</code> to fetch latest changes</li> <li>Leaves the terminal ready for use</li> </ol> <p>This means you only need one script - just run <code>setup.bat</code> every time you connect to the VM.</p>"},{"location":"cloud/cloud_setup/#running-the-script","title":"Running the script","text":"<ol> <li> <p>Copy the setup script to your VM (you can use RDP file transfer or download it). Only the <code>my_setup.bat</code> file needs to be copied - all other scripts are pulled from the git repository.</p> </li> <li> <p>Edit the script if needed (first time only):</p> </li> <li>Replace <code>YOUR_PRIVATE_GDRIVE_FOLDER_ID</code> with your Google Drive folder ID containing <code>.ovpn</code> and <code>.crt</code> files</li> <li>Replace <code>YOUR_PRIVATE_GDRIVE_FILE_ID</code> with your Sim4Life installer file ID</li> <li>Replace <code>YOUR_VPN_USERNAME</code> and <code>YOUR_VPN_PASSWORD</code> with your VPN credentials</li> <li>Replace <code>YOUR_USERNAME</code> with your GitHub username</li> <li>Replace <code>YOUR_EMAIL@example.com</code> and <code>YOUR_NAME</code> with your git credentials</li> <li> <p>Replace <code>YOUR_LICENSE_SERVER</code> with your Sim4Life license server address (e.g., <code>@myserver.domain.com</code>)</p> </li> <li> <p>Run as Administrator:</p> </li> </ol> <pre><code>Right-click setup.bat \u2192 Run as administrator\n</code></pre> <ol> <li> <p>First run: Wait ~10 minutes while the script installs everything. License configuration is automated (takes 30-60 seconds for validation). If VPN is not connected, the license step will fail with a clear error message - you can configure it manually later.</p> </li> <li> <p>Subsequent runs: The script detects the existing installation and runs the quick reconnection flow (~15 seconds).</p> </li> </ol>"},{"location":"cloud/cloud_setup/#file-structure","title":"File structure","text":"<p>The <code>cloud_setup/</code> directory contains:</p> <ul> <li><code>setup.bat</code>: Unified setup script that handles both fresh installation and reconnection (template with placeholders)</li> <li><code>my_setup.bat</code>: Personal copy with actual credentials (gitignored) - this is the only file you need to copy to the VM</li> <li><code>license_automation.py</code>: Automates Sim4Life license configuration, accepts <code>--license-server</code> argument</li> <li><code>deploy_windows_vm.py</code>: Python script for API-based VM deployment (template)</li> <li><code>my_deploy_windows_vm.py</code>: Personal deployment script with credentials (gitignored)</li> </ul> <p>The <code>my_*</code> versions contain actual credentials and are gitignored. The template versions use placeholders like <code>YOUR_VPN_USERNAME</code> and <code>YOUR_LICENSE_SERVER</code> for open source distribution.</p>"},{"location":"cloud/cloud_setup/#cost-estimation","title":"Cost estimation","text":"<p>TensorDock pricing varies by GPU model and location, ranging from approximately \u20ac0.17-1.80/hour:</p> <p>Enterprise GPUs: H100 (~\u20ac1.80/hr), A100 (~\u20ac0.78/hr), L40S (~\u20ac0.60/hr), Tesla V100 (~\u20ac0.19-0.27/hr)</p> <p>Workstation RTX GPUs: RTX PRO 6000 (~\u20ac0.91/hr), RTX 6000 ADA (~\u20ac0.64/hr), RTX 5090 (~\u20ac0.45/hr), RTX A6000 (~\u20ac0.36/hr), RTX 4090 (~\u20ac0.32/hr), RTX 3090 (~\u20ac0.18/hr)</p> <p>Notable features:</p> <ul> <li>High-memory configurations available (up to 512 GB RAM)</li> <li>Per-second billing with no minimum commitment</li> <li>Instances can be stopped when not in use to minimize costs</li> </ul> <p>Monthly estimate (assuming 730 hours): ~\u20ac15-130/month for running instances, plus storage costs when stopped.</p> <p>For current pricing and availability, consult TensorDock's dashboard directly.</p>"},{"location":"cloud/cloud_setup/#provider-comparison","title":"Provider comparison","text":"<p>Hyperscalers (GCP, Azure, AWS): Can create VM images/snapshots and duplicate them to new instances, but quota requests for GPU instances can take days or weeks to be approved. Generally higher pricing.</p> <p>Specialized GPU providers (e.g., TensorDock): No quota requests - instant GPU access. Lower pricing (typically 20-40% cheaper than hyperscalers). Image duplication feature may be available depending on provider.</p>"},{"location":"cloud/cloud_setup/#alternative-providers","title":"Alternative providers","text":"<p>While this guide focuses on TensorDock, similar setups work with AWS EC2 (G4/G5 instances with Windows Server), Google Cloud Platform (GPU-enabled Windows VMs), and Azure (NV-series VMs with Windows). The setup script may need minor modifications for different providers (e.g., different default usernames, network configurations).</p>"},{"location":"cloud/cloud_setup/#related-documentation","title":"Related documentation","text":"<ul> <li>oSPARC: Cloud batch execution via oSPARC platform (alternative to VM setup)</li> <li>Monitoring dashboard: When running studies across multiple cloud VMs, use the monitoring dashboard to track progress, view logs, and coordinate super studies across all workers</li> </ul>"},{"location":"cloud/monitoring/","title":"Monitoring dashboard","text":"<p>Dashboard: https://goliat.waves-ugent.be</p> <p>Web-based interface for monitoring GOLIAT simulation studies across multiple worker machines. Track progress, monitor worker status, and coordinate large-scale studies.</p> <p></p> <p>The main dashboard showing an overview of all workers and their status.</p>"},{"location":"cloud/monitoring/#overview","title":"Overview","text":"<p>The dashboard shows:</p> <ul> <li>Status of all worker machines in one place</li> <li>Real-time progress bars, stage information, and ETA for each worker</li> <li>Super study coordination across multiple workers</li> <li>Color-coded log messages from each worker</li> <li>GPU, CPU, and RAM information for each worker</li> <li>GUI screenshots from each worker (all tabs except Progress)</li> <li>System utilization plots (CPU, RAM, GPU, VRAM) over time</li> </ul>"},{"location":"cloud/monitoring/#features","title":"Features","text":""},{"location":"cloud/monitoring/#worker-status-monitoring","title":"Worker status monitoring","text":"<p>Each worker shows:</p> <ul> <li>Status indicator: Green (online/idle), Blue (running), Red (offline/error)</li> <li>Progress percentage: Overall completion (0-100%)</li> <li>Current stage: Simulation stage (e.g., \"Setup\", \"Run\", \"Extract\")</li> <li>Time remaining: Estimated completion time</li> <li>Warnings and errors: Count of issues encountered</li> <li>System specs: GPU model, CPU cores, RAM capacity</li> <li>Last seen: When the worker last sent a heartbeat</li> </ul> <p></p> <p>The workers page showing detailed information about each worker machine.</p>"},{"location":"cloud/monitoring/#real-time-progress-tracking","title":"Real-time progress tracking","text":"<p>The dashboard shows:</p> <ul> <li>Overall progress: Percentage completion for each worker</li> <li>Stage progress: Progress within the current simulation stage</li> <li>Master progress: Aggregated progress across all workers in a super study</li> <li>ETA: Estimated time to completion based on current progress rate</li> </ul>"},{"location":"cloud/monitoring/#live-log-streaming","title":"Live log streaming","text":"<p>Log messages stream to the dashboard in real-time with color-coded formatting:</p> <ul> <li>Green: Success messages</li> <li>Yellow: Warnings</li> <li>Red: Errors</li> <li>Cyan: Info messages</li> <li>Gray: Standard progress messages</li> </ul>"},{"location":"cloud/monitoring/#super-studies","title":"Super studies","text":"<p>Super studies split a large configuration file into multiple assignments and distribute them across workers:</p> <p></p> <p>The super studies page showing distributed studies across multiple workers.</p> <ul> <li>Automatic splitting: Config files split into N assignments</li> <li>Worker assignment: Workers claim and run available assignments automatically</li> <li>Progress aggregation: Master progress bar shows overall completion</li> <li>Assignment tracking: See which worker runs which assignment</li> </ul>"},{"location":"cloud/monitoring/#how-it-works","title":"How it works","text":""},{"location":"cloud/monitoring/#automatic-connection","title":"Automatic connection","text":"<p>When you run a GOLIAT study with web monitoring enabled, the GUI:</p> <ol> <li>Detects your machine's public IP address (or uses local IP if no public IP)</li> <li>Connects to the monitoring dashboard at <code>https://goliat.waves-ugent.be</code></li> <li>Sends periodic heartbeats every 30 seconds</li> <li>Forwards GUI messages (progress, logs, status) to the dashboard</li> </ol>"},{"location":"cloud/monitoring/#connection-status-indicator","title":"Connection status indicator","text":"<p>The GOLIAT GUI shows a connection status indicator:</p> <ul> <li>Green dot: Successfully connected to dashboard</li> <li>Red dot: Connection failed or dashboard unavailable</li> </ul> <p>The GUI continues to function normally even if the dashboard connection fails.</p>"},{"location":"cloud/monitoring/#message-forwarding","title":"Message forwarding","text":"<p>The GUI bridge forwards messages to the dashboard:</p> <ul> <li>Progress updates: Overall and stage progress percentages</li> <li>Status messages: Log messages with color coding</li> <li>System information: GPU, CPU, RAM, hostname</li> <li>GUI screenshots: All tabs captured at 1 FPS (JPEG compressed)</li> <li>System utilization: CPU, RAM, GPU, VRAM metrics</li> <li>Heartbeats: Periodic messages every 30 seconds</li> </ul> <p>Messages are throttled to prevent overwhelming the API (typically 10 messages/second). Screenshots are sent asynchronously via multipart form upload.</p>"},{"location":"cloud/monitoring/#usage","title":"Usage","text":""},{"location":"cloud/monitoring/#enabling-web-monitoring","title":"Enabling web monitoring","text":"<p>Web monitoring enables automatically when:</p> <ol> <li>The <code>requests</code> library is installed (<code>pip install requests</code>)</li> <li>A machine ID can be detected (public IP or local IP)</li> <li>The dashboard URL is accessible</li> </ol> <p>No configuration required. GOLIAT connects to the hardcoded dashboard URL automatically.</p>"},{"location":"cloud/monitoring/#viewing-worker-details","title":"Viewing worker details","text":"<p>Click \"View Details\" on any worker to see:</p> <ul> <li>Detailed progress information</li> <li>Recent log messages (last 50)</li> <li>System specifications (GPU, CPU, RAM)</li> <li>Worker metadata (IP address, hostname, machine label)</li> </ul>"},{"location":"cloud/monitoring/#creating-super-studies","title":"Creating super studies","text":"<p>Create a super study:</p> <pre><code>goliat super_study configs/near_field_config.json \\\n  --name my_study \\\n  --num-splits 8 \\\n  --description \"Distributed study across 8 workers\"\n</code></pre> <p>This splits your config into 8 assignments, uploads them to the dashboard, and displays the super study ID and dashboard URL.</p>"},{"location":"cloud/monitoring/#running-workers","title":"Running workers","text":"<p>On each worker machine:</p> <pre><code>export GOLIAT_WEBGUI_ENABLED=true\ngoliat worker 0 my_study  # Worker 0 runs assignment 0\ngoliat worker 1 my_study  # Worker 1 runs assignment 1\n# ... and so on\n</code></pre> <p>Each worker fetches its assigned config from the dashboard, claims the assignment, runs the simulation, reports progress in real-time, and marks the assignment complete when finished.</p> <p>When deploying multiple cloud VMs, the monitoring dashboard provides a centralized view of all workers. See Cloud setup for instructions on setting up cloud GPU instances.</p>"},{"location":"cloud/monitoring/#technical-details","title":"Technical details","text":""},{"location":"cloud/monitoring/#worker-identification","title":"Worker identification","text":"<p>Workers are identified by their IP address. If a worker's IP changes (e.g., VPN reconnection), it may appear as a new worker. The dashboard handles this by matching workers by hostname when IP changes, transferring running assignments to the new worker session, and marking stale workers (no heartbeat for 5+ minutes) as inactive.</p>"},{"location":"cloud/monitoring/#message-throttling","title":"Message throttling","text":"<p>To prevent API overload, messages are throttled:</p> <ul> <li>Progress updates: Up to 50 Hz (immediate for progress)</li> <li>Log messages: Batched every 300ms (up to 20 messages per batch)</li> <li>Heartbeats: Every 30 seconds</li> </ul>"},{"location":"cloud/monitoring/#offline-behavior","title":"Offline behavior","text":"<p>If the dashboard is unavailable, the GUI continues to function normally. Progress is still displayed locally, the connection status indicator shows red, and messages are silently dropped (not queued).</p>"},{"location":"cloud/monitoring/#privacy-and-security","title":"Privacy and security","text":"<p>The dashboard is publicly accessible (no authentication required). Workers are identified by IP address only. No sensitive data (passwords, API keys) is transmitted. Log messages may contain simulation details but no credentials.</p>"},{"location":"cloud/monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cloud/monitoring/#worker-not-appearing","title":"Worker not appearing","text":"<p>If your worker doesn't appear on the dashboard:</p> <ol> <li>Check connection: Look for the green/red status indicator in the GOLIAT GUI</li> <li>Verify network: Ensure the worker can reach <code>https://goliat.waves-ugent.be</code></li> <li>Check requests library: Ensure <code>pip install requests</code> has been run</li> <li>Check logs: Look for \"Web GUI bridge\" messages in verbose logs</li> </ol>"},{"location":"cloud/monitoring/#connection-status-red","title":"Connection status red","text":"<p>If the connection indicator is red, the dashboard may be temporarily unavailable, there may be network connectivity issues, a firewall may be blocking HTTPS connections, or the <code>requests</code> library may not be installed.</p> <p>The GUI continues to work normally. You just won't see updates on the web dashboard.</p>"},{"location":"cloud/monitoring/#stale-workers","title":"Stale workers","text":"<p>Workers that haven't sent a heartbeat in 5+ minutes are marked as stale. This is normal if the worker finished its study and stopped, lost network connectivity, or was shut down.</p> <p>Stale workers are automatically resolved when a new worker session starts with the same hostname.</p>"},{"location":"cloud/monitoring/#related-documentation","title":"Related documentation","text":"<ul> <li>Cloud setup: Instructions for deploying and configuring cloud GPU instances that can serve as monitoring dashboard workers</li> <li>Super Studies: Detailed guide on creating and managing super studies</li> <li>Troubleshooting: General troubleshooting guide</li> </ul>"},{"location":"cloud/osparc/","title":"oSPARC cloud execution","text":"<p>oSPARC (Open Simulation Platform for Advanced Research and Computing) is a cloud platform that provides GPU compute resources for Sim4Life simulations. GOLIAT can submit simulations to oSPARC instead of running them locally, allowing you to scale beyond local hardware limits.</p>"},{"location":"cloud/osparc/#when-to-use-osparc","title":"When to use oSPARC","text":"<p>Use oSPARC batch execution when:</p> <ul> <li>You have 50+ simulations to run</li> <li>Local hardware is insufficient (limited GPU, RAM, or time)</li> <li>You need true parallel execution (each job gets its own GPU)</li> <li>You want to offload compute costs to cloud credits</li> </ul> <p>For smaller studies (10-50 simulations), local parallel execution is usually faster and free. See parallel execution for local options.</p>"},{"location":"cloud/osparc/#how-it-works","title":"How it works","text":"<p>oSPARC batch execution uses a three-phase workflow:</p> <ol> <li>Generate input files: Run setup locally to create <code>.h5</code> solver input files</li> <li>Submit to cloud: Upload files and submit jobs to oSPARC compute nodes (oSPARC handles the run phase only)</li> <li>Download and extract: Retrieve results when jobs complete, then extract SAR data locally</li> </ol> <p>Important: oSPARC only handles the run phase. You are responsible for running setup and extraction yourself. Each simulation runs as an independent job on oSPARC. Jobs get their own GPU, so they execute in parallel (unlike local parallel execution where jobs queue for a single GPU). If you use Sim4Life Python Runner on the oSPARC cloud for setup and extraction phases, you'll need licenses for those phases in addition to your local licenses.</p>"},{"location":"cloud/osparc/#setup","title":"Setup","text":""},{"location":"cloud/osparc/#api-credentials","title":"API credentials","text":"<p>oSPARC requires API credentials stored in a <code>.env</code> file in the project root:</p> <pre><code>OSPARC_API_KEY=your_api_key_here\nOSPARC_API_SECRET=your_api_secret_here\n</code></pre> <p>Get credentials from https://api.sim4life.science. The GOLIAT EU Project has access to dedicated resources. For individual use, check pricing and quotas.</p>"},{"location":"cloud/osparc/#configuration","title":"Configuration","text":"<p>Enable batch mode in your config:</p> <pre><code>{\n  \"execution_control\": {\n    \"do_setup\": true,\n    \"only_write_input_file\": true,\n    \"do_run\": false,\n    \"do_extract\": false,\n    \"batch_run\": true\n  }\n}\n</code></pre> <p>Setup phase (<code>do_setup: true</code>, <code>only_write_input_file: true</code>): Creates <code>.h5</code> input files locally without running simulations. This is fast and doesn't require GPU.</p> <p>Batch submission (<code>batch_run: true</code>): Uploads input files and submits jobs to oSPARC. GOLIAT monitors job status and downloads results automatically.</p> <p>Extraction phase (<code>do_extract: true</code>): Processes downloaded results to extract SAR data. Run this after jobs complete.</p>"},{"location":"cloud/osparc/#workflow-example","title":"Workflow example","text":""},{"location":"cloud/osparc/#step-1-generate-input-files","title":"Step 1: Generate input files","text":"<pre><code>goliat study my_config.json\n</code></pre> <p>With <code>only_write_input_file: true</code>, this creates <code>.h5</code> files in your project directory. No GPU needed for this step.</p>"},{"location":"cloud/osparc/#step-2-submit-batch","title":"Step 2: Submit batch","text":"<pre><code>goliat study my_config.json\n</code></pre> <p>With <code>batch_run: true</code>, GOLIAT uploads all input files and submits jobs. The GUI shows job status:</p> <pre><code>--- Submitting Jobs to oSPARC in Parallel ---\n  - Submitted job 1/50: duke_700_x_pos_theta\n  - Submitted job 2/50: duke_700_x_neg_theta\n  ...\n  - Job 1/50: PENDING\n  - Job 2/50: SUCCESS (downloaded)\n  - Job 3/50: RUNNING\n</code></pre>"},{"location":"cloud/osparc/#step-3-extract-results","title":"Step 3: Extract results","text":"<p>After jobs complete, set <code>do_extract: true</code> and run:</p> <pre><code>goliat study my_config.json\n</code></pre> <p>This processes downloaded <code>.h5</code> result files and generates SAR extraction JSON/PKL files.</p>"},{"location":"cloud/osparc/#job-status","title":"Job status","text":"<p>Jobs progress through these states:</p> <ul> <li>PENDING: Queued, waiting for compute resources</li> <li>RUNNING: Executing on oSPARC GPU node</li> <li>SUCCESS: Completed, results downloaded automatically</li> <li>FAILED: Error occurred (check logs in <code>logs/osparc_submission_logs/</code>)</li> </ul> <p>Monitor jobs in the GOLIAT GUI or at https://api.sim4life.science.</p>"},{"location":"cloud/osparc/#limits-and-costs","title":"Limits and costs","text":"<p>oSPARC platform limits:</p> <ul> <li>Maximum ~61 parallel jobs per user</li> <li>Storage quotas (varies by plan)</li> <li>API rate limits (handled automatically by GOLIAT)</li> </ul> <p>Costs depend on compute time and storage. The GOLIAT EU Project has dedicated resources. For individual use, check current pricing at the oSPARC dashboard.</p>"},{"location":"cloud/osparc/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cloud/osparc/#jobs-stuck-in-pending","title":"Jobs stuck in PENDING","text":"<ul> <li>Check oSPARC dashboard for resource availability</li> <li>Verify you haven't exceeded the 61-job limit</li> <li>Wait for compute resources to free up</li> </ul>"},{"location":"cloud/osparc/#submission-failures","title":"Submission failures","text":"<ul> <li>Verify <code>.env</code> file exists with correct credentials</li> <li>Test credentials: run a single simulation first</li> <li>Check <code>logs/osparc_submission_logs/</code> for error details</li> <li>GOLIAT auto-retries failed submissions (3 attempts)</li> </ul>"},{"location":"cloud/osparc/#cancel-stuck-jobs","title":"Cancel stuck jobs","text":"<p>Cancel all running jobs for a config:</p> <pre><code>python scripts/cancel_all_jobs.py --config my_config.json\n</code></pre> <p>Cancel up to N recent jobs:</p> <pre><code>python scripts/cancel_all_jobs.py --config my_config.json --max-jobs 10\n</code></pre>"},{"location":"cloud/osparc/#comparison-with-other-methods","title":"Comparison with other methods","text":"Method Simulations GPU usage Cost Setup Local sequential 1-10 Single GPU, sequential Free None Local parallel 10-50 Single GPU, queued Free None oSPARC batch 50-500+ Multiple GPUs, parallel Paid API credentials Cloud VMs Any Multiple GPUs, parallel Paid VM setup <p>For true parallel GPU execution, use oSPARC batch or multiple cloud VMs. Local parallel execution only speeds up setup/extract phases, not the run phase.</p>"},{"location":"cloud/osparc/#related-documentation","title":"Related documentation","text":"<ul> <li>Tutorial 5: Parallel and cloud execution: Detailed workflow and examples</li> <li>Cloud setup: Setting up cloud VMs as alternative to oSPARC</li> <li>Configuration reference: All config parameters including <code>batch_run</code></li> <li>Troubleshooting: Common issues and solutions</li> </ul>"},{"location":"cloud/overview/","title":"Cloud execution overview","text":"<p>GOLIAT supports multiple execution strategies for scaling beyond local hardware. Each method has trade-offs between cost, complexity, and true parallel execution.</p>"},{"location":"cloud/overview/#execution-methods","title":"Execution methods","text":""},{"location":"cloud/overview/#local-sequential","title":"Local sequential","text":"<p>Run simulations one at a time on your local machine. Simple, free, but slow for large studies.</p>"},{"location":"cloud/overview/#local-parallel","title":"Local parallel","text":"<p>Split a study into multiple processes that run simultaneously. Setup and extract phases benefit from parallelization, but iSolve run phases queue sequentially on a single GPU. Only one iSolve instance can execute at a time per GPU.</p> <p>Limitation: True parallel iSolve execution requires multiple GPUs. Local parallel speeds up setup and extract, not the run phase.</p>"},{"location":"cloud/overview/#osparc-batch","title":"oSPARC batch","text":"<p>Submit simulations to the oSPARC cloud platform. Each job gets its own GPU, enabling true parallel execution. Requires API credentials and platform access.</p> <p>How it works: oSPARC only handles the run phase. Users are responsible for running setup and extraction locally themselves. If you use Sim4Life Python Runner on the oSPARC cloud for setup/extraction, you'll need additional licenses for those phases (beyond your local licenses).</p> <p>Limitation: ~61 concurrent job limit, costs scale with compute time.</p>"},{"location":"cloud/overview/#distributed-cloud-vms","title":"Distributed cloud VMs","text":"<p>Deploy multiple Windows VMs, each with its own GPU. Coordinate via the monitoring dashboard. Scales indefinitely, true parallel execution, centralized monitoring.</p> <p>Best for: Large studies requiring true parallel iSolve execution across many simulations.</p>"},{"location":"cloud/overview/#comparison","title":"Comparison","text":"Feature Local sequential Local parallel oSPARC batch Distributed VMs True parallel iSolve \u2717 \u2717 \u2713 \u2713 Multiple GPUs \u2717 \u2717 \u2713 \u2713 Setup cost Free Free API credentials VM deployment Run cost Free Free Per job Per hour License required Local Local Local (setup/extract), cloud (if using Python Runner) Local (per VM, can use license server) Scalability Single machine Single machine ~61 jobs Unlimited Monitoring Local GUI Local GUI oSPARC dashboard Monitoring dashboard Coordination Manual Manual Automatic Automatic (super studies) Best for 1-10 sims 10-50 sims 50-500+ sims Any scale <p>True parallel iSolve: Multiple simulations run simultaneously, each using its own GPU. Local parallel only parallelizes setup/extract phases; run phases queue sequentially on a single GPU.</p> <p>Distributed VMs provide true parallel execution, unlimited scalability, and centralized monitoring. The monitoring dashboard coordinates super studies across workers automatically. Communication is bidirectional: workers download assignment configs (split from a master config) from the dashboard, and report progress back in real-time.</p>"},{"location":"cloud/overview/#visualization","title":"Visualization","text":"<p>The following diagram illustrates the different execution architectures:</p> <p></p> <p>Key differences:</p> <ul> <li>Local sequential/parallel: Single machine, single GPU. Parallel only helps setup/extract.</li> <li>oSPARC: Cloud platform handles run phase only. Users handle setup/extract locally. If using Sim4Life Python Runner on oSPARC cloud for setup/extract, additional licenses required. Has ~61 job limit.</li> <li>Distributed VMs: Multiple machines, each with dedicated GPU. Monitoring dashboard splits master config into assignments and distributes them to workers. Workers download assignments, run simulations, and report progress back. Scales without platform limits.</li> </ul>"},{"location":"cloud/overview/#choosing-a-method","title":"Choosing a method","text":"<p>1-10 simulations: Local sequential is simplest.</p> <p>10-50 simulations: Local parallel speeds up setup/extract. Run phase remains sequential.</p> <p>50-500+ simulations: oSPARC batch if you have platform access and want managed execution.</p> <p>Any scale, true parallel: Distributed cloud VMs with monitoring dashboard. Best for large studies requiring guaranteed parallel execution without platform constraints.</p>"},{"location":"cloud/overview/#related-documentation","title":"Related documentation","text":"<ul> <li>oSPARC: Cloud batch execution via oSPARC platform</li> <li>Monitoring dashboard: Web-based coordination for distributed VMs</li> <li>Super Studies: Distributed execution across multiple workers</li> <li>Cloud setup: Deploying and configuring cloud GPU instances</li> </ul>"},{"location":"cloud/super_studies/","title":"Super Studies - Distributed Execution","text":"<p>Super Studies allow you to split a large GOLIAT configuration into multiple smaller pieces and distribute them across multiple workers.</p>"},{"location":"cloud/super_studies/#overview","title":"Overview","text":"<p>A Super Study: - Splits a config file into N assignments (similar to <code>goliat parallel</code>) - Uploads the split configs to the web dashboard - Allows workers to claim and run individual assignments - Tracks progress across all assignments</p>"},{"location":"cloud/super_studies/#usage","title":"Usage","text":""},{"location":"cloud/super_studies/#1-create-a-super-study","title":"1. Create a Super Study","text":"<p>On your control machine:</p> <pre><code># Optional: set custom dashboard URL (defaults to https://monitor.goliat.waves-ugent.be)\nexport GOLIAT_MONITORING_URL=https://your-dashboard.com\n\n# Auto splitting (phantoms \u00d7 frequencies)\ngoliat super_study configs/far_field_config.json --name my_study --num-splits 8\n\n# Split by phantom (one assignment per phantom)\ngoliat super_study configs/far_field_config.json --name phantom_study --split-by phantom\n\n# Split by direction (one assignment per incident direction, far-field only)\ngoliat super_study configs/far_field_config.json --name direction_study --split-by direction\n\n# Split by polarization (one assignment per polarization, far-field only)\ngoliat super_study configs/far_field_config.json --name pol_study --split-by polarization\n</code></pre> <p>This will: - Split the config into assignments based on the chosen strategy - Upload them to the web dashboard - Display the super study ID</p>"},{"location":"cloud/super_studies/#2-run-workers","title":"2. Run Workers","text":"<p>On each worker machine:</p> <pre><code># Optional: set custom dashboard URL (defaults to https://monitor.goliat.waves-ugent.be)\nexport GOLIAT_MONITORING_URL=https://your-dashboard.com\nexport GOLIAT_WEBGUI_ENABLED=true\n\n# Worker 0 runs assignment 0\ngoliat worker 0 my_study\n\n# Worker 1 runs assignment 1\ngoliat worker 1 my_study\n\n# ... and so on\n</code></pre> <p>Each worker will: - Fetch its assigned config from the web - Claim the assignment - Run the simulation - Report progress to the dashboard</p>"},{"location":"cloud/super_studies/#commands","title":"Commands","text":""},{"location":"cloud/super_studies/#goliat-super_study","title":"<code>goliat super_study</code>","text":"<p>Creates a super study and uploads it to the web dashboard.</p> <pre><code>goliat super_study &lt;config&gt; --name &lt;name&gt; [options]\n</code></pre> <p>Arguments: - <code>config</code>: Path to the configuration file to split - <code>--name</code>: Name for the super study (used by workers) - <code>--description</code>: Optional description - <code>--num-splits</code>: Number of assignments to create (default: 4, only used with <code>--split-by auto</code>) - <code>--split-by</code>: Dimension to split by (see below) - <code>--server-url</code>: Dashboard URL (default: from <code>GOLIAT_MONITORING_URL</code> env var, or <code>https://monitor.goliat.waves-ugent.be</code>)</p> <p>Split-by Options:</p> Option Description Assignments Created <code>auto</code> Smart split by phantoms \u00d7 frequencies/antennas (default) <code>--num-splits</code> value <code>phantom</code> One assignment per phantom Number of phantoms <code>frequency</code> One assignment per frequency Number of frequencies <code>direction</code> One assignment per incident direction (far-field only) Number of directions <code>polarization</code> One assignment per polarization (far-field only) Number of polarizations <p>Examples: <pre><code># Auto: 16 assignments split across phantoms and frequencies\ngoliat super_study configs/far_field_config.json \\\n  --name full_study_2025 \\\n  --description \"Complete 9-frequency study across 4 phantoms\" \\\n  --num-splits 16\n\n# By phantom: 4 assignments (one per phantom)\ngoliat super_study configs/far_field_config.json \\\n  --name phantom_study \\\n  --split-by phantom\n\n# By direction: 6 assignments (one per direction: x_pos, x_neg, y_pos, y_neg, z_pos, z_neg)\ngoliat super_study configs/far_field_config.json \\\n  --name direction_study \\\n  --split-by direction\n\n# By polarization: 2 assignments (theta, phi)\ngoliat super_study configs/far_field_config.json \\\n  --name pol_study \\\n  --split-by polarization\n</code></pre></p>"},{"location":"cloud/super_studies/#goliat-worker","title":"<code>goliat worker</code>","text":"<p>Runs a specific assignment from a super study.</p> <pre><code>goliat worker &lt;assignment_index&gt; &lt;super_study_name&gt; [options]\n</code></pre> <p>Arguments: - <code>assignment_index</code>: Index of the assignment to run (0-based) - <code>super_study_name</code>: Name of the super study - <code>--title</code>: GUI window title - <code>--no-cache</code>: Force re-running even if cached - <code>--server-url</code>: Dashboard URL (default: from <code>GOLIAT_MONITORING_URL</code> env var, or <code>https://monitor.goliat.waves-ugent.be</code>)</p> <p>Example: <pre><code>goliat worker 0 full_study_2025 --title \"Worker 0\"\n</code></pre></p>"},{"location":"cloud/super_studies/#splitting-strategies","title":"Splitting Strategies","text":""},{"location":"cloud/super_studies/#auto-default","title":"Auto (Default)","text":"<p>The <code>auto</code> splitting algorithm: 1. Prioritizes splitting phantoms first 2. Then splits frequencies/antennas 3. Creates a cartesian product for the final assignments</p> <p>Example: 2 phantoms \u00d7 9 frequencies with <code>--num-splits 6</code>: - Will create 2 phantom groups \u00d7 3 frequency groups = 6 assignments - Each assignment gets 1 phantom and 3 frequencies</p>"},{"location":"cloud/super_studies/#by-phantom","title":"By Phantom","text":"<p>Creates one assignment per phantom. Each assignment runs all frequencies/directions/polarizations for that phantom.</p> <p>Use case: When you have multiple machines and want each to focus on a specific phantom.</p>"},{"location":"cloud/super_studies/#by-direction-far-field-only","title":"By Direction (Far-Field Only)","text":"<p>Creates one assignment per incident direction. Each assignment runs all phantoms/frequencies/polarizations for that direction.</p> <p>Use case: Distributing the 6 orthogonal directions across workers.</p>"},{"location":"cloud/super_studies/#by-polarization-far-field-only","title":"By Polarization (Far-Field Only)","text":"<p>Creates one assignment per polarization. Each assignment runs all phantoms/frequencies/directions for that polarization.</p> <p>Use case: Running theta and phi polarizations on separate machines.</p>"},{"location":"cloud/super_studies/#api-endpoints","title":"API Endpoints","text":""},{"location":"cloud/super_studies/#create-super-study","title":"Create Super Study","text":"<pre><code>POST /api/super-studies\n{\n  \"name\": \"my_study\",\n  \"description\": \"Study description\",\n  \"baseConfig\": {...},\n  \"assignments\": [\n    {\"splitConfig\": {...}, \"status\": \"PENDING\"},\n    ...\n  ]\n}\n</code></pre>"},{"location":"cloud/super_studies/#list-super-studies","title":"List Super Studies","text":"<pre><code>GET /api/super-studies?name=my_study\n</code></pre>"},{"location":"cloud/super_studies/#get-assignments","title":"Get Assignments","text":"<pre><code>GET /api/super-studies/{id}/assignments\n</code></pre>"},{"location":"cloud/super_studies/#claim-assignment","title":"Claim Assignment","text":"<pre><code>POST /api/assignments/{id}/claim\n{\n  \"machineId\": \"192.168.1.100\"\n}\n</code></pre>"},{"location":"cloud/super_studies/#comparison-with-goliat-parallel","title":"Comparison with <code>goliat parallel</code>","text":"Feature <code>goliat parallel</code> Super Studies Splitting Local, creates files Client-side split, uploaded to server Execution All on one machine Distributed across workers Coordination Manual Automatic via web Progress Tracking Local GUIs only Centralized dashboard Worker Assignment Manual Workers claim assignments Use Case Single powerful machine Multiple machines/VMs"},{"location":"cloud/super_studies/#best-practices","title":"Best Practices","text":"<ol> <li>Set Environment Variables (optional):</li> </ol> <pre><code>export GOLIAT_MONITORING_URL=https://your-dashboard.com\nexport GOLIAT_WEBGUI_ENABLED=true\n</code></pre> <p>If <code>GOLIAT_MONITORING_URL</code> is not set, the default dashboard URL <code>https://monitor.goliat.waves-ugent.be</code> will be used.</p> <ol> <li> <p>Name Studies Clearly: Use descriptive names like <code>full_9freq_2phantoms_2025</code></p> </li> <li> <p>Choose Appropriate Splits: Match the number of splits to your available workers</p> </li> <li> <p>Monitor Progress: Check the web dashboard to see which assignments are running/completed</p> </li> <li> <p>Handle Failures: If a worker fails, another worker can claim the same assignment (implement retry logic)</p> </li> </ol>"},{"location":"cloud/super_studies/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Automatic worker assignment (workers pull next available assignment)</li> <li>Retry logic for failed assignments</li> <li>Result aggregation and analysis</li> <li>Worker pool management</li> <li>Priority queues for assignments</li> </ul>"},{"location":"developer_guide/advanced_features/","title":"Advanced features: a deeper dive","text":"<p>This section details the architecture and workflow of the key operational features of the codebase, focusing on the graphical user interface (GUI), logging, session management, and the profiling/timing system.</p>"},{"location":"developer_guide/advanced_features/#1-high-level-workflow","title":"1. High-level workflow","text":"<p>The application is designed to run scientific studies which can be time-consuming. To provide user feedback and manage complexity, the system employs a multi-process architecture.</p> <ol> <li>Main Process: A lightweight PySide6 GUI (<code>ProgressGUI</code>) is launched. This GUI is responsible for displaying progress, logs, and timing information.</li> <li>Study Process: The actual study (<code>NearFieldStudy</code> or <code>FarFieldStudy</code>) is executed in a separate process using Python's <code>multiprocessing</code> module. This prevents the GUI from freezing during intensive calculations.</li> <li>Communication: The study process communicates with the GUI process through a <code>multiprocessing.Queue</code>. It sends messages containing status updates, progress information, and timing data.</li> </ol> <p>The entry point for the study process is the <code>study_process_wrapper</code> function, which sets up a special <code>QueueGUI</code> object. This object mimics the real GUI's interface but directs all its output to the shared queue.</p> <pre><code>graph TD\n    A[Main Process: ProgressGUI] -- Spawns --&gt; B[Study Process: study_process_wrapper];\n    B -- Instantiates --&gt; Study[NearFieldStudy/FarFieldStudy];\n    Study -- Uses --&gt; QueueGUI[QueueGUI object];\n    QueueGUI -- Puts messages --&gt; C{multiprocessing.Queue};\n    C -- Polled by QTimerevery 100ms --&gt; E[QueueHandler];\n    E -- Updates GUI --&gt; A;\n    E -- Forwards messages --&gt; F[WebGUIBridge];\n    F -- HTTP POSTthrottled --&gt; G[Monitoring DashboardAPI];\n    A -- Updates UI --&gt; D[User];\n    G -- Displays status --&gt; H[Web Dashboard];\n    \n    style C fill:#FFE082\n    style E fill:#C5E1A5\n    style F fill:#BBDEFB\n    style G fill:#E1BEE7\n</code></pre>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom"},{"location":"developer_guide/advanced_features/#2-gui-and-profiling-system","title":"2. GUI and profiling system","text":"<p>The user interface, progress estimation, and timing systems are tightly integrated to provide a responsive and informative experience. The GUI architecture is modular, with specialized components handling different aspects of the interface. The core components are the <code>ProgressGUI</code> and the <code>Profiler</code>.</p>"},{"location":"developer_guide/advanced_features/#the-progressgui","title":"The <code>ProgressGUI</code>","text":"<p>The GUI runs in the main process. It uses a <code>QTimer</code> to poll a <code>multiprocessing.Queue</code> for messages sent from the study process. This design keeps the UI responsive. The GUI is responsible for two primary progress indicators:</p> <ul> <li>Overall Progress: Tracks the progress of the entire study (e.g., 5 out of 108 simulations complete).</li> <li>Stage Progress: Tracks the progress of the current major phase (<code>setup</code>, <code>run</code>, or <code>extract</code>) for the current simulation.</li> </ul> <p>The GUI is built using modular components located in <code>goliat/gui/components/</code>:</p> <ul> <li><code>StatusManager</code>: Manages status messages and log display with color-coding.</li> <li><code>DataManager</code>: Handles CSV data files for progress tracking, time series visualization, and system utilization data.</li> <li><code>TimingsTable</code>: Displays execution statistics in a table format.</li> <li><code>PieChartsManager</code>: Generates pie charts showing time breakdown by phase and subtask.</li> <li><code>ProgressAnimation</code>: Manages smooth animations for progress bars during long-running phases.</li> <li><code>TrayManager</code>: Provides system tray integration for background operation.</li> <li><code>QueueHandler</code>: Processes messages from the study process queue and forwards them to the web bridge.</li> <li><code>WebBridgeManager</code>: Manages connection to the web monitoring dashboard, forwards GUI messages, and handles screenshot capture.</li> <li><code>UtilizationManager</code>: Updates CPU, RAM, and GPU utilization displays from system monitoring data.</li> <li><code>SystemMonitor</code>: Provides system resource monitoring (CPU, RAM, GPU) via psutil and nvidia-smi.</li> <li><code>ScreenshotCapture</code>: Captures GUI tab screenshots for remote monitoring via web dashboard.</li> <li><code>UIBuilder</code>: Constructs the window layout and manages UI components.</li> </ul>"},{"location":"developer_guide/advanced_features/#plot-components","title":"Plot components","text":"<p>Plotting functionality is organized into separate classes in <code>goliat/gui/components/plots/</code>:</p> <ul> <li><code>TimeRemainingPlot</code>: Displays time remaining estimates over the course of the study.</li> <li><code>OverallProgressPlot</code>: Shows overall study progress percentage over time.</li> <li><code>SystemUtilizationPlot</code>: Time-series plots for CPU, RAM, GPU utilization, and GPU VRAM.</li> <li><code>PieChartsManager</code>: Pie charts showing time breakdown by phase and subtask.</li> </ul> <p>Each plot class manages its own matplotlib figure and canvas, updating independently based on data from the <code>DataManager</code>. Common utilities (like timezone conversion) are centralized in <code>plots/utils.py</code>.</p>"},{"location":"developer_guide/advanced_features/#the-profiler","title":"The <code>Profiler</code>","text":"<p>The <code>Profiler</code> class is the engine for all timing and estimation.</p> <ul> <li>Session-Based Timing: The profiler maintains a session-specific timing configuration file in the <code>data/</code> folder (e.g., <code>profiling_config_31-10_14-15-30_a1b2c3d4.json</code>). The filename includes a timestamp prefix followed by a unique hash. This file stores the average time taken for each major phase (<code>avg_setup_time</code>, <code>avg_run_time</code>, etc.) and for granular subtasks. The session-specific approach means each study run tracks its own timing data, allowing for cleaner session management and avoiding conflicts between concurrent runs.</li> <li>ETA Calculation: The <code>get_time_remaining</code> method provides the core ETA logic. It calculates the total estimated time for all simulations based on the current session's timing averages and subtracts the time that has already elapsed. This elapsed time is a combination of the total time for already completed simulations and the real-time duration of the current, in-progress simulation.</li> <li>Weighted Progress: The <code>Profiler</code> calculates the progress within a single simulation by using phase weights. These weights are derived from the average time of each phase in the current session, normalized to sum to 1. This makes a longer phase, like <code>run</code>, contribute more to the intra-simulation progress than a shorter one, like <code>extract</code>.</li> </ul>"},{"location":"developer_guide/advanced_features/#the-animation-system","title":"The animation system","text":"<p>For long-running phases where the underlying process provides no feedback (like <code>iSolve.exe</code>), the GUI employs a smooth animation for the Stage Progress bar.</p> <p>How it works:</p> <ol> <li> <p>Initiation: When a major phase (e.g., <code>setup</code>) begins, the <code>profile</code> context manager in the study process retrieves the estimated duration for that entire phase from the <code>Profiler</code> (e.g., <code>avg_setup_time</code>). It sends a <code>start_animation</code> message to the GUI with this duration.</p> </li> <li> <p>Animation Execution: The <code>ProgressGUI</code> receives the message. It resets the stage progress bar to 0% and starts a <code>QTimer</code> that fires every 50ms.</p> </li> <li> <p>Frame-by-Frame Update: With each tick of the timer, the <code>update_animation</code> method calculates the percentage of the estimated duration that has elapsed and updates the stage progress bar to that value. This creates a smooth animation from 0% to 100% over the expected duration of the phase.</p> </li> <li> <p>Synchronization: The <code>update_animation</code> method is also responsible for updating the Overall Progress bar. On each tick, it asks the <code>Profiler</code> for the current weighted progress of the entire study and updates the overall bar accordingly. This keeps both bars synchronized.</p> </li> <li> <p>Termination: When the actual phase completes in the study process, an <code>end_animation</code> message is sent. The GUI stops the timer and sets the stage progress bar to its final value of 100%, correcting for any deviation between the estimate and the actual time taken.</p> </li> </ol> <p>This system presents the user with a constantly updating and reasonably accurate view of the system's progress, even without direct feedback from the core simulation.</p>"},{"location":"developer_guide/advanced_features/#3-logging-logging_managerpy","title":"3. Logging (<code>logging_manager.py</code>)","text":"<p>The system uses Python's standard <code>logging</code> module, configured to provide two distinct streams of information.</p>"},{"location":"developer_guide/advanced_features/#loggers","title":"Loggers:","text":"<ol> <li><code>progress</code> logger: For high-level, user-facing messages. These are shown in the GUI and saved to <code>*.progress.log</code>.</li> <li><code>verbose</code> logger: For detailed, internal messages. These are saved to the main <code>*.log</code> file.</li> </ol>"},{"location":"developer_guide/advanced_features/#implementation-details","title":"Implementation details:","text":"<ul> <li>Log Rotation: The <code>setup_loggers</code> function checks the number of log files in the <code>logs</code> directory. If it exceeds a limit (15 pairs), it deletes the oldest pair (<code>.log</code> and <code>.progress.log</code>) to prevent the directory from growing indefinitely.</li> <li>Data File Cleanup: Similarly, the system automatically manages CSV and JSON files in the <code>data/</code> directory (progress tracking and profiling files). When more than 50 such files exist, the oldest files are automatically deleted to prevent excessive disk usage. These files follow the naming pattern <code>time_remaining_DD-MM_HH-MM-SS_hash.csv</code>, <code>overall_progress_DD-MM_HH-MM-SS_hash.csv</code>, and <code>profiling_config_DD-MM_HH-MM-SS_hash.json</code>, where the timestamp allows easy identification of when each session was run.</li> <li>Handler Configuration: The function creates file handlers and stream (console) handlers for each logger, routing messages to the right places. <code>propagate = False</code> is used to prevent messages from being handled by parent loggers, avoiding duplicate output.</li> </ul>"},{"location":"developer_guide/advanced_features/#4-configuration-configpy","title":"4. Configuration (<code>config.py</code>)","text":"<p>The <code>Config</code> class uses a powerful inheritance mechanism to avoid duplicating settings.</p> <ul> <li> <p>Inheritance: A config can \"extend\" a base config. The <code>_load_config_with_inheritance</code> method recursively loads the base config and merges it with the child config. The child's values override the parent's.</p> <p>For example, <code>near_field_config.json</code> might only specify the settings that differ from the main <code>base_config.json</code>.</p> </li> </ul>"},{"location":"developer_guide/advanced_features/#5-project-management","title":"5. Project management","text":"<ul> <li><code>project_manager.py</code>: This class is critical for reliability. The underlying <code>.smash</code> project files can become corrupted or locked. The <code>_is_valid_smash_file</code> method is a key defensive measure. It first attempts to rename the file to itself (a trick to check for file locks on Windows) and then uses <code>h5py</code> to ensure the file is a valid HDF5 container before attempting to open it in the simulation software. This prevents the application from crashing on a corrupted file.</li> </ul>"},{"location":"developer_guide/advanced_features/#6-phantom-rotation-for-by_cheek-placement","title":"6. Phantom rotation for <code>by_cheek</code> placement","text":"<p>A specialized feature for the <code>by_cheek</code> placement scenario is the ability to rotate the phantom to meet the phone, rather than the other way around. This is controlled by a specific dictionary format in the configuration and uses an automatic angle detection algorithm to ensure precise placement.</p>"},{"location":"developer_guide/advanced_features/#configuration","title":"Configuration","text":"<p>To enable this feature, the orientation in <code>placement_scenarios</code> is defined as a dictionary:</p> <pre><code>\"orientations\": {\n  \"cheek_base\": {\n    \"rotate_phantom_to_cheek\": true,\n    \"angle_offset_deg\": 0\n  }\n}\n</code></pre> <ul> <li><code>rotate_phantom_to_cheek</code>: A boolean that enables or disables the phantom rotation.</li> <li><code>angle_offset_deg</code>: An integer that specifies an additional rotation away from the cheek (0 being the default).</li> </ul>"},{"location":"developer_guide/advanced_features/#automatic-angle-detection","title":"Automatic angle detection","text":"<p>The system uses a binary search algorithm to find the exact angle at which the phantom's \"Skin\" entity touches the phone's ground plane. This is handled by the <code>_find_touching_angle</code> method in <code>goliat/setups/near_field_setup.py</code>. The search is performed between 0 and 30 degrees with a precision of 0.5 degrees.</p>"},{"location":"developer_guide/advanced_features/#workflow-integration","title":"Workflow integration","text":"<p>The phantom rotation is handled in the <code>NearFieldSetup.run_full_setup</code> method, occurring after the antenna is placed but before the final scene alignment. This keeps the phone positioned correctly relative to the un-rotated phantom, after which the phantom is rotated into the final position. When phantom rotation is enabled, the rotation instruction is removed from the antenna's orientation list to prevent the antenna from being rotated along with the phantom.</p>"},{"location":"developer_guide/advanced_features/#65-scene-alignment-for-by_cheek-placements","title":"6.5. Scene alignment for <code>by_cheek</code> placements","text":"<p>For <code>by_cheek</code> placements, GOLIAT automatically aligns the entire simulation scene with the phone's upright orientation. This optimization aligns the computational grid with the phone's orientation, which can reduce simulation time.</p>"},{"location":"developer_guide/advanced_features/#how-it-works","title":"How it works","text":"<p>The alignment process occurs after antenna placement and phantom rotation (if enabled). It identifies reference entities on the phone that define its orientation:</p> <ul> <li>For PIFA antennas: Uses <code>component1:Substrate</code> and <code>component1:Battery</code> as reference points.</li> <li>For IFA antennas: Uses <code>Ground</code> and <code>Battery</code> as reference points.</li> </ul> <p>The system calculates a transformation matrix that makes the phone upright and applies this transformation to all scene entities:</p> <ul> <li>Phantom group</li> <li>Antenna group</li> <li>Simulation bounding box</li> <li>Antenna bounding box</li> <li>Head and trunk bounding boxes</li> <li>Point sensors</li> </ul> <p>Only parent groups and bounding boxes are transformed, not individual tissue entities, to avoid double transformation. This keeps the entire scene's relative geometry correct while optimizing grid alignment.</p>"},{"location":"developer_guide/advanced_features/#configuration_1","title":"Configuration","text":"<p>No configuration is required. The alignment is automatically applied for <code>by_cheek</code> placements.</p>"},{"location":"developer_guide/advanced_features/#7-the-verify-and-resume-caching-system","title":"7. The <code>Verify and Resume</code> caching system","text":"<p>GOLIAT integrates a <code>Verify and Resume</code> feature to prevent redundant computations by caching simulation results. The system intelligently determines whether a simulation with an identical configuration has already been successfully completed, skipping re-runs and saving significant time.</p>"},{"location":"developer_guide/advanced_features/#verification-workflow","title":"Verification workflow","text":"<p>The verification logic is multi-tiered, prioritizing the integrity of the final result files (\"deliverables\") over simple metadata flags. This maintains robustness against interrupted runs or manual file deletions.</p> <ol> <li> <p>Configuration hashing: Before verification, a \"surgical\" configuration is created. This is a snapshot containing only the parameters relevant to a single, specific simulation run (e.g., one phantom, one frequency, one placement). This configuration is then serialized and hashed (SHA256), producing a unique fingerprint that represents the exact setup.</p> </li> <li> <p>Metadata and deliverable validation: The core logic resides in <code>ProjectManager.create_or_open_project</code>, which is called at the start of each simulation. It performs a sequence of checks:</p> <ul> <li>Hash comparison: The hash of the current surgical configuration is compared against the <code>config_hash</code> stored in the <code>config.json</code> metadata file within the simulation's results directory. A mismatch signifies that the configuration has changed, rendering the cached results invalid and triggering a full re-run.</li> <li><code>.smash</code> file integrity: If the hashes match, the system validates the <code>.smash</code> project file itself. This is a critical step for stability, as these files can become locked or corrupted. The validation involves checking for <code>.s4l_lock</code> files and verifying the HDF5 structure with <code>h5py</code>. A missing or corrupt <code>.smash</code> file indicates that the setup phase is incomplete.</li> <li>Deliverable verification: This is the definitive check. The system looks for the actual output files generated by the <code>run</code> and <code>extract</code> phases. It verifies their existence and that their modification timestamps are newer than the <code>setup_timestamp</code> recorded in the metadata.<ul> <li>Run phase deliverables: A valid <code>*_Output.h5</code> file.</li> <li>Extract phase deliverables: <code>sar_results.json</code>, <code>sar_stats_all_tissues.pkl</code>, and <code>sar_stats_all_tissues.html</code>.</li> </ul> </li> </ul> </li> <li> <p>Status reporting and phase skipping: The verification process returns a detailed status dictionary, such as <code>{'setup_done': True, 'run_done': True, 'extract_done': False}</code>. The study orchestrator (<code>NearFieldStudy</code> or <code>FarFieldStudy</code>) uses this status to dynamically skip phases that are already complete. For instance, if <code>run_done</code> is <code>True</code>, the <code>do_run</code> flag for that specific simulation is internally set to <code>False</code>, and the run phase is skipped.</p> </li> <li> <p>Metadata update: Upon the successful completion of the <code>run</code> and <code>extract</code> phases, the <code>BaseStudy._verify_and_update_metadata</code> method is triggered. It re-confirms that the deliverables exist on the file system and then updates the <code>run_done</code> or <code>extract_done</code> flags in the <code>config.json</code> file to <code>true</code>. This keeps the metadata accurately reflecting the state of the deliverables for future runs.</p> </li> </ol> <p>This deliverable-first approach is a key design choice. It guarantees that the system is resilient; even if the metadata file claims a phase is complete, the absence of the actual result files will correctly force the system to re-run the necessary steps.</p>"},{"location":"developer_guide/advanced_features/#overriding-the-cache","title":"Overriding the cache","text":"<p>The entire caching and verification mechanism can be bypassed using the <code>--no-cache</code> command-line flag.</p> <pre><code>goliat study my_study.json --no-cache\n</code></pre> <p>When this flag is active, GOLIAT will ignore any existing project files or metadata. It skips the verification process, deletes any existing <code>.smash</code> file for the target simulation, and executes all phases (setup, run, extract) from a clean state. This is useful for debugging configuration issues, validating code changes, or when a fresh run is explicitly required.</p> <p>The <code>--no-cache</code> flag can also be used when you need to ensure that cached results from a previous configuration are not reused, even if the current configuration appears identical.</p>"},{"location":"developer_guide/advanced_features/#8-web-monitoring-dashboard-integration","title":"8. Web monitoring dashboard integration","text":"<p>GOLIAT supports remote monitoring through a web dashboard. Monitor multiple worker machines from one interface, track progress across distributed studies, and view real-time logs and system information.</p>"},{"location":"developer_guide/advanced_features/#architecture-overview","title":"Architecture overview","text":"<p>The web monitoring system uses a bridge pattern to forward GUI messages to a remote dashboard API without interfering with local GUI operation. The architecture consists of four components:</p> <ul> <li> <p><code>QueueHandler</code>: Processes messages from the study process queue. After updating the local GUI, forwards a copy of each message to the web bridge (if enabled).</p> </li> <li> <p><code>WebBridgeManager</code>: Manages the web bridge connection lifecycle. Initializes the bridge, collects system information (GPU, CPU, RAM, hostname), and handles connection status updates.</p> </li> <li> <p><code>WebGUIBridge</code>: Core bridge component that forwards messages to the dashboard API. Uses an internal queue to decouple from the multiprocessing queue and implements message throttling to prevent API overload.</p> </li> <li> <p><code>HTTPClient</code>: Handles HTTP requests to the dashboard API endpoints (<code>/api/gui-update</code> and <code>/api/heartbeat</code>).</p> </li> </ul>"},{"location":"developer_guide/advanced_features/#message-flow","title":"Message flow","text":"<p>Messages flow from the study process to the web dashboard through this path:</p> <pre><code>sequenceDiagram\n    participant Study as Study Process\n    participant Queue as multiprocessing.Queue\n    participant Handler as QueueHandler\n    participant GUI as ProgressGUI\n    participant Bridge as WebGUIBridge\n    participant API as Dashboard API\n    participant Dashboard as Web Dashboard\n    \n    Study-&gt;&gt;Queue: Put message (status, progress, etc.)\n    Queue-&gt;&gt;Handler: Poll (every 100ms)\n    Handler-&gt;&gt;GUI: Update local UI\n    Handler-&gt;&gt;Bridge: Enqueue message copy\n    Bridge-&gt;&gt;Bridge: Throttle &amp; batch\n    Bridge-&gt;&gt;API: HTTP POST /api/gui-update\n    API-&gt;&gt;Dashboard: Update worker state\n    Bridge-&gt;&gt;Bridge: Send heartbeat (every 30s)\n    Bridge-&gt;&gt;API: HTTP POST /api/heartbeat\n</code></pre>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom"},{"location":"developer_guide/advanced_features/#message-types-and-handling","title":"Message types and handling","text":"<p>The <code>QueueHandler</code> processes several message types, each forwarded to the web bridge (with appropriate sanitization):</p> <ul> <li><code>status</code>: Log messages with color coding. Batched together (up to 20 messages per batch, sent every 300ms) for efficiency.</li> <li><code>overall_progress</code>: Overall study progress (e.g., 5 out of 108 simulations). Sent immediately with throttling (up to 50 Hz).</li> <li><code>stage_progress</code>: Progress within the current phase (setup/run/extract). Sent immediately with throttling.</li> <li><code>profiler_update</code>: ETA and timing information. The profiler object is sanitized to extract only serializable data (e.g., <code>eta_seconds</code>).</li> <li><code>finished</code>: Study completion notification.</li> <li><code>fatal_error</code>: Fatal error notification.</li> </ul>"},{"location":"developer_guide/advanced_features/#throttling-and-batching","title":"Throttling and batching","text":"<p>The <code>WebGUIBridge</code> throttles messages to prevent API overload:</p> <ul> <li>Progress updates (<code>overall_progress</code>, <code>stage_progress</code>, <code>profiler_update</code>): Sent immediately but throttled to 50 Hz (20ms minimum interval).</li> <li>Log messages (<code>status</code>): Batched together and sent every 300ms, or immediately if the batch reaches 20 messages.</li> <li>Heartbeats: Sent every 30 seconds to maintain worker registration and update connection status.</li> </ul>"},{"location":"developer_guide/advanced_features/#connection-management","title":"Connection management","text":"<p>The web bridge maintains connection state and provides feedback to the GUI:</p> <ul> <li>Connection callback: The bridge calls <code>ProgressGUI._update_web_status</code> whenever the connection status changes. Updates a visual indicator (green dot for connected, red dot for disconnected) in the GUI.</li> <li>Graceful degradation: If the dashboard is unavailable or the <code>requests</code> library is not installed, the GUI continues to function normally. Messages are silently dropped (not queued) to prevent memory buildup.</li> <li>System information: On initialization, the bridge collects and sends system information (GPU model, CPU cores, RAM capacity, hostname) with the initial heartbeat. This information is displayed on the web dashboard.</li> </ul>"},{"location":"developer_guide/advanced_features/#worker-identification","title":"Worker identification","text":"<p>Workers are identified by their IP address (or local IP if no public IP is available). The dashboard handles IP changes (e.g., VPN reconnections) by matching workers by hostname and transferring running assignments to the new worker session.</p>"},{"location":"developer_guide/advanced_features/#api-endpoints","title":"API endpoints","text":"<p>The web bridge communicates with two API endpoints:</p> <ul> <li><code>POST /api/gui-update</code>: Sends GUI state updates (progress, logs, status). Payload includes <code>machineId</code>, <code>message</code>, and <code>timestamp</code>.</li> <li><code>POST /api/heartbeat</code>: Registers or updates worker status and sends system information. Called automatically every 30 seconds.</li> </ul>"},{"location":"developer_guide/advanced_features/#initialization","title":"Initialization","text":"<p>The web bridge initializes automatically when:</p> <ul> <li>The <code>requests</code> library is installed (<code>pip install requests</code>).</li> <li>A machine ID can be detected (public IP or local IP).</li> <li>The dashboard URL is accessible (default: <code>https://goliat.waves-ugent.be</code>).</li> </ul> <p>No configuration is required. The GUI shows a connection status indicator to inform users whether web monitoring is active.</p>"},{"location":"developer_guide/advanced_features/#error-handling","title":"Error handling","text":"<p>The web bridge handles errors gracefully:</p> <ul> <li>Network errors: Connection timeouts and errors are logged but do not affect GUI operation.</li> <li>Message serialization: Non-serializable objects (like the <code>Profiler</code> instance) are sanitized before sending.</li> <li>Thread safety: HTTP requests are executed in a thread pool to avoid blocking the GUI thread.</li> </ul> <p>For more information about using the monitoring dashboard, see the Monitoring Dashboard documentation.</p>"},{"location":"developer_guide/advanced_features/#9-system-utilization-monitoring","title":"9. System utilization monitoring","text":"<p>The GUI includes real-time system resource monitoring to track CPU, RAM, GPU utilization, and GPU VRAM usage during simulations. This helps identify bottlenecks and optimize performance.</p>"},{"location":"developer_guide/advanced_features/#architecture","title":"Architecture","text":"<p>System monitoring uses two components:</p> <ul> <li><code>SystemMonitor</code>: Provides low-level system resource queries using <code>psutil</code> for CPU/RAM and <code>nvidia-smi</code> for GPU metrics. Handles missing dependencies gracefully (returns 0.0 or None if unavailable).</li> <li><code>UtilizationManager</code>: Updates GUI progress bars and labels with current utilization values. Called every second by a Qt timer.</li> </ul>"},{"location":"developer_guide/advanced_features/#metrics-tracked","title":"Metrics tracked","text":"<ul> <li>CPU utilization: Percentage (0-100) using non-blocking <code>psutil.cpu_percent()</code> calls</li> <li>RAM utilization: Used and total GB, plus percentage with/without cacheable memory</li> <li>GPU utilization: Percentage (0-100) via <code>nvidia-smi</code> queries</li> <li>GPU VRAM: Used and total GB, plus percentage utilization</li> </ul>"},{"location":"developer_guide/advanced_features/#data-collection-and-export","title":"Data collection and export","text":"<p>Utilization data is written to CSV files (<code>system_utilization_DD-MM_HH-MM-SS_hash.csv</code>) for analysis and plotting. The GUI includes a dedicated \"System Utilization\" tab with time-series plots showing all metrics over the simulation duration.</p>"},{"location":"developer_guide/advanced_features/#update-frequency","title":"Update frequency","text":"<ul> <li>Progress bars: Updated every 1 second via <code>UtilizationManager.update()</code></li> <li>CSV data: Written every 2 seconds (via <code>GraphManager</code> timer)</li> <li>Plot updates: Refreshed every 5 seconds</li> </ul> <p>The monitoring system gracefully handles missing GPU drivers or unavailable hardware, continuing to track CPU and RAM even when GPU data isn't available.</p>"},{"location":"developer_guide/advanced_features/#10-gui-screenshot-streaming","title":"10. GUI screenshot streaming","text":"<p>For remote monitoring scenarios (cloud deployments, distributed workers), GOLIAT streams GUI screenshots to the web dashboard, enabling visual monitoring of simulation progress without direct access to the worker machine.</p>"},{"location":"developer_guide/advanced_features/#architecture_1","title":"Architecture","text":"<p>Screenshot capture is handled by two components:</p> <ul> <li><code>ScreenshotCapture</code>: Captures all GUI tabs as JPEG images using Qt's <code>render()</code> method. Excludes the Progress tab (data sent separately via web bridge).</li> <li><code>WebBridgeManager</code>: Manages screenshot capture timer (1 FPS) and forwards screenshots to the web bridge.</li> </ul>"},{"location":"developer_guide/advanced_features/#capture-process","title":"Capture process","text":"<ol> <li>Timer initialization: A Qt timer fires every 1 second (1 FPS) to capture screenshots</li> <li>Tab rendering: Each visible tab is rendered to a QPixmap using <code>render()</code> without switching tabs (avoids GUI jumping)</li> <li>Compression: Screenshots are compressed to JPEG format (95% quality) to reduce bandwidth</li> <li>Asynchronous upload: Screenshots are enqueued to the web bridge and sent via HTTP POST to <code>/api/gui-screenshots</code></li> </ol>"},{"location":"developer_guide/advanced_features/#screenshot-format","title":"Screenshot format","text":"<p>Screenshots are sent as multipart/form-data with: - Each tab as a separate file field (tab name sanitized for form field names) - <code>machineId</code> included as form data - JPEG format with 95% quality for balance between quality and file size</p>"},{"location":"developer_guide/advanced_features/#error-handling_1","title":"Error handling","text":"<p>Screenshot capture failures don't affect GUI operation. Errors are logged but don't interrupt the simulation or GUI updates. If screenshot capture isn't available (missing dependencies, initialization failures), the GUI continues normally without screenshots.</p>"},{"location":"developer_guide/advanced_features/#dashboard-integration","title":"Dashboard integration","text":"<p>The web dashboard displays screenshots for each worker, allowing remote monitoring of: - Progress tab (via data, not screenshot) - System Utilization tab - Timings tab - Logs tab - Plots tab - Settings tab</p> <p>Screenshots are stored on the dashboard server and served via API endpoints (<code>/api/gui-screenshots/[workerId]/[tabName]</code>).</p> <p>For a complete reference of all features mentioned here and more, see the Full List of Features.</p>"},{"location":"developer_guide/analysis/","title":"Analysis system","text":"<p>GOLIAT's analysis system processes simulation results (SAR and SAPD metrics) and generates reports, plots, and publications. This document covers user-facing usage and internal architecture.</p>"},{"location":"developer_guide/analysis/#user-guide","title":"User guide","text":""},{"location":"developer_guide/analysis/#running-analysis","title":"Running analysis","text":"<p>The analysis command aggregates results from multiple simulations and generates visualizations:</p> <pre><code>goliat analyze --config near_field_config\n</code></pre> <p>Command options:</p> <ul> <li><code>--config &lt;config&gt;</code>: Study configuration file (default: <code>near_field_config</code>)</li> <li><code>--format &lt;pdf|png&gt;</code>: Plot output format (default: <code>pdf</code>)</li> <li><code>--analysis &lt;path&gt;</code>: Path to analysis configuration JSON (default: <code>configs/analysis.json</code>)</li> <li><code>--generate-paper</code>: Generate LaTeX paper after analysis completes</li> </ul> <p>Example:</p> <pre><code># Run analysis with PNG output\ngoliat analyze --config near_field_config --format png\n\n# Run analysis and generate LaTeX paper\ngoliat analyze --config near_field_config --generate-paper\n</code></pre>"},{"location":"developer_guide/analysis/#analysis-configuration","title":"Analysis configuration","text":"<p>The analysis configuration file (<code>configs/analysis.json</code>) controls which plots are generated. Each plot type can be enabled or disabled:</p> <pre><code>{\n  \"load_data\": true,\n  \"generate_excel\": true,\n  \"plot_average_sar_bar\": true,\n  \"plot_sar_heatmap\": true,\n  \"plot_pssar_line\": false\n}\n</code></pre> <p>Key settings:</p> <ul> <li><code>load_data</code>: If <code>false</code>, loads cached results instead of re-processing (faster for re-plotting)</li> <li><code>generate_excel</code>: If <code>true</code> (default), exports results to a formatted Excel file</li> <li>Plot flags: Set to <code>false</code> to skip specific plot types</li> </ul> <p>Available plot types:</p> <p>Near-field plots: - <code>plot_average_sar_bar</code>: Bar charts of average SAR by frequency - <code>plot_average_pssar_bar</code>: Bar charts of average psSAR10g by frequency - <code>plot_sar_line</code>: Line plots of SAR trends across frequencies - <code>plot_pssar_line</code>: Line plots of psSAR10g trends - <code>plot_sar_distribution_boxplots</code>: Boxplots showing SAR distributions - <code>plot_sar_heatmap</code>: Heatmaps of SAR by tissue and frequency - <code>plot_peak_sar_heatmap</code>: Heatmaps of peak SAR values - <code>plot_power_balance_overview</code>: Power balance visualization - <code>plot_peak_location_3d_interactive</code>: 3D interactive peak location plots - <code>plot_peak_location_2d_projections</code>: 2D projections of peak locations - <code>plot_correlation_head_vs_eye_sar</code>: Correlation scatter plots - <code>plot_tissue_group_correlation_matrix</code>: Correlation heatmaps - <code>plot_bubble_mass_vs_sar</code>: Bubble plots of mass vs SAR - <code>plot_top20_tissues_ranking</code>: Top 20 tissues ranking charts - <code>plot_power_efficiency_trends</code>: Power efficiency line plots - <code>plot_penetration_depth_ratio</code>: Penetration depth analysis - <code>plot_tissue_frequency_response</code>: Frequency response plots - <code>plot_cdf</code>: Cumulative distribution function plots - <code>identify_outliers</code>: Outlier detection and visualization</p> <p>Far-field plots: - <code>plot_whole_body_sar_bar</code>: Whole-body SAR bar charts - <code>plot_peak_sar_line</code>: Peak SAR line plots - <code>plot_far_field_distribution_boxplot</code>: Distribution boxplots</p>"},{"location":"developer_guide/analysis/#output-structure","title":"Output structure","text":"<p>Analysis generates outputs in organized directories:</p> <pre><code>plots/\n\u2514\u2500\u2500 near_field/\n    \u2514\u2500\u2500 &lt;phantom_name&gt;/\n        \u251c\u2500\u2500 average_sar_bar_*.pdf\n        \u251c\u2500\u2500 sar_heatmap_*.pdf\n        \u2514\u2500\u2500 ...\n\nresults/\n\u2514\u2500\u2500 near_field/\n    \u2514\u2500\u2500 &lt;phantom_name&gt;/\n        \u251c\u2500\u2500 normalized_results_detailed.csv\n        \u251c\u2500\u2500 normalized_results_summary.csv\n        \u2514\u2500\u2500 Final_Data_UGent.xlsx\n</code></pre> <p>Output files:</p> <ul> <li><code>Final_Data_UGent.xlsx</code>: Autosaved Excel file with multiple sheets (Data, Analysis, Specs) containing all results and metadata.</li> <li><code>normalized_results_detailed.csv</code>: Per-simulation detailed data with all metrics</li> <li><code>normalized_results_summary.csv</code>: Aggregated statistics by frequency and scenario</li> </ul> <p>Caching:</p> <p>Processed results are cached in <code>results/&lt;study_type&gt;/&lt;phantom&gt;/aggregated_results.pkl</code>. Set <code>\"load_data\": false</code> in analysis config to skip re-processing and load from cache.</p>"},{"location":"developer_guide/analysis/#paper-generation","title":"Paper generation","text":"<p>The <code>--generate-paper</code> flag creates a LaTeX document with all plots organized by section:</p> <pre><code>goliat analyze --config near_field_config --generate-paper\n</code></pre> <p>This generates <code>paper/near_field/pure_results/results.tex</code> with: - All plots organized by section and subsection - Automatic figure numbering and cross-references - Captions extracted from plot metadata files - IEEE format document structure</p> <p>Check out the auto-generated first draft paper (only results) to see an example.</p>"},{"location":"developer_guide/analysis/#developer-guide","title":"Developer guide","text":""},{"location":"developer_guide/analysis/#architecture-overview","title":"Architecture overview","text":"<p>The analysis system uses a strategy pattern to handle different study types:</p> <pre><code>graph TB\n    CLI[goliat analyze CLI]\n    Analyzer[Analyzerorchestrator]\n    \n    subgraph \"Strategy Pattern\"\n        BaseStrategy[BaseAnalysisStrategyinterface]\n        NearStrategy[NearFieldAnalysisStrategy]\n        FarStrategy[FarFieldAnalysisStrategy]\n    end\n    \n    subgraph \"Plotter Composition\"\n        Plotter[Plotterdelegator]\n        BarPlotter[BarPlotter]\n        LinePlotter[LinePlotter]\n        HeatmapPlotter[HeatmapPlotter]\n        SpatialPlotter[SpatialPlotter]\n        OtherPlotters[11 other specialized plotters]\n    end\n    \n    Results[Result FilesJSON + PKL]\n    CSV[CSV Reports]\n    Plots[Plot FilesPDF/PNG]\n    Paper[LaTeX Paper]\n    \n    CLI --&gt; Analyzer\n    Analyzer --&gt; BaseStrategy\n    BaseStrategy --&gt; NearStrategy\n    BaseStrategy --&gt; FarStrategy\n    Analyzer --&gt; Plotter\n    Plotter --&gt; BarPlotter\n    Plotter --&gt; LinePlotter\n    Plotter --&gt; HeatmapPlotter\n    Plotter --&gt; SpatialPlotter\n    Plotter --&gt; OtherPlotters\n    Results --&gt; Analyzer\n    Analyzer --&gt; CSV\n    Analyzer --&gt; Plots\n    Analyzer --&gt; Paper\n</code></pre>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom"},{"location":"developer_guide/analysis/#core-components","title":"Core components","text":""},{"location":"developer_guide/analysis/#analyzer","title":"Analyzer","text":"<p>The <code>Analyzer</code> class orchestrates the analysis pipeline:</p> <ol> <li>Initialization: Sets up strategy and plotter based on study type</li> <li>Data loading: Delegates to strategy to load and process results</li> <li>Unit conversion: Normalizes SAR values to standard units (mW/kg)</li> <li>Caching: Saves processed data for faster re-plotting</li> <li>Report export: Generates CSV files</li> <li>Plot generation: Delegates to strategy for plot creation</li> </ol> <p>Key methods:</p> <ul> <li><code>run_analysis()</code>: Main entry point, runs complete pipeline</li> <li><code>_process_single_result()</code>: Processes one simulation's result files</li> <li><code>_convert_units_and_cache()</code>: Normalizes units and caches results</li> <li><code>_export_reports()</code>: Generates CSV output files</li> </ul>"},{"location":"developer_guide/analysis/#baseanalysisstrategy","title":"BaseAnalysisStrategy","text":"<p>Abstract base class defining the analysis interface. Subclasses implement study-specific logic:</p> <p>Abstract methods:</p> <ul> <li><code>load_and_process_results()</code>: Iterates through results and processes each</li> <li><code>get_normalization_factor()</code>: Calculates SAR normalization factor</li> <li><code>extract_data()</code>: Extracts structured data from result files</li> <li><code>apply_bug_fixes()</code>: Applies study-specific data corrections</li> <li><code>generate_plots()</code>: Creates all plots for the study type</li> </ul> <p>Concrete implementations:</p> <ul> <li><code>NearFieldAnalysisStrategy</code>: Handles placement scenarios, positions, orientations</li> <li><code>FarFieldAnalysisStrategy</code>: Handles incident directions and polarizations</li> </ul>"},{"location":"developer_guide/analysis/#plotter","title":"Plotter","text":"<p>The <code>Plotter</code> class uses composition to delegate to specialized plot modules:</p> <p>Specialized plotters:</p> <ul> <li><code>BarPlotter</code>: Bar charts (average SAR, psSAR10g, whole-body SAR)</li> <li><code>LinePlotter</code>: Line plots (SAR trends, psSAR10g trends, variations)</li> <li><code>BoxplotPlotter</code>: Distribution boxplots</li> <li><code>HeatmapPlotter</code>: SAR heatmaps by tissue and frequency</li> <li><code>SpatialPlotter</code>: 3D and 2D peak location visualizations</li> <li><code>CorrelationPlotter</code>: Correlation scatter plots and matrices</li> <li><code>BubblePlotter</code>: Bubble charts (mass vs SAR)</li> <li><code>RankingPlotter</code>: Top tissues ranking charts</li> <li><code>PowerPlotter</code>: Power efficiency and absorption plots</li> <li><code>PenetrationPlotter</code>: Penetration depth analysis</li> <li><code>TissueAnalysisPlotter</code>: Tissue frequency response and mass/volume</li> <li><code>CdfPlotter</code>: Cumulative distribution functions</li> <li><code>OutliersPlotter</code>: Outlier detection and visualization</li> </ul>"},{"location":"developer_guide/analysis/#data-flow","title":"Data flow","text":"<ol> <li>Result loading: Strategy iterates through configured scenarios</li> <li>File discovery: Locates <code>sar_results.json</code> (including SAPD data if collected) and <code>sar_stats_all_tissues.pkl</code> files</li> <li>Data extraction: Strategy extracts relevant metrics per simulation</li> <li>Normalization: Applies power normalization factors</li> <li>Aggregation: Combines all simulations into DataFrames</li> <li>Unit conversion: Converts to standard units (mW/kg)</li> <li>Caching: Saves processed DataFrames to pickle files</li> <li>Report generation: Exports CSV files</li> <li>Plot generation: Strategy calls plotter methods with DataFrames</li> </ol>"},{"location":"developer_guide/analysis/#adding-new-plots","title":"Adding new plots","text":"<p>To add a new plot type:</p> <ol> <li> <p>Create specialized plotter (if needed):    <pre><code># goliat/analysis/plots/my_plot.py\nclass MyPlotter(BasePlotter):\n    def plot_my_plot(self, results_df, all_organ_results_df):\n        # Implementation\n</code></pre></p> </li> <li> <p>Register in Plotter:    <pre><code># goliat/analysis/plotter.py\nself.my_plot = MyPlotter(plots_dir, phantom_name, plot_format)\ndef plot_my_plot(self, *args, **kwargs):\n    return self.my_plot.plot_my_plot(*args, **kwargs)\n</code></pre></p> </li> <li> <p>Add to strategy:    <pre><code># In generate_plots() method\nif self.should_generate_plot(\"plot_my_plot\"):\n    self.plotter.plot_my_plot(results_df, all_organ_results_df)\n</code></pre></p> </li> <li> <p>Add to analysis config:    <pre><code>{\n  \"plot_my_plot\": true\n}\n</code></pre></p> </li> </ol>"},{"location":"developer_guide/analysis/#data-structures","title":"Data structures","text":"<p>Main results DataFrame (<code>results_df</code>): - One row per simulation scenario - Columns: <code>frequency_mhz</code>, <code>scenario_name</code>, <code>position</code>, <code>orientation</code>, SAR metrics, etc. - Used for aggregated analysis and summary plots</p> <p>Organ results DataFrame (<code>all_organ_results_df</code>): - One row per tissue per simulation - Columns: <code>frequency_mhz</code>, <code>scenario_name</code>, <code>tissue_name</code>, <code>tissue_group</code>, SAR metrics - Used for tissue-specific analysis and heatmaps</p> <p>Tissue groups: - Defined in <code>data/material_name_mapping.json</code> - Groups like \"eyes\", \"head\", \"skin\", \"genitals\" aggregate multiple tissues - Used for summary statistics and group-level plots</p>"},{"location":"developer_guide/analysis/#normalization","title":"Normalization","text":"<p>SAR values are normalized to 1W input power:</p> <pre><code>normalization_factor = target_power_w / simulated_power_w\nnormalized_sar = raw_sar * normalization_factor\n</code></pre> <p>Near-field: Uses <code>target_power_mW</code> from antenna config Far-field: Uses 1.0 (already normalized during simulation)</p>"},{"location":"developer_guide/analysis/#caching-mechanism","title":"Caching mechanism","text":"<p>Processed results are cached to avoid re-processing:</p> <ul> <li>Cache location: <code>results/&lt;study_type&gt;/&lt;phantom&gt;/aggregated_results.pkl</code></li> <li>Cache contents: Dictionary with <code>{\"summary_results\": results_df, \"organ_results\": all_organ_results_df}</code></li> <li>Cache invalidation: Manual deletion or set <code>load_data: true</code></li> </ul> <p>Usage:</p> <pre><code># Skip data loading, use cache\nanalysis_config = {\"load_data\": False}\nstrategy = NearFieldAnalysisStrategy(config, phantom_name, analysis_config)\n</code></pre>"},{"location":"developer_guide/analysis/#error-handling","title":"Error handling","text":"<p>The analysis system handles missing files gracefully:</p> <ul> <li>Missing result files: Logs warning, skips simulation</li> <li>Invalid data: Logs error, continues with available data</li> <li>Plot generation errors: Logs error, continues with other plots</li> </ul>"},{"location":"developer_guide/analysis/#performance-considerations","title":"Performance considerations","text":"<ul> <li>Caching: Use <code>load_data: false</code> for re-plotting (10-100x faster)</li> <li>Plot selection: Disable unused plots in config to save time</li> <li>DataFrame operations: Uses pandas for efficient data manipulation</li> <li>Plot generation: Parallel plot generation not implemented (sequential)</li> </ul>"},{"location":"developer_guide/analysis/#testing","title":"Testing","text":"<p>Analysis components are tested in <code>tests/test_analysis_*.py</code>:</p> <ul> <li>Strategy implementations (<code>test_analysis_strategies.py</code>)</li> <li>Analyzer class (<code>test_analysis_analyzer.py</code>)</li> <li>Base strategy interface (<code>test_analysis_base_strategy.py</code>)</li> <li>CLI integration (<code>test_cli_run_analysis.py</code>)</li> </ul> <p>Run tests:</p> <pre><code>pytest tests/test_analysis_*.py\n</code></pre>"},{"location":"developer_guide/coloring_rules/","title":"Coloring Rules for Terminal Output","text":"<p>This document outlines the rules for colorizing terminal output using the <code>colorama</code> library. The goal is to improve readability and draw the user's attention to the most critical information. All colors are defined in the <code>COLOR_MAP</code> dictionary in <code>goliat/colors.py</code> to ensure consistency and ease of maintenance.</p>"},{"location":"developer_guide/coloring_rules/#how-to-use","title":"How to use","text":"<p>To apply a color, use the <code>_log</code> method from the <code>LoggingMixin</code> and specify the <code>log_type</code>.</p> <pre><code># Example usage:\nself._log(\"This is a warning message.\", log_type='warning')\nself._log(\"File saved successfully.\", level='progress', log_type='success')\n</code></pre> <p>Important: When adding a <code>log_type</code>, do not change the existing <code>level</code> parameter (e.g., <code>level='progress'</code>). The <code>level</code> controls which log file the message goes to, while <code>log_type</code> only controls the terminal color.</p>"},{"location":"developer_guide/coloring_rules/#color-to-type-mapping","title":"Color-to-type mapping","text":"<p>This table defines the intended use for each <code>log_type</code> and its corresponding color.</p> <code>log_type</code> Color Description &amp; Use Cases Example <code>default</code> White Standard, neutral output. Used for messages that don't fit any other category. <code>Running full simulation setup...</code> <code>header</code> Bright Magenta For major section headers that announce the start of a significant phase of the study. <code>--- Starting Far-Field Study: My Study ---</code> <code>progress</code> Green High-level progress updates that indicate a specific, positive step forward in the process. <code>--- Processing Frequency 1/5: 700MHz ---</code> <code>success</code> Bright Green Indicates the successful completion of a major operation or the entire study. <code>--- Study Finished ---</code> or <code>All required packages are already installed.</code> <code>info</code> Cyan Important, non-critical information that provides context, such as file paths or key configuration settings. <code>Project path set to: D:\\...</code> or <code>Solver kernel set to: Acceleware</code> <code>highlight</code> Bright Yellow Used to draw attention to a specific value or result within a block of text, such as a key performance metric. <code>Final Balance: 99.87%</code> <code>warning</code> Yellow For non-critical issues or potential problems that the user should be aware of, but that don't stop the process. <code>WARNING: Could not extract power balance.</code> or <code>GetPower() not available, falling back to manual extraction.</code> <code>error</code> Red For recoverable errors or failures within a specific part of the process. The overall study may continue. <code>ERROR: An error occurred during placement 'by_cheek': ...</code> <code>fatal</code> Magenta For critical, non-recoverable errors that will terminate the study. <code>FATAL ERROR: Could not find simulation bounding box.</code> <code>verbose</code> Blue Detailed, low-level debugging information intended for the <code>verbose</code> log stream. Not typically for progress updates. <code>- Activating line profiler for subtask: setup_simulation</code> <p>By following these rules, we can create a more intuitive and effective user experience.</p>"},{"location":"developer_guide/configuration/","title":"GOLIAT Configuration Guide","text":"<p>GOLIAT uses a hierarchical JSON configuration system to define all aspects of a simulation study. This modular approach allows for flexibility and reproducibility. A study-specific configuration file (e.g., <code>near_field_config.json</code>) inherits settings from a <code>base_config.json</code> file, allowing you to override only the parameters you need for a specific study.</p> <p>This guide provides a reference for all available configuration parameters, their purpose, and valid values.</p>"},{"location":"developer_guide/configuration/#configuration-hierarchy","title":"Configuration hierarchy","text":"<p>The system is designed to avoid repetition by allowing configurations to \"extend\" a base file. The child's values will always override the parent's.</p> <pre><code>graph TD\n    base[base_config.jsonShared settings]\n    nf[near_field_config.jsonNear-field specifics]\n    ff[far_field_config.jsonFar-field specifics]\n    \n    base --&gt;|extends| nf\n    base --&gt;|extends| ff\n    \n    style base fill:#4CAF50\n    style nf fill:#2196F3\n    style ff fill:#2196F3\n</code></pre>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom  <p>To create a custom study, you can copy an existing configuration and modify it. For example, to create <code>my_study.json</code>:</p> <pre><code>{\n  \"extends\": \"near_field_config.json\",\n  \"phantoms\": [\"thelonious\"],\n  \"frequencies_mhz\": [900]\n}\n</code></pre>"},{"location":"developer_guide/configuration/#1-core-settings-base_configjson","title":"1. Core Settings (<code>base_config.json</code>)","text":"<p>These are the foundational settings shared across all study types.</p> Parameter Type Example Value Description <code>extends</code> string <code>\"base_config.json\"</code> (Optional) Specifies the parent configuration file to inherit from. This is typically used in study-specific configs. <code>study_type</code> string <code>\"near_field\"</code> (Required) The type of study to run. Valid options are <code>\"near_field\"</code> or <code>\"far_field\"</code>. <code>use_gui</code> boolean <code>true</code> If <code>true</code>, the graphical user interface (GUI) will be launched to monitor progress. If <code>false</code>, the study runs in headless mode, printing logs to the console. <code>phantoms</code> array <code>[\"thelonious\", \"eartha\"]</code> A list of the virtual human phantom models to be used in the study. For near-field studies, you can also include <code>\"freespace\"</code> to run a simulation of the antenna in isolation. <code>verbose</code> boolean <code>false</code> If <code>true</code>, enables detailed verbose logging to the console, in addition to the standard progress logs. <p></p>"},{"location":"developer_guide/configuration/#2-extraction-settings-extraction","title":"2. Extraction Settings (<code>extraction</code>)","text":"<p>This object controls which data is extracted from simulation results. All flags default to <code>true</code> except SAPD which defaults to <code>false</code>.</p> Parameter Type Default Description <code>extraction.sar</code> boolean <code>true</code> If <code>true</code>, extracts Specific Absorption Rate (SAR) statistics from simulation results including tissue-specific SAR, peak 10g SAR, and tissue group averages. When disabled, placeholder files are created for caching compatibility. <code>extraction.power_balance</code> boolean <code>true</code> If <code>true</code>, extracts power balance metrics (Pin, DielLoss, RadPower) to verify energy conservation. Balance should be close to 100% for accurate simulations. <code>extraction.sapd</code> boolean <code>false</code> If <code>true</code>, extracts Surface Absorbed Power Density (SAPD) from simulation results. Recommended for frequencies &gt; 6 GHz where SAPD is the relevant exposure metric. Overridden to <code>true</code> in far-field configs. <code>extraction.point_sensors</code> boolean <code>true</code> If <code>true</code>, extracts time-domain E-field data from point sensors configured via <code>simulation_parameters.number_of_point_sensors</code>. Generates plots and raw data for field dynamics analysis. <p>Example: <pre><code>{\n    \"extraction\": {\n        \"sar\": true,\n        \"power_balance\": true,\n        \"sapd\": false,\n        \"point_sensors\": true\n    }\n}\n</code></pre></p> <p>Backward Compatibility: Legacy top-level keys (<code>extract_sar</code>, <code>extract_power_balance</code>, <code>extract_sapd</code>) are still supported but deprecated. The new <code>extraction.*</code> structure takes precedence.</p> <p></p>"},{"location":"developer_guide/configuration/#3-execution-control-execution_control","title":"3. Execution Control (<code>execution_control</code>)","text":"<p>This object controls which phases of the workflow are executed. This is useful for re-running specific parts of a study, such as only extracting results from an already completed simulation.</p> Parameter Type Default Description <code>do_setup</code> boolean <code>true</code> If <code>true</code>, the simulation scene will be built (phantoms loaded, materials assigned, etc.). <code>do_run</code> boolean <code>true</code> If <code>true</code>, the simulation solver will be executed. <code>do_extract</code> boolean <code>true</code> If <code>true</code>, the results will be extracted from the simulation output and processed. <code>only_write_input_file</code> boolean <code>false</code> If <code>true</code>, the <code>run</code> phase will only generate the solver input file (<code>.h5</code>) and then stop, without actually running the simulation. This is useful for debugging the setup or for preparing files for a manual cloud submission. Note: This flag modifies the behavior of the run phase, so <code>do_run</code> must be <code>true</code> for this to have any effect. <code>batch_run</code> boolean <code>false</code> If <code>true</code>, enables the oSPARC batch submission workflow. This is an advanced feature for running many simulations in parallel on the cloud. <code>auto_cleanup_previous_results</code> array <code>[]</code> A list of file types to automatically delete after a simulation's results have been successfully extracted. This helps to preserve disk space in serial workflows. Valid values are: <code>\"output\"</code> (<code>*_Output.h5</code>), <code>\"input\"</code> (<code>*_Input.h5</code>), and <code>\"smash\"</code> (<code>*.smash</code>). Warning: This feature is incompatible with parallel or batch runs and should only be used when <code>do_setup</code>, <code>do_run</code>, and <code>do_extract</code> are all <code>true</code>. <p>The <code>do_setup</code> flag directly controls the project file (<code>.smash</code>) handling. Its behavior is summarized below:</p> <code>do_setup</code> Value File Exists? Action <code>true</code> Yes Delete and Override with a new project. <code>true</code> No Create a new project. <code>false</code> Yes Open and Use the existing project. <code>false</code> No Error and terminate the program. <p>Example: Write input file without running solver <pre><code>\"execution_control\": {\n  \"do_setup\": true,\n  \"do_run\": true,\n  \"do_extract\": false,\n  \"only_write_input_file\": true\n}\n</code></pre></p> <p>Common mistake</p> <p>Setting <code>only_write_input_file: true</code> with <code>do_run: false</code> will skip the run phase entirely. The flag only affects the behavior of the run phase, not whether it executes. You must set <code>do_run: true</code> for the input file to be written.</p> <p>Example: Extraction-only workflow <pre><code>\"execution_control\": {\n  \"do_setup\": false,\n  \"do_run\": false,\n  \"do_extract\": true\n}\n</code></pre></p> <p>Example: Aggressive Cleanup in a Serial Workflow <pre><code>\"execution_control\": {\n  \"do_setup\": true,\n  \"do_run\": true,\n  \"do_extract\": true,\n  \"auto_cleanup_previous_results\": [\"output\", \"input\"]\n}\n</code></pre></p> <p></p>"},{"location":"developer_guide/configuration/#4-simulation-parameters-simulation_parameters","title":"4. Simulation Parameters (<code>simulation_parameters</code>)","text":"<p>These settings control the core behavior of the FDTD solver.</p> Parameter Type Example Value Description <code>global_auto_termination</code> string <code>\"GlobalAutoTerminationUserDefined\"</code> The solver's termination criteria. <code>\"GlobalAutoTerminationWeak\"</code> is a common default, while <code>\"GlobalAutoTerminationUserDefined\"</code> allows for a custom convergence level. <code>convergence_level_dB</code> number <code>-15</code> The convergence threshold in decibels (dB) when using user-defined termination. The simulation stops when the energy in the system decays below this level. <code>simulation_time_multiplier</code> number <code>3.5</code> A multiplier used to determine the total simulation time. The time is calculated as the duration it takes for a wave to traverse the simulation bounding box diagonal, multiplied by this value. <code>number_of_point_sensors</code> number <code>8</code> The number of point sensors to place at the corners of the simulation bounding box. These sensors monitor the electric field over time. <code>point_source_order</code> array <code>[\"lower_left_bottom\", ...]</code> Defines the specific order and location of the point sensors at the 8 corners of the bounding box. <code>excitation_type</code> string <code>\"Harmonic\"</code> The type of excitation source. <code>\"Harmonic\"</code> is used for single-frequency simulations (standard for SAR). <code>\"Gaussian\"</code> is used for frequency-domain analysis, typically for antenna characterization or near-field detuning detection. <code>bandwidth_mhz</code> number <code>50.0</code> The bandwidth in MHz for a Gaussian excitation. Typical values are 50-150 MHz. Narrower bandwidths provide better frequency resolution but require longer simulation times. <code>target_freq_resolution_mhz</code> number <code>10.0</code> Target frequency resolution for Gaussian excitation simulations. Smaller values provide finer frequency resolution but increase simulation time. <code>gaussian_pulse_k</code> number <code>3</code> Gaussian pulse k parameter. When set to 5, uses Sim4Life's built-in Gaussian excitation. Values other than 5 use custom UserDefined waveforms. Lower k values create faster pulses. <code>bbox_padding_mm</code> number <code>50</code> (Far-Field) Padding in millimeters to add around the phantom's bounding box to define the simulation domain. <code>freespace_antenna_bbox_expansion_mm</code> array <code>[20, 20, 20]</code> (Near-Field) Padding in [x, y, z] millimeters to add around the antenna for free-space simulations. <code>keep_awake</code> boolean <code>true</code> If <code>true</code>, launches a keep-awake script when the simulation starts to prevent system sleep during long-running simulations. <code>detuning_enabled</code> boolean <code>false</code> (Near-Field) If <code>true</code>, applies calibrated frequency detuning to account for body loading effects on antenna resonance. Requires detuning values in the <code>detuning_config</code> object. <code>detuning_config</code> object <code>{\"700\": -15}</code> (Near-Field) Maps frequencies (MHz) to detuning offsets. E.g., <code>{\"700\": -15}</code> means the 700 MHz source is shifted down 15 MHz to compensate for body loading. <p>| <code>sapd_mesh_slicing_side_length_mm</code> | number | <code>100.0</code> | Side length in mm for the mesh slicing box around the peak SAR location for faster SAPD calculation. | | <code>sapd_slicing_side_length_mm</code> | number | <code>100.0</code> | Side length in mm for the H5 data slicing box around the peak SAR location to optimize extraction speed. |</p>"},{"location":"developer_guide/configuration/#overall-field-sensor-configuration-overall_field_sensor","title":"Overall Field Sensor Configuration (<code>overall_field_sensor</code>)","text":"<p>This object controls the overall field sensor that records E-field and H-field data during the simulation. By default, Sim4Life uses its built-in defaults. Configuring this explicitly allows you to control exactly which fields are recorded.</p> Parameter Type Default Description <code>overall_field_sensor.enabled</code> boolean <code>true</code> If <code>false</code>, skips explicit sensor configuration (uses Sim4Life defaults). <code>overall_field_sensor.record_e_field</code> boolean <code>true</code> If <code>true</code>, records the Electric field (E). Required for SAR extraction. <code>overall_field_sensor.record_h_field</code> boolean <code>false</code> If <code>true</code>, records the Magnetic field (H). May significantly increase output file size. <code>overall_field_sensor.recording_domain</code> string <code>\"frequency\"</code> Recording domain. Options: <code>\"frequency\"</code> (recommended for most cases), <code>\"time\"</code>, or <code>\"both\"</code>. <code>overall_field_sensor.on_the_fly_dft</code> boolean <code>true</code> If <code>true</code>, performs DFT during simulation (memory-efficient). Recommended for frequency domain. <p>Example: Record only E-field in frequency domain (default, smallest output) <pre><code>\"simulation_parameters\": {\n    \"overall_field_sensor\": {\n        \"enabled\": true,\n        \"record_e_field\": true,\n        \"record_h_field\": false,\n        \"recording_domain\": \"frequency\"\n    }\n}\n</code></pre></p> <p>Example: Record both E and H fields (needed for Poynting vector / SAPD) <pre><code>\"simulation_parameters\": {\n    \"overall_field_sensor\": {\n        \"enabled\": true,\n        \"record_e_field\": true,\n        \"record_h_field\": true,\n        \"recording_domain\": \"frequency\"\n    }\n}\n</code></pre></p> <p>Multi-sine simulations</p> <p>For multi-sine far-field simulations (e.g., <code>\"700+2450\"</code>), both E and H fields are always recorded regardless of this config. This is required for SAPD extraction with combined fields.</p> <p></p>"},{"location":"developer_guide/configuration/#5-gridding-parameters-gridding_parameters","title":"5. Gridding Parameters (<code>gridding_parameters</code>)","text":"<p>These settings define the spatial discretization of the simulation domain.</p> Parameter Type Example Value Description <code>global_gridding.grid_mode</code> string <code>\"automatic\"</code> The global gridding strategy. Can be <code>\"automatic\"</code> or <code>\"manual\"</code>. <code>global_gridding.refinement</code> string <code>\"AutoRefinementDefault\"</code> For automatic gridding, this sets the refinement level. Options: <code>\"VeryFine\"</code>, <code>\"Fine\"</code>, <code>\"Default\"</code>, <code>\"Coarse\"</code>, <code>\"VeryCoarse\"</code>. <code>global_gridding.manual_fallback_max_step_mm</code> number <code>3.0</code> For manual gridding, this is the maximum grid step size in millimeters used as a fallback. Note: GOLIAT enforces a hard limit of 3.0 mm for manual grids. Values larger than 3.0 mm will cause an error. See Troubleshooting for details. <code>global_gridding_per_frequency</code> object <code>{\"700\": 3.0}</code> (Far-Field) A mapping of frequency (in MHz) to a specific manual grid step size in millimeters. This allows for finer grids at higher frequencies. Note: All values must be \u2264 3.0 mm (GOLIAT enforces a hard limit). <code>padding.padding_mode</code> string <code>\"automatic\"</code> Defines how padding is applied around the simulation domain. Can be <code>\"automatic\"</code> or <code>\"manual\"</code>. <code>padding.manual_bottom_padding_mm</code> array <code>[0, 0, 0]</code> For manual padding, the [x, y, z] padding in millimeters at the bottom (minimum corner) of the domain. Positive values expand the domain away from the computational region (i.e., in the negative x, y, z directions). <code>padding.manual_top_padding_mm</code> array <code>[0, 0, 0]</code> For manual padding, the [x, y, z] padding in millimeters at the top (maximum corner) of the domain. Positive values expand the domain away from the computational region (i.e., in the positive x, y, z directions). <code>phantom_bbox_reduction.auto_reduce_bbox</code> boolean <code>false</code> (Far-Field) If <code>true</code>, enables automatic phantom height reduction for frequencies above <code>reference_frequency_mhz</code>. <code>phantom_bbox_reduction.reference_frequency_mhz</code> number <code>5800</code> (Far-Field) The reference frequency where full-body simulation fits in memory. For higher frequencies, height is reduced by <code>(reference/current)\u00b3</code>. <code>phantom_bbox_reduction.height_limit_per_frequency_mm</code> object <code>{}</code> (Far-Field) Manual height limits per frequency in mm (e.g., <code>{\"10000\": 400}</code>). Overrides automatic calculation. <code>phantom_bbox_reduction.use_symmetry_reduction</code> boolean <code>false</code> (Far-Field) If <code>true</code>, cuts the phantom bounding box at x=0 to exploit left-right symmetry. Reduces cell count by ~50%. Not compatible with auto-induced exposure (you'd miss half the body's skin surface). <p></p>"},{"location":"developer_guide/configuration/#6-solver-and-miscellaneous-settings","title":"6. Solver and Miscellaneous Settings","text":"Parameter Type Example Value Description <code>solver_settings.kernel</code> string <code>\"Acceleware\"</code> The solver kernel to use. <code>\"Software\"</code> (CPU), <code>\"Acceleware\"</code> (GPU, required for near-field due to SIBC support), or <code>\"CUDA\"</code> (GPU). <code>solver_settings.boundary_conditions.type</code> string <code>\"UpmlCpml\"</code> The type of Perfectly Matched Layer (PML) boundary conditions. <code>solver_settings.boundary_conditions.strength</code> string <code>\"Medium\"</code> The strength of the PML boundary conditions. Options: <code>\"Weak\"</code>, <code>\"Medium\"</code>, <code>\"Strong\"</code>. <code>manual_isolve</code> boolean <code>true</code> If <code>true</code>, runs the <code>iSolve.exe</code> solver directly. This is the recommended setting to avoid a known bug with the Ares scheduler. <code>save_retry_count</code> number <code>4</code> The number of times to retry saving a project file if Sim4Life randomly errors out. Each retry attempt logs a warning. If all attempts fail, the error is raised. <code>export_material_properties</code> boolean <code>false</code> (Advanced) If <code>true</code>, the framework will extract and save material properties from the simulation to a <code>.pkl</code> file. <code>line_profiling</code> object See below (Advanced) Enables detailed line-by-line code profiling for specific functions to debug performance. <p>Example: Line Profiling <pre><code>\"line_profiling\": {\n  \"enabled\": true,\n  \"subtasks\": {\n    \"setup_simulation\": [\"goliat.setups.base_setup.BaseSetup._finalize_setup\"]\n  }\n}\n</code></pre></p>"},{"location":"developer_guide/configuration/#7-far-field-specifics-far_field_configjson","title":"7. Far-Field Specifics (<code>far_field_config.json</code>)","text":"<p>These settings are unique to far-field (environmental exposure) studies.</p> Parameter Type Example Value Description <code>frequencies_mhz</code> array <code>[450, 700, 900]</code> An array of frequencies in MHz to simulate. Each frequency generates a separate <code>.smash</code> project file. For multi-sine excitation (multiple frequencies in one simulation), use <code>\"700+2450\"</code> format, e.g., <code>[\"700+2450\", 5800]</code>. See the technical docs for details. <code>far_field_setup.type</code> string <code>\"environmental\"</code> The far-field scenario type. Currently, only <code>\"environmental\"</code> (plane waves) is fully implemented. <code>far_field_setup.environmental.incident_directions</code> array <code>[\"x_pos\", \"y_neg\"]</code> A list of plane wave incident directions. Supported values are single-axis directions: <code>\"x_pos\"</code>, <code>\"x_neg\"</code>, <code>\"y_pos\"</code>, <code>\"y_neg\"</code>, <code>\"z_pos\"</code>, <code>\"z_neg\"</code>. Mutually exclusive with <code>spherical_tessellation</code>. <code>far_field_setup.environmental.spherical_tessellation</code> object See below Alternative to <code>incident_directions</code>. Generates arbitrary incident wave directions using either explicit angle lists or divisions. Supports two modes: Explicit lists (<code>theta_values</code>, <code>phi_values</code>) for precise control, or Divisions (<code>theta_divisions</code>, <code>phi_divisions</code>) for auto-generation. Explicit lists take precedence when both are provided. Direction names use <code>\"theta_phi\"</code> format in degrees (e.g., <code>\"90_180\"</code>). <code>far_field_setup.environmental.spherical_tessellation.theta_values</code> array <code>[90]</code> Explicit list of theta angles in degrees. Theta is the polar angle from +z axis (0\u00b0 = <code>z_pos</code>, 90\u00b0 = equator, 180\u00b0 = <code>z_neg</code>). <code>far_field_setup.environmental.spherical_tessellation.phi_values</code> array <code>[135, 165, 195, 225]</code> Explicit list of phi angles in degrees. Phi is the azimuthal angle defining wave propagation direction (phi=180\u00b0 = wave travels toward -x, coming from +x side like <code>x_neg</code>). <code>far_field_setup.environmental.spherical_tessellation.theta_divisions</code> number <code>2</code> Number of divisions for theta (0\u00b0-180\u00b0). Generates <code>theta_divisions + 1</code> values including endpoints. Ignored if <code>theta_values</code> is provided. <code>far_field_setup.environmental.spherical_tessellation.phi_divisions</code> number <code>4</code> Number of divisions for phi (0\u00b0-360\u00b0, exclusive of 360\u00b0). Ignored if <code>phi_values</code> is provided. <code>far_field_setup.environmental.polarizations</code> array <code>[\"theta\", \"phi\"]</code> A list of polarizations to simulate for each incident direction. <code>\"theta\"</code> corresponds to vertical polarization and <code>\"phi\"</code> to horizontal. <code>power_balance.input_method</code> string <code>\"bounding_box\"</code> Method for computing input power in far-field power balance. <code>\"bounding_box\"</code> uses simulation domain cross-section (default, gives ~100% balance). <code>\"phantom_cross_section\"</code> uses pre-computed phantom projected area (physically meaningful but gives &gt;100% balance). See power normalization for details."},{"location":"developer_guide/configuration/#auto-induced-exposure-auto_induced","title":"Auto-induced exposure (<code>auto_induced</code>)","text":"<p>Auto-induced exposure simulates the worst-case scenario where a MaMIMO base station focuses its beams onto a human through beamforming. After all environmental simulations complete for each (phantom, frequency) pair, GOLIAT can optionally combine the results with optimal phase weights to find the worst-case SAPD.</p> Parameter Type Default Description <code>auto_induced.enabled</code> boolean <code>false</code> If <code>true</code>, runs auto-induced analysis after environmental simulations complete for each (phantom, freq) pair. Requires all <code>_Output.h5</code> files to exist (can use files from previous runs even if <code>do_run: false</code>). <code>auto_induced.top_n</code> number <code>10</code> Number of candidate focus points to evaluate. The algorithm finds the top N candidates, combines fields for each, and reports the worst-case SAPD. <code>auto_induced.cube_size_mm</code> number <code>50</code> Side length in mm of the extraction cube around each focus point. Only fields within this cube are combined, dramatically reducing computation time and output file size. <code>auto_induced.search_metric</code> string <code>\"E_magnitude\"</code> [Legacy mode only] Metric used for worst-case focus search in skin-based mode. Options: <code>\"E_magnitude\"</code>, <code>\"E_z_magnitude\"</code>, <code>\"poynting_z\"</code>. <code>auto_induced.save_intermediate_files</code> boolean <code>false</code> If <code>true</code>, saves <code>.smash</code> project files after SAPD extraction for debugging. <code>auto_induced.use_xy_diagonal_for_sim_time</code> boolean <code>false</code> If <code>true</code>, calculates simulation time based on XY-plane diagonal only (ignoring Z). Useful when phantom height is reduced via <code>phantom_bbox_reduction</code>, since the Z-extent no longer reflects the actual simulation domain size. <code>auto_induced.search.mode</code> string <code>\"air\"</code> Search mode for focus points. <code>\"air\"</code> (recommended, physically correct) searches in air near body surface. <code>\"skin\"</code> (legacy) searches directly on skin voxels. <code>auto_induced.search.n_samples</code> number <code>10000</code> [Air mode only] Number of air points to randomly sample and score. Can be an integer (exact count) or a float &lt; 1 (fraction of valid points, e.g., <code>0.01</code> = 1%). <code>auto_induced.search.shell_size_mm</code> number <code>10.0</code> [Air mode only] Maximum distance from skin surface for a valid air focus point. Smaller values keep focus points closer to the body. <code>auto_induced.search.selection_percentile</code> number <code>95.0</code> [Air mode only] Percentile threshold for candidate selection. Only points scoring above this percentile are considered. Default <code>95.0</code> = top 5%. <code>auto_induced.search.min_candidate_distance_mm</code> number <code>50.0</code> [Air mode only] Minimum distance in mm between selected candidates. Ensures spatial diversity across the body surface. <code>auto_induced.search.random_seed</code> number/null <code>42</code> [Air mode only] Random seed for sampling reproducibility. Set to <code>null</code> for non-reproducible random sampling. <code>auto_induced.search.low_memory_mode</code> boolean/null <code>null</code> [Air mode only] Memory mode for field cache. <code>true</code> = streaming mode (reads from disk, slower but works on low-RAM machines). <code>false</code> = in-memory mode (fast but needs lots of RAM). <code>null</code> (default) = auto-detect based on available RAM. <p>Example: Enable auto-induced exposure with air-based search <pre><code>{\n    \"auto_induced\": {\n        \"enabled\": true,\n        \"top_n\": 10,\n        \"cube_size_mm\": 50,\n        \"search\": {\n            \"mode\": \"air\",\n            \"n_samples\": 10000,\n            \"shell_size_mm\": 10.0,\n            \"selection_percentile\": 95.0,\n            \"min_candidate_distance_mm\": 50.0,\n            \"random_seed\": 42,\n            \"low_memory_mode\": null\n        }\n    }\n}\n</code></pre></p> <p>Example: Legacy skin-based search (for comparison) <pre><code>{\n    \"auto_induced\": {\n        \"enabled\": true,\n        \"top_n\": 10,\n        \"cube_size_mm\": 100,\n        \"search_metric\": \"E_z_magnitude\",\n        \"search\": {\n            \"mode\": \"skin\"\n        }\n    }\n}\n</code></pre></p> <p>Important notes:</p> <ul> <li>Physical correctness: The <code>\"air\"</code> mode models how MaMIMO beamforming actually works (beam focused in air, illuminating body). The <code>\"skin\"</code> mode is legacy and physically incorrect.</li> <li>Symmetry reduction incompatibility: Do not use <code>phantom_bbox_reduction.use_symmetry_reduction: true</code> with auto-induced exposure. Symmetry reduction cuts the bounding box at x=0, keeping only one half of the body - you'd miss half the skin surface and cannot find the true worst-case focus point.</li> <li>Results location: Auto-induced results are saved to <code>results/far_field/{phantom}/{freq}MHz/auto_induced/auto_induced_summary.json</code>.</li> <li>Caching: The analysis is skipped if the summary file exists and is newer than all <code>_Output.h5</code> files.</li> <li>Performance: Air-based search with <code>n_samples=100</code> typically takes 5-10 minutes per (phantom, freq) pair on a modern CPU.</li> </ul> <p></p>"},{"location":"developer_guide/configuration/#8-near-field-specifics-near_field_configjson","title":"8. Near-Field Specifics (<code>near_field_config.json</code>)","text":"<p>These settings are unique to near-field (device exposure) studies.</p>"},{"location":"developer_guide/configuration/#antenna-configuration-antenna_config","title":"Antenna configuration (<code>antenna_config</code>)","text":"<p>This object defines all antenna-specific information, with a separate entry for each frequency.</p> Parameter Type Example Value Description <code>antenna_config.{freq}.model_type</code> string <code>\"PIFA\"</code> The type of antenna model, used to select specific setup logic. Options: <code>\"PIFA\"</code>, <code>\"IFA\"</code>. <code>antenna_config.{freq}.source_name</code> string <code>\"Lines 1\"</code> The name of the source entity within the antenna's CAD model. <code>antenna_config.{freq}.materials</code> object <code>{ \"Extrude 1\": \"Copper\", ...}</code> Maps component names in the antenna's CAD model to Sim4Life material names. <code>antenna_config.{freq}.gridding</code> object <code>{ \"automatic\": [...], \"manual\": {...} }</code> Defines gridding strategies (automatic or manual with specific step sizes) for different parts of the antenna model. <code>antenna_config.{freq}.gridding.subgridding</code> object <code>{ \"components\": [...], ...}</code> (Optional) Enables subgridding for a list of components, which overrides any manual gridding settings for those components. This is useful for finely detailed parts that require a much higher resolution than the rest of the model. See below for subgridding configuration details."},{"location":"developer_guide/configuration/#placement-scenarios-placement_scenarios","title":"Placement scenarios (<code>placement_scenarios</code>)","text":"<p>This object defines the different device placements to be simulated.</p> Parameter Type Example Value Description <code>placement_scenarios.{name}.positions</code> object <code>{ \"center\": [0,0,0], ...}</code> A set of named relative positions (as [x, y, z] offsets) for the placement scenario. <code>placement_scenarios.{name}.orientations</code> object <code>{ \"vertical\": [], ...}</code> A set of named orientations to be applied at each position. Each orientation is a list of rotation steps. See below for an alternative dictionary format for <code>by_cheek</code> phantom rotation. <code>placement_scenarios.{name}.bounding_box</code> string <code>\"default\"</code> Determines which part of the phantom to include in the simulation bounding box. Options: <code>\"default\"</code>, <code>\"head\"</code>, <code>\"trunk\"</code>, <code>\"whole_body\"</code>. The <code>\"default\"</code> option intelligently chooses \"head\" for eye/cheek placements and \"trunk\" for belly placements. <code>placement_scenarios.{name}.phantom_reference</code> string <code>\"tragus\"</code> (Optional) Specifies an anatomical reference point used for placement calculations. The reference point coordinates are defined in <code>phantom_definitions.{phantom_name}</code>. Common values: <code>\"nasion\"</code> (for <code>front_of_eyes</code>), <code>\"tragus\"</code> (for <code>by_cheek</code>), <code>\"belly_button\"</code> (for <code>by_belly</code>). If not specified, the default placement center is used. <code>placement_scenarios.{name}.antenna_reference</code> object <code>{ \"distance_from_top\": 10 }</code> (Optional) Defines antenna positioning relative to a reference point on the antenna model. <p></p> <p>Alternative orientation format for <code>by_cheek</code> phantom rotation</p> <p>For the <code>by_cheek</code> scenario, an alternative dictionary format can be used to enable automatic phantom rotation towards the phone. This is useful for precise placement based on contact.</p> <pre><code>\"orientations\": {\n  \"cheek_base\": {\n    \"rotate_phantom_to_cheek\": true,\n    \"angle_offset_deg\": 0\n  }\n}\n</code></pre> <ul> <li><code>rotate_phantom_to_cheek</code>: (boolean) If <code>true</code>, the phantom rotates on its Z-axis to touch the phone.</li> <li><code>angle_offset_deg</code>: (number) An additional angle in degrees to rotate the phantom away from the phone after contact is detected.</li> </ul> <p>Subgridding configuration</p> <p>Subgridding allows specific antenna components to use a finer grid resolution than the global grid. This is configured in the <code>antenna_config.{freq}.gridding.subgridding</code> object:</p> <pre><code>{\n  \"antenna_config\": {\n    \"700\": {\n      \"gridding\": {\n        \"subgridding\": {\n          \"components\": [\"component1:Battery\", \"component1:Patch\", \"Extrude 1\", \"component1:ShortingPin\"],\n          \"SubGridMode\": \"Box\",\n          \"SubGridLevel\": \"x9\",\n          \"AutoRefinement\": \"AutoRefinementVeryFine\"\n        }\n      }\n    }\n  }\n}\n</code></pre> <ul> <li><code>components</code>: (array of strings) List of component names to apply subgridding to. These components will use the subgrid resolution instead of the global or manual grid settings.</li> <li><code>SubGridMode</code>: (string) The subgrid mode, typically <code>\"Box\"</code>.</li> <li><code>SubGridLevel</code>: (string) The subgrid level multiplier relative to the global grid. Common values: <code>\"x9\"</code> (9x finer), <code>\"x3\"</code> (3x finer). Higher values provide finer resolution but increase computation time.</li> <li><code>AutoRefinement</code>: (string) The refinement level for subgridded components. Options: <code>\"AutoRefinementVeryFine\"</code>, <code>\"AutoRefinementFine\"</code>, <code>\"AutoRefinementDefault\"</code>.</li> </ul> <p>Subgridding overrides any manual gridding settings for the specified components. Components not listed in the <code>components</code> array use the global gridding strategy (automatic or manual) as configured.</p>"},{"location":"developer_guide/configuration/#phantom-definitions-phantom_definitions","title":"Phantom definitions (<code>phantom_definitions</code>)","text":"<p>This object contains phantom-specific settings, such as which placements to run and the separation distances.</p> Parameter Type Example Value Description <code>phantom_definitions.{name}.placements</code> object <code>{ \"do_by_cheek\": true, ...}</code> A set of booleans to enable or disable specific placement scenarios for a given phantom. The key must match a scenario name from <code>placement_scenarios</code>. <code>phantom_definitions.{name}.distance_from_cheek</code> number <code>8</code> The separation distance in millimeters for the \"by_cheek\" placement. <code>phantom_definitions.{name}.distance_from_eye</code> number <code>200</code> The separation distance in millimeters for the \"front_of_eyes\" placement. <code>phantom_definitions.{name}.distance_from_belly</code> number <code>100</code> The separation distance in millimeters for the \"by_belly\" placement. <code>phantom_definitions.{name}.lips</code> array <code>[0, 122, 31]</code> The [x, y, z] coordinates of the center of the lips, used for the 'cheek' placement calculation. <code>phantom_definitions.{name}.nasion</code> array <code>[-1, 0, 0]</code> (Optional) Relative [x, y, z] offset coordinates for the nasion landmark, used as a reference point for <code>front_of_eyes</code> placement when <code>phantom_reference: \"nasion\"</code> is specified. These coordinates are offsets from the geometrically calculated eye center (derived from eye entity bounding boxes). The coordinate system: X (inside head to right ear out), Y (out of face), Z (up head and out). <code>phantom_definitions.{name}.tragus</code> array <code>[0, 7, -5]</code> (Optional) Relative [x, y, z] offset coordinates for the tragus landmark, used as a reference point for <code>by_cheek</code> placement when <code>phantom_reference: \"tragus\"</code> is specified. These coordinates are offsets from the geometrically calculated ear center (derived from Ear_skin entity bounding box). The coordinate system: X (inside head to right ear out), Y (out of face), Z (up head and out). <code>phantom_definitions.{name}.belly_button</code> array <code>[-5, 0, -140]</code> (Optional) Relative [x, y, z] offset coordinates for the belly button landmark, used as a reference point for <code>by_belly</code> placement when <code>phantom_reference: \"belly_button\"</code> is specified. These coordinates are offsets from the geometrically calculated trunk center (derived from trunk bounding box). The coordinate system: X (inside head to right ear out), Y (out of face), Z (up head and out). <p>How reference point coordinates are derived:</p> <p>The reference point coordinates (nasion, tragus, belly_button) are relative offsets, not absolute positions. They are calculated as offsets from geometrically derived centers:</p> <ul> <li><code>nasion</code>: Offset from the center of the eye bounding box (calculated from Eye/Cornea entities)</li> <li><code>tragus</code>: Offset from the center of the ear bounding box (calculated from Ear_skin entity)</li> <li><code>belly_button</code>: Offset from the center of the trunk bounding box (calculated from Trunk_BBox entity)</li> </ul> <p>These offsets are determined through anatomical landmark identification techniques and are added to the calculated geometric centers during placement. The coordinate system is consistent across all phantoms: X-axis extends from inside the head toward the right ear, Y-axis extends outward from the face, and Z-axis extends upward along the head.</p>"},{"location":"developer_guide/configuration/#9-credentials-and-data","title":"9. Credentials and Data","text":"<p>For security and portability, certain information is handled outside the main configuration files.</p>"},{"location":"developer_guide/configuration/#osparc-credentials","title":"oSPARC Credentials","text":"<p>oSPARC API credentials should be stored in a <code>.env</code> file in the project root directory.</p> <pre><code># .env file\nOSPARC_API_KEY=your_osparc_api_key\nOSPARC_API_SECRET=your_osparc_api_secret\n</code></pre>"},{"location":"developer_guide/configuration/#phantom-downloads","title":"Phantom downloads","text":"<p>Some phantom models require an email address for download, which can also be set in the <code>.env</code> file. This should be the email associated with your institution's Sim4Life license.</p> <pre><code># .env file\nDOWNLOAD_EMAIL=your_email@example.com\n</code></pre>"},{"location":"developer_guide/configuration/#10-accessing-configuration-in-code","title":"10. Accessing Configuration in Code","text":"<p>The <code>Config</code> class supports dictionary-style access with dot-notation for nested paths:</p> <pre><code># Simple top-level access\nsim_params = config[\"simulation_parameters\"] or {}\nantenna_config = config[\"antenna_config\"] or {}\n\n# Nested path access\nexcitation_type = config[\"simulation_parameters.excitation_type\"] or \"Harmonic\"\ngridding_params = config[\"gridding_parameters\"] or {}\n\n# With fallback values\nexpansion = config[\"simulation_parameters.freespace_antenna_bbox_expansion_mm\"] or [10, 10, 10]\n</code></pre> <p>Note: The <code>or</code> operator provides a fallback when a key doesn't exist (returns <code>None</code>). This is the standard pythonic pattern.</p>"},{"location":"developer_guide/configuration/#accessing-complex-structures","title":"Accessing Complex Structures","text":"<p>For accessing nested dictionaries within config values:</p> <pre><code># Get a top-level dict, then access nested keys\nplacement_scenarios = config[\"placement_scenarios\"] or {}\nscenario = placement_scenarios.get(\"by_cheek\") if isinstance(placement_scenarios, dict) else None\n\n# Or use dot notation directly\nscenario = config[\"placement_scenarios.by_cheek\"]\n</code></pre> <p>This structure makes every aspect of a GOLIAT simulation controllable, reproducible, and easy to manage. For more workflow-oriented information, please see the User Guide. For a complete list of all GOLIAT features, see the Full List of Features.</p>"},{"location":"developer_guide/developer_guide/","title":"Developer Guide","text":"<p>This guide is for developers extending or maintaining GOLIAT. It covers the codebase structure, testing, and contribution process. GOLIAT is modular Python code interfacing with Sim4Life for EMF simulations.</p>"},{"location":"developer_guide/developer_guide/#codebase-structure","title":"Codebase structure","text":"<p>GOLIAT's architecture separates concerns:</p> <ul> <li>goliat/config.py: Loads JSON configs with inheritance (e.g., base + study-specific).</li> <li>goliat/studies/: Orchestrates workflows (NearFieldStudy, FarFieldStudy inherit from BaseStudy).</li> <li>goliat/setups/: Builds Sim4Life scenes (PhantomSetup, PlacementSetup, MaterialSetup, etc.). See Sim4Life API snippets for API patterns used.</li> <li>goliat/project_manager.py: Handles .smash files (create/open/save/close), including a \"Verify and Resume\" feature to avoid re-running simulations with unchanged configurations.</li> <li>goliat/simulation_runner.py: Executes simulations (local iSolve or oSPARC cloud).</li> <li>goliat/results_extractor.py: Extracts SAR/power data post-simulation.</li> <li>goliat/analysis/: Aggregates results (Analyzer with strategies for near/far-field). Includes paper generation via <code>cli/generate_paper.py</code>.</li> <li>goliat/gui_manager.py: Multiprocessing GUI for progress/ETA.</li> <li>goliat/logging_manager.py: Dual loggers (progress/verbose) with colors.</li> <li>goliat/profiler.py: Tracks phases (setup/run/extract) for ETAs.</li> <li>goliat/utils.py: Helpers (format_time, non_blocking_sleep, simple Profiler).</li> </ul> <p>Key flow: Config \u2192 BaseStudy.run() \u2192 Setups \u2192 Runner \u2192 Extractor \u2192 Analyzer. For more details on the high-level architecture, see the Technical Guide.</p>"},{"location":"developer_guide/developer_guide/#installation","title":"Installation","text":"<p>For development, use editable installation from the repository. Users can install from PyPI instead. See the installation guide for both options.</p> <p>Developer setup:</p> <ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/rwydaegh/goliat.git\ncd goliat\n</code></pre> <ol> <li>Set up Sim4Life Python environment:</li> </ol> <pre><code>source .bashrc\n</code></pre> <ol> <li>Install GOLIAT package in editable mode (or in a venv):</li> </ol> <pre><code>python -m pip install -e .\n</code></pre> <p>Always use <code>python -m pip</code>: Always use <code>python -m pip</code> instead of <code>pip</code> directly. This ensures you're using the pip associated with Sim4Life's Python interpreter. The same applies to other Python commands: use <code>python -m &lt;module&gt;</code> when possible.</p> <ol> <li>Run the initialization command:</li> </ol> <pre><code>goliat init\n</code></pre> <p>This will: - Verify Sim4Life Python interpreter is being used - Prepare data files (phantoms, antennas)</p> <p>Benefits of editable install: - Code modifications are immediately reflected (no reinstall needed) - Better IDE support and autocomplete - Full repository access (scripts, tests, docs) - Can contribute to development</p> <p>Note: If you need to reinstall (e.g., after pulling updates), you can manually run: <pre><code>python -m pip install -e .\n</code></pre></p> <p>GOLIAT uses <code>pytest</code> for testing, with tests located in the <code>tests/</code> directory.</p>"},{"location":"developer_guide/developer_guide/#handling-the-s4l_v1-dependency","title":"Handling the <code>s4l_v1</code> dependency","text":"<p>Much of the codebase requires <code>s4l_v1</code>, a proprietary library available only within the Sim4Life Python environment on Windows. This prevents tests that rely on it from running in the Linux-based CI environment.</p> <p>To manage this, tests requiring <code>s4l_v1</code> are marked with <code>@pytest.mark.skip_on_ci</code>. The CI pipeline is configured to exclude these marked tests, allowing it to validate platform-independent code while avoiding environment-specific failures.</p> <pre><code># Command used in .github/workflows/test.yml\npytest -m \"not skip_on_ci\" tests/\n</code></pre>"},{"location":"developer_guide/developer_guide/#local-testing-setup","title":"Local testing setup","text":"<p>To run the complete test suite, your local development environment must use the Sim4Life Python interpreter.</p>"},{"location":"developer_guide/developer_guide/#vs-code-configuration","title":"VS Code Configuration","text":"<ol> <li>Open the Command Palette (<code>Ctrl+Shift+P</code>).</li> <li>Run the <code>Python: Select Interpreter</code> command.</li> <li>Select <code>+ Enter interpreter path...</code> and find the <code>python.exe</code> in your Sim4Life installation directory (e.g., <code>C:\\Program Files\\Sim4Life_8.2.0.16876\\Python\\python.exe</code>). This configures VS Code to use the correct interpreter, which includes the <code>s4l_v1</code> library.</li> </ol>"},{"location":"developer_guide/developer_guide/#running-tests-locally","title":"Running tests locally","text":"<p>With the interpreter set, run the full test suite from the terminal.</p> <ol> <li>First-time Setup: Run <code>goliat init</code> to install dependencies and set up the environment. Alternatively, run any command (e.g., <code>goliat --help</code>) and accept the dependency installation prompt when asked.</li> <li>Run Pytest:</li> </ol> <pre><code># This executes all tests, including those skipped by CI\npytest tests/ -v\n</code></pre>"},{"location":"developer_guide/developer_guide/#adding-new-tests","title":"Adding new tests","text":"<ul> <li>If a new test depends on <code>s4l_v1</code> (or imports a module that does), it must be decorated with <code>@pytest.mark.skip_on_ci</code>.</li> <li>If a test is self-contained and has no Sim4Life dependencies, it does not need the marker.</li> </ul> <pre><code>import pytest\nfrom goliat.utils import format_time # This module has s4l_v1 dependencies\n\n# This test requires the Sim4Life environment and will be skipped on CI.\n@pytest.mark.skip_on_ci\ndef test_a_function_that_needs_s4l():\n    # ... test logic ...\n    pass\n\n# This test is self-contained and will run everywhere.\ndef test_a_self_contained_function():\n    assert 2 + 2 == 4\n</code></pre>"},{"location":"developer_guide/developer_guide/#extending-the-framework","title":"Extending the framework","text":""},{"location":"developer_guide/developer_guide/#adding-a-new-setup","title":"Adding a new setup","text":"<p>To add a custom source (e.g., dipole):</p> <ol> <li>Create <code>goliat/setups/dipole_setup.py</code> inheriting BaseSetup.</li> <li>Implement <code>run_full_setup()</code>: Load dipole CAD, position.</li> <li>Update NearFieldStudy/FarFieldStudy to use it (e.g., if \"study_type\": \"dipole\").</li> <li>Add to config schema in config.py.</li> </ol> <p>Example in dipole_setup.py:</p> <pre><code>class DipoleSetup(BaseSetup):\n    def run_full_setup(self, project_manager):\n        # Custom logic\n        pass\n</code></pre>"},{"location":"developer_guide/developer_guide/#contribution-workflow","title":"Contribution workflow","text":"<ol> <li>Fork the repo.</li> <li>Create branch: <code>git checkout -b feature/new-setup</code>.</li> <li>Code: Follow style (Ruff-formatted, type hints).</li> <li>Test locally: <code>pytest</code>.</li> <li>Commit: <code>git commit -m \"Add dipole setup\"</code>.</li> <li>PR to main: Describe changes, reference issues.</li> </ol> <p>PR requirements: - Run pre-commit: <code>pre-commit run --all-files</code>. - Tests: Add for new features. - Docs: Update user_guide.md if user-facing.</p>"},{"location":"developer_guide/developer_guide/#building-docs","title":"Building docs","text":"<p>To build the documentation, you first need to install the documentation-specific dependencies.</p> <pre><code># Install docs dependencies\npython -m pip install -e .[docs]\n</code></pre> <p>Then, you can use MkDocs to serve the documentation locally or build the static site.</p> <pre><code># Serve the docs locally\nmkdocs serve  # Local server at http://127.0.0.1:8000\n\n# Build the static site\nmkdocs build  # Outputs to site/\n</code></pre>"},{"location":"developer_guide/developer_guide/#code-style","title":"Code style","text":"<ul> <li>Formatting &amp; Linting: Ruff (replaces Black, flake8, isort).</li> <li>Type Checking: Pyright.</li> <li>Types: Use typing (e.g., <code>Dict[str, Any]</code>).</li> <li>Docs: Google-style docstrings.</li> </ul> <p>Pre-commit hook (install: <code>pre-commit install</code>):</p> <pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.14.2 # Or newer\n    hooks:\n      - id: ruff-format\n      - id: ruff\n        args: [--fix]\n  - repo: https://github.com/RobertCraigie/pyright-python\n    rev: v1.1.407 # Or newer\n    hooks:\n      - id: pyright\n</code></pre> <p>Run: <code>pre-commit run</code>.</p>"},{"location":"developer_guide/developer_guide/#other-notes","title":"Other notes","text":"<ul> <li>Dependencies: Defined in <code>pyproject.toml</code> (PEP 621 standard).</li> <li>Gitignore: Ignore logs/, results/, .env.</li> <li>License: Apache-2.0 - see LICENSE.</li> <li>Changelog: Update CHANGELOG.md for releases.</li> <li>Version management: Version is stored in <code>pyproject.toml</code> (<code>[project] version</code>) as the single source of truth. The package reads it via <code>importlib.metadata</code> when installed, or from <code>pyproject.toml</code> directly when running from source.</li> </ul>"},{"location":"developer_guide/developer_guide/#analysis-system","title":"Analysis system","text":"<p>GOLIAT's analysis system aggregates results from multiple simulations and generates reports, plots, and publications. The <code>goliat analyze</code> command processes all simulation outputs in a study, computes statistics, and creates visualizations.</p> <p>What it does: - Loads SAR data from all completed simulations in a study - Aggregates metrics by frequency, scenario, and tissue group - Generates statistical summaries (mean, median, percentiles, correlations) - Creates publication-ready plots (heatmaps, bar charts, boxplots, 3D visualizations) - Exports CSV files with detailed and summary data - Optionally generates LaTeX papers with all figures organized by section</p> <p>How it works: The system uses a strategy pattern (<code>BaseAnalysisStrategy</code>) with separate implementations for near-field and far-field analysis. The <code>Analyzer</code> coordinates data loading and processing, while specialized <code>Plotter</code> modules handle visualization. Results are cached to speed up re-plotting. See the Analysis Guide for detailed documentation covering:</p> <ul> <li>User-facing usage (commands, configuration, output structure)</li> <li>Developer-facing architecture (components, data flow, extending the system)</li> <li>Paper generation workflow</li> </ul> <p>Check out the auto-generated first draft paper (only results): - Results PDF - Download the compiled PDF - Results LaTeX Source - Download the LaTeX source</p> <p>For more, see Contributing. For a deep dive into all available parameters, refer to the Configuration Guide. For a complete reference of all features, see the Full List of Features.</p>"},{"location":"developer_guide/system_architecture/","title":"System architecture","text":"<p>This document provides a comprehensive overview of the GOLIAT system architecture, showing all major components and their relationships.</p>"},{"location":"developer_guide/system_architecture/#architecture-diagram","title":"Architecture diagram","text":"<p>The diagram below is interactive: hold Alt (or Option on Mac) and use your mouse wheel to zoom in/out, or hold Alt and drag to pan around.</p> <pre><code>graph TB\n    subgraph \"Entry points\"\n        CLI[CLI Commandsstudy, analyze, parallelworker, super_study]\n    end\n    \n    subgraph \"Main process\"\n        subgraph \"GUI layer\"\n            ProgressGUI[ProgressGUIPySide6]\n            QueueHandler[QueueHandlerprocesses messages]\n            WebBridgeMgr[WebBridgeManagerconnection lifecycle]\n        end\n        \n        subgraph \"GUI components\"\n            StatusMgr[StatusManagerlog display]\n            ProgressMgr[ProgressManagerprogress bars]\n            DataMgr[DataManagerCSV tracking]\n            GraphMgr[GraphManagerplot updates]\n            UtilMgr[UtilizationManagersystem metrics]\n            SystemMon[SystemMonitorCPU/RAM/GPU]\n            Plots[Plotsmatplotlib]\n            Timings[TimingsTableexecution stats]\n            PieCharts[PieChartsManagertime breakdown]\n            TrayMgr[TrayManagersystem tray]\n        end\n        \n        subgraph \"Web monitoring\"\n            WebBridge[WebGUIBridgemessage forwarding]\n            HTTPClient[HTTPClientAPI requests]\n            MsgSanitizer[MessageSanitizerserialization]\n        end\n    end\n    \n    subgraph \"Study process\"\n        subgraph \"Orchestration\"\n            BaseStudy[BaseStudycommon logic]\n            NearFieldStudy[NearFieldStudy]\n            FarFieldStudy[FarFieldStudy]\n            Config[Confighierarchical JSON]\n            Profiler[Profilertiming &amp; ETA]\n        end\n        \n        subgraph \"Core processing\"\n            ProjectMgr[ProjectManager.smash files]\n            Setup[NearFieldSetupFarFieldSetup]\n            SetupModules[Setup ModulesPhantom, PlacementMaterial, GriddingBoundary, Source]\n            SimRunner[SimulationRunneriSolve / oSPARC]\n            ResultsExt[ResultsExtractorSAR extraction]\n            Extractors[Extractor ModulesPower, SAR, SensorReporter, Cleaner]\n        end\n        \n        subgraph \"Analysis\"\n            Analyzer[Analyzerstrategy pattern]\n            NearStrategy[NearFieldStrategy]\n            FarStrategy[FarFieldStrategy]\n            Plotter[Plottervisualization]\n        end\n        \n        QueueGUI[QueueGUIproxy interface]\n    end\n    \n    subgraph \"Worker system\"\n        SuperStudy[Super Studyconfig splitting]\n        WorkerCLI[Worker CLIassignment fetch]\n        Assignment[Assignmentclaim &amp; run]\n    end\n    \n    subgraph \"Cloud execution\"\n        oSPARCBatch[oSPARC Batchjob submission]\n        oSPARCClient[oSPARC ClientAPI wrapper]\n        oSPARCWorker[oSPARC Workerjob monitoring]\n    end\n    \n    subgraph \"External services\"\n        S4L[Sim4Life EngineiSolve.exe]\n        oSPARC[oSPARC Platformcloud compute]\n        Dashboard[Monitoring DashboardPostgreSQL + Next.js]\n    end\n    \n    subgraph \"Communication\"\n        Queue[multiprocessing.QueueGUI messages]\n        InternalQueue[Internal Queueweb bridge]\n    end\n    \n    %% Entry point flows\n    CLI --&gt;|study| ProgressGUI\n    CLI --&gt;|analyze| Analyzer\n    CLI --&gt;|parallel| ProgressGUI\n    CLI --&gt;|worker| WorkerCLI\n    CLI --&gt;|super_study| SuperStudy\n    \n    %% Main process flows\n    ProgressGUI --&gt; QueueHandler\n    QueueHandler --&gt; StatusMgr\n    QueueHandler --&gt; ProgressMgr\n    QueueHandler --&gt; DataMgr\n    QueueHandler --&gt; GraphMgr\n    QueueHandler --&gt; UtilMgr\n    QueueHandler --&gt; WebBridgeMgr\n    \n    ProgressMgr --&gt; ProgressGUI\n    GraphMgr --&gt; Plots\n    UtilMgr --&gt; SystemMon\n    DataMgr --&gt; GraphMgr\n    \n    WebBridgeMgr --&gt; WebBridge\n    WebBridge --&gt; InternalQueue\n    WebBridge --&gt; HTTPClient\n    HTTPClient --&gt; MsgSanitizer\n    HTTPClient --&gt;|POST| Dashboard\n    \n    %% Study process flows\n    ProgressGUI --&gt;|spawns| QueueGUI\n    QueueGUI --&gt; Queue\n    Queue --&gt; QueueHandler\n    \n    QueueGUI --&gt; BaseStudy\n    BaseStudy --&gt; Config\n    BaseStudy --&gt; Profiler\n    BaseStudy --&gt; ProjectMgr\n    \n    BaseStudy --&gt; NearFieldStudy\n    BaseStudy --&gt; FarFieldStudy\n    \n    NearFieldStudy --&gt; Setup\n    FarFieldStudy --&gt; Setup\n    Setup --&gt; SetupModules\n    Setup --&gt; ProjectMgr\n    Setup --&gt; S4L\n    \n    NearFieldStudy --&gt; SimRunner\n    FarFieldStudy --&gt; SimRunner\n    SimRunner --&gt; S4L\n    SimRunner --&gt;|batch mode| oSPARCBatch\n    oSPARCBatch --&gt; oSPARCClient\n    oSPARCClient --&gt; oSPARC\n    \n    NearFieldStudy --&gt; ResultsExt\n    FarFieldStudy --&gt; ResultsExt\n    ResultsExt --&gt; Extractors\n    ResultsExt --&gt; S4L\n    \n    ResultsExt --&gt; Analyzer\n    Analyzer --&gt; NearStrategy\n    Analyzer --&gt; FarStrategy\n    Analyzer --&gt; Plotter\n    \n    %% Worker system flows\n    SuperStudy --&gt;|uploads| Dashboard\n    WorkerCLI --&gt;|fetches| Dashboard\n    WorkerCLI --&gt; Assignment\n    Assignment --&gt;|runs| BaseStudy\n    Assignment --&gt;|reports| Dashboard\n    \n    %% Styling\n    style ProgressGUI fill:#E1BEE7\n    style WebBridge fill:#BBDEFB\n    style BaseStudy fill:#BBDEFB\n    style NearFieldStudy fill:#BBDEFB\n    style FarFieldStudy fill:#BBDEFB\n    style Setup fill:#C5E1A5\n    style SimRunner fill:#FFE082\n    style ResultsExt fill:#FFCCBC\n    style Analyzer fill:#D1C4E9\n    style Plotter fill:#D1C4E9\n    style Dashboard fill:#E1BEE7\n    style Queue fill:#FFE082\n    style S4L fill:#FFCCBC\n    style oSPARC fill:#FFCCBC\n</code></pre>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom"},{"location":"developer_guide/system_architecture/#component-descriptions","title":"Component descriptions","text":""},{"location":"developer_guide/system_architecture/#entry-points","title":"Entry points","text":"<ul> <li>CLI Commands: Main entry points (<code>goliat study</code>, <code>goliat analyze</code>, <code>goliat parallel</code>, <code>goliat worker</code>, <code>goliat super_study</code>)</li> </ul>"},{"location":"developer_guide/system_architecture/#main-process-gui","title":"Main process (GUI)","text":"<ul> <li>ProgressGUI: Main PySide6 window, manages all GUI components</li> <li>QueueHandler: Polls multiprocessing queue (every 100ms), dispatches messages to GUI components and web bridge</li> <li>WebBridgeManager: Manages web bridge lifecycle, collects system info, handles connection status</li> </ul> <p>GUI Components:</p> <ul> <li>StatusManager: Color-coded log display</li> <li>ProgressManager: Overall and stage progress bars</li> <li>DataManager: CSV file management for time series data</li> <li>GraphManager: Coordinates plot updates</li> <li>UtilizationManager: System resource monitoring (CPU, RAM, GPU)</li> <li>SystemMonitor: Low-level system metrics via psutil and nvidia-smi</li> <li>Plots: Matplotlib-based visualizations (time remaining, progress, utilization)</li> <li>TimingsTable: Execution statistics display</li> <li>PieChartsManager: Time breakdown visualization</li> <li>TrayManager: System tray integration</li> </ul> <p>Web Monitoring:</p> <ul> <li>WebGUIBridge: Forwards GUI messages to dashboard API, throttles and batches</li> <li>HTTPClient: HTTP request handling for <code>/api/gui-update</code> and <code>/api/heartbeat</code></li> <li>MessageSanitizer: Serializes non-serializable objects before sending</li> </ul>"},{"location":"developer_guide/system_architecture/#study-process","title":"Study process","text":"<p>Orchestration:</p> <ul> <li>BaseStudy: Common study logic, phase management, error handling</li> <li>NearFieldStudy: Near-field simulation orchestration</li> <li>FarFieldStudy: Far-field simulation orchestration</li> <li>Config: Hierarchical JSON configuration with inheritance</li> <li>Profiler: Timing tracking, ETA estimation, weighted progress</li> </ul> <p>Core Processing:</p> <ul> <li>ProjectManager: Sim4Life <code>.smash</code> file lifecycle, verification, metadata</li> <li>Setup: Coordinates scene building (NearFieldSetup or FarFieldSetup)</li> <li>Setup Modules: Specialized setup tasks (PhantomSetup, PlacementSetup, MaterialSetup, GriddingSetup, BoundarySetup, SourceSetup)</li> <li>SimulationRunner: Executes simulations via iSolve.exe or oSPARC</li> <li>ResultsExtractor: Orchestrates result extraction</li> <li>Extractor Modules: Specialized extraction (PowerExtractor, SarExtractor, SensorExtractor, Reporter, Cleaner)</li> </ul> <p>Analysis:</p> <ul> <li>Analyzer: Strategy-based analysis orchestration</li> <li>NearFieldStrategy: Near-field specific analysis logic</li> <li>FarFieldStrategy: Far-field specific analysis logic</li> <li>Plotter: Generates plots and visualizations</li> </ul> <p>Communication:</p> <ul> <li>QueueGUI: Proxy interface that mimics GUI but sends to multiprocessing queue</li> </ul>"},{"location":"developer_guide/system_architecture/#worker-system","title":"Worker system","text":"<ul> <li>Super Study: Splits config into assignments, uploads to dashboard</li> <li>Worker CLI: Fetches assignments from dashboard, claims them, runs studies</li> <li>Assignment: Individual config slice executed by a worker</li> </ul>"},{"location":"developer_guide/system_architecture/#cloud-execution","title":"Cloud execution","text":"<ul> <li>oSPARC Batch: Manages batch job submission and monitoring</li> <li>oSPARC Client: Wraps oSPARC API for job submission</li> <li>oSPARC Worker: Monitors job status, downloads results</li> </ul>"},{"location":"developer_guide/system_architecture/#external-services","title":"External services","text":"<ul> <li>Sim4Life Engine: FDTD solver (<code>iSolve.exe</code>), scene building API</li> <li>oSPARC Platform: Cloud compute platform for parallel execution</li> <li>Monitoring Dashboard: Web-based monitoring (PostgreSQL database, Next.js frontend)</li> </ul>"},{"location":"developer_guide/system_architecture/#communication-channels","title":"Communication channels","text":"<ul> <li>multiprocessing.Queue: Inter-process communication between GUI and study process</li> <li>Internal Queue: WebGUIBridge internal queue for message throttling</li> </ul>"},{"location":"developer_guide/system_architecture/#data-flow","title":"Data flow","text":"<ol> <li>User starts study: CLI command \u2192 ProgressGUI spawns study process</li> <li>Study process: QueueGUI \u2192 multiprocessing.Queue \u2192 QueueHandler \u2192 GUI components</li> <li>Web monitoring: QueueHandler \u2192 WebGUIBridge \u2192 HTTPClient \u2192 Dashboard API</li> <li>Worker mode: Worker CLI \u2192 Dashboard API \u2192 Assignment \u2192 Study process</li> <li>Cloud execution: SimulationRunner \u2192 oSPARC Batch \u2192 oSPARC Platform</li> </ol>"},{"location":"developer_guide/system_architecture/#key-design-patterns","title":"Key design patterns","text":"<ul> <li>Multiprocessing: GUI and study run in separate processes for responsiveness</li> <li>Queue-based communication: Decoupled message passing between processes</li> <li>Strategy pattern: Analysis strategies (near-field vs far-field)</li> <li>Bridge pattern: WebGUIBridge forwards messages without coupling</li> <li>Modular components: GUI and setup use modular, replaceable components</li> <li>Configuration-driven: JSON configs drive simulation parameters</li> </ul>"},{"location":"developer_guide/technical_guide/","title":"GOLIAT technical guide","text":"<p>This document provides an overview of the GOLIAT project's architecture, key components, and core functionalities. It is intended for developers who want to understand, extend, or maintain the codebase.</p>"},{"location":"developer_guide/technical_guide/#core-philosophy","title":"Core philosophy","text":"<p>GOLIAT is designed with a modular, configuration-driven architecture. The primary goal is to automate the entire EMF dosimetry simulation workflow\u2014scene setup, execution, and results analysis\u2014while maintaining reproducibility and scalability. The system is orchestrated by Study classes, which manage the simulation lifecycle based on parameters defined in JSON configuration files. This approach allows for easy modification of simulation parameters without changing the underlying code, and it allows simulations to be repeated with the exact same settings.</p>"},{"location":"developer_guide/technical_guide/#system-architecture","title":"System architecture","text":"<p>The application is structured in several distinct layers, each with a specific responsibility. This separation of concerns makes the system easier to understand, maintain, and extend.</p> <pre><code>graph TB\n    subgraph \"User Interface Layer\"\n        GUI[GUI ManagerPySide6]\n        CLI[Command Line]\n    end\n    \n    subgraph \"Orchestration Layer\"\n        Study[Study ClassesNearFieldStudy / FarFieldStudy]\n        Config[Configuration Manager]\n        Profiler[Profiler &amp; Progress Tracking]\n    end\n    \n    subgraph \"Core Processing Layer\"\n        PM[Project Manager]\n        Setup[Setup ClassesScene Building]\n        Runner[Simulation Runner]\n        Strategies[Execution StrategiesStrategy Pattern]\n        Extractor[Results Extractor]\n    end\n\n    subgraph \"Analysis Layer\"\n        Analyzer[Analyzerorchestrator]\n        Strategy[Analysis StrategiesNearField / FarField]\n        Plotter[Plotter13 specialized modules]\n    end\n    \n    subgraph \"External Services\"\n        S4L[Sim4Life Engine]\n        oSPARC[oSPARC Cloud]\n    end\n    \n    GUI --&gt; Study\n    CLI --&gt; Study\n    Study --&gt; Config\n    Study --&gt; Profiler\n    Study --&gt; PM\n    Study --&gt; Setup\n    Study --&gt; Runner\n    Study --&gt; Extractor\n    Runner --&gt; Strategies\n    Extractor --&gt; Analyzer\n    Analyzer --&gt; Strategy\n    Analyzer --&gt; Plotter\n    Strategies --&gt; S4L\n    Strategies --&gt; oSPARC\n    Setup --&gt; S4L\n    Extractor --&gt; S4L\n    \n    style GUI fill:#E1BEE7\n    style Study fill:#BBDEFB\n    style Setup fill:#C5E1A5\n    style Runner fill:#FFE082\n    style Strategies fill:#FFE082\n    style Extractor fill:#FFCCBC\n    style Analyzer fill:#D1C4E9\n    style Plotter fill:#D1C4E9\n</code></pre>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom"},{"location":"developer_guide/technical_guide/#workflow-and-component-interactions","title":"Workflow and component interactions","text":"<p>The simulation process follows a clear, sequential workflow, orchestrated by the <code>NearFieldStudy</code> or <code>FarFieldStudy</code> classes. This workflow completes each step successfully before the next one begins, and it provides a clear structure for the entire simulation process.</p> <pre><code>sequenceDiagram\n    participant User\n    participant GUI\n    participant Study\n    participant Setup\n    participant Runner\n    participant Extractor\n    participant Analyzer\n    participant Files\n    \n    User-&gt;&gt;GUI: Start Study\n    GUI-&gt;&gt;Study: Initialize\n    Study-&gt;&gt;Setup: Configure Scene\n    Setup-&gt;&gt;Files: Create .smash\n    Study-&gt;&gt;Runner: Execute Simulation\n    Runner-&gt;&gt;Files: Generate Input (.h5)\n    Runner-&gt;&gt;Runner: Run Solver\n    Runner-&gt;&gt;Files: Write Results\n    Study-&gt;&gt;Extractor: Process Results\n    Extractor-&gt;&gt;Files: Read Output\n    Extractor-&gt;&gt;Files: Save Reports\n    User-&gt;&gt;Analyzer: Run Analysis\n    Analyzer-&gt;&gt;Files: Load Results\n    Analyzer-&gt;&gt;Files: Generate Plots\n    Analyzer-&gt;&gt;Files: Export CSV\n    Study-&gt;&gt;GUI: Update Progress\n    GUI-&gt;&gt;User: Show Completion\n</code></pre>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom"},{"location":"developer_guide/technical_guide/#core-components","title":"Core components","text":"<p>This section details GOLIAT's core classes and their roles within the framework. For a complete API reference, please see the Full API Reference.</p>"},{"location":"developer_guide/technical_guide/#orchestration-layer","title":"Orchestration layer","text":""},{"location":"developer_guide/technical_guide/#config","title":"<code>Config</code>","text":"<ul> <li>Function: Loads and manages hierarchical JSON configurations. A study-specific config (e.g., <code>near_field_config.json</code>) extends a <code>base_config.json</code>, allowing for a clean override system. This design minimizes duplication and makes it easy to manage different simulation scenarios. The <code>Config</code> class is responsible for loading the <code>base_config.json</code> and then recursively merging the study-specific configuration over it.</li> <li> <p>Some interesting methods:</p> <ul> <li><code>__getitem__(path)</code>: Dictionary-style access with dot-notation support. Returns <code>None</code> if key doesn't exist, enabling pythonic fallback patterns: <code>config[\"simulation_parameters\"] or {}</code></li> <li><code>get_material_mapping(phantom_name)</code>: Returns material name mapping for a specific phantom.</li> <li><code>get_profiling_config(study_type)</code>: Returns profiling configuration for a study type.</li> <li><code>_load_config_with_inheritance(path)</code>: The core method that handles the hierarchical loading of configuration files.</li> </ul> </li> </ul> <p>Access Pattern: The Config class uses dictionary-style access with fallback: - <code>config[\"simulation_parameters.excitation_type\"] or \"Harmonic\"</code> (pythonic fallback pattern)</p> <p>\u26a0\ufe0f Important: When using the <code>or</code> pattern for default values, be careful about falsy values:</p> <ul> <li>Safe: If the default is falsy (<code>False</code>, <code>0</code>, <code>[]</code>, <code>{}</code>, <code>\"\"</code>), the <code>or</code> pattern is safe because falsy values won't be masked:</li> <li><code>config[\"key\"] or False</code> - <code>False</code> stays <code>False</code></li> <li><code>config[\"key\"] or 0</code> - <code>0</code> stays <code>0</code></li> <li> <p><code>config[\"key\"] or []</code> - Empty list stays empty</p> </li> <li> <p>Problematic: If the default is truthy (<code>True</code>, non-zero numbers, non-empty strings/lists), use explicit <code>None</code> checks to avoid masking falsy values:</p> </li> <li>\u274c <code>config[\"use_gui\"] or True</code> - <code>False</code> becomes <code>True</code> (wrong!)</li> <li>\u2705 <code>use_gui = config[\"use_gui\"]; if use_gui is None: use_gui = True</code> - <code>False</code> stays <code>False</code></li> <li>\u274c <code>config[\"bbox_padding_mm\"] or 50</code> - <code>0</code> becomes <code>50</code> (wrong if <code>0</code> is valid!)</li> <li>\u2705 <code>padding = config[\"bbox_padding_mm\"]; if padding is None: padding = 50</code> - <code>0</code> stays <code>0</code></li> </ul> <p>Rule of thumb: If the default is falsy, the <code>or</code> pattern is safe. If the default is truthy, use explicit <code>None</code> checks to avoid masking falsy values.</p> <ul> <li>API Reference: goliat.config.Config</li> </ul>"},{"location":"developer_guide/technical_guide/#tissue-grouping","title":"Tissue Grouping","text":"<p>GOLIAT groups individual tissues into logical categories (e.g., eyes, brain, skin) for aggregated SAR analysis. The grouping process occurs during SAR extraction and uses explicit mappings defined in <code>material_name_mapping.json</code>.</p> <p>How it works:</p> <ol> <li> <p>Tissue Name Extraction: Sim4Life returns tissue names that may include phantom suffixes (e.g., <code>\"Cornea  (Thelonious_6y_V6)\"</code>). These original names are preserved in the SAR DataFrame without cleaning or normalization.</p> </li> <li> <p>Matching Process: The <code>TissueGrouper</code> class matches tissues to groups by:</p> </li> <li>Stripping phantom suffixes (e.g., <code>\"Cornea  (Thelonious_6y_V6)\"</code> \u2192 <code>\"Cornea\"</code>)</li> <li>Checking if the cleaned name matches an entity name directly in <code>material_name_mapping.json</code></li> <li>If not found, checking if it matches a material name (using a reverse lookup)</li> <li> <p>Once the entity is identified, checking which group(s) it belongs to in <code>_tissue_groups</code></p> </li> <li> <p>Configuration: Tissue groups are defined per phantom in <code>material_name_mapping.json</code> under the <code>_tissue_groups</code> key:    <pre><code>{\n  \"thelonious\": {\n    \"_tissue_groups\": {\n      \"eyes_group\": [\"Cornea\", \"Eye_lens\", \"Eye_Sclera\", \"Eye_vitreous_humor\"],\n      \"brain_group\": [\"Brain_grey_matter\", \"Brain_white_matter\", ...],\n      ...\n    },\n    \"Cornea\": \"Eye (Cornea)\",\n    \"Eye_lens\": \"Eye (Lens)\",\n    ...\n  }\n}\n</code></pre></p> </li> <li> <p>Output: The grouping returns a dictionary mapping group names to lists of matched tissue names (with original phantom suffixes preserved). This ensures consistency between the DataFrame and the grouping results.</p> </li> </ol> <p>Note: Far-field analysis uses keyword-based substring matching for plotting (defined in <code>Analyzer.tissue_group_definitions</code>), which is separate from the extraction-phase grouping. This works because tissue names in pickle files contain the keywords (e.g., <code>\"Cornea\"</code> matches <code>\"Cornea  (Thelonious_6y_V6)\"</code> via substring search).</p> <ul> <li>API Reference: goliat.extraction.tissue_grouping.TissueGrouper</li> </ul>"},{"location":"developer_guide/technical_guide/#basestudy-nearfieldstudy-farfieldstudy","title":"<code>BaseStudy</code>, <code>NearFieldStudy</code>, <code>FarFieldStudy</code>","text":"<ul> <li>Function: Orchestrates the entire simulation workflow. <code>BaseStudy</code> provides the core structure, including the main <code>run()</code> method, logging, and profiling. <code>NearFieldStudy</code> and <code>FarFieldStudy</code> inherit from <code>BaseStudy</code> and implement the <code>_run_study()</code> method, which contains the specific logic for each study type. This inheritance-based design allows for code reuse and a clear separation of concerns.</li> <li> <p>Some interesting methods:</p> <ul> <li><code>run()</code>: The main entry point to execute the study. It handles top-level error handling and checks that the necessary Sim4Life environment is running. It then calls the <code>_run_study</code> method.</li> <li><code>_run_study()</code>: This is the core of each study. It loops through phantoms, frequencies, and placements, coordinating the setup, run, and extraction phases for each simulation.</li> </ul> </li> <li> <p>API Reference:</p> <ul> <li>goliat.studies.base_study.BaseStudy</li> <li>goliat.studies.near_field_study.NearFieldStudy</li> <li>goliat.studies.far_field_study.FarFieldStudy</li> </ul> </li> </ul>"},{"location":"developer_guide/technical_guide/#core-processing-layer","title":"Core processing layer","text":""},{"location":"developer_guide/technical_guide/#projectmanager","title":"<code>ProjectManager</code>","text":"<ul> <li>Function: Manages Sim4Life project files (<code>.smash</code>). It handles file creation, opening, saving, and validation to prevent issues with file locks or corruption. This is a component for maintaining the stability of the simulation process. It includes a <code>_is_valid_smash_file()</code> method that checks for file locks and verifies the HDF5 structure of the project file before attempting to open it.</li> <li> <p>Some interesting methods:</p> <ul> <li><code>create_or_open_project(...)</code>: Creates a new project or opens an existing one based on the configuration.</li> </ul> </li> <li> <p>API Reference: goliat.project_manager.ProjectManager</p> </li> </ul>"},{"location":"developer_guide/technical_guide/#setup-modules-goliatsetups","title":"Setup modules (<code>goliat/setups/</code>)","text":"<ul> <li>Function: A collection of specialized classes, each responsible for a specific part of the scene setup in Sim4Life. All setup classes inherit from <code>BaseSetup</code>, which provides common functionalities like logging and access to the Sim4Life API. The <code>NearFieldSetup</code> and <code>FarFieldSetup</code> classes coordinate the execution of the other setup modules. This modular design makes it easy to add new setup steps or modify existing ones.</li> <li> <p>Some components:</p> <ul> <li><code>PhantomSetup</code>: Loads and validates phantom models.</li> <li><code>PlacementSetup</code>: Positions the antenna relative to the phantom.</li> <li><code>MaterialSetup</code>: Assigns material properties to all entities.</li> <li><code>GriddingSetup</code>: Configures the spatial grid for the simulation.</li> <li><code>BoundarySetup</code>: Sets up the boundary conditions (e.g., PML).</li> <li><code>SourceSetup</code>: Configures the EMF sources and sensors.</li> </ul> </li> <li> <p>API Reference: goliat.setups</p> </li> </ul>"},{"location":"developer_guide/technical_guide/#simulationrunner","title":"<code>SimulationRunner</code>","text":"<ul> <li>Function: Executes a single simulation using the Strategy pattern to select the appropriate execution method. The runner delegates actual execution to specialized strategy classes, making it easy to add new execution methods without modifying the core runner logic.</li> <li>Execution Strategies: The runner uses three main strategies:<ul> <li><code>ISolveManualStrategy</code>: Executes simulations locally using <code>iSolve.exe</code> subprocess. Handles real-time output logging, progress milestone tracking, and retry logic for failed runs.</li> <li><code>Sim4LifeAPIStrategy</code>: Executes simulations via the Sim4Life Python API. Used when running simulations directly through the API.</li> <li><code>OSPARCDirectStrategy</code>: Submits simulations to the oSPARC cloud platform for distributed execution.</li> </ul> </li> <li> <p>Some interesting methods:</p> <ul> <li><code>run()</code>: Writes the input file, then delegates to the appropriate execution strategy based on configuration.</li> <li><code>_create_execution_strategy()</code>: Factory method that selects the correct strategy based on solver settings.</li> </ul> </li> <li> <p>API Reference: goliat.simulation_runner.SimulationRunner</p> </li> </ul>"},{"location":"developer_guide/technical_guide/#resultsextractor","title":"<code>ResultsExtractor</code>","text":"<ul> <li>Function: Post-processes the simulation output. It uses a set of specialized extractor modules in the <code>goliat/extraction/</code> directory to pull key metrics. This modular approach makes it easy to add new extraction capabilities.</li> <li> <p>Extractor modules:</p> <ul> <li><code>PowerExtractor</code>: Extracts input power and power balance.</li> <li><code>SarExtractor</code>: Extracts detailed SAR statistics for all tissues.</li> <li><code>SapdExtractor</code>: Extracts Surface Absorbed Power Density on the skin surface.</li> <li><code>SensorExtractor</code>: Extracts data from point sensors.</li> <li><code>Reporter</code>: Generates detailed reports in Pickle and HTML formats.</li> <li><code>Cleaner</code>: Handles cleanup of simulation files to save disk space.</li> </ul> </li> </ul>"},{"location":"developer_guide/technical_guide/#surface-absorbed-power-density-sapd","title":"Surface absorbed power density (SAPD)","text":"<p>GOLIAT extracts the power density absorbed at the skin surface for frequencies above 6 GHz. This automated workflow uses Sim4Life's <code>GenericSAPDEvaluator</code> plugin.</p> <ol> <li>Surface preparation: The system unites the Skin and Ear_skin entities (defined in the material mapping) into a single Skin_Merged_For_SAPD entity. This merged mesh is cached in <code>data/phantom_skins/</code> as a <code>.sab</code> file.</li> <li>Speed optimizations:<ul> <li>HDF5 slicing: Creates a sub-sampled H5 output file around the peak SAR location to reduce memory overhead.</li> <li>Mesh slicing: Clips the skin mesh to a 100 mm box using 6 planar cuts.</li> </ul> </li> <li>Mesh cleanup: Sliced meshes are repaired using RemoveBackToBackTriangles, RepairTriangleMesh, and RemeshTriangleMesh (2 mm target edge length) for accurate evaluation.</li> <li>Evaluation: The evaluator uses a 4 cm\u00b2 averaging area and a 10 mm depth threshold, compliant with IEC/IEEE 63195-2:2022.</li> <li> <p>Some interesting methods:</p> <ul> <li><code>extract()</code>: Orchestrates the entire extraction process.</li> </ul> </li> <li> <p>API Reference: goliat.results_extractor.ResultsExtractor</p> </li> </ol>"},{"location":"developer_guide/technical_guide/#analysis-layer","title":"Analysis layer","text":""},{"location":"developer_guide/technical_guide/#analyzer-strategies","title":"<code>Analyzer</code> &amp; Strategies","text":"<ul> <li>Function: The <code>Analyzer</code> class orchestrates the analysis of extracted results. It uses a strategy pattern, delegating the specifics of the analysis to a <code>BaseAnalysisStrategy</code> subclass (<code>NearFieldAnalysisStrategy</code> or <code>FarFieldAnalysisStrategy</code>). This design allows for different analysis workflows to be implemented without changing the core <code>Analyzer</code> logic. The strategy is responsible for loading the correct data, calculating summary statistics, and generating the appropriate plots.</li> <li> <p>Some interesting methods:</p> <ul> <li><code>run_analysis()</code>: Loads results, applies the strategy, and generates reports and plots.</li> </ul> </li> <li> <p>API Reference:</p> <ul> <li>goliat.analysis.analyzer.Analyzer</li> <li>goliat.analysis.base_strategy.BaseAnalysisStrategy</li> </ul> </li> </ul>"},{"location":"developer_guide/technical_guide/#plotter","title":"<code>Plotter</code>","text":"<ul> <li>Function: Generates a variety of plots from the analyzed data. It is designed to be a flexible component that can be easily extended to create new types of visualizations.</li> <li> <p>Some interesting methods:</p> <ul> <li><code>plot_sar_heatmap(...)</code>: Creates a heatmap of SAR distribution by tissue.</li> <li><code>plot_average_sar_bar(...)</code>: Generates a bar chart of average SAR values.</li> <li><code>plot_pssar_line(...)</code>: Creates a line plot of peak spatial-average SAR.</li> <li><code>plot_sar_distribution_boxplots(...)</code>: Generates boxplots to show the distribution of SAR values.</li> </ul> </li> <li> <p>API Reference: goliat.analysis.plotter.Plotter</p> </li> </ul>"},{"location":"developer_guide/technical_guide/#advanced-features","title":"Advanced features","text":""},{"location":"developer_guide/technical_guide/#gui-profiling-and-logging","title":"GUI, profiling, and logging","text":"<p>The application uses a multi-process architecture to provide a responsive GUI. The <code>Profiler</code> class manages time estimation and progress tracking, using historical data from <code>profiling_config.json</code> to improve its accuracy over time. The logging system is split into a user-facing <code>progress</code> stream and a detailed <code>verbose</code> stream.</p> <p>For a deep dive into the architecture of these systems, refer to the Advanced Features Guide.</p> <p>For a complete and detailed API reference, please refer to the Full API Reference. For a comprehensive list of all user-facing features, see the Full List of Features.</p>"},{"location":"reference/api_reference/","title":"API Reference","text":"<p>Complete API documentation for GOLIAT, organized by module category.</p>"},{"location":"reference/api_reference/#core-modules","title":"Core Modules","text":"<p>Core functionality for configuration, logging, and utilities.</p>"},{"location":"reference/api_reference/#antenna","title":"Antenna","text":""},{"location":"reference/api_reference/#goliat.antenna.Antenna","title":"goliat.antenna.Antenna","text":"<pre><code>Antenna(config: Config, frequency_mhz: int)\n</code></pre> <p>Manages antenna-specific properties and configurations.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>The configuration object containing antenna settings.</p> required <code>frequency_mhz</code> <code>int</code> <p>The operating frequency in MHz.</p> required Source code in <code>goliat/antenna.py</code> <pre><code>def __init__(self, config: \"Config\", frequency_mhz: int):\n    \"\"\"Initializes the Antenna object.\n\n    Args:\n        config: The configuration object containing antenna settings.\n        frequency_mhz: The operating frequency in MHz.\n    \"\"\"\n    self.config = config\n    self.frequency_mhz = frequency_mhz\n    self.antenna_config = self.config[\"antenna_config\"] or {}\n</code></pre>"},{"location":"reference/api_reference/#goliat.antenna.Antenna-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.antenna.Antenna.get_config_for_frequency","title":"get_config_for_frequency","text":"<pre><code>get_config_for_frequency() -&gt; dict\n</code></pre> <p>Gets the antenna configuration for the current frequency.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no configuration is defined for the frequency.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The antenna configuration dictionary.</p> Source code in <code>goliat/antenna.py</code> <pre><code>def get_config_for_frequency(self) -&gt; dict:\n    \"\"\"Gets the antenna configuration for the current frequency.\n\n    Raises:\n        ValueError: If no configuration is defined for the frequency.\n\n    Returns:\n        The antenna configuration dictionary.\n    \"\"\"\n    freq_str = str(self.frequency_mhz)\n    if freq_str not in self.antenna_config:\n        raise ValueError(f\"Antenna configuration not defined for frequency: {self.frequency_mhz} MHz\")\n    return self.antenna_config[freq_str]\n</code></pre>"},{"location":"reference/api_reference/#goliat.antenna.Antenna.get_model_type","title":"get_model_type","text":"<pre><code>get_model_type() -&gt; str\n</code></pre> <p>Returns the antenna model type string.</p> Source code in <code>goliat/antenna.py</code> <pre><code>def get_model_type(self) -&gt; str:\n    \"\"\"Returns the antenna model type string.\"\"\"\n    return str(self.get_config_for_frequency().get(\"model_type\"))\n</code></pre>"},{"location":"reference/api_reference/#goliat.antenna.Antenna.get_source_entity_name","title":"get_source_entity_name","text":"<pre><code>get_source_entity_name() -&gt; str\n</code></pre> <p>Returns the source entity name from the antenna config.</p> Source code in <code>goliat/antenna.py</code> <pre><code>def get_source_entity_name(self) -&gt; str:\n    \"\"\"Returns the source entity name from the antenna config.\"\"\"\n    return str(self.get_config_for_frequency().get(\"source_name\"))\n</code></pre>"},{"location":"reference/api_reference/#goliat.antenna.Antenna.get_centered_antenna_path","title":"get_centered_antenna_path","text":"<pre><code>get_centered_antenna_path(centered_antennas_dir: str) -&gt; str\n</code></pre> <p>Constructs the path to the centered .sab antenna file.</p> <p>If the exact frequency file doesn't exist, finds the nearest available frequency and shows a warning.</p> <p>Parameters:</p> Name Type Description Default <code>centered_antennas_dir</code> <code>str</code> <p>The directory for centered antenna files.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The absolute path to the centered antenna model file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If no antenna files are found in the directory.</p> Source code in <code>goliat/antenna.py</code> <pre><code>def get_centered_antenna_path(self, centered_antennas_dir: str) -&gt; str:\n    \"\"\"Constructs the path to the centered .sab antenna file.\n\n    If the exact frequency file doesn't exist, finds the nearest available frequency\n    and shows a warning.\n\n    Args:\n        centered_antennas_dir: The directory for centered antenna files.\n\n    Returns:\n        The absolute path to the centered antenna model file.\n\n    Raises:\n        FileNotFoundError: If no antenna files are found in the directory.\n    \"\"\"\n    antenna_filename = f\"{self.frequency_mhz}MHz_centered.sab\"\n    antenna_path = os.path.join(centered_antennas_dir, antenna_filename)\n\n    # Check if exact file exists\n    if os.path.exists(antenna_path) and os.path.isfile(antenna_path):\n        return antenna_path\n\n    # File doesn't exist, try to find nearest frequency\n    logger.warning(f\"Antenna file for {self.frequency_mhz} MHz not found: {antenna_path}. Searching for nearest available frequency...\")\n\n    # Scan directory for available antenna files\n    if not os.path.exists(centered_antennas_dir):\n        raise FileNotFoundError(f\"Antenna directory does not exist: {centered_antennas_dir}\")\n\n    available_files = []\n    pattern = re.compile(r\"(\\d+)MHz_centered\\.sab$\")\n\n    try:\n        for filename in os.listdir(centered_antennas_dir):\n            match = pattern.match(filename)\n            if match:\n                freq = int(match.group(1))\n                filepath = os.path.join(centered_antennas_dir, filename)\n                if os.path.isfile(filepath):\n                    available_files.append((freq, filepath))\n    except (OSError, PermissionError) as e:\n        raise FileNotFoundError(f\"Could not read antenna directory {centered_antennas_dir}: {e}\") from e\n\n    if not available_files:\n        raise FileNotFoundError(f\"No antenna files found in directory: {centered_antennas_dir}\")\n\n    # Find nearest frequency\n    available_files.sort(key=lambda x: x[0])  # Sort by frequency\n    nearest_freq, nearest_path = min(available_files, key=lambda x: abs(x[0] - self.frequency_mhz))\n\n    logger.warning(f\"Using antenna file for {nearest_freq} MHz instead of {self.frequency_mhz} MHz. File: {nearest_path}\")\n\n    return nearest_path\n</code></pre>"},{"location":"reference/api_reference/#colors","title":"Colors","text":""},{"location":"reference/api_reference/#goliat.colors","title":"goliat.colors","text":""},{"location":"reference/api_reference/#goliat.colors-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.colors.init_colorama","title":"init_colorama","text":"<pre><code>init_colorama()\n</code></pre> <p>Initialize colorama for current environment.</p> <p>Preserves ANSI codes when stdout is piped (e.g., in Jupyter notebooks) by checking for JUPYTER_NOTEBOOK or COLORAMA_STRIP environment variables.</p> Source code in <code>goliat/colors.py</code> <pre><code>def init_colorama():\n    \"\"\"Initialize colorama for current environment.\n\n    Preserves ANSI codes when stdout is piped (e.g., in Jupyter notebooks)\n    by checking for JUPYTER_NOTEBOOK or COLORAMA_STRIP environment variables.\n    \"\"\"\n    # Preserve ANSI codes when stdout is piped (e.g., in Jupyter notebooks)\n    strip_codes = os.environ.get(\"COLORAMA_STRIP\", \"\").lower() == \"0\" or os.environ.get(\"JUPYTER_NOTEBOOK\", \"\").lower() == \"1\"\n    init(autoreset=True, strip=not strip_codes, convert=False if strip_codes else True)\n</code></pre>"},{"location":"reference/api_reference/#goliat.colors.get_color","title":"get_color","text":"<pre><code>get_color(log_type: str) -&gt; str\n</code></pre> <p>Returns the colorama color code for a log type, or white if not found.</p> <p>Parameters:</p> Name Type Description Default <code>log_type</code> <code>str</code> <p>Log type key (e.g., 'info', 'warning', 'error').</p> required <p>Returns:</p> Type Description <code>str</code> <p>Colorama color code string.</p> Source code in <code>goliat/colors.py</code> <pre><code>def get_color(log_type: str) -&gt; str:\n    \"\"\"Returns the colorama color code for a log type, or white if not found.\n\n    Args:\n        log_type: Log type key (e.g., 'info', 'warning', 'error').\n\n    Returns:\n        Colorama color code string.\n    \"\"\"\n    return COLOR_MAP.get(log_type, Fore.WHITE)\n</code></pre>"},{"location":"reference/api_reference/#constants","title":"Constants","text":""},{"location":"reference/api_reference/#goliat.constants","title":"goliat.constants","text":"<p>Constants used throughout the GOLIAT codebase.</p> <p>This module centralizes magic numbers, thresholds, and hardcoded values to improve maintainability and reduce technical debt.</p>"},{"location":"reference/api_reference/#goliat.constants-attributes","title":"Attributes","text":""},{"location":"reference/api_reference/#goliat.constants.MIN_H5_FILE_SIZE_BYTES","title":"MIN_H5_FILE_SIZE_BYTES  <code>module-attribute</code>","text":"<pre><code>MIN_H5_FILE_SIZE_BYTES = 8 * 1024 * 1024\n</code></pre> <p>Minimum size in bytes for a valid H5 output file.</p> <p>iSolve sometimes creates incomplete files that are smaller than this threshold. Files smaller than this are considered invalid.</p>"},{"location":"reference/api_reference/#goliat.constants.H5_SIZE_INCREASE_THRESHOLD","title":"H5_SIZE_INCREASE_THRESHOLD  <code>module-attribute</code>","text":"<pre><code>H5_SIZE_INCREASE_THRESHOLD = 1.1\n</code></pre> <p>Minimum size increase ratio for Output.h5 compared to Input.h5.</p> <p>Output.h5 must be at least 10% bigger than Input.h5 to ensure the simulation completed successfully. This helps detect incomplete or corrupted output files.</p>"},{"location":"reference/api_reference/#goliat.constants.PLOT_Y_AXIS_BUFFER_MULTIPLIER","title":"PLOT_Y_AXIS_BUFFER_MULTIPLIER  <code>module-attribute</code>","text":"<pre><code>PLOT_Y_AXIS_BUFFER_MULTIPLIER = 1.1\n</code></pre> <p>Multiplier for y-axis maximum in plots.</p> <p>Adds 10% buffer above the maximum value for better visualization.</p>"},{"location":"reference/api_reference/#data-extractor","title":"Data Extractor","text":""},{"location":"reference/api_reference/#goliat.data_extractor","title":"goliat.data_extractor","text":""},{"location":"reference/api_reference/#goliat.data_extractor-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.data_extractor.get_parameter_from_json","title":"get_parameter_from_json","text":"<pre><code>get_parameter_from_json(file_path: str, json_path: str) -&gt; Any\n</code></pre> <p>Extracts a nested value from a JSON file using dot notation.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the JSON file.</p> required <code>json_path</code> <code>str</code> <p>Dot-separated path like 'section.subsection.key'.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The value at the path, or None if not found.</p> Source code in <code>goliat/data_extractor.py</code> <pre><code>def get_parameter_from_json(file_path: str, json_path: str) -&gt; Any:\n    \"\"\"Extracts a nested value from a JSON file using dot notation.\n\n    Args:\n        file_path: Path to the JSON file.\n        json_path: Dot-separated path like 'section.subsection.key'.\n\n    Returns:\n        The value at the path, or None if not found.\n    \"\"\"\n    if not os.path.exists(file_path):\n        return None\n\n    try:\n        with open(file_path, \"r\") as f:\n            data = json.load(f)\n    except (json.JSONDecodeError, ValueError):\n        return None\n\n    keys = json_path.split(\".\")\n    value = data\n    for key in keys:\n        if isinstance(value, dict) and key in value:\n            value = value[key]\n        else:\n            return None\n    return value\n</code></pre>"},{"location":"reference/api_reference/#goliat.data_extractor.get_parameter","title":"get_parameter","text":"<pre><code>get_parameter(source_config: Dict[str, Any], context: Dict[str, Any]) -&gt; Any\n</code></pre> <p>Retrieves a parameter from a data source using a config-driven approach.</p> <p>Supports JSON sources currently. The source_config defines where to look, and context provides values for formatting paths (e.g., project_root).</p> <p>Parameters:</p> Name Type Description Default <code>source_config</code> <code>Dict[str, Any]</code> <p>Dict with 'source_type', 'file_path_template', 'json_path'.</p> required <code>context</code> <code>Dict[str, Any]</code> <p>Values for formatting file paths.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The retrieved value, or None on error.</p> Source code in <code>goliat/data_extractor.py</code> <pre><code>def get_parameter(source_config: Dict[str, Any], context: Dict[str, Any]) -&gt; Any:\n    \"\"\"Retrieves a parameter from a data source using a config-driven approach.\n\n    Supports JSON sources currently. The source_config defines where to look,\n    and context provides values for formatting paths (e.g., project_root).\n\n    Args:\n        source_config: Dict with 'source_type', 'file_path_template', 'json_path'.\n        context: Values for formatting file paths.\n\n    Returns:\n        The retrieved value, or None on error.\n    \"\"\"\n    source_type = source_config.get(\"source_type\")\n\n    if source_type == \"json\":\n        file_path_template = source_config.get(\"file_path_template\")\n        if not file_path_template:\n            return None\n\n        try:\n            file_path = file_path_template.format(**context)\n        except KeyError as e:\n            import logging\n\n            logging.getLogger(\"verbose\").error(f\"Error: Missing context for placeholder in file_path_template: {e}\")\n            return None\n\n        json_path = source_config.get(\"json_path\")\n        if not json_path:\n            return None\n\n        project_root = context.get(\"project_root\", \"\")\n        full_path = os.path.join(project_root, file_path)\n\n        return get_parameter_from_json(full_path, json_path)\n\n    # Future extension for other data source types\n    # elif source_type == 'simulation':\n    #     # ... implementation for extracting from simulation results ...\n    #     pass\n\n    else:\n        import logging\n\n        logging.getLogger(\"verbose\").error(f\"Error: Unsupported source type '{source_type}'\")\n        return None\n</code></pre>"},{"location":"reference/api_reference/#gui-manager","title":"Gui Manager","text":""},{"location":"reference/api_reference/#goliat.gui_manager","title":"goliat.gui_manager","text":"<p>Main GUI manager module.</p>"},{"location":"reference/api_reference/#goliat.gui_manager-classes","title":"Classes","text":""},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI","title":"QueueGUI","text":"<pre><code>QueueGUI(queue: Queue, stop_event: Event, profiler: Profiler, progress_logger: Logger, verbose_logger: Logger)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Proxy for ProgressGUI that operates in a separate process.</p> <p>Mimics the ProgressGUI interface but routes all calls through a multiprocessing queue, enabling thread-safe communication between worker and GUI processes. All methods serialize their arguments and send them via queue for the GUI process to handle.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>Multiprocessing queue for IPC.</p> required <code>stop_event</code> <code>Event</code> <p>Event flagging user cancellation.</p> required <code>profiler</code> <code>Profiler</code> <p>Profiler for ETA calculations.</p> required <code>progress_logger</code> <code>Logger</code> <p>Logger for progress-level messages.</p> required <code>verbose_logger</code> <code>Logger</code> <p>Logger for detailed messages.</p> required Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def __init__(\n    self,\n    queue: Queue,\n    stop_event: Event,\n    profiler: \"Profiler\",\n    progress_logger: Logger,\n    verbose_logger: Logger,\n) -&gt; None:\n    \"\"\"Sets up the queue GUI proxy.\n\n    Args:\n        queue: Multiprocessing queue for IPC.\n        stop_event: Event flagging user cancellation.\n        profiler: Profiler for ETA calculations.\n        progress_logger: Logger for progress-level messages.\n        verbose_logger: Logger for detailed messages.\n    \"\"\"\n    self.queue: Queue = queue\n    self.stop_event: Event = stop_event\n    self.profiler: \"Profiler\" = profiler\n    self.progress_logger: Logger = progress_logger\n    self.verbose_logger: Logger = verbose_logger\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI.log","title":"log","text":"<pre><code>log(message: str, level: str = 'verbose', log_type: str = 'default') -&gt; None\n</code></pre> <p>Sends a log message to the GUI via queue.</p> <p>All messages are forwarded through the queue for terminal output (S4L 9.2 fix). Progress messages update the GUI status box; verbose messages only print to terminal.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Log message text.</p> required <code>level</code> <code>str</code> <p>Log level ('progress' or 'verbose').</p> <code>'verbose'</code> <code>log_type</code> <code>str</code> <p>Type for color coding in GUI.</p> <code>'default'</code> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def log(self, message: str, level: str = \"verbose\", log_type: str = \"default\") -&gt; None:\n    \"\"\"Sends a log message to the GUI via queue.\n\n    All messages are forwarded through the queue for terminal output (S4L 9.2 fix).\n    Progress messages update the GUI status box; verbose messages only print to terminal.\n\n    Args:\n        message: Log message text.\n        level: Log level ('progress' or 'verbose').\n        log_type: Type for color coding in GUI.\n    \"\"\"\n    import time\n\n    # Use monotonic time with a small increment to ensure unique timestamps\n    # even for messages sent in rapid succession\n    if not hasattr(self, \"_last_timestamp\"):\n        self._last_timestamp = 0.0\n    current_time = time.time()\n    # Ensure timestamp is always increasing, even if system clock jumps backward\n    if current_time &lt;= self._last_timestamp:\n        self._last_timestamp += 0.000001  # 1 microsecond increment\n    else:\n        self._last_timestamp = current_time\n\n    # Determine message type based on level\n    # 'status' messages update GUI status box AND print to terminal\n    # 'terminal_only' messages only print to terminal (for verbose logs)\n    msg_type = \"status\" if level == \"progress\" else \"terminal_only\"\n\n    self.queue.put(\n        {\n            \"type\": msg_type,\n            \"message\": message,\n            \"log_type\": log_type,\n            \"timestamp\": self._last_timestamp,\n        }\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI.update_simulation_details","title":"update_simulation_details","text":"<pre><code>update_simulation_details(sim_count: int, total_sims: int, details: str) -&gt; None\n</code></pre> <p>Sends current simulation case details to GUI.</p> <p>Parameters:</p> Name Type Description Default <code>sim_count</code> <code>int</code> <p>Current simulation number (1-indexed).</p> required <code>total_sims</code> <code>int</code> <p>Total simulations in study.</p> required <code>details</code> <code>str</code> <p>Human-readable description of current case.</p> required Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def update_simulation_details(self, sim_count: int, total_sims: int, details: str) -&gt; None:\n    \"\"\"Sends current simulation case details to GUI.\n\n    Args:\n        sim_count: Current simulation number (1-indexed).\n        total_sims: Total simulations in study.\n        details: Human-readable description of current case.\n    \"\"\"\n    self.queue.put(\n        {\n            \"type\": \"sim_details\",\n            \"count\": sim_count,\n            \"total\": total_sims,\n            \"details\": details,\n        }\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI.update_overall_progress","title":"update_overall_progress","text":"<pre><code>update_overall_progress(current_step: float, total_steps: int) -&gt; None\n</code></pre> <p>Updates overall study progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>current_step</code> <code>float</code> <p>Current step number or percentage (0-100).</p> required <code>total_steps</code> <code>int</code> <p>Total steps in study.</p> required Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def update_overall_progress(self, current_step: float, total_steps: int) -&gt; None:\n    \"\"\"Updates overall study progress bar.\n\n    Args:\n        current_step: Current step number or percentage (0-100).\n        total_steps: Total steps in study.\n    \"\"\"\n    self.queue.put({\"type\": \"overall_progress\", \"current\": current_step, \"total\": total_steps})\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI.update_stage_progress","title":"update_stage_progress","text":"<pre><code>update_stage_progress(stage_name: str, current_step: int, total_steps: int, sub_stage: str = '') -&gt; None\n</code></pre> <p>Updates progress for a specific stage (setup/run/extract).</p> <p>Parameters:</p> Name Type Description Default <code>stage_name</code> <code>str</code> <p>Stage name like 'Setup' or 'Running Simulation'.</p> required <code>current_step</code> <code>int</code> <p>Current step within stage.</p> required <code>total_steps</code> <code>int</code> <p>Total steps for stage.</p> required <code>sub_stage</code> <code>str</code> <p>Optional sub-stage description.</p> <code>''</code> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def update_stage_progress(self, stage_name: str, current_step: int, total_steps: int, sub_stage: str = \"\") -&gt; None:\n    \"\"\"Updates progress for a specific stage (setup/run/extract).\n\n    Args:\n        stage_name: Stage name like 'Setup' or 'Running Simulation'.\n        current_step: Current step within stage.\n        total_steps: Total steps for stage.\n        sub_stage: Optional sub-stage description.\n    \"\"\"\n    self.queue.put(\n        {\n            \"type\": \"stage_progress\",\n            \"name\": stage_name,\n            \"current\": current_step,\n            \"total\": total_steps,\n            \"sub_stage\": sub_stage,\n        }\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI.start_stage_animation","title":"start_stage_animation","text":"<pre><code>start_stage_animation(task_name: str, end_value: int) -&gt; None\n</code></pre> <p>Starts animated progress bar for a stage.</p> <p>Looks up time estimate from profiler and starts animation that progresses toward end_value over that duration.</p> <p>Parameters:</p> Name Type Description Default <code>task_name</code> <code>str</code> <p>Task name ('setup', 'run', 'extract', or subtask name).</p> required <code>end_value</code> <code>int</code> <p>Target progress value (typically 100).</p> required Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def start_stage_animation(self, task_name: str, end_value: int) -&gt; None:\n    \"\"\"Starts animated progress bar for a stage.\n\n    Looks up time estimate from profiler and starts animation that\n    progresses toward end_value over that duration.\n\n    Args:\n        task_name: Task name ('setup', 'run', 'extract', or subtask name).\n        end_value: Target progress value (typically 100).\n    \"\"\"\n    if task_name in [\"setup\", \"run\", \"extract\"]:\n        estimate = self.profiler.profiling_config.get(f\"avg_{task_name}_time\", 60)\n    else:\n        estimate = self.profiler.get_subtask_estimate(task_name)\n    self.queue.put({\"type\": \"start_animation\", \"estimate\": estimate, \"end_value\": end_value})\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI.end_stage_animation","title":"end_stage_animation","text":"<pre><code>end_stage_animation() -&gt; None\n</code></pre> <p>Stops the current animated progress bar.</p> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def end_stage_animation(self) -&gt; None:\n    \"\"\"Stops the current animated progress bar.\"\"\"\n    self.queue.put({\"type\": \"end_animation\"})\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI.update_profiler","title":"update_profiler","text":"<pre><code>update_profiler() -&gt; None\n</code></pre> <p>Sends profiler state to GUI for ETA display.</p> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def update_profiler(self) -&gt; None:\n    \"\"\"Sends profiler state to GUI for ETA display.\"\"\"\n    self.queue.put({\"type\": \"profiler_update\", \"profiler\": self.profiler})\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI.process_events","title":"process_events","text":"<pre><code>process_events() -&gt; None\n</code></pre> <p>No-op for interface compatibility with ProgressGUI.</p> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def process_events(self) -&gt; None:\n    \"\"\"No-op for interface compatibility with ProgressGUI.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.QueueGUI.is_stopped","title":"is_stopped","text":"<pre><code>is_stopped() -&gt; bool\n</code></pre> <p>Checks if user requested cancellation via GUI.</p> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def is_stopped(self) -&gt; bool:\n    \"\"\"Checks if user requested cancellation via GUI.\"\"\"\n    return self.stop_event.is_set()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI","title":"ProgressGUI","text":"<pre><code>ProgressGUI(queue: Queue, stop_event: Event, process: Process, init_window_title: str = '', use_web: bool = True, auto_close: bool = False)\n</code></pre> <p>               Bases: <code>QWidget</code></p> <p>Main GUI window for monitoring simulation progress.</p> <p>Provides real-time progress tracking via progress bars, ETA estimation, and status logs. Runs in the main process and communicates with worker process through a multiprocessing queue.</p> <p>The GUI architecture: - Main window runs in main process, worker runs in separate process - Communication via multiprocessing.Queue for thread-safe message passing - QueueHandler polls queue every 100ms and updates UI - Multiple timers handle different update frequencies (queue, clock, graphs)</p> <p>Features: - Overall progress bar (weighted across all simulations) - Stage progress bar (current phase: setup/run/extract) - Real-time ETA calculation based on profiler estimates - Status log with color-coded messages - Timings table showing execution statistics - Pie charts showing phase/subtask breakdowns - Time series plots for progress and ETA trends - System tray integration for background operation</p> <p>Initializes data manager, status manager, UI builder, timers, and queue handler. Sets up Qt timers for periodic updates (queue polling, clock updates, graph refreshes).</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>Queue for receiving messages from worker process.</p> required <code>stop_event</code> <code>Event</code> <p>Event to signal termination to worker process.</p> required <code>process</code> <code>Process</code> <p>Worker process running the study.</p> required <code>init_window_title</code> <code>str</code> <p>Initial window title.</p> <code>''</code> <code>use_web</code> <code>bool</code> <p>Whether to enable web bridge for remote monitoring.</p> <code>True</code> <code>auto_close</code> <code>bool</code> <p>Whether to automatically close GUI on successful completion.</p> <code>False</code> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def __init__(\n    self,\n    queue: Queue,\n    stop_event: Event,\n    process: Process,\n    init_window_title: str = \"\",\n    use_web: bool = True,\n    auto_close: bool = False,\n) -&gt; None:\n    \"\"\"Sets up the GUI window and all components.\n\n    Initializes data manager, status manager, UI builder, timers, and\n    queue handler. Sets up Qt timers for periodic updates (queue polling,\n    clock updates, graph refreshes).\n\n    Args:\n        queue: Queue for receiving messages from worker process.\n        stop_event: Event to signal termination to worker process.\n        process: Worker process running the study.\n        init_window_title: Initial window title.\n        use_web: Whether to enable web bridge for remote monitoring.\n        auto_close: Whether to automatically close GUI on successful completion.\n    \"\"\"\n    super().__init__()\n    self.queue: Queue = queue\n    self.stop_event: Event = stop_event\n    self.process: Process = process\n    self.start_time: float = time.monotonic()\n    self.progress_logger: logging.Logger = logging.getLogger(\"progress\")\n    self.verbose_logger: logging.Logger = logging.getLogger(\"verbose\")\n    self.init_window_title: str = init_window_title\n    self.auto_close: bool = auto_close\n    self.DEBUG: bool = False\n    self.study_is_finished: bool = False\n    self.study_had_errors: bool = False\n    self.child_exit_code: int = 0  # Exit code from child process (42 = memory error)\n\n    self.total_simulations: int = 0\n    self.current_simulation_count: int = 0\n\n    # Initialize components\n    self._initialize_components()\n\n    # Auto-detect machine ID\n    self.machine_id = MachineIdDetector.detect(self.verbose_logger)\n    self.server_url = \"https://monitor.goliat.waves-ugent.be\"\n\n    # Build UI\n    UIBuilder.build(self, self.status_manager)\n\n    # Initialize managers\n    self.web_bridge_manager = WebBridgeManager(self, self.server_url, self.machine_id, use_web=use_web)\n    self.progress_manager = ProgressManager(self)\n    self.clock_manager = ClockManager(self)\n    self.utilization_manager = UtilizationManager(self)\n    self.graph_manager = GraphManager(self)\n\n    # Initialize web GUI bridge after UI is built (so we can set callback)\n    self.web_bridge_manager.initialize()\n\n    # Initialize animation and other components\n    self._initialize_animation()\n    self._initialize_managers()\n    self._setup_timers()\n    self._initialize_system_monitoring()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.update_overall_progress","title":"update_overall_progress","text":"<pre><code>update_overall_progress(current_step: float, total_steps: int) -&gt; None\n</code></pre> <p>Updates overall progress bar across all simulations.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_overall_progress(self, current_step: float, total_steps: int) -&gt; None:\n    \"\"\"Updates overall progress bar across all simulations.\"\"\"\n    self.progress_manager.update_overall(current_step, total_steps)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.update_stage_progress","title":"update_stage_progress","text":"<pre><code>update_stage_progress(stage_name: str, current_step: int, total_steps: int, sub_stage: str = '') -&gt; None\n</code></pre> <p>Updates stage-specific progress bar and label.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_stage_progress(self, stage_name: str, current_step: int, total_steps: int, sub_stage: str = \"\") -&gt; None:\n    \"\"\"Updates stage-specific progress bar and label.\"\"\"\n    self.progress_manager.update_stage(stage_name, current_step, total_steps, sub_stage)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.start_stage_animation","title":"start_stage_animation","text":"<pre><code>start_stage_animation(estimated_duration: float, end_step: int) -&gt; None\n</code></pre> <p>Starts smooth animated progress bar for a stage.</p> <p>Instead of jumping to discrete progress values, animates smoothly over the estimated duration. This provides visual feedback during long-running tasks where progress updates are infrequent.</p> <p>The animation uses linear interpolation between current value and target (always 100% = 1000). Updates every 50ms via Qt timer.</p> <p>Parameters:</p> Name Type Description Default <code>estimated_duration</code> <code>float</code> <p>Estimated task duration in seconds (from profiler).</p> required <code>end_step</code> <code>int</code> <p>Target step value (unused, always animates to 100%).</p> required Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def start_stage_animation(self, estimated_duration: float, end_step: int) -&gt; None:\n    \"\"\"Starts smooth animated progress bar for a stage.\n\n    Instead of jumping to discrete progress values, animates smoothly over\n    the estimated duration. This provides visual feedback during long-running\n    tasks where progress updates are infrequent.\n\n    The animation uses linear interpolation between current value and target\n    (always 100% = 1000). Updates every 50ms via Qt timer.\n\n    Args:\n        estimated_duration: Estimated task duration in seconds (from profiler).\n        end_step: Target step value (unused, always animates to 100%).\n    \"\"\"\n    if self.DEBUG:\n        self.update_status(f\"DEBUG: start_stage_animation received: duration={estimated_duration:.2f}s, end_step={end_step}\")\n    self.progress_animation.start(estimated_duration, end_step)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.end_stage_animation","title":"end_stage_animation","text":"<pre><code>end_stage_animation() -&gt; None\n</code></pre> <p>Stops stage progress bar animation.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def end_stage_animation(self) -&gt; None:\n    \"\"\"Stops stage progress bar animation.\"\"\"\n    self.progress_animation.stop()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.update_animation","title":"update_animation","text":"<pre><code>update_animation() -&gt; None\n</code></pre> <p>Updates progress bar animation frame and syncs overall progress.</p> <p>Called every 50ms by Qt timer when animation is active. Calculates current progress based on elapsed time and estimated duration, then updates stage progress bar. Also syncs overall progress bar using weighted progress calculation from profiler.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_animation(self) -&gt; None:\n    \"\"\"Updates progress bar animation frame and syncs overall progress.\n\n    Called every 50ms by Qt timer when animation is active. Calculates\n    current progress based on elapsed time and estimated duration, then\n    updates stage progress bar. Also syncs overall progress bar using\n    weighted progress calculation from profiler.\n    \"\"\"\n    self.progress_animation.update()\n\n    # Sync overall progress based on stage animation\n    if self.profiler and self.profiler.current_phase:\n        current_value = self.stage_progress_bar.value()\n        percent = (current_value / 1000) * 100\n        progress = self.profiler.get_weighted_progress(self.profiler.current_phase, percent / 100.0)\n        self.progress_manager.update_overall(progress, 100)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.update_simulation_details","title":"update_simulation_details","text":"<pre><code>update_simulation_details(sim_count: int, total_sims: int, details: str) -&gt; None\n</code></pre> <p>Updates simulation counter and details labels.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_simulation_details(self, sim_count: int, total_sims: int, details: str) -&gt; None:\n    \"\"\"Updates simulation counter and details labels.\"\"\"\n    self.progress_manager.update_simulation_details(sim_count, total_sims, details)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.update_status","title":"update_status","text":"<pre><code>update_status(message: str, log_type: str = 'default') -&gt; None\n</code></pre> <p>Appends message to status log with color formatting.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message text.</p> required <code>log_type</code> <code>str</code> <p>Log type for color coding.</p> <code>'default'</code> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_status(self, message: str, log_type: str = \"default\") -&gt; None:\n    \"\"\"Appends message to status log with color formatting.\n\n    Args:\n        message: Message text.\n        log_type: Log type for color coding.\n    \"\"\"\n    self.status_manager.record_log(log_type)\n    # Update error counter with current web status\n    web_connected = False\n    if (\n        hasattr(self, \"web_bridge_manager\")\n        and self.web_bridge_manager.web_bridge\n        and hasattr(self.web_bridge_manager.web_bridge, \"is_connected\")\n    ):\n        web_connected = self.web_bridge_manager.web_bridge.is_connected\n    self.error_counter_label.setText(self.status_manager.get_error_summary(web_connected=web_connected))\n    formatted_message = self.status_manager.format_message(message, log_type)\n    self.status_text.append(formatted_message)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.update_utilization","title":"update_utilization","text":"<pre><code>update_utilization() -&gt; None\n</code></pre> <p>Updates CPU, RAM, and GPU utilization displays.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_utilization(self) -&gt; None:\n    \"\"\"Updates CPU, RAM, and GPU utilization displays.\"\"\"\n    self.utilization_manager.update()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.update_utilization_plot","title":"update_utilization_plot","text":"<pre><code>update_utilization_plot() -&gt; None\n</code></pre> <p>Updates the system utilization plot with current values.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_utilization_plot(self) -&gt; None:\n    \"\"\"Updates the system utilization plot with current values.\"\"\"\n    self.utilization_manager.update_plot()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.update_clock","title":"update_clock","text":"<pre><code>update_clock() -&gt; None\n</code></pre> <p>Updates elapsed time, ETA labels, and window title.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_clock(self) -&gt; None:\n    \"\"\"Updates elapsed time, ETA labels, and window title.\"\"\"\n    self.clock_manager.update()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.update_graphs","title":"update_graphs","text":"<pre><code>update_graphs() -&gt; None\n</code></pre> <p>Updates time remaining and overall progress graphs.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_graphs(self) -&gt; None:\n    \"\"\"Updates time remaining and overall progress graphs.\"\"\"\n    self.graph_manager.update()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.hide_to_tray","title":"hide_to_tray","text":"<pre><code>hide_to_tray() -&gt; None\n</code></pre> <p>Hides main window and shows system tray icon.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def hide_to_tray(self) -&gt; None:\n    \"\"\"Hides main window and shows system tray icon.\"\"\"\n    self.hide()\n    self.tray_manager.show()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.show_from_tray","title":"show_from_tray","text":"<pre><code>show_from_tray() -&gt; None\n</code></pre> <p>Shows main window from system tray.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def show_from_tray(self) -&gt; None:\n    \"\"\"Shows main window from system tray.\"\"\"\n    self.show()\n    self.tray_manager.hide()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.stop_study","title":"stop_study","text":"<pre><code>stop_study() -&gt; None\n</code></pre> <p>Sends stop signal to worker process.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def stop_study(self) -&gt; None:\n    \"\"\"Sends stop signal to worker process.\"\"\"\n    message = \"--- Sending stop signal to study process ---\"\n    self.progress_logger.info(message, extra={\"log_type\": \"warning\"})\n    self.verbose_logger.info(message, extra={\"log_type\": \"warning\"})\n    self.update_status(message, log_type=\"warning\")\n    self.stop_button.setEnabled(False)\n    self.tray_button.setEnabled(False)\n    self.stop_event.set()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.study_finished","title":"study_finished","text":"<pre><code>study_finished(error: bool = False, memory_error: bool = False) -&gt; None\n</code></pre> <p>Handles study completion, stopping timers and updating UI.</p> <p>Called when worker process signals completion. Stops all timers, updates final progress to 100%, sets stage label, and schedules window auto-close after 3 seconds (if no errors).</p> <p>For memory errors (exit code 42), the GUI auto-closes even with errors so the batch worker can retry the assignment.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>bool</code> <p>Whether study finished with errors (affects UI styling).</p> <code>False</code> <code>memory_error</code> <code>bool</code> <p>Whether this was a memory error (exit code 42).          Memory errors auto-close to allow batch retry.</p> <code>False</code> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def study_finished(self, error: bool = False, memory_error: bool = False) -&gt; None:\n    \"\"\"Handles study completion, stopping timers and updating UI.\n\n    Called when worker process signals completion. Stops all timers,\n    updates final progress to 100%, sets stage label, and schedules\n    window auto-close after 3 seconds (if no errors).\n\n    For memory errors (exit code 42), the GUI auto-closes even with errors\n    so the batch worker can retry the assignment.\n\n    Args:\n        error: Whether study finished with errors (affects UI styling).\n        memory_error: Whether this was a memory error (exit code 42).\n                     Memory errors auto-close to allow batch retry.\n    \"\"\"\n    self.study_is_finished = True\n    self.study_had_errors = error\n    self.clock_timer.stop()\n    self.queue_timer.stop()\n    self.graph_timer.stop()\n    self.utilization_timer.stop()\n    self.utilization_plot_timer.stop()\n    self.progress_sync_timer.stop()\n    self.progress_animation.stop()\n    if not error:\n        self.update_status(\"--- Study Finished ---\", log_type=\"success\")\n        self.overall_progress_bar.setValue(self.overall_progress_bar.maximum())\n        self.stage_label.setText(\"Finished\")\n    elif memory_error:\n        self.update_status(\"--- Study Stopped: Memory Error (will retry) ---\", log_type=\"fatal\")\n        self.stage_label.setText(\"Memory Error\")\n    else:\n        self.update_status(\"--- Study Finished with Errors ---\", log_type=\"fatal\")\n        self.stage_label.setText(\"Error\")\n\n    self.stop_button.setEnabled(False)\n    self.tray_button.setEnabled(False)\n\n    # Send final status update to web before stopping bridge\n    self.web_bridge_manager.send_finished(error)\n\n    self.update_clock()  # Final title update\n\n    # Instead of auto-closing, show a message that user can close the window\n    if not error:\n        self.progress_logger.info(\"All done! You may close this window now.\", extra={\"log_type\": \"success\"})\n        self.update_status(\"\\n\u2713 All done! You may close this window now.\", log_type=\"success\")\n        # Auto-close if enabled (used by batch worker mode)\n        if self.auto_close:\n            self.progress_logger.info(\"Auto-closing GUI in 2 seconds...\", extra={\"log_type\": \"info\"})\n            from PySide6.QtCore import QTimer as _QTimer\n\n            _QTimer.singleShot(2000, self.close)\n    elif memory_error:\n        # Memory errors should ALWAYS auto-close so the process can be restarted to free GPU memory.\n        # This is required for both batch worker retry logic and persistent mode retry logic.\n        # Unlike normal errors, memory errors cannot be resolved without a full process restart.\n        self.progress_logger.info(\"Memory error detected. Auto-closing for retry...\", extra={\"log_type\": \"warning\"})\n        self.update_status(\"\\n\u26a0 Memory error detected. Auto-closing for retry...\", log_type=\"warning\")\n        from PySide6.QtCore import QTimer as _QTimer\n\n        _QTimer.singleShot(2000, self.close)\n    else:\n        self.progress_logger.info(\"Finished with errors. You may close this window now.\", extra={\"log_type\": \"warning\"})\n        self.update_status(\"\\n\u2713 Finished with errors. You may close this window now.\", log_type=\"warning\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui_manager.ProgressGUI.closeEvent","title":"closeEvent","text":"<pre><code>closeEvent(event: Any) -&gt; None\n</code></pre> <p>Handles window close event, ensuring worker process termination.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Any</code> <p>Close event.</p> required Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def closeEvent(self, event: Any) -&gt; None:\n    \"\"\"Handles window close event, ensuring worker process termination.\n\n    Args:\n        event: Close event.\n    \"\"\"\n    if self.tray_manager.is_visible():\n        self.tray_manager.hide()\n\n    if self.process.is_alive():\n        self.progress_logger.info(\"Terminating study process...\", extra={\"log_type\": \"warning\"})\n        self.process.terminate()\n        self.process.join(timeout=5)\n\n    # Stop web bridge if enabled\n    self.web_bridge_manager.stop()\n\n    shutdown_loggers()\n    event.accept()\n</code></pre>"},{"location":"reference/api_reference/#logging-manager","title":"Logging Manager","text":""},{"location":"reference/api_reference/#goliat.logging_manager.ColorFormatter","title":"goliat.logging_manager.ColorFormatter","text":"<p>               Bases: <code>Formatter</code></p> <p>Custom formatter that colorizes log messages based on log_type.</p> <p>Applies colorama color codes to messages and caller info based on the log_type attribute (info, warning, error, success, etc.).</p>"},{"location":"reference/api_reference/#goliat.logging_manager.ColorFormatter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.logging_manager.ColorFormatter.format","title":"format","text":"<pre><code>format(record: LogRecord) -&gt; str\n</code></pre> <p>Adds color codes to log messages based on log_type.</p> Source code in <code>goliat/logging_manager.py</code> <pre><code>def format(self, record: logging.LogRecord) -&gt; str:\n    \"\"\"Adds color codes to log messages based on log_type.\"\"\"\n    log_type = getattr(record, \"log_type\", \"default\")\n    message_color = get_color(log_type)\n    caller_color = get_color(\"caller\")\n    message = record.getMessage()\n    caller_info = getattr(record, \"caller_info\", \"\")\n    return f\"{message_color}{message}{Style.RESET_ALL} {caller_color}{caller_info}{Style.RESET_ALL}\"\n</code></pre>"},{"location":"reference/api_reference/#metadata-exporter","title":"Metadata Exporter","text":""},{"location":"reference/api_reference/#goliat.metadata_exporter.TimingBreakdown","title":"goliat.metadata_exporter.TimingBreakdown  <code>dataclass</code>","text":"<pre><code>TimingBreakdown(phase_name: str, avg_time_s: float, total_time_s: float, num_executions: int, subtasks: dict[str, float] = dict())\n</code></pre> <p>Breakdown of timing data for a single phase.</p>"},{"location":"reference/api_reference/#profiler","title":"Profiler","text":""},{"location":"reference/api_reference/#goliat.profiler.Profiler","title":"goliat.profiler.Profiler","text":"<pre><code>Profiler(execution_control: dict, profiling_config: dict, study_type: str, config_path: str)\n</code></pre> <p>Manages execution time tracking, ETA estimation, and study phase management.</p> <p>This class divides a study into phases (setup, run, extract), calculates weighted progress, and estimates the time remaining. It also saves updated time estimates to a configuration file after each run, making it self-improving.</p> <p>Parameters:</p> Name Type Description Default <code>execution_control</code> <code>dict</code> <p>Dict indicating which phases are enabled.</p> required <code>profiling_config</code> <code>dict</code> <p>Historical timing data for estimates.</p> required <code>study_type</code> <code>str</code> <p>Study type ('near_field' or 'far_field').</p> required <code>config_path</code> <code>str</code> <p>Path where profiling config is saved.</p> required Source code in <code>goliat/profiler.py</code> <pre><code>def __init__(\n    self,\n    execution_control: dict,\n    profiling_config: dict,\n    study_type: str,\n    config_path: str,\n):\n    \"\"\"Initialize profiler with phase weights and timing config.\n\n    Args:\n        execution_control: Dict indicating which phases are enabled.\n        profiling_config: Historical timing data for estimates.\n        study_type: Study type ('near_field' or 'far_field').\n        config_path: Path where profiling config is saved.\n    \"\"\"\n    self.execution_control = execution_control\n    self.profiling_config = profiling_config\n    self.study_type = study_type\n    self.config_path = config_path\n\n    self.phase_weights = self._calculate_phase_weights()\n    self.subtask_times = defaultdict(list)\n    self.subtask_stack = []\n\n    self.total_simulations = 0\n    self.completed_simulations = 0\n    self.total_projects = 0\n    self.current_project = 0\n    self.completed_phases = set()\n\n    self.start_time = time.monotonic()\n    self.current_phase = None\n    self.phase_start_time = None\n    self.phase_skipped = False\n    self.run_phase_total_duration = 0\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.profiler.Profiler.set_total_simulations","title":"set_total_simulations","text":"<pre><code>set_total_simulations(total: int)\n</code></pre> <p>Sets total simulation count for progress tracking.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def set_total_simulations(self, total: int):\n    \"\"\"Sets total simulation count for progress tracking.\"\"\"\n    self.total_simulations = total\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.set_project_scope","title":"set_project_scope","text":"<pre><code>set_project_scope(total_projects: int)\n</code></pre> <p>Sets total project count for progress tracking.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def set_project_scope(self, total_projects: int):\n    \"\"\"Sets total project count for progress tracking.\"\"\"\n    self.total_projects = total_projects\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.set_current_project","title":"set_current_project","text":"<pre><code>set_current_project(project_index: int)\n</code></pre> <p>Sets the current project index.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def set_current_project(self, project_index: int):\n    \"\"\"Sets the current project index.\"\"\"\n    self.current_project = project_index\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.simulation_completed","title":"simulation_completed","text":"<pre><code>simulation_completed()\n</code></pre> <p>Marks one simulation as completed.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def simulation_completed(self):\n    \"\"\"Marks one simulation as completed.\"\"\"\n    self.completed_simulations += 1\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.start_stage","title":"start_stage","text":"<pre><code>start_stage(phase_name: str, total_stages: int = 1)\n</code></pre> <p>Starts tracking a new phase (setup/run/extract).</p> <p>Parameters:</p> Name Type Description Default <code>phase_name</code> <code>str</code> <p>Phase name like 'setup', 'run', or 'extract'.</p> required <code>total_stages</code> <code>int</code> <p>Number of stages within this phase.</p> <code>1</code> Source code in <code>goliat/profiler.py</code> <pre><code>def start_stage(self, phase_name: str, total_stages: int = 1):\n    \"\"\"Starts tracking a new phase (setup/run/extract).\n\n    Args:\n        phase_name: Phase name like 'setup', 'run', or 'extract'.\n        total_stages: Number of stages within this phase.\n    \"\"\"\n    self.current_phase = phase_name\n    self.phase_start_time = time.monotonic()\n    self.phase_skipped = False\n    self.completed_stages_in_phase = 0\n    self.total_stages_in_phase = total_stages\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.end_stage","title":"end_stage","text":"<pre><code>end_stage()\n</code></pre> <p>Ends current phase and records its duration for future estimates.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def end_stage(self):\n    \"\"\"Ends current phase and records its duration for future estimates.\"\"\"\n    if self.phase_start_time:\n        elapsed = time.monotonic() - self.phase_start_time\n\n        # For setup phase: if it was cached/skipped, don't add to statistics\n        # (cached phases pollute real execution time statistics)\n        if self.current_phase == \"setup\" and self.phase_skipped:\n            # Cached setup: don't pollute statistics\n            # avg_{phase}_time remains unchanged (uses previous real measurements)\n            pass\n        else:\n            # Real phase: add to statistics and compute simple average for display\n            self.subtask_times[self.current_phase].append(elapsed)\n            times = self.subtask_times[self.current_phase]\n            # Store simple average for pie charts, timings table, etc.\n            self.profiling_config[f\"avg_{self.current_phase}_time\"] = sum(times) / len(times)\n\n    self.current_phase = None\n    self.phase_skipped = False  # Reset for next phase\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.complete_run_phase","title":"complete_run_phase","text":"<pre><code>complete_run_phase()\n</code></pre> <p>Stores the total duration of the 'run' phase from its subtasks.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def complete_run_phase(self):\n    \"\"\"Stores the total duration of the 'run' phase from its subtasks.\"\"\"\n    self.run_phase_total_duration = sum(self.subtask_times.get(\"run_simulation_total\", [0]))\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.get_weighted_progress","title":"get_weighted_progress","text":"<pre><code>get_weighted_progress(phase_name: str, phase_progress_ratio: float) -&gt; float\n</code></pre> <p>Calculates overall study progress using phase weights and simulation count.</p> <p>This method handles the complexity that different phases (setup, run, extract) take different amounts of time. For example, if setup takes 10 minutes, run takes 2 hours, and extract takes 5 minutes, then the run phase should account for roughly 85% of the progress bar, not 33%.</p> <p>The calculation works in two parts: 1. Progress within current simulation: Sums weights of completed phases,    plus partial weight for the current phase based on its progress ratio. 2. Overall progress: Divides (completed_simulations + current_sim_progress)    by total_simulations to get the overall percentage.</p> <p>Parameters:</p> Name Type Description Default <code>phase_name</code> <code>str</code> <p>The name of the current phase ('setup', 'run', or 'extract').</p> required <code>phase_progress_ratio</code> <code>float</code> <p>Progress within current phase (0.0 = not started,                  1.0 = fully complete).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Overall progress percentage (0.0 to 100.0).</p> Source code in <code>goliat/profiler.py</code> <pre><code>def get_weighted_progress(self, phase_name: str, phase_progress_ratio: float) -&gt; float:\n    \"\"\"Calculates overall study progress using phase weights and simulation count.\n\n    This method handles the complexity that different phases (setup, run, extract)\n    take different amounts of time. For example, if setup takes 10 minutes, run takes\n    2 hours, and extract takes 5 minutes, then the run phase should account for\n    roughly 85% of the progress bar, not 33%.\n\n    The calculation works in two parts:\n    1. Progress within current simulation: Sums weights of completed phases,\n       plus partial weight for the current phase based on its progress ratio.\n    2. Overall progress: Divides (completed_simulations + current_sim_progress)\n       by total_simulations to get the overall percentage.\n\n    Args:\n        phase_name: The name of the current phase ('setup', 'run', or 'extract').\n        phase_progress_ratio: Progress within current phase (0.0 = not started,\n                             1.0 = fully complete).\n\n    Returns:\n        Overall progress percentage (0.0 to 100.0).\n    \"\"\"\n    if self.total_simulations == 0:\n        return 0.0\n\n    # Progress within the current simulation\n    progress_current_sim = 0\n    for p, w in self.phase_weights.items():\n        if p == phase_name:\n            progress_current_sim += w * phase_progress_ratio\n            break\n        progress_current_sim += w\n\n    # Overall progress\n    overall_progress = (self.completed_simulations + progress_current_sim) / self.total_simulations\n    # print(f\"DEBUG: get_weighted_progress: phase={phase_name}, ratio={phase_progress_ratio:.2f}, completed={self.completed_simulations}, total={self.total_simulations}, progress={overall_progress * 100:.1f}%\")\n    return overall_progress * 100\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.get_subtask_estimate","title":"get_subtask_estimate","text":"<pre><code>get_subtask_estimate(task_name: str) -&gt; float\n</code></pre> <p>Retrieves the estimated time for a specific subtask. Args:     task_name: The name of the subtask. Returns:     The estimated duration in seconds.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def get_subtask_estimate(self, task_name: str) -&gt; float:\n    \"\"\"Retrieves the estimated time for a specific subtask.\n    Args:\n        task_name: The name of the subtask.\n    Returns:\n        The estimated duration in seconds.\n    \"\"\"\n    return self.profiling_config.get(f\"avg_{task_name}\", 1.0)\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.get_phase_subtasks","title":"get_phase_subtasks","text":"<pre><code>get_phase_subtasks(phase_name: str) -&gt; list\n</code></pre> <p>Gets a list of subtasks for a given phase. Args:     phase_name: The name of the phase. Returns:     A list of subtask names.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def get_phase_subtasks(self, phase_name: str) -&gt; list:\n    \"\"\"Gets a list of subtasks for a given phase.\n    Args:\n        phase_name: The name of the phase.\n    Returns:\n        A list of subtask names.\n    \"\"\"\n    subtasks = []\n    for key in self.profiling_config.keys():\n        if key.startswith(f\"avg_{phase_name}_\"):\n            subtasks.append(key.replace(\"avg_\", \"\"))\n    return subtasks\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.get_time_remaining","title":"get_time_remaining","text":"<pre><code>get_time_remaining(current_stage_progress: float = 0.0) -&gt; float\n</code></pre> <p>Estimates total time remaining for the entire study.</p> <p>Uses historical timing data to predict how long each phase will take, then calculates remaining time by subtracting elapsed time from total estimated time. This gives a realistic ETA that accounts for the fact that different phases take different amounts of time.</p> <p>The calculation considers: - Time already spent on fully completed simulations - Time spent on phases within the current simulation that are done - Estimated time remaining in the current phase (based on progress ratio) - Estimated time for all future simulations</p> <p>Parameters:</p> Name Type Description Default <code>current_stage_progress</code> <code>float</code> <p>Progress within current stage (0.0 to 1.0).</p> <code>0.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Estimated time remaining in seconds.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def get_time_remaining(self, current_stage_progress: float = 0.0) -&gt; float:\n    \"\"\"Estimates total time remaining for the entire study.\n\n    Uses historical timing data to predict how long each phase will take,\n    then calculates remaining time by subtracting elapsed time from total\n    estimated time. This gives a realistic ETA that accounts for the fact\n    that different phases take different amounts of time.\n\n    The calculation considers:\n    - Time already spent on fully completed simulations\n    - Time spent on phases within the current simulation that are done\n    - Estimated time remaining in the current phase (based on progress ratio)\n    - Estimated time for all future simulations\n\n    Args:\n        current_stage_progress: Progress within current stage (0.0 to 1.0).\n\n    Returns:\n        Estimated time remaining in seconds.\n    \"\"\"\n    if not self.current_phase or self.total_simulations == 0:\n        return 0.0\n\n    # Calculate the total estimated time for one simulation using smart estimates\n    total_time_per_sim = 0\n    for phase in [\"setup\", \"run\", \"extract\"]:\n        if self.execution_control.get(f\"do_{phase}\", False):\n            total_time_per_sim += self._get_smart_phase_estimate(phase)\n\n    # Calculate estimated time remaining in the current simulation\n    ordered_phases = [p for p in [\"setup\", \"run\", \"extract\"] if self.execution_control.get(f\"do_{p}\", False)]\n    try:\n        current_phase_index = ordered_phases.index(self.current_phase)\n    except ValueError:\n        current_phase_index = 0\n\n    # Estimated time remaining in current phase (based on progress)\n    # Clamp progress to [0.0, 1.0] to handle edge cases\n    progress = max(0.0, min(1.0, current_stage_progress))\n    current_phase_time = self._get_smart_phase_estimate(self.current_phase)\n    time_remaining_in_current_sim = current_phase_time * (1.0 - progress)\n\n    # Add time for phases not yet started in current simulation\n    for i in range(current_phase_index + 1, len(ordered_phases)):\n        phase = ordered_phases[i]\n        time_remaining_in_current_sim += self._get_smart_phase_estimate(phase)\n\n    # Calculate remaining simulations (excluding current one)\n    remaining_simulations = self.total_simulations - self.completed_simulations - 1\n\n    # Estimated time remaining = time left in current sim + time for all remaining sims\n    eta = time_remaining_in_current_sim + (remaining_simulations * total_time_per_sim)\n    return max(0, eta)\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.subtask","title":"subtask","text":"<pre><code>subtask(task_name: str)\n</code></pre> <p>A context manager to time a subtask.</p> Source code in <code>goliat/profiler.py</code> <pre><code>@contextlib.contextmanager\ndef subtask(self, task_name: str):\n    \"\"\"A context manager to time a subtask.\"\"\"\n    self.subtask_stack.append({\"name\": task_name, \"start_time\": time.monotonic()})\n    try:\n        yield\n    finally:\n        subtask = self.subtask_stack.pop()\n        elapsed = time.monotonic() - subtask[\"start_time\"]\n        self.subtask_times[subtask[\"name\"]].append(elapsed)\n        self.update_and_save_estimates()\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.update_and_save_estimates","title":"update_and_save_estimates","text":"<pre><code>update_and_save_estimates()\n</code></pre> <p>Updates the profiling configuration with the latest average times and saves it.</p> <p>This makes the profiler's estimates self-improving over time.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def update_and_save_estimates(self):\n    \"\"\"Updates the profiling configuration with the latest average times and saves it.\n\n    This makes the profiler's estimates self-improving over time.\n    \"\"\"\n    try:\n        with open(self.config_path, \"r\") as f:\n            full_config = json.load(f)\n    except (FileNotFoundError, json.JSONDecodeError):\n        full_config = {}\n\n    if self.study_type not in full_config:\n        full_config[self.study_type] = {}\n\n    for key, value in self.profiling_config.items():\n        if key.startswith(\"avg_\"):\n            full_config[self.study_type][key] = round(value, 2)\n\n    for task_name, times in self.subtask_times.items():\n        if times:\n            avg_task_time = sum(times) / len(times)\n            avg_key = f\"avg_{task_name}\"\n            full_config[self.study_type][avg_key] = round(avg_task_time, 2)\n            # Also update the in-memory profiling_config so it's available when sent to GUI\n            self.profiling_config[avg_key] = round(avg_task_time, 2)\n\n    with open(self.config_path, \"w\") as f:\n        json.dump(full_config, f, indent=4)\n</code></pre>"},{"location":"reference/api_reference/#goliat.profiler.Profiler.save_estimates","title":"save_estimates","text":"<pre><code>save_estimates()\n</code></pre> <p>Saves the final profiling estimates at the end of the study.</p> Source code in <code>goliat/profiler.py</code> <pre><code>def save_estimates(self):\n    \"\"\"Saves the final profiling estimates at the end of the study.\"\"\"\n    self.update_and_save_estimates()\n</code></pre>"},{"location":"reference/api_reference/#project-manager","title":"Project Manager","text":""},{"location":"reference/api_reference/#goliat.project_manager.ProjectCorruptionError","title":"goliat.project_manager.ProjectCorruptionError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a project file is corrupted, locked, or inaccessible.</p>"},{"location":"reference/api_reference/#results-extractor","title":"Results Extractor","text":""},{"location":"reference/api_reference/#goliat.results_extractor.ExtractionContext","title":"goliat.results_extractor.ExtractionContext  <code>dataclass</code>","text":"<pre><code>ExtractionContext(config: Config, simulation: Simulation, phantom_name: str, frequency_mhz: int | list[int], scenario_name: str, position_name: str, orientation_name: str, study_type: str, verbose_logger: Logger, progress_logger: Logger, free_space: bool = False, gui: Optional[QueueGUI] = None, study: Optional[BaseStudy] = None)\n</code></pre> <p>Context object containing all parameters needed for result extraction.</p> <p>Groups related parameters together to reduce the parameter count of ResultsExtractor.init.</p>"},{"location":"reference/api_reference/#simulation-runner","title":"Simulation Runner","text":""},{"location":"reference/api_reference/#goliat.simulation_runner.SimulationRunner","title":"goliat.simulation_runner.SimulationRunner","text":"<pre><code>SimulationRunner(config: Config, project_path: str, simulation: Simulation, profiler: Profiler, verbose_logger: Logger, progress_logger: Logger, project_manager: ProjectManager, gui: Optional[QueueGUI] = None)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Manages simulation execution via the Sim4Life API or iSolve.exe.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required <code>project_path</code> <code>str</code> <p>Path to the Sim4Life project file.</p> required <code>simulation</code> <code>Simulation</code> <p>The simulation object to run.</p> required <code>profiler</code> <code>Profiler</code> <p>Profiler for timing subtasks.</p> required <code>verbose_logger</code> <code>Logger</code> <p>Logger for detailed output.</p> required <code>progress_logger</code> <code>Logger</code> <p>Logger for high-level updates.</p> required <code>gui</code> <code>Optional[QueueGUI]</code> <p>Optional GUI proxy for updates.</p> <code>None</code> <code>project_manager</code> <code>ProjectManager</code> <p>ProjectManager instance. Uses its save() method.</p> required Source code in <code>goliat/simulation_runner.py</code> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    project_path: str,\n    simulation: \"s4l_v1.simulation.emfdtd.Simulation\",\n    profiler: \"Profiler\",\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n    project_manager: \"ProjectManager\",\n    gui: \"Optional[QueueGUI]\" = None,\n):\n    \"\"\"Sets up the simulation runner.\n\n    Args:\n        config: Configuration object.\n        project_path: Path to the Sim4Life project file.\n        simulation: The simulation object to run.\n        profiler: Profiler for timing subtasks.\n        verbose_logger: Logger for detailed output.\n        progress_logger: Logger for high-level updates.\n        gui: Optional GUI proxy for updates.\n        project_manager: ProjectManager instance. Uses its save() method.\n    \"\"\"\n    self.config = config\n    self.project_path = project_path\n    self.simulation = simulation\n    self.profiler = profiler\n    self.verbose_logger = verbose_logger\n    self.progress_logger = progress_logger\n    self.gui = gui\n    self.project_manager = project_manager\n    import s4l_v1.document\n\n    self.document = s4l_v1.document\n    self.current_strategy: Optional[\"ExecutionStrategy\"] = None  # Track current execution strategy\n    _active_runners.add(self)  # Register this instance for global cleanup\n</code></pre>"},{"location":"reference/api_reference/#goliat.simulation_runner.SimulationRunner-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.simulation_runner.SimulationRunner.run","title":"run","text":"<pre><code>run()\n</code></pre> <p>Runs the simulation using the configured execution method.</p> <p>Writes input file first, then runs via Sim4Life API, manual iSolve, or oSPARC depending on config. Handles errors and provides helpful messages for common issues.</p> Source code in <code>goliat/simulation_runner.py</code> <pre><code>def run(self):\n    \"\"\"Runs the simulation using the configured execution method.\n\n    Writes input file first, then runs via Sim4Life API, manual iSolve,\n    or oSPARC depending on config. Handles errors and provides helpful\n    messages for common issues.\n    \"\"\"\n    if not self.simulation:\n        self._log(\n            \"ERROR: Simulation object not found. Cannot run simulation.\",\n            level=\"progress\",\n            log_type=\"error\",\n        )\n        return\n    self._log(f\"Running simulation: {self.simulation.Name}\", log_type=\"verbose\")\n\n    server_name = (self.config[\"solver_settings\"] or {}).get(\"server\")\n\n    try:\n        if hasattr(self.simulation, \"WriteInputFile\"):\n            self._log(\n                \"    - Write input file...\",\n                level=\"progress\",\n                log_type=\"progress\",\n            )\n            with self.profiler.subtask(\"run_write_input_file\"):\n                self.simulation.WriteInputFile()\n                # Force a save to flush files\n                self.project_manager.save()\n            elapsed = self.profiler.subtask_times[\"run_write_input_file\"][-1]\n            self._log(f\"      - Subtask 'run_write_input_file' done in {elapsed:.2f}s\", log_type=\"verbose\")\n            self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n        # Stop here if we only want to write the input file\n        if self.config.get_only_write_input_file():\n            self._log(\n                \"'only_write_input_file' is true, skipping simulation run.\",\n                level=\"progress\",\n                log_type=\"info\",\n            )\n            return\n\n        # Select and execute strategy\n        strategy = self._create_execution_strategy(server_name)\n        self.current_strategy = strategy\n        try:\n            strategy.run()\n        finally:\n            self.current_strategy = None\n\n    except Exception as e:\n        self._log(\n            f\"An error occurred during simulation run: {e}\",\n            level=\"progress\",\n            log_type=\"error\",\n        )\n        # Check if a cloud server was intended for the run\n        server_name = (self.config[\"solver_settings\"] or {}).get(\"server\")\n        if server_name and server_name != \"localhost\":\n            self._log(\n                \"If you are running on the cloud, please ensure you are logged into Sim4Life \"\n                \"via the GUI and your API credentials are correct.\",\n                level=\"progress\",\n                log_type=\"warning\",\n            )\n        self.verbose_logger.error(traceback.format_exc())\n\n    return self.simulation\n</code></pre>"},{"location":"reference/api_reference/#configuration","title":"Configuration","text":"<p>Configuration management and settings.</p>"},{"location":"reference/api_reference/#core","title":"Core","text":""},{"location":"reference/api_reference/#goliat.config.core.Config","title":"goliat.config.core.Config","text":"<pre><code>Config(base_dir: str, config_filename: str = 'near_field_config.json', no_cache: bool = False)\n</code></pre> <p>Manages loading and access of hierarchical JSON configurations.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>str</code> <p>The base directory of the project.</p> required <code>config_filename</code> <code>str</code> <p>The name of the main configuration file to load.</p> <code>'near_field_config.json'</code> <code>no_cache</code> <code>bool</code> <p>This parameter is accepted but not used directly by the Config class.       It's used by other managers to control caching behavior.</p> <code>False</code> Source code in <code>goliat/config/core.py</code> <pre><code>def __init__(self, base_dir: str, config_filename: str = \"near_field_config.json\", no_cache: bool = False):\n    \"\"\"Load main config, material mapping, and profiling config.\n\n    Args:\n        base_dir: The base directory of the project.\n        config_filename: The name of the main configuration file to load.\n        no_cache: This parameter is accepted but not used directly by the Config class.\n                  It's used by other managers to control caching behavior.\n    \"\"\"\n    self.base_dir = base_dir\n    self.config_path = self._resolve_config_path(config_filename, self.base_dir)\n    self.material_mapping_path = os.path.join(self.base_dir, \"data\", \"material_name_mapping.json\")\n\n    # Generate session hash for profiling config (similar to GUI session tracking)\n    session_hash = hashlib.md5(f\"{time.time()}_{os.getpid()}\".encode()).hexdigest()[:8]\n    data_dir = os.path.join(self.base_dir, \"data\")\n    os.makedirs(data_dir, exist_ok=True)\n\n    # Generate timestamp for filename\n    session_timestamp = datetime.now().strftime(\"%d-%m_%H-%M-%S\")\n\n    # Cleanup old JSON files before creating new one\n    cleanup_old_data_files(data_dir)\n\n    self.profiling_config_path = os.path.join(data_dir, f\"profiling_config_{session_timestamp}_{session_hash}.json\")\n\n    self.config = self._load_config_with_inheritance(self.config_path)\n\n    # Load material mapping - provide helpful error if missing\n    try:\n        self.material_mapping = self._load_json(self.material_mapping_path)\n    except FileNotFoundError:\n        raise FileNotFoundError(\n            f\"Material mapping file not found at: {self.material_mapping_path}\\nPlease run 'goliat init' to set up the required files.\"\n        )\n\n    # Load or initialize profiling config\n    self.profiling_config = load_or_create_profiling_config(self.profiling_config_path)\n\n    # Load detuning config if enabled\n    self.detuning_data = None\n    self.detuning_enabled = self.config.get(\"detuning_enabled\", \"\") or False\n    self.detuning_write_during_calibration = self.config.get(\"detuning_write_during_calibration\", \"\") or False\n\n    if self.detuning_enabled:\n        # Validate study type\n        study_type = self.config[\"study_type\"]\n        if study_type == \"far_field\":\n            raise ValueError(\"Detuning feature is only supported for near_field studies, not far_field\")\n\n        detuning_config_path = self.config.get(\"detuning_config\", \"\")\n        if detuning_config_path:\n            resolved_path = self._resolve_path_relative_to_config(self.config_path, detuning_config_path)\n            self.detuning_data = self._load_detuning_config(resolved_path)\n        else:\n            import logging\n\n            logging.getLogger(\"progress\").warning(\n                \"detuning_enabled is true but detuning_config not specified. Detuning will default to 0.\", extra={\"log_type\": \"warning\"}\n            )\n    elif self.config.get(\"detuning_config\", \"\"):\n        # Only warn if config provided but both enabled and write are false\n        # If write_during_calibration is true, we're in calibration mode (writing), so no warning needed\n        if not self.detuning_write_during_calibration:\n            import logging\n\n            logging.getLogger(\"progress\").warning(\n                \"detuning_config provided but detuning_enabled is false, ignoring detuning config\", extra={\"log_type\": \"warning\"}\n            )\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.core.Config-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.config.core.Config.get_material_mapping","title":"get_material_mapping","text":"<pre><code>get_material_mapping(phantom_name: str) -&gt; dict\n</code></pre> <p>Gets the material name mapping for a specific phantom.</p> <p>Parameters:</p> Name Type Description Default <code>phantom_name</code> <code>str</code> <p>The name of the phantom.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The material mapping dictionary.</p> Source code in <code>goliat/config/core.py</code> <pre><code>def get_material_mapping(self, phantom_name: str) -&gt; dict:\n    \"\"\"Gets the material name mapping for a specific phantom.\n\n    Args:\n        phantom_name: The name of the phantom.\n\n    Returns:\n        The material mapping dictionary.\n    \"\"\"\n    if phantom_name in self.material_mapping:\n        return self.material_mapping[phantom_name]\n    else:\n        return self.material_mapping\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.core.Config.get_profiling_config","title":"get_profiling_config","text":"<pre><code>get_profiling_config(study_type: str) -&gt; dict\n</code></pre> <p>Gets the profiling configuration for a given study type.</p> <p>Parameters:</p> Name Type Description Default <code>study_type</code> <code>str</code> <p>The type of the study (e.g., 'near_field').</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The profiling configuration for the study type.</p> Source code in <code>goliat/config/core.py</code> <pre><code>def get_profiling_config(self, study_type: str) -&gt; dict:\n    \"\"\"Gets the profiling configuration for a given study type.\n\n    Args:\n        study_type: The type of the study (e.g., 'near_field').\n\n    Returns:\n        The profiling configuration for the study type.\n    \"\"\"\n    return get_profiling_config(self.profiling_config, study_type)\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.core.Config.get_download_email","title":"get_download_email","text":"<pre><code>get_download_email() -&gt; str\n</code></pre> <p>Returns the download email from environment variables.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If DOWNLOAD_EMAIL is not set in the environment.</p> Source code in <code>goliat/config/core.py</code> <pre><code>def get_download_email(self) -&gt; str:\n    \"\"\"Returns the download email from environment variables.\n\n    Raises:\n        ValueError: If DOWNLOAD_EMAIL is not set in the environment.\n    \"\"\"\n    return get_download_email()\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.core.Config.get_osparc_credentials","title":"get_osparc_credentials","text":"<pre><code>get_osparc_credentials() -&gt; dict\n</code></pre> <p>Gets oSPARC credentials from environment variables.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required oSPARC credentials are not set.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing oSPARC API credentials.</p> Source code in <code>goliat/config/core.py</code> <pre><code>def get_osparc_credentials(self) -&gt; dict:\n    \"\"\"Gets oSPARC credentials from environment variables.\n\n    Raises:\n        ValueError: If required oSPARC credentials are not set.\n\n    Returns:\n        A dictionary containing oSPARC API credentials.\n    \"\"\"\n    return get_osparc_credentials()\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.core.Config.get_only_write_input_file","title":"get_only_write_input_file","text":"<pre><code>get_only_write_input_file() -&gt; bool\n</code></pre> <p>Returns whether to only write input files without running simulations.</p> Source code in <code>goliat/config/core.py</code> <pre><code>def get_only_write_input_file(self) -&gt; bool:\n    \"\"\"Returns whether to only write input files without running simulations.\"\"\"\n    result = self[\"execution_control.only_write_input_file\"]\n    if result is None:\n        result = False\n    assert isinstance(result, bool)\n    return result\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.core.Config.get_auto_cleanup_previous_results","title":"get_auto_cleanup_previous_results","text":"<pre><code>get_auto_cleanup_previous_results() -&gt; list\n</code></pre> <p>Gets the 'auto_cleanup_previous_results' setting from 'execution_control'.</p> <p>This setting determines which previous simulation files to automatically delete to preserve disk space. It should only be used in serial workflows.</p> <p>Also checks GOLIAT_AUTO_CLEANUP environment variable for worker scenarios where config is downloaded from cloud. Format: comma-separated values like \"output,input\".</p> <p>Returns:</p> Type Description <code>list</code> <p>A list of file types to clean up (e.g., [\"output\", \"input\"]).</p> Source code in <code>goliat/config/core.py</code> <pre><code>def get_auto_cleanup_previous_results(self) -&gt; list:\n    \"\"\"Gets the 'auto_cleanup_previous_results' setting from 'execution_control'.\n\n    This setting determines which previous simulation files to automatically delete\n    to preserve disk space. It should only be used in serial workflows.\n\n    Also checks GOLIAT_AUTO_CLEANUP environment variable for worker scenarios where\n    config is downloaded from cloud. Format: comma-separated values like \"output,input\".\n\n    Returns:\n        A list of file types to clean up (e.g., [\"output\", \"input\"]).\n    \"\"\"\n    # Check environment variable first (for worker scenarios)\n    env_cleanup = os.environ.get(\"GOLIAT_AUTO_CLEANUP\", \"\").strip()\n    if env_cleanup:\n        # Parse comma-separated values\n        env_types = [t.strip().lower() for t in env_cleanup.split(\",\") if t.strip()]\n        valid_types = {\"output\", \"input\", \"smash\"}\n        valid_env_types = [t for t in env_types if t in valid_types]\n        if valid_env_types:\n            return valid_env_types\n\n    cleanup_setting = self[\"execution_control.auto_cleanup_previous_results\"] or []\n\n    # Handle legacy boolean format for backwards compatibility\n    if isinstance(cleanup_setting, bool):\n        if cleanup_setting:\n            # Legacy behavior: only clean output files\n            return [\"output\"]\n        else:\n            return []\n\n    # Validate that it's a list\n    if not isinstance(cleanup_setting, list):\n        import logging\n\n        logging.warning(f\"'auto_cleanup_previous_results' should be a list, got {type(cleanup_setting)}. Disabling cleanup for safety.\")\n        return []\n\n    # Validate file types\n    valid_types = {\"output\", \"input\", \"smash\"}\n    invalid_types = [t for t in cleanup_setting if t not in valid_types]\n    if invalid_types:\n        import logging\n\n        logging.warning(f\"Invalid file types in 'auto_cleanup_previous_results': {invalid_types}. Valid types are: {valid_types}\")\n\n    return [t for t in cleanup_setting if t in valid_types]\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.core.Config.build_simulation_config","title":"build_simulation_config","text":"<pre><code>build_simulation_config(phantom_name: str, frequency_mhz: int | list[int], scenario_name: Optional[str] = None, position_name: Optional[str] = None, orientation_name: Optional[str] = None, direction_name: Optional[str] = None, polarization_name: Optional[str] = None) -&gt; dict\n</code></pre> <p>Constructs a minimal, simulation-specific configuration dictionary.</p> <p>This method is the core of the \"Verify and Resume\" feature. It creates a \"surgical\" snapshot of the configuration that is unique to a single simulation run. This snapshot is then hashed to determine if a valid, reusable simulation already exists.</p> <p>The key principle is to only include parameters that directly affect the outcome of the specific simulation. For example, instead of including the entire 'gridding_parameters' block, it surgically extracts only the gridding value for the specific 'frequency_mhz' being used. This ensures that a change to one frequency's gridding in the main config does not invalidate the hashes for other, unaffected frequencies.</p> <p>Parameters:</p> Name Type Description Default <code>phantom_name</code> <code>str</code> <p>The name of the phantom model.</p> required <code>frequency_mhz</code> <code>int | list[int]</code> <p>The simulation frequency in MHz.</p> required <code>scenario_name</code> <code>Optional[str]</code> <p>(Near-Field) The base name of the placement scenario.</p> <code>None</code> <code>position_name</code> <code>Optional[str]</code> <p>(Near-Field) The name of the position within the scenario.</p> <code>None</code> <code>orientation_name</code> <code>Optional[str]</code> <p>(Near-Field) The name of the orientation.</p> <code>None</code> <code>direction_name</code> <code>Optional[str]</code> <p>(Far-Field) The incident direction of the plane wave.</p> <code>None</code> <code>polarization_name</code> <code>Optional[str]</code> <p>(Far-Field) The polarization of the plane wave.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the minimal, surgical configuration snapshot.</p> Source code in <code>goliat/config/core.py</code> <pre><code>def build_simulation_config(\n    self,\n    phantom_name: str,\n    frequency_mhz: int | list[int],\n    scenario_name: Optional[str] = None,\n    position_name: Optional[str] = None,\n    orientation_name: Optional[str] = None,\n    direction_name: Optional[str] = None,\n    polarization_name: Optional[str] = None,\n) -&gt; dict:\n    \"\"\"Constructs a minimal, simulation-specific configuration dictionary.\n\n    This method is the core of the \"Verify and Resume\" feature. It creates a\n    \"surgical\" snapshot of the configuration that is unique to a single\n    simulation run. This snapshot is then hashed to determine if a valid,\n    reusable simulation already exists.\n\n    The key principle is to only include parameters that directly affect the\n    outcome of the specific simulation. For example, instead of including the\n    entire 'gridding_parameters' block, it surgically extracts only the\n    gridding value for the specific 'frequency_mhz' being used. This ensures\n    that a change to one frequency's gridding in the main config does not\n    invalidate the hashes for other, unaffected frequencies.\n\n    Args:\n        phantom_name: The name of the phantom model.\n        frequency_mhz: The simulation frequency in MHz.\n        scenario_name: (Near-Field) The base name of the placement scenario.\n        position_name: (Near-Field) The name of the position within the scenario.\n        orientation_name: (Near-Field) The name of the orientation.\n        direction_name: (Far-Field) The incident direction of the plane wave.\n        polarization_name: (Far-Field) The polarization of the plane wave.\n\n    Returns:\n        A dictionary containing the minimal, surgical configuration snapshot.\n    \"\"\"\n    surgical_config = {}\n\n    # 1. Copy global parameters\n    global_keys = [\n        \"study_type\",\n        \"simulation_parameters\",\n        \"solver_settings\",\n        \"manual_isolve\",\n        \"export_material_properties\",\n    ]\n    for key in global_keys:\n        if key in self.config:\n            surgical_config[key] = self[key]\n\n    # 2. Surgically handle gridding parameters\n    gridding_params = self[\"gridding_parameters\"] or {}\n    surgical_config[\"gridding_parameters\"] = build_surgical_gridding(gridding_params, frequency_mhz)\n\n    # 3. Add simulation-specific identifiers\n    surgical_config[\"phantom\"] = phantom_name\n    surgical_config[\"frequency_mhz\"] = frequency_mhz\n\n    # 4. Surgically select study-specific parameters\n    study_type = self[\"study_type\"]\n    if study_type == \"near_field\":\n        build_near_field_simulation_config(\n            self, surgical_config, phantom_name, frequency_mhz, scenario_name, position_name, orientation_name\n        )\n    elif study_type == \"far_field\":\n        build_far_field_simulation_config(self, surgical_config, phantom_name, direction_name, polarization_name)\n\n    return surgical_config\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.core.Config.get_detuning_mhz","title":"get_detuning_mhz","text":"<pre><code>get_detuning_mhz(phantom_name: str, frequency_mhz: int, placement_name: str) -&gt; float\n</code></pre> <p>Gets detuning value in MHz for a specific simulation.</p> <p>Parameters:</p> Name Type Description Default <code>phantom_name</code> <code>str</code> <p>Name of the phantom (will be normalized to lowercase).</p> required <code>frequency_mhz</code> <code>int</code> <p>Frequency in MHz.</p> required <code>placement_name</code> <code>str</code> <p>Placement name (format: {scenario}{position}).</p> required <p>Returns:</p> Type Description <code>float</code> <p>Detuning value in MHz. Returns 0.0 if not found or detuning disabled.</p> Source code in <code>goliat/config/core.py</code> <pre><code>def get_detuning_mhz(\n    self,\n    phantom_name: str,\n    frequency_mhz: int,\n    placement_name: str,\n) -&gt; float:\n    \"\"\"Gets detuning value in MHz for a specific simulation.\n\n    Args:\n        phantom_name: Name of the phantom (will be normalized to lowercase).\n        frequency_mhz: Frequency in MHz.\n        placement_name: Placement name (format: {scenario}_{position}_{orientation}).\n\n    Returns:\n        Detuning value in MHz. Returns 0.0 if not found or detuning disabled.\n    \"\"\"\n    if not self.detuning_enabled or not self.detuning_data:\n        return 0.0\n\n    # Normalize phantom name to lowercase\n    phantom_lower = phantom_name.lower()\n\n    # Convert frequency to string format\n    freq_str = f\"{frequency_mhz}MHz\"\n\n    # Lookup in nested structure\n    try:\n        detuning_value = self.detuning_data.get(phantom_lower, {}).get(freq_str, {}).get(placement_name)\n        if detuning_value is None:\n            # Missing entry - warn and return 0\n            import logging\n\n            logging.getLogger(\"progress\").warning(\n                f\"No detuning data for {phantom_name}/{freq_str}/{placement_name}, using 0 MHz\", extra={\"log_type\": \"warning\"}\n            )\n            return 0.0\n        return float(detuning_value)\n    except (AttributeError, TypeError):\n        # Invalid structure - warn and return 0\n        import logging\n\n        logging.getLogger(\"progress\").warning(\n            f\"Invalid detuning data structure for {phantom_name}/{freq_str}/{placement_name}, using 0 MHz\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return 0.0\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.core.Config.update_detuning_file","title":"update_detuning_file","text":"<pre><code>update_detuning_file(phantom_name: str, frequency_mhz: int | list[int], placement_name: str, detuning_mhz: float) -&gt; None\n</code></pre> <p>Updates detuning file with a new detuning value.</p> <p>Parameters:</p> Name Type Description Default <code>phantom_name</code> <code>str</code> <p>Name of the phantom (will be normalized to lowercase).</p> required <code>frequency_mhz</code> <code>int | list[int]</code> <p>Frequency in MHz.</p> required <code>placement_name</code> <code>str</code> <p>Placement name (format: {scenario}{position}).</p> required <code>detuning_mhz</code> <code>float</code> <p>Detuning value in MHz to write.</p> required Source code in <code>goliat/config/core.py</code> <pre><code>def update_detuning_file(\n    self,\n    phantom_name: str,\n    frequency_mhz: int | list[int],\n    placement_name: str,\n    detuning_mhz: float,\n) -&gt; None:\n    \"\"\"Updates detuning file with a new detuning value.\n\n    Args:\n        phantom_name: Name of the phantom (will be normalized to lowercase).\n        frequency_mhz: Frequency in MHz.\n        placement_name: Placement name (format: {scenario}_{position}_{orientation}).\n        detuning_mhz: Detuning value in MHz to write.\n    \"\"\"\n    if not self.detuning_enabled or not self.detuning_write_during_calibration:\n        return\n\n    detuning_config_path = self.config.get(\"detuning_config\")\n    if not detuning_config_path:\n        return\n\n    resolved_path = self._resolve_path_relative_to_config(self.config_path, detuning_config_path)\n\n    # Normalize phantom name to lowercase\n    phantom_lower = phantom_name.lower()\n    # For multi-sine, format as \"700+2450MHz\"\n    freq_str_val = \"+\".join(str(f) for f in frequency_mhz) if isinstance(frequency_mhz, list) else str(frequency_mhz)\n    freq_str = f\"{freq_str_val}MHz\"\n\n    # Load existing data or create empty structure\n    if os.path.exists(resolved_path):\n        try:\n            detuning_config = self._load_json(resolved_path)\n            detuning_data = detuning_config.get(\"detuning_data\", {})\n        except (json.JSONDecodeError, FileNotFoundError):\n            detuning_data = {}\n    else:\n        detuning_data = {}\n\n    # Initialize nested structure if needed\n    if phantom_lower not in detuning_data:\n        detuning_data[phantom_lower] = {}\n    if freq_str not in detuning_data[phantom_lower]:\n        detuning_data[phantom_lower][freq_str] = {}\n\n    # Only write if entry doesn't exist (never overwrite)\n    if placement_name not in detuning_data[phantom_lower][freq_str]:\n        detuning_data[phantom_lower][freq_str][placement_name] = detuning_mhz\n\n        # Save updated file\n        detuning_config = {\"detuning_data\": detuning_data}\n        os.makedirs(os.path.dirname(resolved_path), exist_ok=True)\n        with open(resolved_path, \"w\") as f:\n            json.dump(detuning_config, f, indent=2)\n\n        # Update in-memory data\n        self.detuning_data = detuning_data\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.core.Config.initialize_missing_detuning_entries","title":"initialize_missing_detuning_entries","text":"<pre><code>initialize_missing_detuning_entries() -&gt; None\n</code></pre> <p>Initializes missing detuning entries for all simulations in the study.</p> <p>Called at the end of a calibration run to ensure all simulation entries exist in the detuning file (with value 0) before manual calibration values are added.</p> Source code in <code>goliat/config/core.py</code> <pre><code>def initialize_missing_detuning_entries(self) -&gt; None:\n    \"\"\"Initializes missing detuning entries for all simulations in the study.\n\n    Called at the end of a calibration run to ensure all simulation entries exist\n    in the detuning file (with value 0) before manual calibration values are added.\n    \"\"\"\n    if not self.detuning_enabled or not self.detuning_write_during_calibration:\n        return\n\n    detuning_config_path = self.config[\"detuning_config\"]\n    if not detuning_config_path:\n        return\n\n    resolved_path = self._resolve_path_relative_to_config(self.config_path, detuning_config_path)\n    detuning_data = self._load_or_create_detuning_data(resolved_path)\n\n    # Initialize missing entries for all simulation combinations\n    for phantom_lower, freq_str, placement_name in self._iter_simulation_combinations():\n        if phantom_lower not in detuning_data:\n            detuning_data[phantom_lower] = {}\n        if freq_str not in detuning_data[phantom_lower]:\n            detuning_data[phantom_lower][freq_str] = {}\n        if placement_name not in detuning_data[phantom_lower][freq_str]:\n            detuning_data[phantom_lower][freq_str][placement_name] = 0.0\n\n    self._save_detuning_data(resolved_path, detuning_data)\n</code></pre>"},{"location":"reference/api_reference/#credentials","title":"Credentials","text":""},{"location":"reference/api_reference/#goliat.config.credentials","title":"goliat.config.credentials","text":"<p>Environment variable and credentials management.</p>"},{"location":"reference/api_reference/#goliat.config.credentials-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.config.credentials.get_download_email","title":"get_download_email","text":"<pre><code>get_download_email() -&gt; str\n</code></pre> <p>Returns the download email from environment variables.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If DOWNLOAD_EMAIL is not set in the environment.</p> Source code in <code>goliat/config/credentials.py</code> <pre><code>def get_download_email() -&gt; str:\n    \"\"\"Returns the download email from environment variables.\n\n    Raises:\n        ValueError: If DOWNLOAD_EMAIL is not set in the environment.\n    \"\"\"\n    email = os.getenv(\"DOWNLOAD_EMAIL\")\n    if not email:\n        raise ValueError(\"Missing DOWNLOAD_EMAIL. Please set this in your .env file.\")\n    return email\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.credentials.get_osparc_credentials","title":"get_osparc_credentials","text":"<pre><code>get_osparc_credentials() -&gt; dict\n</code></pre> <p>Gets oSPARC credentials from environment variables.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If required oSPARC credentials are not set.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing oSPARC API credentials.</p> Source code in <code>goliat/config/credentials.py</code> <pre><code>def get_osparc_credentials() -&gt; dict:\n    \"\"\"Gets oSPARC credentials from environment variables.\n\n    Raises:\n        ValueError: If required oSPARC credentials are not set.\n\n    Returns:\n        A dictionary containing oSPARC API credentials.\n    \"\"\"\n    credentials = {\n        \"api_key\": os.getenv(\"OSPARC_API_KEY\"),\n        \"api_secret\": os.getenv(\"OSPARC_API_SECRET\"),\n        \"api_server\": \"https://api.sim4life.science\",\n        \"api_version\": \"v0\",\n    }\n\n    missing = [key for key, value in credentials.items() if value is None and key != \"api_version\"]\n    if missing:\n        raise ValueError(\n            f\"Missing oSPARC credentials: {', '.join(missing)}. \"\n            \"Please create a .env file in the project root with your oSPARC API credentials. \"\n            \"See README.md for setup instructions.\"\n        )\n\n    return credentials\n</code></pre>"},{"location":"reference/api_reference/#file-management","title":"File Management","text":""},{"location":"reference/api_reference/#goliat.config.file_management","title":"goliat.config.file_management","text":"<p>File management utilities for configuration.</p>"},{"location":"reference/api_reference/#goliat.config.file_management-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.config.file_management.cleanup_old_data_files","title":"cleanup_old_data_files","text":"<pre><code>cleanup_old_data_files(data_dir: str)\n</code></pre> <p>Removes old CSV/JSON files from data/ when there are more than 50.</p> <p>Only cleans files matching specific patterns (time_remaining_, overall_progress_, profiling_config_). Files are sorted by creation time and oldest are deleted first.</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str</code> <p>The data directory to clean up.</p> required Source code in <code>goliat/config/file_management.py</code> <pre><code>def cleanup_old_data_files(data_dir: str):\n    \"\"\"Removes old CSV/JSON files from data/ when there are more than 50.\n\n    Only cleans files matching specific patterns (time_remaining_, overall_progress_,\n    profiling_config_). Files are sorted by creation time and oldest are deleted first.\n\n    Args:\n        data_dir: The data directory to clean up.\n    \"\"\"\n    try:\n        # Get all CSV and JSON files in the data directory\n        data_files = []\n        for f in os.listdir(data_dir):\n            if f.endswith(\".csv\") or f.endswith(\".json\"):\n                # Only include files with the expected naming pattern\n                if any(prefix in f for prefix in [\"time_remaining_\", \"overall_progress_\", \"profiling_config_\"]):\n                    full_path = os.path.join(data_dir, f)\n                    data_files.append(full_path)\n\n        # Sort by creation time (oldest first)\n        data_files.sort(key=os.path.getctime)\n\n        # Remove oldest files if we have more than 50\n        while len(data_files) &gt; 50:\n            old_file = None\n            try:\n                old_file = data_files.pop(0)\n                os.remove(old_file)\n                logging.getLogger(\"verbose\").debug(f\"Removed old data file: {os.path.basename(old_file)}\")\n            except OSError as e:\n                if old_file:\n                    logging.getLogger(\"verbose\").warning(f\"Failed to remove {os.path.basename(old_file)}: {e}\")\n                else:\n                    logging.getLogger(\"verbose\").warning(f\"Failed to remove a file: {e}\")\n    except Exception as e:\n        logging.getLogger(\"verbose\").warning(f\"Error during data file cleanup: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#merge","title":"Merge","text":""},{"location":"reference/api_reference/#goliat.config.merge","title":"goliat.config.merge","text":"<p>Dictionary merging utilities.</p>"},{"location":"reference/api_reference/#goliat.config.merge-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.config.merge.deep_merge","title":"deep_merge","text":"<pre><code>deep_merge(source: dict, destination: dict) -&gt; dict\n</code></pre> <p>Recursively merges two dictionaries, overwriting destination with source values.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>dict</code> <p>The dictionary with values to merge.</p> required <code>destination</code> <code>dict</code> <p>The dictionary to be merged into.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The merged dictionary.</p> Source code in <code>goliat/config/merge.py</code> <pre><code>def deep_merge(source: dict, destination: dict) -&gt; dict:\n    \"\"\"Recursively merges two dictionaries, overwriting destination with source values.\n\n    Args:\n        source: The dictionary with values to merge.\n        destination: The dictionary to be merged into.\n\n    Returns:\n        The merged dictionary.\n    \"\"\"\n    for key, value in source.items():\n        if isinstance(value, dict) and key in destination and isinstance(destination[key], dict):\n            deep_merge(value, destination[key])\n        else:\n            destination[key] = value\n    return destination\n</code></pre>"},{"location":"reference/api_reference/#profiling","title":"Profiling","text":""},{"location":"reference/api_reference/#goliat.config.profiling","title":"goliat.config.profiling","text":"<p>Profiling configuration management.</p>"},{"location":"reference/api_reference/#goliat.config.profiling-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.config.profiling.load_or_create_profiling_config","title":"load_or_create_profiling_config","text":"<pre><code>load_or_create_profiling_config(profiling_config_path: str) -&gt; dict\n</code></pre> <p>Loads profiling config from disk, or creates a new one if missing.</p> <p>Parameters:</p> Name Type Description Default <code>profiling_config_path</code> <code>str</code> <p>Path to the profiling config file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The profiling config dict, initialized with empty structure if new.</p> Source code in <code>goliat/config/profiling.py</code> <pre><code>def load_or_create_profiling_config(profiling_config_path: str) -&gt; dict:\n    \"\"\"Loads profiling config from disk, or creates a new one if missing.\n\n    Args:\n        profiling_config_path: Path to the profiling config file.\n\n    Returns:\n        The profiling config dict, initialized with empty structure if new.\n    \"\"\"\n    if os.path.exists(profiling_config_path):\n        try:\n            with open(profiling_config_path, \"r\") as f:\n                return json.load(f)\n        except (json.JSONDecodeError, IOError):\n            # If file is corrupted, start fresh\n            pass\n\n    # Create a new profiling config with empty structure\n    profiling_config = {}\n\n    # Initialize with empty structure for each study type\n    for study_type in [\"near_field\", \"far_field\"]:\n        profiling_config[study_type] = {}\n\n    # Save the initial config\n    try:\n        with open(profiling_config_path, \"w\") as f:\n            json.dump(profiling_config, f, indent=4)\n    except IOError:\n        # If we can't write, just return the empty dict\n        pass\n\n    return profiling_config\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.profiling.get_profiling_config","title":"get_profiling_config","text":"<pre><code>get_profiling_config(profiling_config: dict, study_type: str) -&gt; dict\n</code></pre> <p>Gets the profiling configuration for a given study type.</p> <p>Parameters:</p> Name Type Description Default <code>profiling_config</code> <code>dict</code> <p>The profiling configuration dictionary.</p> required <code>study_type</code> <code>str</code> <p>The type of the study (e.g., 'near_field').</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The profiling configuration for the study type.</p> Source code in <code>goliat/config/profiling.py</code> <pre><code>def get_profiling_config(profiling_config: dict, study_type: str) -&gt; dict:\n    \"\"\"Gets the profiling configuration for a given study type.\n\n    Args:\n        profiling_config: The profiling configuration dictionary.\n        study_type: The type of the study (e.g., 'near_field').\n\n    Returns:\n        The profiling configuration for the study type.\n    \"\"\"\n    if study_type not in profiling_config:\n        logging.warning(f\"Profiling configuration not defined for study type: {study_type}. Returning empty configuration.\")\n        return {}\n    return profiling_config[study_type]\n</code></pre>"},{"location":"reference/api_reference/#simulation-config","title":"Simulation Config","text":""},{"location":"reference/api_reference/#goliat.config.simulation_config","title":"goliat.config.simulation_config","text":"<p>Simulation-specific configuration building utilities.</p>"},{"location":"reference/api_reference/#goliat.config.simulation_config-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.config.simulation_config.build_surgical_gridding","title":"build_surgical_gridding","text":"<pre><code>build_surgical_gridding(gridding_params: dict, frequency_mhz: int | list[int]) -&gt; dict\n</code></pre> <p>Extracts frequency-specific gridding parameters.</p> <p>This surgically extracts only the gridding value for the specific frequency, ensuring that changes to other frequencies don't invalidate hashes.</p> <p>Parameters:</p> Name Type Description Default <code>gridding_params</code> <code>dict</code> <p>The full gridding parameters dictionary.</p> required <code>frequency_mhz</code> <code>int | list[int]</code> <p>The simulation frequency in MHz.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing surgical gridding parameters.</p> Source code in <code>goliat/config/simulation_config.py</code> <pre><code>def build_surgical_gridding(gridding_params: dict, frequency_mhz: int | list[int]) -&gt; dict:\n    \"\"\"Extracts frequency-specific gridding parameters.\n\n    This surgically extracts only the gridding value for the specific frequency,\n    ensuring that changes to other frequencies don't invalidate hashes.\n\n    Args:\n        gridding_params: The full gridding parameters dictionary.\n        frequency_mhz: The simulation frequency in MHz.\n\n    Returns:\n        A dictionary containing surgical gridding parameters.\n    \"\"\"\n    surgical_gridding = {}\n    # Copy non-frequency specific gridding params\n    for key, value in gridding_params.items():\n        if key != \"global_gridding_per_frequency\":\n            surgical_gridding[key] = value\n\n    # Extract only the relevant frequency's gridding value\n    if \"global_gridding_per_frequency\" in gridding_params:\n        # For multi-sine, use highest frequency's gridding\n        ref_freq = max(frequency_mhz) if isinstance(frequency_mhz, list) else frequency_mhz\n        freq_str = str(ref_freq)\n        if freq_str in gridding_params[\"global_gridding_per_frequency\"]:\n            surgical_gridding[\"global_gridding_per_frequency\"] = {freq_str: gridding_params[\"global_gridding_per_frequency\"][freq_str]}\n\n    return surgical_gridding\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.simulation_config.build_near_field_simulation_config","title":"build_near_field_simulation_config","text":"<pre><code>build_near_field_simulation_config(config_accessor, surgical_config: dict, phantom_name: str, frequency_mhz: int | list[int], scenario_name: Optional[str], position_name: Optional[str], orientation_name: Optional[str]) -&gt; None\n</code></pre> <p>Builds near-field specific configuration components.</p> <p>Parameters:</p> Name Type Description Default <code>config_accessor</code> <p>Object with getitem method to access config values.</p> required <code>surgical_config</code> <code>dict</code> <p>The configuration dictionary to populate.</p> required <code>phantom_name</code> <code>str</code> <p>The name of the phantom model.</p> required <code>frequency_mhz</code> <code>int | list[int]</code> <p>The simulation frequency in MHz.</p> required <code>scenario_name</code> <code>Optional[str]</code> <p>The base name of the placement scenario.</p> required <code>position_name</code> <code>Optional[str]</code> <p>The name of the position within the scenario.</p> required <code>orientation_name</code> <code>Optional[str]</code> <p>The name of the orientation.</p> required Source code in <code>goliat/config/simulation_config.py</code> <pre><code>def build_near_field_simulation_config(\n    config_accessor,\n    surgical_config: dict,\n    phantom_name: str,\n    frequency_mhz: int | list[int],\n    scenario_name: Optional[str],\n    position_name: Optional[str],\n    orientation_name: Optional[str],\n) -&gt; None:\n    \"\"\"Builds near-field specific configuration components.\n\n    Args:\n        config_accessor: Object with __getitem__ method to access config values.\n        surgical_config: The configuration dictionary to populate.\n        phantom_name: The name of the phantom model.\n        frequency_mhz: The simulation frequency in MHz.\n        scenario_name: The base name of the placement scenario.\n        position_name: The name of the position within the scenario.\n        orientation_name: The name of the orientation.\n    \"\"\"\n    # Select the specific antenna config for the given frequency\n    # For multi-sine, use highest frequency's antenna config\n    ref_freq = max(frequency_mhz) if isinstance(frequency_mhz, list) else frequency_mhz\n    surgical_config[\"antenna_config\"] = config_accessor[f\"antenna_config.{ref_freq}\"]\n\n    # Reconstruct placement_scenarios for the specific placement\n    if scenario_name:\n        placement_scenarios = config_accessor[\"placement_scenarios\"] or {}\n        original_scenario = placement_scenarios.get(scenario_name) if isinstance(placement_scenarios, dict) else None\n        if original_scenario and position_name and orientation_name:\n            surgical_config[\"placement_scenarios\"] = {\n                scenario_name: {\n                    \"positions\": {position_name: original_scenario[\"positions\"][position_name]},\n                    \"orientations\": {orientation_name: original_scenario[\"orientations\"][orientation_name]},\n                    \"bounding_box\": original_scenario.get(\"bounding_box\", \"default\"),\n                }\n            }\n\n    # Select the specific phantom definition\n    phantom_definitions = config_accessor[\"phantom_definitions\"] or {}\n    surgical_config[\"phantom_definitions\"] = {\n        phantom_name: phantom_definitions.get(phantom_name, {}) if isinstance(phantom_definitions, dict) else {}\n    }\n</code></pre>"},{"location":"reference/api_reference/#goliat.config.simulation_config.build_far_field_simulation_config","title":"build_far_field_simulation_config","text":"<pre><code>build_far_field_simulation_config(config_accessor, surgical_config: dict, phantom_name: str, direction_name: Optional[str], polarization_name: Optional[str]) -&gt; None\n</code></pre> <p>Builds far-field specific configuration components.</p> <p>Parameters:</p> Name Type Description Default <code>config_accessor</code> <p>Object with getitem method to access config values.</p> required <code>surgical_config</code> <code>dict</code> <p>The configuration dictionary to populate.</p> required <code>phantom_name</code> <code>str</code> <p>The name of the phantom model.</p> required <code>direction_name</code> <code>Optional[str]</code> <p>The incident direction of the plane wave.</p> required <code>polarization_name</code> <code>Optional[str]</code> <p>The polarization of the plane wave.</p> required Source code in <code>goliat/config/simulation_config.py</code> <pre><code>def build_far_field_simulation_config(\n    config_accessor,\n    surgical_config: dict,\n    phantom_name: str,\n    direction_name: Optional[str],\n    polarization_name: Optional[str],\n) -&gt; None:\n    \"\"\"Builds far-field specific configuration components.\n\n    Args:\n        config_accessor: Object with __getitem__ method to access config values.\n        surgical_config: The configuration dictionary to populate.\n        phantom_name: The name of the phantom model.\n        direction_name: The incident direction of the plane wave.\n        polarization_name: The polarization of the plane wave.\n    \"\"\"\n    # Surgically build the far_field_setup to be robust against future changes\n    original_ff_setup = config_accessor[\"far_field_setup\"] or {}\n    if original_ff_setup:\n        surgical_config[\"far_field_setup\"] = {\n            \"type\": original_ff_setup.get(\"type\"),\n            \"environmental\": {\n                \"incident_directions\": [direction_name],\n                \"polarizations\": [polarization_name],\n            },\n        }\n    # Also include the specific phantom definition, if it's not empty\n    phantom_definitions = config_accessor[\"phantom_definitions\"] or {}\n    phantom_def = phantom_definitions.get(phantom_name, {}) if isinstance(phantom_definitions, dict) else {}\n    if phantom_def:\n        surgical_config[\"phantom_definitions\"] = {phantom_name: phantom_def}\n</code></pre>"},{"location":"reference/api_reference/#study-orchestration","title":"Study Orchestration","text":"<p>Study classes that orchestrate simulation workflows.</p>"},{"location":"reference/api_reference/#base-study","title":"Base Study","text":""},{"location":"reference/api_reference/#goliat.studies.base_study.BaseStudy","title":"goliat.studies.base_study.BaseStudy","text":"<pre><code>BaseStudy(study_type: str, config_filename: Optional[str] = None, gui: Optional[QueueGUI] = None, profiler=None, no_cache: bool = False)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Base class for simulation studies.</p> <p>Handles common setup like config loading, profiling, project management, and GUI coordination. Subclasses implement _run_study() for specific logic.</p> Source code in <code>goliat/studies/base_study.py</code> <pre><code>def __init__(\n    self,\n    study_type: str,\n    config_filename: Optional[str] = None,\n    gui: Optional[\"QueueGUI\"] = None,\n    profiler=None,\n    no_cache: bool = False,\n):\n    \"\"\"Load config, set up loggers and profiler, determine base directory.\"\"\"\n    self.study_type = study_type\n    self.gui = gui\n    self.verbose_logger = logging.getLogger(\"verbose\")\n    self.progress_logger = logging.getLogger(\"progress\")\n    self.no_cache = no_cache\n\n    # Determine base_dir: prefer cwd if it has configs/, otherwise fallback to package location\n    cwd = os.getcwd()\n    if os.path.isdir(os.path.join(cwd, \"configs\")):\n        self.base_dir = cwd\n    else:\n        # Fallback: calculate from package location (for backwards compatibility)\n        self.base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\n    self.config = Config(\n        self.base_dir,\n        config_filename if config_filename else f\"{self.study_type}_config.json\",\n    )\n\n    # Get study-specific profiling config\n    profiling_config = self.config.get_profiling_config(self.study_type)\n    execution_control = self.config[\"execution_control\"] or {\"do_setup\": True, \"do_run\": True, \"do_extract\": True}\n\n    self.profiler = Profiler(\n        execution_control,  # type: ignore\n        profiling_config,\n        self.study_type,\n        self.config.profiling_config_path,\n    )\n    self.line_profiler = None\n\n    self.project_manager = ProjectManager(\n        self.config,\n        self.verbose_logger,\n        self.progress_logger,\n        self.gui,\n        no_cache=self.no_cache,\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.studies.base_study.BaseStudy-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.studies.base_study.BaseStudy.subtask","title":"subtask","text":"<pre><code>subtask(task_name: str, instance_to_profile=None)\n</code></pre> <p>A context manager for a 'subtask' within a phase.</p> Source code in <code>goliat/studies/base_study.py</code> <pre><code>@contextlib.contextmanager\ndef subtask(self, task_name: str, instance_to_profile=None):\n    \"\"\"A context manager for a 'subtask' within a phase.\"\"\"\n    is_top_level_subtask = not self.profiler.subtask_stack\n    sub_stage_display_name = task_name.replace(\"_\", \" \").capitalize()\n\n    if is_top_level_subtask:\n        self._log(f\"  - {sub_stage_display_name}...\", level=\"progress\", log_type=\"progress\")\n        if self.gui and self.profiler.current_phase:\n            self.gui.update_stage_progress(self.profiler.current_phase.capitalize(), 0, 1, sub_stage=sub_stage_display_name)\n            self.start_stage_animation(task_name, 100)\n\n    lp, wrapper = self._setup_line_profiler_if_needed(task_name, instance_to_profile)\n\n    try:\n        with self.profiler.subtask(task_name):\n            if lp and wrapper:\n                yield wrapper\n            else:\n                yield\n    finally:\n        elapsed = self.profiler.subtask_times[task_name][-1]\n        self._log(f\"    - Subtask '{task_name}' done in {elapsed:.2f}s\", log_type=\"verbose\")\n\n        if is_top_level_subtask:\n            self._log(f\"    - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n            if self.gui:\n                self.end_stage_animation()\n                if self.profiler.current_phase:\n                    self.gui.update_stage_progress(self.profiler.current_phase.capitalize(), 1, 1)\n\n        if lp:\n            self._log_line_profiler_stats(task_name, lp)\n</code></pre>"},{"location":"reference/api_reference/#goliat.studies.base_study.BaseStudy.start_stage_animation","title":"start_stage_animation","text":"<pre><code>start_stage_animation(task_name: str, end_value: int)\n</code></pre> <p>Starts progress bar animation for the current stage.</p> Source code in <code>goliat/studies/base_study.py</code> <pre><code>def start_stage_animation(self, task_name: str, end_value: int):\n    \"\"\"Starts progress bar animation for the current stage.\"\"\"\n    if self.gui:\n        self.gui.start_stage_animation(task_name, end_value)\n</code></pre>"},{"location":"reference/api_reference/#goliat.studies.base_study.BaseStudy.end_stage_animation","title":"end_stage_animation","text":"<pre><code>end_stage_animation()\n</code></pre> <p>Stops the current stage animation.</p> Source code in <code>goliat/studies/base_study.py</code> <pre><code>def end_stage_animation(self):\n    \"\"\"Stops the current stage animation.\"\"\"\n    if self.gui:\n        self.gui.end_stage_animation()\n</code></pre>"},{"location":"reference/api_reference/#goliat.studies.base_study.BaseStudy.run","title":"run","text":"<pre><code>run()\n</code></pre> <p>Main entry point to run the study.</p> <p>Ensures Sim4Life is running, calls _run_study(), and handles cleanup and error reporting. Catches StudyCancelledError for graceful shutdown.</p> Source code in <code>goliat/studies/base_study.py</code> <pre><code>def run(self):\n    \"\"\"Main entry point to run the study.\n\n    Ensures Sim4Life is running, calls _run_study(), and handles cleanup\n    and error reporting. Catches StudyCancelledError for graceful shutdown.\n    \"\"\"\n    ensure_s4l_running()\n    try:\n        self._run_study()\n    except StudyCancelledError:\n        self._log(\n            \"--- Study execution cancelled by user. ---\",\n            level=\"progress\",\n            log_type=\"warning\",\n        )\n    except Exception as e:\n        self._log(f\"--- FATAL ERROR in study: {e} ---\", level=\"progress\", log_type=\"fatal\")\n        self.verbose_logger.error(traceback.format_exc())\n    finally:\n        self._log(\n            f\"\\n--- {self.__class__.__name__} Finished ---\",\n            level=\"progress\",\n            log_type=\"success\",\n        )\n        self.profiler.save_estimates()\n        self.project_manager.cleanup()\n        if self.gui:\n            self.gui.update_profiler()  # Send final profiler state\n</code></pre>"},{"location":"reference/api_reference/#far-field-study","title":"Far Field Study","text":""},{"location":"reference/api_reference/#goliat.studies.far_field_study.FarFieldStudy","title":"goliat.studies.far_field_study.FarFieldStudy","text":"<pre><code>FarFieldStudy(study_type: str, config_filename: Optional[str] = None, gui: Optional[QueueGUI] = None, profiler=None, no_cache: bool = False)\n</code></pre> <p>               Bases: <code>BaseStudy</code></p> <p>Manages far-field simulation campaigns.</p> <p>Runs plane wave simulations across phantoms, frequencies, directions, and polarizations. Handles setup, run, and extraction phases with progress tracking.</p> Source code in <code>goliat/studies/base_study.py</code> <pre><code>def __init__(\n    self,\n    study_type: str,\n    config_filename: Optional[str] = None,\n    gui: Optional[\"QueueGUI\"] = None,\n    profiler=None,\n    no_cache: bool = False,\n):\n    \"\"\"Load config, set up loggers and profiler, determine base directory.\"\"\"\n    self.study_type = study_type\n    self.gui = gui\n    self.verbose_logger = logging.getLogger(\"verbose\")\n    self.progress_logger = logging.getLogger(\"progress\")\n    self.no_cache = no_cache\n\n    # Determine base_dir: prefer cwd if it has configs/, otherwise fallback to package location\n    cwd = os.getcwd()\n    if os.path.isdir(os.path.join(cwd, \"configs\")):\n        self.base_dir = cwd\n    else:\n        # Fallback: calculate from package location (for backwards compatibility)\n        self.base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\n    self.config = Config(\n        self.base_dir,\n        config_filename if config_filename else f\"{self.study_type}_config.json\",\n    )\n\n    # Get study-specific profiling config\n    profiling_config = self.config.get_profiling_config(self.study_type)\n    execution_control = self.config[\"execution_control\"] or {\"do_setup\": True, \"do_run\": True, \"do_extract\": True}\n\n    self.profiler = Profiler(\n        execution_control,  # type: ignore\n        profiling_config,\n        self.study_type,\n        self.config.profiling_config_path,\n    )\n    self.line_profiler = None\n\n    self.project_manager = ProjectManager(\n        self.config,\n        self.verbose_logger,\n        self.progress_logger,\n        self.gui,\n        no_cache=self.no_cache,\n    )\n</code></pre>"},{"location":"reference/api_reference/#near-field-study","title":"Near Field Study","text":""},{"location":"reference/api_reference/#goliat.studies.near_field_study.NearFieldStudy","title":"goliat.studies.near_field_study.NearFieldStudy","text":"<pre><code>NearFieldStudy(study_type: str, config_filename: Optional[str] = None, gui: Optional[QueueGUI] = None, profiler=None, no_cache: bool = False)\n</code></pre> <p>               Bases: <code>BaseStudy</code></p> <p>Manages near-field simulation campaigns.</p> <p>Runs simulations across phantoms, frequencies, placements, positions, and orientations. Handles setup, run, and extraction phases with progress tracking and metadata verification.</p> Source code in <code>goliat/studies/base_study.py</code> <pre><code>def __init__(\n    self,\n    study_type: str,\n    config_filename: Optional[str] = None,\n    gui: Optional[\"QueueGUI\"] = None,\n    profiler=None,\n    no_cache: bool = False,\n):\n    \"\"\"Load config, set up loggers and profiler, determine base directory.\"\"\"\n    self.study_type = study_type\n    self.gui = gui\n    self.verbose_logger = logging.getLogger(\"verbose\")\n    self.progress_logger = logging.getLogger(\"progress\")\n    self.no_cache = no_cache\n\n    # Determine base_dir: prefer cwd if it has configs/, otherwise fallback to package location\n    cwd = os.getcwd()\n    if os.path.isdir(os.path.join(cwd, \"configs\")):\n        self.base_dir = cwd\n    else:\n        # Fallback: calculate from package location (for backwards compatibility)\n        self.base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\n    self.config = Config(\n        self.base_dir,\n        config_filename if config_filename else f\"{self.study_type}_config.json\",\n    )\n\n    # Get study-specific profiling config\n    profiling_config = self.config.get_profiling_config(self.study_type)\n    execution_control = self.config[\"execution_control\"] or {\"do_setup\": True, \"do_run\": True, \"do_extract\": True}\n\n    self.profiler = Profiler(\n        execution_control,  # type: ignore\n        profiling_config,\n        self.study_type,\n        self.config.profiling_config_path,\n    )\n    self.line_profiler = None\n\n    self.project_manager = ProjectManager(\n        self.config,\n        self.verbose_logger,\n        self.progress_logger,\n        self.gui,\n        no_cache=self.no_cache,\n    )\n</code></pre>"},{"location":"reference/api_reference/#setup-modules","title":"Setup Modules","text":"<p>Classes responsible for building the Sim4Life simulation scene.</p>"},{"location":"reference/api_reference/#base-setup","title":"Base Setup","text":""},{"location":"reference/api_reference/#goliat.setups.base_setup.BaseSetup","title":"goliat.setups.base_setup.BaseSetup","text":"<pre><code>BaseSetup(config: Config, verbose_logger: Logger, progress_logger: Logger, gui: Optional[QueueGUI] = None)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Base class for simulation setup modules.</p> <p>Provides common functionality like solver configuration, time/termination setup, point sensor creation, and final voxelization. Subclasses implement run_full_setup() for specific setup logic.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required <code>verbose_logger</code> <code>Logger</code> <p>Logger for detailed output.</p> required <code>progress_logger</code> <code>Logger</code> <p>Logger for progress updates.</p> required <code>gui</code> <code>Optional[QueueGUI]</code> <p>Optional GUI instance for forwarding progress messages.</p> <code>None</code> Source code in <code>goliat/setups/base_setup.py</code> <pre><code>def __init__(self, config: \"Config\", verbose_logger: \"Logger\", progress_logger: \"Logger\", gui: Optional[\"QueueGUI\"] = None):\n    \"\"\"Sets up the base setup.\n\n    Args:\n        config: Configuration object.\n        verbose_logger: Logger for detailed output.\n        progress_logger: Logger for progress updates.\n        gui: Optional GUI instance for forwarding progress messages.\n    \"\"\"\n    self.config = config\n    self.verbose_logger = verbose_logger\n    self.progress_logger = progress_logger\n    self.gui = gui\n    import s4l_v1\n\n    self.s4l_v1 = s4l_v1\n    self.emfdtd = self.s4l_v1.simulation.emfdtd\n    self.model = self.s4l_v1.model\n</code></pre>"},{"location":"reference/api_reference/#goliat.setups.base_setup.BaseSetup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.setups.base_setup.BaseSetup.run_full_setup","title":"run_full_setup","text":"<pre><code>run_full_setup(project_manager: ProjectManager)\n</code></pre> <p>Prepares the simulation scene. Must be implemented by subclasses.</p> <p>Returns:</p> Type Description <p>The configured simulation object.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If not overridden by subclass.</p> Source code in <code>goliat/setups/base_setup.py</code> <pre><code>def run_full_setup(self, project_manager: \"ProjectManager\"):\n    \"\"\"Prepares the simulation scene. Must be implemented by subclasses.\n\n    Returns:\n        The configured simulation object.\n\n    Raises:\n        NotImplementedError: If not overridden by subclass.\n    \"\"\"\n    raise NotImplementedError(\"The 'run_full_setup' method must be implemented by a subclass.\")\n</code></pre>"},{"location":"reference/api_reference/#boundary-setup","title":"Boundary Setup","text":""},{"location":"reference/api_reference/#goliat.setups.boundary_setup.BoundarySetup","title":"goliat.setups.boundary_setup.BoundarySetup","text":"<pre><code>BoundarySetup(config: Config, simulation: Simulation, verbose_logger: Logger, progress_logger: Logger)\n</code></pre> <p>               Bases: <code>BaseSetup</code></p> <p>Configures the boundary conditions for the simulation.</p> Source code in <code>goliat/setups/boundary_setup.py</code> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    simulation: \"emfdtd.Simulation\",\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n):\n    \"\"\"Store simulation reference for boundary configuration.\"\"\"\n    super().__init__(config, verbose_logger, progress_logger)\n    self.simulation = simulation\n</code></pre>"},{"location":"reference/api_reference/#goliat.setups.boundary_setup.BoundarySetup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.setups.boundary_setup.BoundarySetup.setup_boundary_conditions","title":"setup_boundary_conditions","text":"<pre><code>setup_boundary_conditions()\n</code></pre> <p>Configures PML boundary conditions from the solver settings.</p> <p>Sets the global boundary type (e.g., UPML/CPML) and PML strength (Low/Medium/High) based on the config.</p> Source code in <code>goliat/setups/boundary_setup.py</code> <pre><code>def setup_boundary_conditions(self):\n    \"\"\"Configures PML boundary conditions from the solver settings.\n\n    Sets the global boundary type (e.g., UPML/CPML) and PML strength\n    (Low/Medium/High) based on the config.\n    \"\"\"\n    self._log(\"Setting up boundary conditions...\", log_type=\"progress\")\n    solver_settings = self.config[\"solver_settings\"] or {}\n    boundary_config = solver_settings.get(\"boundary_conditions\", {})\n\n    # Set Boundary Type (e.g., UpmlCpml)\n    bc_type = boundary_config.get(\"type\", \"UpmlCpml\")\n    self._log(f\"  - Setting global boundary conditions to: {bc_type}\", log_type=\"info\")\n\n    global_boundaries = self.simulation.GlobalBoundarySettings\n    if global_boundaries:\n        bc_enum = global_boundaries.GlobalBoundaryType.enum\n        if hasattr(bc_enum, bc_type):\n            global_boundaries.GlobalBoundaryType = getattr(bc_enum, bc_type)\n            self._log(\n                f\"    - Successfully set GlobalBoundaryType to {bc_type}\",\n                log_type=\"verbose\",\n            )\n        else:\n            self._log(\n                f\"    - Warning: Invalid boundary condition type '{bc_type}'. Using default.\",\n                log_type=\"warning\",\n            )\n    else:\n        self._log(\n            \"    - Warning: 'GlobalBoundarySettings' not found on simulation object.\",\n            log_type=\"warning\",\n        )\n\n    # Set PML Strength\n    strength = boundary_config.get(\"strength\", \"Medium\").capitalize()\n    self._log(f\"  - Setting PML strength to: {strength}\", log_type=\"info\")\n\n    boundary_settings_list = [x for x in self.simulation.AllSettings if isinstance(x, self.emfdtd.BoundarySettings)]\n    if not boundary_settings_list:\n        self._log(\n            \"  - No BoundarySettings found in simulation. Cannot set PML strength.\",\n            log_type=\"warning\",\n        )\n        return\n\n    boundary_settings = boundary_settings_list[0]\n\n    strength_enum = boundary_settings.PmlStrength.enum\n    if hasattr(strength_enum, strength):\n        boundary_settings.PmlStrength = getattr(strength_enum, strength)\n        self._log(f\"    - Successfully set PmlStrength to {strength}\", log_type=\"verbose\")\n    else:\n        self._log(\n            f\"    - Warning: Invalid PML strength '{strength}'. Using default (Medium).\",\n            log_type=\"warning\",\n        )\n        boundary_settings.PmlStrength = strength_enum.Medium\n</code></pre>"},{"location":"reference/api_reference/#far-field-setup","title":"Far Field Setup","text":""},{"location":"reference/api_reference/#goliat.setups.far_field_setup.FarFieldSetup","title":"goliat.setups.far_field_setup.FarFieldSetup","text":"<pre><code>FarFieldSetup(config: Config, phantom_name: str, frequency_mhz: int | list[int], direction_name: str, polarization_name: str, project_manager: ProjectManager, verbose_logger: Logger, progress_logger: Logger, profiler: Profiler, gui=None)\n</code></pre> <p>               Bases: <code>BaseSetup</code></p> <p>Configures a far-field simulation for a specific direction and polarization.</p> Source code in <code>goliat/setups/far_field_setup.py</code> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    phantom_name: str,\n    frequency_mhz: int | list[int],\n    direction_name: str,\n    polarization_name: str,\n    project_manager: \"ProjectManager\",\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n    profiler: \"Profiler\",\n    gui=None,\n):\n    \"\"\"Store far-field parameters (direction, polarization, frequency).\"\"\"\n    super().__init__(config, verbose_logger, progress_logger, gui)\n    self.phantom_name = phantom_name\n    self.frequency_mhz = frequency_mhz\n    # For multi-sine, use highest frequency for grid/reference\n    self.reference_frequency_mhz = max(frequency_mhz) if isinstance(frequency_mhz, list) else frequency_mhz\n    self.is_multisine = isinstance(frequency_mhz, list)\n    self.direction_name = direction_name\n    self.polarization_name = polarization_name\n    self.project_manager = project_manager\n    self.profiler = profiler\n    self.gui = gui\n    self.simulation_type = self.config[\"far_field_setup.type\"]\n    if self.simulation_type is None:\n        self.simulation_type = \"environmental\"\n    self.document = self.s4l_v1.document\n</code></pre>"},{"location":"reference/api_reference/#goliat.setups.far_field_setup.FarFieldSetup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.setups.far_field_setup.FarFieldSetup.run_full_setup","title":"run_full_setup","text":"<pre><code>run_full_setup(project_manager: ProjectManager) -&gt; emfdtd.Simulation\n</code></pre> <p>Executes the full setup sequence for a single far-field simulation with granular timing.</p> Source code in <code>goliat/setups/far_field_setup.py</code> <pre><code>def run_full_setup(self, project_manager: \"ProjectManager\") -&gt; \"emfdtd.Simulation\":\n    \"\"\"Executes the full setup sequence for a single far-field simulation with granular timing.\"\"\"\n    self._log(\"--- Setting up single Far-Field sim ---\", log_type=\"header\")\n\n    # Subtask 1: Load phantom\n    self._log(\"    - Load phantom...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_load_phantom\"):\n        phantom_setup = PhantomSetup(\n            self.config,\n            self.phantom_name,\n            self.verbose_logger,\n            self.progress_logger,\n        )\n        phantom_setup.ensure_phantom_is_loaded()\n    elapsed = self.profiler.subtask_times[\"setup_load_phantom\"][-1]\n    self._log(f\"      - Subtask 'setup_load_phantom' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Subtask 2: Configure scene\n    self._log(\"    - Configure scene (bbox, plane wave)...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_configure_scene\"):\n        bbox_entity = self._create_or_get_simulation_bbox()\n        simulation = self._create_simulation_entity(bbox_entity)\n    elapsed = self.profiler.subtask_times[\"setup_configure_scene\"][-1]\n    self._log(f\"      - Subtask 'setup_configure_scene' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Subtask 3: Assign materials\n    self._log(\"    - Assign materials...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_materials\"):\n        material_setup = MaterialSetup(\n            self.config,\n            simulation,\n            None,  # type: ignore\n            self.phantom_name,\n            self.verbose_logger,\n            self.progress_logger,\n            free_space=False,\n            frequencies_mhz=list(self.frequency_mhz) if self.is_multisine else None,  # type: ignore[arg-type]\n        )\n        material_setup.assign_materials(phantom_only=True)\n    elapsed = self.profiler.subtask_times[\"setup_materials\"][-1]\n    self._log(f\"      - Subtask 'setup_materials' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Subtask 4: Configure solver\n    self._log(\"    - Configure solver (gridding, boundaries, sensors)...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_solver\"):\n        gridding_setup = GriddingSetup(\n            self.config,\n            simulation,\n            None,  # type: ignore\n            None,  # type: ignore\n            self.verbose_logger,\n            self.progress_logger,\n            frequency_mhz=self.reference_frequency_mhz,\n        )\n        gridding_setup.setup_gridding()\n\n        boundary_setup = BoundarySetup(self.config, simulation, self.verbose_logger, self.progress_logger)\n        boundary_setup.setup_boundary_conditions()\n\n        self._add_point_sensors(simulation, \"far_field_simulation_bbox\")\n        self._setup_solver_settings(simulation)\n    elapsed = self.profiler.subtask_times[\"setup_solver\"][-1]\n    self._log(f\"      - Subtask 'setup_solver' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Subtask 5: Voxelize\n    self._log(\"    - Voxelize simulation...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_voxelize\"):\n        bbox_entity = next(\n            (e for e in self.model.AllEntities() if hasattr(e, \"Name\") and e.Name == \"far_field_simulation_bbox\"),\n            None,\n        )\n        if not bbox_entity:\n            raise RuntimeError(\"Could not find 'far_field_simulation_bbox' for voxelization.\")\n\n        import XCoreModeling\n\n        phantom_entities = [e for e in self.model.AllEntities() if isinstance(e, XCoreModeling.TriangleMesh)]\n        point_sensor_entities = [e for e in self.model.AllEntities() if \"Point Sensor Entity\" in e.Name]\n\n        all_simulation_parts = phantom_entities + [bbox_entity] + point_sensor_entities\n\n        super()._finalize_setup(self.project_manager, simulation, all_simulation_parts, self.reference_frequency_mhz)\n    elapsed = self.profiler.subtask_times[\"setup_voxelize\"][-1]\n    self._log(f\"      - Subtask 'setup_voxelize' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Subtask 6: Save project\n    self._log(\"    - Save project...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_save_project\"):\n        project_manager.save()\n    elapsed = self.profiler.subtask_times[\"setup_save_project\"][-1]\n    self._log(f\"      - Subtask 'setup_save_project' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    self._log(\"Common settings applied.\", log_type=\"success\")\n    return simulation\n</code></pre>"},{"location":"reference/api_reference/#gridding-setup","title":"Gridding Setup","text":""},{"location":"reference/api_reference/#goliat.setups.gridding_setup.GriddingSetup","title":"goliat.setups.gridding_setup.GriddingSetup","text":"<pre><code>GriddingSetup(config: Config, simulation: Simulation, placement_name: str, antenna: Antenna, verbose_logger: Logger, progress_logger: Logger, frequency_mhz: int | None = None)\n</code></pre> <p>               Bases: <code>BaseSetup</code></p> <p>Configures simulation grid resolution and subgridding.</p> <p>Sets up main grid (automatic or manual) with padding, and optional antenna-specific subgrids for fine details.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required <code>simulation</code> <code>Simulation</code> <p>The simulation object to configure gridding for.</p> required <code>placement_name</code> <code>str</code> <p>Name of the placement scenario.</p> required <code>antenna</code> <code>Antenna</code> <p>Antenna object.</p> required <code>verbose_logger</code> <code>Logger</code> <p>Logger for detailed output.</p> required <code>progress_logger</code> <code>Logger</code> <p>Logger for progress updates.</p> required <code>frequency_mhz</code> <code>int | None</code> <p>Simulation frequency in MHz (optional).</p> <code>None</code> Source code in <code>goliat/setups/gridding_setup.py</code> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    simulation: \"emfdtd.Simulation\",\n    placement_name: str,\n    antenna: \"Antenna\",\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n    frequency_mhz: int | None = None,\n):\n    \"\"\"Initializes the GriddingSetup.\n\n    Args:\n        config: Configuration object.\n        simulation: The simulation object to configure gridding for.\n        placement_name: Name of the placement scenario.\n        antenna: Antenna object.\n        verbose_logger: Logger for detailed output.\n        progress_logger: Logger for progress updates.\n        frequency_mhz: Simulation frequency in MHz (optional).\n    \"\"\"\n    super().__init__(config, verbose_logger, progress_logger)\n    self.simulation = simulation\n    self.placement_name = placement_name\n    self.antenna = antenna\n    self.frequency_mhz = frequency_mhz\n\n    import s4l_v1.units\n\n    self.units = s4l_v1.units\n</code></pre>"},{"location":"reference/api_reference/#goliat.setups.gridding_setup.GriddingSetup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.setups.gridding_setup.GriddingSetup.setup_gridding","title":"setup_gridding","text":"<pre><code>setup_gridding(antenna_components: dict | None = None)\n</code></pre> <p>Sets up main grid and optional antenna subgrids.</p> <p>Parameters:</p> Name Type Description Default <code>antenna_components</code> <code>dict | None</code> <p>Dict mapping component names to entities.</p> <code>None</code> Source code in <code>goliat/setups/gridding_setup.py</code> <pre><code>def setup_gridding(self, antenna_components: dict | None = None):\n    \"\"\"Sets up main grid and optional antenna subgrids.\n\n    Args:\n        antenna_components: Dict mapping component names to entities.\n    \"\"\"\n    self._log(\"Setting up gridding...\", log_type=\"progress\")\n    self._setup_main_grid()\n    if antenna_components:\n        self._setup_subgrids(antenna_components)\n    else:\n        self._log(\n            \"  - No antenna components provided, skipping subgridding.\",\n            log_type=\"info\",\n        )\n</code></pre>"},{"location":"reference/api_reference/#material-setup","title":"Material Setup","text":""},{"location":"reference/api_reference/#goliat.setups.material_setup.MaterialSetup","title":"goliat.setups.material_setup.MaterialSetup","text":"<pre><code>MaterialSetup(config: Config, simulation: Simulation, antenna: Antenna, phantom_name: str, verbose_logger: Logger, progress_logger: Logger, free_space: bool = False, frequencies_mhz: list[int] | None = None)\n</code></pre> <p>               Bases: <code>BaseSetup</code></p> <p>Assigns materials to phantom tissues and antenna components.</p> <p>Maps tissue names to IT'IS database materials and assigns antenna materials from config. Uses file locking for thread-safe database access.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required <code>simulation</code> <code>Simulation</code> <p>The simulation object to assign materials to.</p> required <code>antenna</code> <code>Antenna</code> <p>Antenna object.</p> required <code>phantom_name</code> <code>str</code> <p>Name of the phantom model.</p> required <code>verbose_logger</code> <code>Logger</code> <p>Logger for detailed output.</p> required <code>progress_logger</code> <code>Logger</code> <p>Logger for progress updates.</p> required <code>free_space</code> <code>bool</code> <p>Whether this is a free-space simulation.</p> <code>False</code> <code>frequencies_mhz</code> <code>list[int] | None</code> <p>List of frequencies for multisine dispersion fitting.</p> <code>None</code> Source code in <code>goliat/setups/material_setup.py</code> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    simulation: \"emfdtd.Simulation\",\n    antenna: \"Antenna\",\n    phantom_name: str,\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n    free_space: bool = False,\n    frequencies_mhz: list[int] | None = None,\n):\n    \"\"\"Initializes the MaterialSetup.\n\n    Args:\n        config: Configuration object.\n        simulation: The simulation object to assign materials to.\n        antenna: Antenna object.\n        phantom_name: Name of the phantom model.\n        verbose_logger: Logger for detailed output.\n        progress_logger: Logger for progress updates.\n        free_space: Whether this is a free-space simulation.\n        frequencies_mhz: List of frequencies for multisine dispersion fitting.\n    \"\"\"\n    super().__init__(config, verbose_logger, progress_logger)\n    self.simulation = simulation\n    self.antenna = antenna\n    self.phantom_name = phantom_name\n    self.free_space = free_space\n    self.frequencies_mhz = frequencies_mhz\n    self.is_multisine = frequencies_mhz is not None and len(frequencies_mhz) &gt; 1\n\n    # Import required modules\n    import s4l_v1.materials.database\n    import XCoreModeling\n\n    # Access material database - use s4l_v1.materials.database\n    self.database = s4l_v1.materials.database\n    self.XCoreModeling = XCoreModeling\n</code></pre>"},{"location":"reference/api_reference/#goliat.setups.material_setup.MaterialSetup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.setups.material_setup.MaterialSetup.assign_materials","title":"assign_materials","text":"<pre><code>assign_materials(antenna_components: dict | None = None, phantom_only: bool = False)\n</code></pre> <p>Assigns materials to simulation entities.</p> <p>Sets background to Air, then assigns phantom materials if not free-space, and antenna materials if not phantom_only mode.</p> <p>Parameters:</p> Name Type Description Default <code>antenna_components</code> <code>dict | None</code> <p>Dict mapping component names to entities.</p> <code>None</code> <code>phantom_only</code> <code>bool</code> <p>If True, skips antenna material assignment.</p> <code>False</code> Source code in <code>goliat/setups/material_setup.py</code> <pre><code>def assign_materials(self, antenna_components: dict | None = None, phantom_only: bool = False):\n    \"\"\"Assigns materials to simulation entities.\n\n    Sets background to Air, then assigns phantom materials if not free-space,\n    and antenna materials if not phantom_only mode.\n\n    Args:\n        antenna_components: Dict mapping component names to entities.\n        phantom_only: If True, skips antenna material assignment.\n    \"\"\"\n    self._log(\"Assigning materials...\", log_type=\"progress\")\n\n    # Background material\n    background_settings = self.simulation.raw.BackgroundMaterialSettings()  # type: ignore\n    air_material = self.database[\"Generic 1.1\"][\"Air\"]  # type: ignore\n    self.simulation.raw.AssignMaterial(background_settings, air_material)  # type: ignore\n\n    # Phantom materials\n    if not self.free_space:\n        if self.is_multisine:\n            self._assign_phantom_materials_multisine()\n        else:\n            self._assign_phantom_materials()\n\n    # Antenna materials\n    if not phantom_only:\n        if not antenna_components:\n            raise ValueError(\"antenna_components must be provided when not in phantom_only mode.\")\n        self._assign_antenna_materials(antenna_components)\n</code></pre>"},{"location":"reference/api_reference/#near-field-setup","title":"Near Field Setup","text":""},{"location":"reference/api_reference/#goliat.setups.near_field_setup.NearFieldSetup","title":"goliat.setups.near_field_setup.NearFieldSetup","text":"<pre><code>NearFieldSetup(config: Config, phantom_name: str, frequency_mhz: int, scenario_name: str, position_name: str, orientation_name: str, antenna: Antenna, verbose_logger: Logger, progress_logger: Logger, profiler: Profiler, gui=None, free_space: bool = False)\n</code></pre> <p>               Bases: <code>BaseSetup</code></p> <p>Configures the simulation environment by coordinating setup modules.</p> Source code in <code>goliat/setups/near_field_setup.py</code> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    phantom_name: str,\n    frequency_mhz: int,\n    scenario_name: str,\n    position_name: str,\n    orientation_name: str,\n    antenna: \"Antenna\",\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n    profiler: \"Profiler\",\n    gui=None,\n    free_space: bool = False,\n):\n    \"\"\"Store near-field parameters (scenario, position, orientation, antenna).\"\"\"\n    super().__init__(config, verbose_logger, progress_logger, gui)\n    self.phantom_name = phantom_name\n    self.frequency_mhz = frequency_mhz\n    self.base_placement_name = scenario_name\n    self.position_name = position_name\n    self.orientation_name = orientation_name\n    self.placement_name = f\"{scenario_name}_{position_name}_{orientation_name}\"\n    self.antenna = antenna\n    self.profiler = profiler\n    self.gui = gui\n    self.free_space = free_space\n    # Will be set in _setup_simulation_entity if detuning is enabled\n    self.final_frequency_mhz = frequency_mhz\n\n    # S4L modules\n    import XCoreModeling\n\n    self.document = self.s4l_v1.document\n    self.XCoreModeling = XCoreModeling\n</code></pre>"},{"location":"reference/api_reference/#goliat.setups.near_field_setup.NearFieldSetup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.setups.near_field_setup.NearFieldSetup.run_full_setup","title":"run_full_setup","text":"<pre><code>run_full_setup(project_manager: ProjectManager, lock=None) -&gt; emfdtd.Simulation\n</code></pre> <p>Executes complete setup sequence with detailed timing.</p> <p>Orchestrates the entire simulation setup process in 6 major subtasks:</p> <ol> <li> <p>Load phantom: Imports phantom model from disk or downloads if missing.    Creates head/trunk bounding boxes if needed.</p> </li> <li> <p>Configure scene: Imports antenna, places it relative to phantom, creates    simulation bounding box, sets up simulation entity, adds point sensors.    Handles special cases like phantom rotation and phone alignment.</p> </li> <li> <p>Assign materials: Maps tissue names to IT'IS database materials, assigns    antenna component materials from config. Uses file locking for thread safety.</p> </li> <li> <p>Configure solver: Sets up gridding (automatic or manual with subgrids),    configures boundary conditions (PML), and sets up excitation sources.</p> </li> <li> <p>Voxelize: Runs automatic voxelization on all simulation entities, updates    materials and grid, optionally exports material properties.</p> </li> <li> <p>Save project: Saves the .smash file to disk.</p> </li> </ol> <p>Each subtask is profiled individually for accurate timing estimates. The method returns a fully configured simulation object ready to run.</p> <p>Parameters:</p> Name Type Description Default <code>project_manager</code> <code>ProjectManager</code> <p>Project manager for saving operations.</p> required <code>lock</code> <p>Optional lock (currently unused, reserved for future use).</p> <code>None</code> <p>Returns:</p> Type Description <code>Simulation</code> <p>Fully configured simulation object ready for execution.</p> Source code in <code>goliat/setups/near_field_setup.py</code> <pre><code>def run_full_setup(self, project_manager: \"ProjectManager\", lock=None) -&gt; \"emfdtd.Simulation\":\n    \"\"\"Executes complete setup sequence with detailed timing.\n\n    Orchestrates the entire simulation setup process in 6 major subtasks:\n\n    1. Load phantom: Imports phantom model from disk or downloads if missing.\n       Creates head/trunk bounding boxes if needed.\n\n    2. Configure scene: Imports antenna, places it relative to phantom, creates\n       simulation bounding box, sets up simulation entity, adds point sensors.\n       Handles special cases like phantom rotation and phone alignment.\n\n    3. Assign materials: Maps tissue names to IT'IS database materials, assigns\n       antenna component materials from config. Uses file locking for thread safety.\n\n    4. Configure solver: Sets up gridding (automatic or manual with subgrids),\n       configures boundary conditions (PML), and sets up excitation sources.\n\n    5. Voxelize: Runs automatic voxelization on all simulation entities, updates\n       materials and grid, optionally exports material properties.\n\n    6. Save project: Saves the .smash file to disk.\n\n    Each subtask is profiled individually for accurate timing estimates. The method\n    returns a fully configured simulation object ready to run.\n\n    Args:\n        project_manager: Project manager for saving operations.\n        lock: Optional lock (currently unused, reserved for future use).\n\n    Returns:\n        Fully configured simulation object ready for execution.\n    \"\"\"\n    self._log(\"Running full simulation setup...\", log_type=\"progress\")\n\n    # Subtask 1: Load phantom\n    if not self.free_space:\n        self._log(\"    - Load phantom...\", level=\"progress\", log_type=\"progress\")\n        with self.profiler.subtask(\"setup_load_phantom\"):\n            phantom_setup = PhantomSetup(\n                self.config,\n                self.phantom_name,\n                self.verbose_logger,\n                self.progress_logger,\n            )\n            phantom_setup.ensure_phantom_is_loaded()\n        elapsed = self.profiler.subtask_times[\"setup_load_phantom\"][-1]\n        self._log(f\"      - Subtask 'setup_load_phantom' done in {elapsed:.2f}s\", log_type=\"verbose\")\n        self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Subtask 2: Configure scene\n    self._log(\"    - Configure scene (bboxes, placement, simulation, sensors)...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_configure_scene\"):\n        if not self.free_space:\n            self._setup_bounding_boxes()\n\n        placement_setup = PlacementSetup(\n            self.config,\n            self.phantom_name,\n            self.frequency_mhz,\n            self.base_placement_name,\n            self.position_name,\n            self.orientation_name,\n            self.antenna,\n            self.verbose_logger,\n            self.progress_logger,\n            self.free_space,\n        )\n        placement_setup.place_antenna()\n\n        antenna_components = self._get_antenna_components()\n        self._create_simulation_bbox()\n        simulation = self._setup_simulation_entity()\n\n        # Configure overall field sensor based on config\n        self._configure_overall_field_sensor(simulation, self.frequency_mhz)\n\n        sim_bbox_name = f\"{self.placement_name.lower()}_simulation_bbox\"\n        self._add_point_sensors(simulation, sim_bbox_name)\n\n        self._handle_phantom_rotation(placement_setup)\n        self._align_simulation_with_phone()\n\n    elapsed = self.profiler.subtask_times[\"setup_configure_scene\"][-1]\n    self._log(f\"      - Subtask 'setup_configure_scene' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Subtask 3: Assign materials\n    self._log(\"    - Assign materials...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_materials\"):\n        material_setup = MaterialSetup(\n            self.config,\n            simulation,\n            self.antenna,\n            self.phantom_name,\n            self.verbose_logger,\n            self.progress_logger,\n            self.free_space,\n        )\n        material_setup.assign_materials(antenna_components)\n\n    elapsed = self.profiler.subtask_times[\"setup_materials\"][-1]\n    self._log(f\"      - Subtask 'setup_materials' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Subtask 4: Configure solver\n    self._log(\"    - Configure solver (gridding, boundaries, sources)...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_solver\"):\n        gridding_setup = GriddingSetup(\n            self.config,\n            simulation,\n            self.placement_name,\n            self.antenna,\n            self.verbose_logger,\n            self.progress_logger,\n            frequency_mhz=self.frequency_mhz,\n        )\n        gridding_setup.setup_gridding(antenna_components)\n\n        boundary_setup = BoundarySetup(self.config, simulation, self.verbose_logger, self.progress_logger)\n        boundary_setup.setup_boundary_conditions()\n\n        # Use final frequency (with detuning applied) for source setup\n        source_frequency = getattr(self, \"final_frequency_mhz\", self.frequency_mhz)\n        source_setup = SourceSetup(\n            self.config,\n            simulation,\n            source_frequency,\n            self.antenna,\n            self.verbose_logger,\n            self.progress_logger,\n            self.free_space,\n            self.phantom_name,\n            self.placement_name,\n        )\n        source_setup.setup_source_and_sensors(antenna_components)\n\n    elapsed = self.profiler.subtask_times[\"setup_solver\"][-1]\n    self._log(f\"      - Subtask 'setup_solver' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Subtask 5: Voxelize\n    self._log(\"    - Voxelize simulation...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_voxelize\"):\n        all_antenna_parts = list(antenna_components.values())\n        point_sensor_entities = [e for e in self.model.AllEntities() if \"Point Sensor Entity\" in e.Name]\n\n        if self.free_space:\n            sim_bbox_name = \"freespace_simulation_bbox\"\n        else:\n            sim_bbox_name = f\"{self.placement_name.lower()}_simulation_bbox\"\n\n        sim_bbox_entity = next(\n            (e for e in self.model.AllEntities() if hasattr(e, \"Name\") and e.Name == sim_bbox_name),\n            None,\n        )\n        if not sim_bbox_entity:\n            raise RuntimeError(f\"Could not find simulation bounding box: '{sim_bbox_name}' for voxelization.\")\n\n        phantom_entities = [e for e in self.model.AllEntities() if isinstance(e, self.XCoreModeling.TriangleMesh)]\n        all_simulation_parts = phantom_entities + all_antenna_parts + point_sensor_entities + [sim_bbox_entity]\n\n        super()._finalize_setup(project_manager, simulation, all_simulation_parts, self.frequency_mhz)\n\n    elapsed = self.profiler.subtask_times[\"setup_voxelize\"][-1]\n    self._log(f\"      - Subtask 'setup_voxelize' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Subtask 6: Save project\n    self._log(\"    - Save project...\", level=\"progress\", log_type=\"progress\")\n    with self.profiler.subtask(\"setup_save_project\"):\n        project_manager.save()\n    elapsed = self.profiler.subtask_times[\"setup_save_project\"][-1]\n    self._log(f\"      - Subtask 'setup_save_project' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    self._log(\"Full simulation setup complete.\", log_type=\"success\")\n    return simulation\n</code></pre>"},{"location":"reference/api_reference/#phantom-setup","title":"Phantom Setup","text":""},{"location":"reference/api_reference/#goliat.setups.phantom_setup.PhantomSetup","title":"goliat.setups.phantom_setup.PhantomSetup","text":"<pre><code>PhantomSetup(config: Config, phantom_name: str, verbose_logger: Logger, progress_logger: Logger)\n</code></pre> <p>               Bases: <code>BaseSetup</code></p> <p>Handles loading and importing phantom models into Sim4Life.</p> Source code in <code>goliat/setups/phantom_setup.py</code> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    phantom_name: str,\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n):\n    \"\"\"Store phantom name and import S4L modules.\"\"\"\n    super().__init__(config, verbose_logger, progress_logger)\n    self.phantom_name = phantom_name\n\n    import s4l_v1.data\n    import s4l_v1.model\n    import XCoreModeling\n\n    self.model = s4l_v1.model\n    self.data = s4l_v1.data\n    self.XCoreModeling = XCoreModeling\n</code></pre>"},{"location":"reference/api_reference/#goliat.setups.phantom_setup.PhantomSetup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.setups.phantom_setup.PhantomSetup.ensure_phantom_is_loaded","title":"ensure_phantom_is_loaded","text":"<pre><code>ensure_phantom_is_loaded() -&gt; bool\n</code></pre> <p>Checks if phantom is loaded, imports from disk if available, or downloads if missing.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if phantom is now loaded, False if download was initiated (requires re-run).</p> Source code in <code>goliat/setups/phantom_setup.py</code> <pre><code>def ensure_phantom_is_loaded(self) -&gt; bool:\n    \"\"\"Checks if phantom is loaded, imports from disk if available, or downloads if missing.\n\n    Returns:\n        True if phantom is now loaded, False if download was initiated (requires re-run).\n    \"\"\"\n    self._log(\"--- Running Phantom Check ---\", log_type=\"header\")\n    all_entities = self.model.AllEntities()\n    self._log(f\"Found {len(all_entities)} total entities in the project.\", log_type=\"info\")\n\n    is_loaded = False\n    for i, entity in enumerate(all_entities):\n        if hasattr(entity, \"Name\"):\n            entity_name_lower = entity.Name.lower()\n            phantom_name_lower = self.phantom_name.lower()\n            if phantom_name_lower in entity_name_lower:\n                is_loaded = True\n                break\n        else:\n            self._log(f\"  - Entity {i}: (No 'Name' attribute)\", log_type=\"verbose\")\n\n    if is_loaded:\n        self._log(\n            \"--- Phantom Check Result: Phantom model is already present. ---\",\n            log_type=\"success\",\n        )\n        return True\n    else:\n        self._log(\n            \"--- Phantom Check Result: Phantom not found in project. ---\",\n            log_type=\"warning\",\n        )\n\n    study_type = self.config[\"study_type\"]\n    if study_type == \"near_field\" or study_type == \"far_field\":\n        sab_path = os.path.join(self.config.base_dir, \"data\", \"phantoms\", f\"{self.phantom_name}.sab\")\n        if os.path.exists(sab_path):\n            self._log(\n                f\"Phantom not found in document. Importing from '{sab_path}'...\",\n                log_type=\"info\",\n            )\n            self.XCoreModeling.Import(sab_path)\n            self._log(\"Phantom imported successfully.\", log_type=\"success\")\n            return True\n\n        self._log(\n            f\"Local .sab file not found. Attempting to download '{self.phantom_name}'...\",\n            log_type=\"info\",\n        )\n        available_downloads = self.data.GetAvailableDownloads()\n        phantom_to_download = next(\n            (item for item in available_downloads if self.phantom_name.lower() in item.Name.lower()),\n            None,\n        )\n\n        if not phantom_to_download:\n            raise FileNotFoundError(f\"Phantom '{self.phantom_name}' not found for download or in local files.\")\n\n        self._log(f\"Found '{phantom_to_download.Name}'. Downloading...\", log_type=\"info\")\n        download_email = self.config[\"download_email\"]\n        if download_email is None:\n            download_email = \"example@example.com\"\n        self.data.DownloadModel(\n            phantom_to_download,\n            email=download_email,  # type: ignore\n            directory=os.path.join(self.config.base_dir, \"data\", \"phantoms\"),\n        )\n        self._log(\n            \"Phantom downloaded successfully. Please re-run the script to import the new .sab file.\",\n            log_type=\"success\",\n        )\n        return False\n    else:\n        raise ValueError(f\"Unknown study type: {study_type}\")\n</code></pre>"},{"location":"reference/api_reference/#placement-setup","title":"Placement Setup","text":""},{"location":"reference/api_reference/#goliat.setups.placement_setup.PlacementSetup","title":"goliat.setups.placement_setup.PlacementSetup","text":"<pre><code>PlacementSetup(config: Config, phantom_name: str, frequency_mhz: int, base_placement_name: str, position_name: str, orientation_name: str, antenna: Antenna, verbose_logger: Logger, progress_logger: Logger, free_space: bool = False)\n</code></pre> <p>               Bases: <code>BaseSetup</code></p> <p>Handles antenna placement and orientation relative to phantom.</p> <p>Imports antenna model, calculates target position based on placement scenario, and applies composed transformation (stand-up rotation, translation, orientation twists) to position antenna correctly.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required <code>phantom_name</code> <code>str</code> <p>Name of the phantom model.</p> required <code>frequency_mhz</code> <code>int</code> <p>Simulation frequency in MHz.</p> required <code>base_placement_name</code> <code>str</code> <p>Base name of the placement scenario.</p> required <code>position_name</code> <code>str</code> <p>Name of the position within the scenario.</p> required <code>orientation_name</code> <code>str</code> <p>Name of the orientation within the scenario.</p> required <code>antenna</code> <code>Antenna</code> <p>Antenna object to place.</p> required <code>verbose_logger</code> <code>Logger</code> <p>Logger for detailed output.</p> required <code>progress_logger</code> <code>Logger</code> <p>Logger for progress updates.</p> required <code>free_space</code> <code>bool</code> <p>Whether this is a free-space simulation.</p> <code>False</code> Source code in <code>goliat/setups/placement_setup.py</code> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    phantom_name: str,\n    frequency_mhz: int,\n    base_placement_name: str,\n    position_name: str,\n    orientation_name: str,\n    antenna: \"Antenna\",\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n    free_space: bool = False,\n):\n    \"\"\"Initializes the PlacementSetup.\n\n    Args:\n        config: Configuration object.\n        phantom_name: Name of the phantom model.\n        frequency_mhz: Simulation frequency in MHz.\n        base_placement_name: Base name of the placement scenario.\n        position_name: Name of the position within the scenario.\n        orientation_name: Name of the orientation within the scenario.\n        antenna: Antenna object to place.\n        verbose_logger: Logger for detailed output.\n        progress_logger: Logger for progress updates.\n        free_space: Whether this is a free-space simulation.\n    \"\"\"\n    super().__init__(config, verbose_logger, progress_logger)\n    self.phantom_name = phantom_name\n    self.frequency_mhz = frequency_mhz\n    self.base_placement_name = base_placement_name\n    self.position_name = position_name\n    self.orientation_name = orientation_name\n    self.placement_name = f\"{base_placement_name}_{position_name}_{orientation_name}\"\n    self.antenna = antenna\n    self.free_space = free_space\n\n    # Import XCoreMath for transformations\n    import XCoreMath\n\n    self.XCoreMath = XCoreMath\n</code></pre>"},{"location":"reference/api_reference/#goliat.setups.placement_setup.PlacementSetup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.setups.placement_setup.PlacementSetup.place_antenna","title":"place_antenna","text":"<pre><code>place_antenna()\n</code></pre> <p>Places and orients antenna using a single composed transformation.</p> <p>This method implements a key optimization: instead of applying multiple transforms sequentially (which causes precision loss and can accumulate errors), it composes all transformations into a single matrix and applies it once.</p> <p>The transformation sequence is: 1. Stand-up rotation: Rotates antenna 90\u00b0 around X-axis to make it upright 2. Base translation: Moves antenna to a reference point (speaker location) 3. Special rotation: For 'by_cheek', applies -90\u00b0 Z-rotation to align with YZ plane 4. Orientation twists: Applies any rotations specified in orientation config 5. Final translation: Moves antenna to its target position relative to phantom</p> <p>The order matters because matrix multiplication is not commutative. Each step builds on the previous transform, so the antenna ends up correctly positioned and oriented relative to the phantom regardless of how many rotations are needed.</p> <p>Parameters:</p> Name Type Description Default <code>None (uses instance attributes</code> <p>antenna, placement_name, etc.)</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If antenna import fails or required entities aren't found.</p> Source code in <code>goliat/setups/placement_setup.py</code> <pre><code>def place_antenna(self):\n    \"\"\"Places and orients antenna using a single composed transformation.\n\n    This method implements a key optimization: instead of applying multiple\n    transforms sequentially (which causes precision loss and can accumulate errors),\n    it composes all transformations into a single matrix and applies it once.\n\n    The transformation sequence is:\n    1. Stand-up rotation: Rotates antenna 90\u00b0 around X-axis to make it upright\n    2. Base translation: Moves antenna to a reference point (speaker location)\n    3. Special rotation: For 'by_cheek', applies -90\u00b0 Z-rotation to align with YZ plane\n    4. Orientation twists: Applies any rotations specified in orientation config\n    5. Final translation: Moves antenna to its target position relative to phantom\n\n    The order matters because matrix multiplication is not commutative. Each step\n    builds on the previous transform, so the antenna ends up correctly positioned\n    and oriented relative to the phantom regardless of how many rotations are needed.\n\n    Args:\n        None (uses instance attributes: antenna, placement_name, etc.)\n\n    Raises:\n        RuntimeError: If antenna import fails or required entities aren't found.\n    \"\"\"\n    self._log(\n        f\"--- Starting Placement: {self.base_placement_name} - {self.position_name} - {self.orientation_name} ---\",\n        log_type=\"header\",\n    )\n\n    phantom_definition = (self.config[\"phantom_definitions\"] or {}).get(self.phantom_name.lower(), {})\n    if not self.free_space and not phantom_definition.get(\"placements\", {}).get(f\"do_{self.base_placement_name}\"):\n        self._log(\n            f\"Placement '{self.base_placement_name}' is disabled in the configuration.\",\n            log_type=\"info\",\n        )\n        return\n\n    base_target_point, position_offset = self._get_placement_details()\n\n    # Import antenna model\n    antenna_path = self.antenna.get_centered_antenna_path(os.path.join(self.config.base_dir, \"data\", \"antennas\", \"centered\"))\n    imported_entities = list(self.model.Import(antenna_path))\n\n    antenna_group = next(\n        (e for e in imported_entities if \"Antenna\" in e.Name and \"bounding box\" not in e.Name),\n        None,\n    )\n    bbox_entity = next((e for e in imported_entities if \"bounding box\" in e.Name), None)\n\n    if not antenna_group:\n        raise RuntimeError(\"Could not find imported antenna group.\")\n\n    # Find the \"Ground\" entity/entities (\"PCB\" of the phone excl. IFA antenna)\n    ground_entities = [e for e in antenna_group.Entities if \"Ground\" in e.Name or \"Substrate\" in e.Name]  # type: ignore\n\n    # Normalize antenna group name to use requested frequency (in case fallback file was used)\n    # Replace any frequency in the name with the requested frequency\n    normalized_name = re.sub(r\"\\d+\\s*MHz\", f\"{self.antenna.frequency_mhz} MHz\", antenna_group.Name)\n\n    # Rename the entities to include the placement name for uniqueness\n    antenna_group.Name = f\"{normalized_name} ({self.placement_name})\"\n    if bbox_entity:\n        # Also normalize bounding box name if it contains frequency\n        normalized_bbox_name = re.sub(r\"\\d+\\s*MHz\", f\"{self.antenna.frequency_mhz} MHz\", bbox_entity.Name)\n        bbox_entity.Name = f\"{normalized_bbox_name} ({self.placement_name})\"\n\n    entities_to_transform = [antenna_group, bbox_entity] if bbox_entity else [antenna_group]\n\n    # --- Transformation Composition ---\n    self._log(\"Composing final transformation...\", log_type=\"progress\")\n\n    # Start with an identity transform\n    final_transform = self.XCoreMath.Transform()\n\n    # 1. Stand-up Rotation\n    rot_stand_up = self.XCoreMath.Rotation(self.XCoreMath.Vec3(1, 0, 0), np.deg2rad(90))\n    final_transform = rot_stand_up * final_transform\n\n    # 2. Base translation to antenna reference point (speaker output of the mock-up phone)\n    reference_target_point = self._get_speaker_reference(ground_entities, upright_transform=final_transform)\n    base_translation = self.XCoreMath.Translation(reference_target_point)\n    final_transform = base_translation * final_transform\n\n    # Special rotation for 'by_cheek' to align with YZ plane\n    if self.base_placement_name.startswith(\"by_cheek\"):\n        self._log(\"Applying 'by_cheek' specific Z-rotation.\", log_type=\"info\")\n        rot_z_cheek = self.XCoreMath.Rotation(self.XCoreMath.Vec3(0, 0, 1), np.deg2rad(-90))\n        final_transform = rot_z_cheek * final_transform\n\n    # 3. Orientation Twist\n    if self.orientation_rotations:\n        for rot in self.orientation_rotations:\n            axis_map = {\n                \"X\": self.XCoreMath.Vec3(1, 0, 0),\n                \"Y\": self.XCoreMath.Vec3(0, 1, 0),\n                \"Z\": self.XCoreMath.Vec3(0, 0, 1),\n            }\n            rot_twist = self.XCoreMath.Rotation(axis_map[rot[\"axis\"].upper()], np.deg2rad(rot[\"angle_deg\"]))\n            final_transform = rot_twist * final_transform\n\n    # 4. Final Translation\n    final_target_point = self.model.Vec3(\n        base_target_point[0] + position_offset[0],\n        base_target_point[1] + position_offset[1],\n        base_target_point[2] + position_offset[2],\n    )\n    translation_transform = self.XCoreMath.Translation(final_target_point)\n    final_transform = translation_transform * final_transform\n\n    # --- Apply the single, composed transform ---\n    self._log(\"Applying final composed transform.\", log_type=\"progress\")\n    for entity in entities_to_transform:\n        entity.ApplyTransform(final_transform)\n\n    self._log(\"--- Transformation Sequence Complete ---\", log_type=\"success\")\n</code></pre>"},{"location":"reference/api_reference/#source-setup","title":"Source Setup","text":""},{"location":"reference/api_reference/#goliat.setups.source_setup.SourceSetup","title":"goliat.setups.source_setup.SourceSetup","text":"<pre><code>SourceSetup(config: Config, simulation: Simulation, frequency_mhz: int, antenna: Antenna, verbose_logger: Logger, progress_logger: Logger, free_space: bool = False, phantom_name: Optional[str] = None, placement_name: Optional[str] = None)\n</code></pre> <p>               Bases: <code>BaseSetup</code></p> <p>Configures excitation sources and sensors for the simulation.</p> Source code in <code>goliat/setups/source_setup.py</code> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    simulation: \"emfdtd.Simulation\",\n    frequency_mhz: int,\n    antenna: \"Antenna\",\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n    free_space: bool = False,\n    phantom_name: Optional[str] = None,\n    placement_name: Optional[str] = None,\n):\n    \"\"\"Store simulation, frequency, and antenna for source configuration.\"\"\"\n    super().__init__(config, verbose_logger, progress_logger)\n    self.simulation = simulation\n    self.frequency_mhz = frequency_mhz\n    self.antenna = antenna\n    self.free_space = free_space\n    self.phantom_name = phantom_name\n    self.placement_name = placement_name\n\n    import s4l_v1.units\n\n    self.units = s4l_v1.units\n</code></pre>"},{"location":"reference/api_reference/#goliat.setups.source_setup.SourceSetup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.setups.source_setup.SourceSetup.setup_source_and_sensors","title":"setup_source_and_sensors","text":"<pre><code>setup_source_and_sensors(antenna_components: dict)\n</code></pre> <p>Sets up the edge source and sensors based on excitation type.</p> <p>Uses excitation_type from config to determine Harmonic or Gaussian excitation. For free-space simulations, also adds far-field sensors for Gaussian sources.</p> <p>Parameters:</p> Name Type Description Default <code>antenna_components</code> <code>dict</code> <p>Dict mapping component names to entities.</p> required Source code in <code>goliat/setups/source_setup.py</code> <pre><code>def setup_source_and_sensors(self, antenna_components: dict):\n    \"\"\"Sets up the edge source and sensors based on excitation type.\n\n    Uses excitation_type from config to determine Harmonic or Gaussian excitation.\n    For free-space simulations, also adds far-field sensors for Gaussian sources.\n\n    Args:\n        antenna_components: Dict mapping component names to entities.\n    \"\"\"\n    self._log(\"Setting up source and sensors...\", log_type=\"progress\")\n\n    source_name = self.antenna.get_source_entity_name()\n    if source_name not in antenna_components:\n        raise RuntimeError(f\"Could not find source entity '{source_name}' in antenna group.\")\n    source_entity = antenna_components[source_name]\n\n    # Source setup\n    edge_source_settings = self.emfdtd.EdgeSourceSettings()\n\n    # Get the enum for ExcitationType\n    excitation_enum = edge_source_settings.ExcitationType.enum\n\n    # Read excitation type from config (default to Harmonic for backward compatibility)\n    excitation_type = self.config[\"simulation_parameters.excitation_type\"] or \"Harmonic\"\n    excitation_type_lower = excitation_type.lower() if isinstance(excitation_type, str) else \"harmonic\"\n\n    if excitation_type_lower == \"gaussian\":\n        bandwidth_mhz_val = self.config[\"simulation_parameters.bandwidth_mhz\"] or 50.0\n        bandwidth_mhz = float(bandwidth_mhz_val) if not isinstance(bandwidth_mhz_val, dict) else 50.0\n        k_val = self.config[\"simulation_parameters.gaussian_pulse_k\"] or 3\n        k = int(k_val) if not isinstance(k_val, dict) else 3\n\n        if k == 5:\n            # Use Sim4Life built-in Gaussian (forced k=5)\n            self._log(f\"  - Using Sim4Life built-in Gaussian source (BW: {bandwidth_mhz} MHz, k=5).\", log_type=\"info\")\n            edge_source_settings.ExcitationType = excitation_enum.Gaussian\n            edge_source_settings.CenterFrequency = self.frequency_mhz, self.units.MHz\n            edge_source_settings.Bandwidth = bandwidth_mhz, self.units.MHz\n        else:\n            # Use custom Gaussian waveform with user-defined k (faster pulse)\n            self._log(f\"  - Using custom Gaussian source (BW: {bandwidth_mhz} MHz, k={k}).\", log_type=\"info\")\n            edge_source_settings.ExcitationType = excitation_enum.UserDefined\n\n            # Set up user-defined signal from equation\n            user_signal_enum = edge_source_settings.UserSignalType.enum\n            edge_source_settings.UserSignalType = user_signal_enum.FromEquation\n\n            # Calculate parameters for Gaussian pulse\n            # \u03c3 = 0.94/(\u03c0\u00b7BW), t\u2080 = k\u00b7\u03c3 (to start near zero)\n            bandwidth_hz = bandwidth_mhz * 1e6\n            center_freq_hz = self.frequency_mhz * 1e6\n            sigma = 0.94 / (np.pi * bandwidth_hz)\n            t0 = float(k) * sigma\n\n            # Create Gaussian-modulated pulse expression: A * exp(-(_t-t\u2080)\u00b2/(2\u03c3\u00b2)) * cos(2\u03c0\u00b7f\u2080\u00b7_t)\n            # Using Sim4Life expression syntax with '_t' as time variable\n            # Note: Using ** for exponentiation (Python-style) instead of ^\n            amplitude = 1.0\n            expression = f\"{amplitude} * exp(-(_t - {t0})**2 / (2 * {sigma}**2)) * cos(2 * pi * {center_freq_hz} * _t)\"\n            edge_source_settings.UserExpression = expression\n\n            # Set center frequency for reference (used by post-processing)\n            edge_source_settings.CenterFrequency = self.frequency_mhz, self.units.MHz\n    else:\n        self._log(\"  - Using Harmonic source.\", log_type=\"info\")\n        # Frequency already has detuning applied in NearFieldSetup if enabled\n        edge_source_settings.ExcitationType = excitation_enum.Harmonic\n        edge_source_settings.Frequency = self.frequency_mhz, self.units.MHz\n        edge_source_settings.CenterFrequency = self.frequency_mhz, self.units.MHz\n\n    self.simulation.Add(edge_source_settings, [source_entity])\n\n    # Sensor setup\n    edge_sensor_settings = self.emfdtd.EdgeSensorSettings()\n    self.simulation.Add(edge_sensor_settings, [source_entity])\n\n    # Far-field sensors only for free-space simulations (for radiation patterns)\n    if self.free_space:\n        far_field_sensor_settings = self.simulation.AddFarFieldSensorSettings()\n\n        # Configure extracted frequencies for Gaussian source\n        if excitation_type_lower == \"gaussian\":\n            center_freq_hz = self.frequency_mhz * 1e6\n            bandwidth_mhz_val = self.config[\"simulation_parameters.bandwidth_mhz\"] or 50.0\n            bandwidth_mhz_ff = float(bandwidth_mhz_val) if not isinstance(bandwidth_mhz_val, dict) else 50.0\n            bandwidth_hz = bandwidth_mhz_ff * 1e6\n            start_freq_hz = center_freq_hz - (bandwidth_hz / 2)\n            end_freq_hz = center_freq_hz + (bandwidth_hz / 2)\n\n            # Create a list of 21 frequencies, including the center frequency\n            num_samples = 21\n            extracted_frequencies_hz = [start_freq_hz + i * (bandwidth_hz / (num_samples - 1)) for i in range(num_samples)]\n\n            far_field_sensor_settings.ExtractedFrequencies = (\n                extracted_frequencies_hz,\n                self.units.Hz,\n            )\n            self._log(\n                f\"  - Set extracted frequencies from {start_freq_hz / 1e6} MHz to {end_freq_hz / 1e6} MHz.\",\n                log_type=\"info\",\n            )\n</code></pre>"},{"location":"reference/api_reference/#execution-strategies","title":"Execution Strategies","text":"<p>Strategy pattern implementations for different simulation execution methods.</p>"},{"location":"reference/api_reference/#execution-strategy","title":"Execution Strategy","text":""},{"location":"reference/api_reference/#goliat.runners.execution_strategy.ExecutionStrategy","title":"goliat.runners.execution_strategy.ExecutionStrategy","text":"<pre><code>ExecutionStrategy(config: Config, project_path: str, simulation: Simulation, profiler: Profiler, verbose_logger: LoggingMixin, progress_logger: LoggingMixin, project_manager: ProjectManager, gui: QueueGUI | None = None)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for simulation execution strategies.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required <code>project_path</code> <code>str</code> <p>Path to the Sim4Life project file.</p> required <code>simulation</code> <code>Simulation</code> <p>The simulation object to run.</p> required <code>profiler</code> <code>Profiler</code> <p>Profiler for timing subtasks.</p> required <code>verbose_logger</code> <code>LoggingMixin</code> <p>Logger for detailed output.</p> required <code>progress_logger</code> <code>LoggingMixin</code> <p>Logger for high-level updates.</p> required <code>project_manager</code> <code>ProjectManager</code> <p>ProjectManager instance.</p> required <code>gui</code> <code>QueueGUI | None</code> <p>Optional GUI proxy for updates.</p> <code>None</code> Source code in <code>goliat/runners/execution_strategy.py</code> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    project_path: str,\n    simulation: \"s4l_v1.simulation.emfdtd.Simulation\",\n    profiler: \"Profiler\",\n    verbose_logger: \"LoggingMixin\",\n    progress_logger: \"LoggingMixin\",\n    project_manager: \"ProjectManager\",\n    gui: \"QueueGUI | None\" = None,\n):\n    \"\"\"Initialize execution strategy.\n\n    Args:\n        config: Configuration object.\n        project_path: Path to the Sim4Life project file.\n        simulation: The simulation object to run.\n        profiler: Profiler for timing subtasks.\n        verbose_logger: Logger for detailed output.\n        progress_logger: Logger for high-level updates.\n        project_manager: ProjectManager instance.\n        gui: Optional GUI proxy for updates.\n    \"\"\"\n    self.config = config\n    self.project_path = project_path\n    self.simulation = simulation\n    self.profiler = profiler\n    self.verbose_logger = verbose_logger\n    self.progress_logger = progress_logger\n    self.project_manager = project_manager\n    self.gui = gui\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.execution_strategy.ExecutionStrategy-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.runners.execution_strategy.ExecutionStrategy.run","title":"run  <code>abstractmethod</code>","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Execute the simulation using this strategy.</p> <p>Raises:</p> Type Description <code>StudyCancelledError</code> <p>If execution is cancelled by user.</p> <code>RuntimeError</code> <p>If execution fails.</p> <code>FileNotFoundError</code> <p>If required files are missing.</p> Source code in <code>goliat/runners/execution_strategy.py</code> <pre><code>@abstractmethod\ndef run(self) -&gt; None:\n    \"\"\"Execute the simulation using this strategy.\n\n    Raises:\n        StudyCancelledError: If execution is cancelled by user.\n        RuntimeError: If execution fails.\n        FileNotFoundError: If required files are missing.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/api_reference/#isolve-manual-strategy","title":"Isolve Manual Strategy","text":""},{"location":"reference/api_reference/#goliat.runners.isolve_manual_strategy.ISolveManualStrategy","title":"goliat.runners.isolve_manual_strategy.ISolveManualStrategy","text":"<pre><code>ISolveManualStrategy(*args, **kwargs)\n</code></pre> <p>               Bases: <code>ExecutionStrategy</code>, <code>LoggingMixin</code></p> <p>Execution strategy for running iSolve.exe directly via subprocess.</p> Source code in <code>goliat/runners/isolve_manual_strategy.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"Initialize iSolve manual strategy.\"\"\"\n    super().__init__(*args, **kwargs)\n    self.current_isolve_process = None\n    self.current_process_manager = None\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_manual_strategy.ISolveManualStrategy-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.runners.isolve_manual_strategy.ISolveManualStrategy.reset_memory_error_count","title":"reset_memory_error_count  <code>classmethod</code>","text":"<pre><code>reset_memory_error_count() -&gt; None\n</code></pre> <p>Reset the memory error counter. Called at start of new session.</p> Source code in <code>goliat/runners/isolve_manual_strategy.py</code> <pre><code>@classmethod\ndef reset_memory_error_count(cls) -&gt; None:\n    \"\"\"Reset the memory error counter. Called at start of new session.\"\"\"\n    cls._memory_error_count = 0\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_manual_strategy.ISolveManualStrategy.run","title":"run","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Runs iSolve.exe directly with real-time output logging.</p> <p>This method bypasses Sim4Life's API and runs the solver executable directly. This is useful when you need more control over the execution environment or when the API has issues. The key challenge is capturing output in real-time without blocking the main thread.</p> <p>The solution uses a background thread with a queue: - A daemon thread reads stdout line-by-line and puts lines into a queue - The main thread polls the queue non-blockingly and logs output - After process completion, remaining output is drained from the queue</p> <p>This approach allows the GUI to remain responsive and users to see progress updates as they happen. Without threading, reading stdout would block until the process finishes, making it impossible to show real-time progress.</p> <p>Steps: 1. Locate iSolve.exe relative to Python executable 2. Spawn subprocess with stdout/stderr pipes 3. Start background thread to read stdout into queue 4. Poll process and queue, logging output without blocking 5. After completion, reload project to load results into Sim4Life</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If iSolve.exe or input file not found.</p> <code>RuntimeError</code> <p>If iSolve exits with non-zero code or simulation           can't be found after reload.</p> Source code in <code>goliat/runners/isolve_manual_strategy.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Runs iSolve.exe directly with real-time output logging.\n\n    This method bypasses Sim4Life's API and runs the solver executable directly.\n    This is useful when you need more control over the execution environment or when\n    the API has issues. The key challenge is capturing output in real-time without\n    blocking the main thread.\n\n    The solution uses a background thread with a queue:\n    - A daemon thread reads stdout line-by-line and puts lines into a queue\n    - The main thread polls the queue non-blockingly and logs output\n    - After process completion, remaining output is drained from the queue\n\n    This approach allows the GUI to remain responsive and users to see progress\n    updates as they happen. Without threading, reading stdout would block until\n    the process finishes, making it impossible to show real-time progress.\n\n    Steps:\n    1. Locate iSolve.exe relative to Python executable\n    2. Spawn subprocess with stdout/stderr pipes\n    3. Start background thread to read stdout into queue\n    4. Poll process and queue, logging output without blocking\n    5. After completion, reload project to load results into Sim4Life\n\n    Raises:\n        FileNotFoundError: If iSolve.exe or input file not found.\n        RuntimeError: If iSolve exits with non-zero code or simulation\n                      can't be found after reload.\n    \"\"\"\n    command = self._prepare_isolve_command()\n\n    try:\n        self._log(\"    - Execute iSolve...\", level=\"progress\", log_type=\"progress\")\n        with self.profiler.subtask(\"run_isolve_execution\"):\n            output_parser = ISolveOutputParser(self.verbose_logger, self.progress_logger, self.gui)\n            keep_awake_handler = KeepAwakeHandler(self.config)\n            retry_handler = RetryHandler(self.progress_logger, self.gui)\n            keep_awake_handler.trigger_before_retry()\n\n            while True:\n                self._check_for_stop_signal()\n                if retry_handler.get_attempt_number() &gt; 0:\n                    keep_awake_handler.trigger_before_retry()\n                if self._run_single_attempt(command, output_parser, keep_awake_handler, retry_handler) == \"done\":\n                    break\n\n        elapsed = self.profiler.subtask_times[\"run_isolve_execution\"][-1]\n        self._log(f\"      - Subtask 'run_isolve_execution' done in {elapsed:.2f}s\", log_type=\"verbose\")\n        self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n        post_handler = PostSimulationHandler(self.project_path, self.profiler, self.verbose_logger, self.progress_logger)\n        post_handler.wait_and_reload()\n\n    except StudyCancelledError:\n        self._cleanup()\n        raise\n    except Exception as e:\n        self._cleanup()\n        self._log(\n            f\"An unexpected error occurred while running iSolve.exe: {e}\",\n            level=\"progress\",\n            log_type=\"error\",\n        )\n        self.verbose_logger.error(traceback.format_exc())\n        raise\n    finally:\n        self._cleanup()\n</code></pre>"},{"location":"reference/api_reference/#isolve-output-parser","title":"Isolve Output Parser","text":""},{"location":"reference/api_reference/#goliat.runners.isolve_output_parser.ProgressInfo","title":"goliat.runners.isolve_output_parser.ProgressInfo  <code>dataclass</code>","text":"<pre><code>ProgressInfo(percentage: int, time_remaining: str, mcells_per_sec: str)\n</code></pre> <p>Extracted progress information from iSolve output.</p>"},{"location":"reference/api_reference/#isolve-process-manager","title":"Isolve Process Manager","text":""},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager","title":"goliat.runners.isolve_process_manager.ISolveProcessManager","text":"<pre><code>ISolveProcessManager(command: List[str], gui: Optional[QueueGUI], verbose_logger: Logger, progress_logger: Logger)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Manages iSolve subprocess lifecycle and non-blocking I/O.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>List[str]</code> <p>Command to execute (e.g., [isolve_path, \"-i\", input_file]).</p> required <code>gui</code> <code>Optional[QueueGUI]</code> <p>GUI proxy for stop signal checks.</p> required <code>verbose_logger</code> <code>Logger</code> <p>Logger for verbose output.</p> required <code>progress_logger</code> <code>Logger</code> <p>Logger for progress output.</p> required Source code in <code>goliat/runners/isolve_process_manager.py</code> <pre><code>def __init__(\n    self,\n    command: List[str],\n    gui: Optional[\"QueueGUI\"],\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n):\n    \"\"\"Initialize process manager.\n\n    Args:\n        command: Command to execute (e.g., [isolve_path, \"-i\", input_file]).\n        gui: GUI proxy for stop signal checks.\n        verbose_logger: Logger for verbose output.\n        progress_logger: Logger for progress output.\n    \"\"\"\n    self.command = command\n    self.gui = gui\n    self.verbose_logger = verbose_logger\n    self.progress_logger = progress_logger\n    self.process: Optional[subprocess.Popen] = None\n    self.output_queue: Optional[Queue] = None\n    self.reader_thread: Optional[threading.Thread] = None\n    self._is_running = False\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager.start","title":"start","text":"<pre><code>start() -&gt; None\n</code></pre> <p>Start the subprocess and begin reading output.</p> Source code in <code>goliat/runners/isolve_process_manager.py</code> <pre><code>def start(self) -&gt; None:\n    \"\"\"Start the subprocess and begin reading output.\"\"\"\n    self.process = subprocess.Popen(\n        self.command,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=True,\n        creationflags=subprocess.CREATE_NO_WINDOW,\n    )\n    self.output_queue = Queue()\n    self.reader_thread = threading.Thread(target=_reader_thread, args=(self.process.stdout, self.output_queue))\n    self.reader_thread.daemon = True\n    self.reader_thread.start()\n    self._is_running = True\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager.is_running","title":"is_running","text":"<pre><code>is_running() -&gt; bool\n</code></pre> <p>Check if process is still running.</p> Source code in <code>goliat/runners/isolve_process_manager.py</code> <pre><code>def is_running(self) -&gt; bool:\n    \"\"\"Check if process is still running.\"\"\"\n    return self._is_running and self.process is not None and self.process.poll() is None\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager.read_available_lines","title":"read_available_lines","text":"<pre><code>read_available_lines() -&gt; List[str]\n</code></pre> <p>Read all available lines from output queue (non-blocking).</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of lines read (may be empty if no output available).</p> Source code in <code>goliat/runners/isolve_process_manager.py</code> <pre><code>def read_available_lines(self) -&gt; List[str]:\n    \"\"\"Read all available lines from output queue (non-blocking).\n\n    Returns:\n        List of lines read (may be empty if no output available).\n    \"\"\"\n    if self.output_queue is None:\n        return []\n\n    lines = []\n    try:\n        while True:\n            lines.append(self.output_queue.get_nowait())\n    except Empty:\n        pass\n    return lines\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager.read_all_remaining_lines","title":"read_all_remaining_lines","text":"<pre><code>read_all_remaining_lines() -&gt; List[str]\n</code></pre> <p>Read all remaining lines after process completes.</p> <p>Should be called after is_running() returns False. Ensures reader thread has finished and queue is drained.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of all remaining lines.</p> Source code in <code>goliat/runners/isolve_process_manager.py</code> <pre><code>def read_all_remaining_lines(self) -&gt; List[str]:\n    \"\"\"Read all remaining lines after process completes.\n\n    Should be called after is_running() returns False.\n    Ensures reader thread has finished and queue is drained.\n\n    Returns:\n        List of all remaining lines.\n    \"\"\"\n    if self.reader_thread is not None and self.reader_thread.is_alive():\n        self.reader_thread.join()\n\n    lines = []\n    if self.output_queue is not None:\n        while not self.output_queue.empty():\n            try:\n                lines.append(self.output_queue.get_nowait())\n            except Empty:\n                break\n    return lines\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager.get_return_code","title":"get_return_code","text":"<pre><code>get_return_code() -&gt; Optional[int]\n</code></pre> <p>Get process return code (None if still running).</p> Source code in <code>goliat/runners/isolve_process_manager.py</code> <pre><code>def get_return_code(self) -&gt; Optional[int]:\n    \"\"\"Get process return code (None if still running).\"\"\"\n    return self.process.returncode if self.process else None\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager.read_stderr","title":"read_stderr","text":"<pre><code>read_stderr() -&gt; str\n</code></pre> <p>Read stderr output (fallback - most errors are in stdout).</p> <p>Returns:</p> Type Description <code>str</code> <p>Stripped stderr string or empty string.</p> Source code in <code>goliat/runners/isolve_process_manager.py</code> <pre><code>def read_stderr(self) -&gt; str:\n    \"\"\"Read stderr output (fallback - most errors are in stdout).\n\n    Returns:\n        Stripped stderr string or empty string.\n    \"\"\"\n    if self.process is None or self.process.stderr is None:\n        return \"\"\n\n    try:\n        stderr_output = self.process.stderr.read()\n        if stderr_output:\n            return stderr_output.strip()\n    except Exception:\n        pass\n    return \"\"\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager.terminate","title":"terminate","text":"<pre><code>terminate(timeout: float = 2.0) -&gt; None\n</code></pre> <p>Terminate process, force kill if it doesn't stop in time.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>float</code> <p>Seconds to wait before force killing.</p> <code>2.0</code> Source code in <code>goliat/runners/isolve_process_manager.py</code> <pre><code>def terminate(self, timeout: float = 2.0) -&gt; None:\n    \"\"\"Terminate process, force kill if it doesn't stop in time.\n\n    Args:\n        timeout: Seconds to wait before force killing.\n    \"\"\"\n    if self.process is None:\n        return\n\n    if self.process.poll() is None:\n        try:\n            self.process.terminate()\n            self.process.wait(timeout=timeout)\n        except subprocess.TimeoutExpired:\n            self.process.kill()\n            self.process.wait()\n        except Exception:\n            pass\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager.cleanup","title":"cleanup","text":"<pre><code>cleanup() -&gt; None\n</code></pre> <p>Clean up process and threads.</p> Source code in <code>goliat/runners/isolve_process_manager.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"Clean up process and threads.\"\"\"\n    if self.process is not None:\n        if self.process.poll() is None:\n            try:\n                self.process.terminate()\n                self.process.wait(timeout=2)\n            except subprocess.TimeoutExpired:\n                self.process.kill()\n                self.process.wait()\n            except Exception:\n                pass\n        self.process = None\n\n    if self.reader_thread is not None and self.reader_thread.is_alive():\n        self.reader_thread.join()\n\n    self._is_running = False\n\n    # Adaptive delay based on memory usage (more memory = longer wait)\n    if psutil is not None:\n        try:\n            memory = psutil.virtual_memory()\n            used_gb = memory.used / (1024**3)\n            # Scale delay: 0.5s base + 0.1s per 10GB used (max 3s)\n            delay = min(0.5 + (used_gb / 10.0) * 0.1, 3.0)\n            time.sleep(delay)\n        except Exception:\n            time.sleep(0.5)  # Fallback to default\n    else:\n        time.sleep(0.5)\n\n    # Force garbage collection to free Python-side memory\n    gc.collect()\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.isolve_process_manager.ISolveProcessManager.check_stop_signal","title":"check_stop_signal","text":"<pre><code>check_stop_signal() -&gt; None\n</code></pre> <p>Check for stop signal and terminate if requested.</p> <p>Raises:</p> Type Description <code>StudyCancelledError</code> <p>If stop signal detected.</p> Source code in <code>goliat/runners/isolve_process_manager.py</code> <pre><code>def check_stop_signal(self) -&gt; None:\n    \"\"\"Check for stop signal and terminate if requested.\n\n    Raises:\n        StudyCancelledError: If stop signal detected.\n    \"\"\"\n    if self.gui and self.gui.is_stopped():\n        self._log(\"Stop signal detected, terminating iSolve subprocess...\", log_type=\"warning\")\n        self.terminate(timeout=2)\n        raise StudyCancelledError(\"Study cancelled by user.\")\n</code></pre>"},{"location":"reference/api_reference/#keep-awake-handler","title":"Keep Awake Handler","text":""},{"location":"reference/api_reference/#goliat.runners.keep_awake_handler.KeepAwakeHandler","title":"goliat.runners.keep_awake_handler.KeepAwakeHandler","text":"<pre><code>KeepAwakeHandler(config: Config)\n</code></pre> <p>Handles keep_awake script triggering.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required Source code in <code>goliat/runners/keep_awake_handler.py</code> <pre><code>def __init__(self, config: \"Config\"):\n    \"\"\"Initialize keep_awake handler.\n\n    Args:\n        config: Configuration object.\n    \"\"\"\n    self.config = config\n    self.triggered = False\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.keep_awake_handler.KeepAwakeHandler-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.runners.keep_awake_handler.KeepAwakeHandler.trigger_before_retry","title":"trigger_before_retry","text":"<pre><code>trigger_before_retry() -&gt; None\n</code></pre> <p>Trigger keep_awake before retry attempt.</p> Source code in <code>goliat/runners/keep_awake_handler.py</code> <pre><code>def trigger_before_retry(self) -&gt; None:\n    \"\"\"Trigger keep_awake before retry attempt.\"\"\"\n    if not (self.config[\"keep_awake\"] or False):\n        return\n\n    try:\n        # Path: goliat/goliat/runners/keep_awake_handler.py -&gt; goliat/goliat/utils/scripts/\n        script_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), \"utils\", \"scripts\")\n        if script_dir not in sys.path:\n            sys.path.insert(0, script_dir)\n        from keep_awake import keep_awake  # type: ignore\n\n        keep_awake()\n    except Exception as e:\n        print(f\"Warning: keep_awake() failed: {e}\")\n        if sys.stdout is not None:\n            sys.stdout.flush()\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.keep_awake_handler.KeepAwakeHandler.trigger_on_progress","title":"trigger_on_progress","text":"<pre><code>trigger_on_progress() -&gt; None\n</code></pre> <p>Trigger keep_awake script on first progress update.</p> Source code in <code>goliat/runners/keep_awake_handler.py</code> <pre><code>def trigger_on_progress(self) -&gt; None:\n    \"\"\"Trigger keep_awake script on first progress update.\"\"\"\n    if not (self.config[\"keep_awake\"] or False):\n        return\n\n    if self.triggered:\n        return\n\n    script_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), \"utils\", \"scripts\", \"keep_awake.py\")\n    if os.path.exists(script_path):\n        subprocess.Popen([sys.executable, script_path])\n    self.triggered = True\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.keep_awake_handler.KeepAwakeHandler.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset triggered flag (for new simulation).</p> Source code in <code>goliat/runners/keep_awake_handler.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Reset triggered flag (for new simulation).\"\"\"\n    self.triggered = False\n</code></pre>"},{"location":"reference/api_reference/#osparc-direct-strategy","title":"Osparc Direct Strategy","text":""},{"location":"reference/api_reference/#goliat.runners.osparc_direct_strategy.OSPARCDirectStrategy","title":"goliat.runners.osparc_direct_strategy.OSPARCDirectStrategy","text":"<pre><code>OSPARCDirectStrategy(server_name: str, *args, **kwargs)\n</code></pre> <p>               Bases: <code>ExecutionStrategy</code>, <code>LoggingMixin</code></p> <p>Execution strategy for submitting simulations to oSPARC cloud platform.</p> <p>Parameters:</p> Name Type Description Default <code>server_name</code> <code>str</code> <p>oSPARC resource name to use (e.g., 'local', 'osparc-1').</p> required <code>*args</code> <p>Passed to parent class.</p> <code>()</code> <code>**kwargs</code> <p>Passed to parent class.</p> <code>{}</code> Source code in <code>goliat/runners/osparc_direct_strategy.py</code> <pre><code>def __init__(self, server_name: str, *args, **kwargs):\n    \"\"\"Initialize oSPARC direct strategy.\n\n    Args:\n        server_name: oSPARC resource name to use (e.g., 'local', 'osparc-1').\n        *args: Passed to parent class.\n        **kwargs: Passed to parent class.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.server_name = server_name\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.osparc_direct_strategy.OSPARCDirectStrategy-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.runners.osparc_direct_strategy.OSPARCDirectStrategy.run","title":"run","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Submits simulation directly to oSPARC cloud platform.</p> <p>This method handles cloud-based simulation execution through the oSPARC platform. Instead of running locally, it uploads the solver input file to oSPARC, submits a job, and polls for completion.</p> <p>The process: 1. Initializes oSPARC API client using credentials from config 2. Creates a job submission with input file path and resource name 3. Submits job and waits for completion (polls status periodically) 4. Downloads results when job completes successfully 5. Reloads project to load results into Sim4Life</p> <p>This requires Sim4Life 9.2+ for the XOsparcApiClient module. The method handles authentication, job lifecycle, and error reporting.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If API client unavailable, job creation fails, job           completes with non-success status, or simulation can't           be found after reload.</p> <code>FileNotFoundError</code> <p>If solver input file not found.</p> <code>ValueError</code> <p>If oSPARC credentials are missing from config.</p> Source code in <code>goliat/runners/osparc_direct_strategy.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Submits simulation directly to oSPARC cloud platform.\n\n    This method handles cloud-based simulation execution through the oSPARC\n    platform. Instead of running locally, it uploads the solver input file\n    to oSPARC, submits a job, and polls for completion.\n\n    The process:\n    1. Initializes oSPARC API client using credentials from config\n    2. Creates a job submission with input file path and resource name\n    3. Submits job and waits for completion (polls status periodically)\n    4. Downloads results when job completes successfully\n    5. Reloads project to load results into Sim4Life\n\n    This requires Sim4Life 9.2+ for the XOsparcApiClient module. The method\n    handles authentication, job lifecycle, and error reporting.\n\n    Raises:\n        RuntimeError: If API client unavailable, job creation fails, job\n                      completes with non-success status, or simulation can't\n                      be found after reload.\n        FileNotFoundError: If solver input file not found.\n        ValueError: If oSPARC credentials are missing from config.\n    \"\"\"\n    # XOsparcApiClient is only available in Sim4Life 9.2+\n    if not is_sim4life_92_or_later():\n        detected = get_version_display_string()\n        self._log(\n            f\"XOsparcApiClient requires Sim4Life 9.2+. Detected: {detected}\",\n            level=\"progress\",\n            log_type=\"error\",\n        )\n        self._log(\n            \"Use the osparc PyPI package for batch runs on 8.2, or upgrade to 9.2.\",\n            level=\"progress\",\n            log_type=\"info\",\n        )\n        raise RuntimeError(f\"oSPARC direct strategy requires Sim4Life 9.2+, but running on {detected}.\")\n\n    import XOsparcApiClient  # type: ignore\n\n    self._log(\n        f\"--- Running simulation on oSPARC server: {self.server_name} ---\",\n        level=\"progress\",\n        log_type=\"header\",\n    )\n\n    # 1. Get Credentials and Initialize Client\n    creds = self.config.get_osparc_credentials()\n    if not all(k in creds for k in [\"api_key\", \"api_secret\", \"api_server\"]):\n        raise ValueError(\"Missing oSPARC credentials in configuration.\")\n\n    client = XOsparcApiClient.OsparcApiClient(\n        api_key=creds[\"api_key\"],\n        api_secret=creds[\"api_secret\"],\n        api_server=creds[\"api_server\"],\n        api_version=creds.get(\"api_version\", \"v0\"),\n    )\n    self._log(\"oSPARC client initialized.\", log_type=\"verbose\")\n\n    # 2. Prepare Job Submission Data\n    input_file_path = os.path.join(os.path.dirname(self.project_path), self.simulation.GetInputFileName())\n    if not os.path.exists(input_file_path):\n        raise FileNotFoundError(f\"Solver input file not found at: {input_file_path}\")\n\n    job_data = XOsparcApiClient.JobSubmissionData()\n    job_data.InputFilePath = input_file_path\n    job_data.ResourceName = self.server_name\n    job_data.SolverKey = \"sim4life-isolve\"\n    job_data.SolverVersion = \"\"  # Let the API choose the default version\n\n    # 3. Create and Start the Job\n    self._log(\n        f\"Creating job for input file: {os.path.basename(input_file_path)}\",\n        level=\"progress\",\n        log_type=\"info\",\n    )\n    create_response = client.CreateJob(job_data)\n    if not create_response.Success:\n        raise RuntimeError(f\"Failed to create oSPARC job: {create_response.Content}\")\n\n    job_id = create_response.Content.get(\"id\")\n    if not job_id:\n        raise RuntimeError(\"oSPARC API did not return a job ID after creation.\")\n\n    self._log(\n        f\"Job created with ID: {job_id}. Starting job...\",\n        level=\"progress\",\n        log_type=\"info\",\n    )\n    start_response = client.StartJob(job_data, job_id)\n    if not start_response.Success:\n        raise RuntimeError(f\"Failed to start oSPARC job {job_id}: {start_response.Content}\")\n\n    # 4. Poll for Job Completion\n    self._log(\"Job started. Polling for status...\", level=\"progress\", log_type=\"progress\")\n    while True:\n        self._check_for_stop_signal()\n\n        status_response = client.GetJobStatus(job_data.SolverKey, job_data.SolverVersion, job_id)\n        if not status_response.Success:\n            self._log(\n                f\"Warning: Could not get job status for {job_id}.\",\n                level=\"progress\",\n                log_type=\"warning\",\n            )\n            time.sleep(10)\n            continue\n\n        status = status_response.Content.get(\"state\")\n        self._log(f\"  - Job '{job_id}' status: {status}\", log_type=\"verbose\")\n\n        if status in [\"SUCCESS\", \"FAILED\", \"ABORTED\"]:\n            log_type = \"success\" if status == \"SUCCESS\" else \"error\"\n            self._log(\n                f\"Job {job_id} finished with status: {status}\",\n                level=\"progress\",\n                log_type=log_type,\n            )\n            if status != \"SUCCESS\":\n                raise RuntimeError(f\"oSPARC job {job_id} failed with status: {status}\")\n            break\n\n        time.sleep(30)\n\n    # 5. Post-simulation steps\n    post_handler = PostSimulationHandler(self.project_path, self.profiler, self.verbose_logger, self.progress_logger)\n    post_handler.wait_and_reload()\n</code></pre>"},{"location":"reference/api_reference/#post-simulation-handler","title":"Post Simulation Handler","text":""},{"location":"reference/api_reference/#goliat.runners.post_simulation_handler.PostSimulationHandler","title":"goliat.runners.post_simulation_handler.PostSimulationHandler","text":"<pre><code>PostSimulationHandler(project_path: str, profiler: Profiler, verbose_logger: Logger, progress_logger: Logger)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Handles post-simulation tasks: waiting for results and reloading project.</p> <p>Parameters:</p> Name Type Description Default <code>project_path</code> <code>str</code> <p>Path to project file to reload.</p> required <code>profiler</code> <code>Profiler</code> <p>Profiler for timing subtasks.</p> required <code>verbose_logger</code> <code>Logger</code> <p>Logger for verbose output.</p> required <code>progress_logger</code> <code>Logger</code> <p>Logger for progress output.</p> required Source code in <code>goliat/runners/post_simulation_handler.py</code> <pre><code>def __init__(\n    self,\n    project_path: str,\n    profiler: \"Profiler\",\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n):\n    \"\"\"Initialize post-simulation handler.\n\n    Args:\n        project_path: Path to project file to reload.\n        profiler: Profiler for timing subtasks.\n        verbose_logger: Logger for verbose output.\n        progress_logger: Logger for progress output.\n    \"\"\"\n    self.project_path = project_path\n    self.profiler = profiler\n    self.verbose_logger = verbose_logger\n    self.progress_logger = progress_logger\n    import s4l_v1.document\n\n    self.document = s4l_v1.document\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.post_simulation_handler.PostSimulationHandler-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.runners.post_simulation_handler.PostSimulationHandler.wait_and_reload","title":"wait_and_reload","text":"<pre><code>wait_and_reload() -&gt; None\n</code></pre> <p>Wait for results and reload project.</p> <p>Waits 5 seconds for results to be written, then closes and reopens the project to load results into Sim4Life. Only reloads if memory usage is above 60% to free memory.</p> Source code in <code>goliat/runners/post_simulation_handler.py</code> <pre><code>def wait_and_reload(self) -&gt; None:\n    \"\"\"Wait for results and reload project.\n\n    Waits 5 seconds for results to be written, then closes and reopens\n    the project to load results into Sim4Life. Only reloads if memory\n    usage is above 60% to free memory.\n    \"\"\"\n    self._log(\n        \"    - Wait for results...\",\n        level=\"progress\",\n        log_type=\"progress\",\n    )\n    with self.profiler.subtask(\"run_wait_for_results\"):\n        non_blocking_sleep(5)\n    elapsed = self.profiler.subtask_times[\"run_wait_for_results\"][-1]\n    self._log(f\"      - Subtask 'run_wait_for_results' done in {elapsed:.2f}s\", log_type=\"verbose\")\n    self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    # Check memory usage and reload only if above threshold\n    should_reload = False\n    if psutil is not None:\n        try:\n            memory = psutil.virtual_memory()\n            memory_percent = memory.percent\n            if memory_percent &gt; 60.0:\n                should_reload = True\n                self._log(\n                    f\"    - Memory usage at {memory_percent:.1f}%, reloading project to free memory...\",\n                    level=\"progress\",\n                    log_type=\"progress\",\n                )\n        except Exception:\n            # If memory check fails, reload anyway to be safe\n            should_reload = True\n    else:\n        # If psutil not available, reload anyway\n        should_reload = True\n\n    if should_reload:\n        self._log(\n            \"    - Reload project...\",\n            level=\"progress\",\n            log_type=\"progress\",\n        )\n        with self.profiler.subtask(\"run_reload_project\"):\n            self.document.Close()\n            open_project(self.project_path)\n        elapsed = self.profiler.subtask_times[\"run_reload_project\"][-1]\n        self._log(f\"      - Subtask 'run_reload_project' done in {elapsed:.2f}s\", log_type=\"verbose\")\n        self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n        # Force garbage collection after reload to free memory\n        gc.collect()\n\n        self._log(\n            \"Project reloaded and results are available.\",\n            log_type=\"success\",\n        )\n    else:\n        self._log(\n            \"Memory usage acceptable, skipping reload.\",\n            log_type=\"verbose\",\n        )\n</code></pre>"},{"location":"reference/api_reference/#retry-handler","title":"Retry Handler","text":""},{"location":"reference/api_reference/#goliat.runners.retry_handler.RetryHandler","title":"goliat.runners.retry_handler.RetryHandler","text":"<pre><code>RetryHandler(progress_logger: Logger, gui: Optional[QueueGUI] = None)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Manages retry logic and attempt tracking.</p> <p>Parameters:</p> Name Type Description Default <code>progress_logger</code> <code>Logger</code> <p>Logger for progress-level messages.</p> required <code>gui</code> <code>Optional[QueueGUI]</code> <p>Optional GUI proxy for sending progress messages.</p> <code>None</code> Source code in <code>goliat/runners/retry_handler.py</code> <pre><code>def __init__(self, progress_logger: \"Logger\", gui: Optional[\"QueueGUI\"] = None):\n    \"\"\"Initialize retry handler.\n\n    Args:\n        progress_logger: Logger for progress-level messages.\n        gui: Optional GUI proxy for sending progress messages.\n    \"\"\"\n    self.progress_logger = progress_logger\n    self.gui = gui\n    self.attempt_number = 0\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.retry_handler.RetryHandler-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.runners.retry_handler.RetryHandler.should_retry","title":"should_retry","text":"<pre><code>should_retry(return_code: Optional[int], detected_errors: list) -&gt; bool\n</code></pre> <p>Determine if retry should occur.</p> <p>Parameters:</p> Name Type Description Default <code>return_code</code> <code>Optional[int]</code> <p>Process return code (None if exception).</p> required <code>detected_errors</code> <code>list</code> <p>List of errors detected in output.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if should retry (always True for non-zero return code).</p> Source code in <code>goliat/runners/retry_handler.py</code> <pre><code>def should_retry(self, return_code: Optional[int], detected_errors: list) -&gt; bool:\n    \"\"\"Determine if retry should occur.\n\n    Args:\n        return_code: Process return code (None if exception).\n        detected_errors: List of errors detected in output.\n\n    Returns:\n        True if should retry (always True for non-zero return code).\n    \"\"\"\n    return return_code != 0\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.retry_handler.RetryHandler.record_attempt","title":"record_attempt","text":"<pre><code>record_attempt() -&gt; None\n</code></pre> <p>Record a retry attempt and log it.</p> Source code in <code>goliat/runners/retry_handler.py</code> <pre><code>def record_attempt(self) -&gt; None:\n    \"\"\"Record a retry attempt and log it.\"\"\"\n    self.attempt_number += 1\n    if self.attempt_number &gt; 0:\n        self._log(\n            f\"    - iSolve failed, retry attempt {self.attempt_number}\",\n            level=\"progress\",\n            log_type=\"warning\",\n        )\n\n    # Log error every 50 retries\n    if self.attempt_number &gt; 0 and self.attempt_number % 50 == 0:\n        self._log(\n            f\"iSolve failed {self.attempt_number} times\",\n            level=\"progress\",\n            log_type=\"error\",\n        )\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.retry_handler.RetryHandler.get_attempt_number","title":"get_attempt_number","text":"<pre><code>get_attempt_number() -&gt; int\n</code></pre> <p>Get current attempt number (0 = first attempt).</p> Source code in <code>goliat/runners/retry_handler.py</code> <pre><code>def get_attempt_number(self) -&gt; int:\n    \"\"\"Get current attempt number (0 = first attempt).\"\"\"\n    return self.attempt_number\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.retry_handler.RetryHandler.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset attempt counter (for new simulation).</p> Source code in <code>goliat/runners/retry_handler.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Reset attempt counter (for new simulation).\"\"\"\n    self.attempt_number = 0\n</code></pre>"},{"location":"reference/api_reference/#sim4life-api-strategy","title":"Sim4Life Api Strategy","text":""},{"location":"reference/api_reference/#goliat.runners.sim4life_api_strategy.Sim4LifeAPIStrategy","title":"goliat.runners.sim4life_api_strategy.Sim4LifeAPIStrategy","text":"<pre><code>Sim4LifeAPIStrategy(server_id: str | None, *args, **kwargs)\n</code></pre> <p>               Bases: <code>ExecutionStrategy</code>, <code>LoggingMixin</code></p> <p>Execution strategy for running simulations via Sim4Life API.</p> <p>Parameters:</p> Name Type Description Default <code>server_id</code> <code>str | None</code> <p>Server ID to use (None for localhost).</p> required <code>*args</code> <p>Passed to parent class.</p> <code>()</code> <code>**kwargs</code> <p>Passed to parent class.</p> <code>{}</code> Source code in <code>goliat/runners/sim4life_api_strategy.py</code> <pre><code>def __init__(self, server_id: str | None, *args, **kwargs):\n    \"\"\"Initialize Sim4Life API strategy.\n\n    Args:\n        server_id: Server ID to use (None for localhost).\n        *args: Passed to parent class.\n        **kwargs: Passed to parent class.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.server_id = server_id\n</code></pre>"},{"location":"reference/api_reference/#goliat.runners.sim4life_api_strategy.Sim4LifeAPIStrategy-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.runners.sim4life_api_strategy.Sim4LifeAPIStrategy.run","title":"run","text":"<pre><code>run() -&gt; None\n</code></pre> <p>Run simulation using Sim4Life API.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If simulation execution fails.</p> Source code in <code>goliat/runners/sim4life_api_strategy.py</code> <pre><code>def run(self) -&gt; None:\n    \"\"\"Run simulation using Sim4Life API.\n\n    Raises:\n        RuntimeError: If simulation execution fails.\n    \"\"\"\n    self.simulation.RunSimulation(wait=True, server_id=self.server_id)\n    server_name = (self.config[\"solver_settings\"] or {}).get(\"server\", \"localhost\")\n    log_msg = f\"Simulation finished on '{server_name}'.\"\n    self._log(log_msg, level=\"progress\", log_type=\"success\")\n</code></pre>"},{"location":"reference/api_reference/#results-extraction","title":"Results Extraction","text":"<p>Classes for extracting and processing simulation results.</p>"},{"location":"reference/api_reference/#auto-induced-processor","title":"Auto Induced Processor","text":""},{"location":"reference/api_reference/#goliat.extraction.auto_induced_processor.AutoInducedProcessor","title":"goliat.extraction.auto_induced_processor.AutoInducedProcessor","text":"<pre><code>AutoInducedProcessor(parent_study: FarFieldStudy, phantom_name: str, freq: int)\n</code></pre> <p>               Bases: <code>LoggingMixin</code>, <code>_AutoInducedExtractionMixin</code></p> <p>Processes auto-induced exposure using existing SAPD extraction infrastructure.</p> <p>Orchestrates focus search, field combination, and SAPD extraction for a completed set of environmental simulations.</p> <p>Parameters:</p> Name Type Description Default <code>parent_study</code> <code>FarFieldStudy</code> <p>Parent FarFieldStudy instance (provides loggers, profiler, config).</p> required <code>phantom_name</code> <code>str</code> <p>Name of the phantom (e.g., \"thelonious\").</p> required <code>freq</code> <code>int</code> <p>Frequency in MHz.</p> required Source code in <code>goliat/extraction/auto_induced_processor.py</code> <pre><code>def __init__(self, parent_study: \"FarFieldStudy\", phantom_name: str, freq: int):\n    \"\"\"Initialize the processor.\n\n    Args:\n        parent_study: Parent FarFieldStudy instance (provides loggers, profiler, config).\n        phantom_name: Name of the phantom (e.g., \"thelonious\").\n        freq: Frequency in MHz.\n    \"\"\"\n    self.study = parent_study\n    self.config = parent_study.config\n    self.phantom_name = phantom_name\n    self.freq = freq\n\n    # Share loggers from parent study\n    self.verbose_logger = parent_study.verbose_logger\n    self.progress_logger = parent_study.progress_logger\n    self.gui = parent_study.gui\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.auto_induced_processor.AutoInducedProcessor-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.auto_induced_processor.AutoInducedProcessor.process","title":"process","text":"<pre><code>process(h5_paths: list[Path], input_h5: Path, output_dir: Path) -&gt; dict\n</code></pre> <p>Run the auto-induced analysis pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>h5_paths</code> <code>list[Path]</code> <p>List of _Output.h5 file paths (one per direction/polarization).</p> required <code>input_h5</code> <code>Path</code> <p>Path to any _Input.h5 file (for skin mask extraction).</p> required <code>output_dir</code> <code>Path</code> <p>Directory to write combined H5 files and results.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dict with analysis results including candidates, SAPD values, and worst-case.</p> Source code in <code>goliat/extraction/auto_induced_processor.py</code> <pre><code>def process(\n    self,\n    h5_paths: list[Path],\n    input_h5: Path,\n    output_dir: Path,\n) -&gt; dict:\n    \"\"\"Run the auto-induced analysis pipeline.\n\n    Args:\n        h5_paths: List of _Output.h5 file paths (one per direction/polarization).\n        input_h5: Path to any _Input.h5 file (for skin mask extraction).\n        output_dir: Directory to write combined H5 files and results.\n\n    Returns:\n        Dict with analysis results including candidates, SAPD values, and worst-case.\n    \"\"\"\n    auto_cfg = self.config[\"auto_induced\"] or {}\n    top_n = auto_cfg.get(\"top_n\", 10)\n    cube_size_mm = auto_cfg.get(\"cube_size_mm\", 100)\n    save_intermediate_files = auto_cfg.get(\"save_intermediate_files\", False)\n    search_metric = auto_cfg.get(\"search_metric\", \"E_magnitude\")\n    extraction_metric = auto_cfg.get(\"extraction_metric\", \"sapd\")\n    full_volume = auto_cfg.get(\"full_volume_combination\", False)\n    combine_chunk_size = auto_cfg.get(\"combine_chunk_size\", 50)\n    # For SAR, only E-field is needed; for SAPD, both E and H\n    field_types = (\"E\",) if extraction_metric == \"sar\" else (\"E\", \"H\")\n\n    self._log(\n        f\"\\n--- Auto-Induced Analysis: {self.phantom_name}, {self.freq}MHz ---\",\n        level=\"progress\",\n        log_type=\"header\",\n    )\n    self._log(\n        f\"  Combining {len(h5_paths)} simulations, extracting top {top_n} candidates\",\n        level=\"progress\",\n        log_type=\"info\",\n    )\n\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Step 1: Focus search\n    with self.study.subtask(\"auto_induced_focus_search\"):\n        candidates = self._find_focus_candidates(h5_paths, input_h5, top_n, search_metric, output_dir)\n\n    if not candidates:\n        self._log(\"    ERROR: No focus candidates found\", log_type=\"error\")\n        return {\"error\": \"No focus candidates found\", \"candidates\": []}\n\n    # Step 2: Combine fields for each candidate\n    with self.study.subtask(\"auto_induced_combine_fields\"):\n        combined_h5_paths = []\n        from tqdm import tqdm\n        from .field_cache import FieldCache\n\n        # Pre-load all source fields once, shared across all candidates.\n        # FieldCache auto-detects available RAM:\n        #   - Memory mode (RAM sufficient): loads all files into numpy arrays.\n        #     Weighted sum per candidate is then pure numpy \u2014 no file I/O.\n        #   - Streaming mode (low RAM): uses slab LRU cache, falls back to\n        #     the original chunked approach.\n        slab_cache_gb = (self.config[\"auto_induced\"] or {}).get(\"search\", {}).get(\"slab_cache_gb\", 2.0)\n        low_memory_mode = (self.config[\"auto_induced\"] or {}).get(\"search\", {}).get(\"low_memory_mode\", None)\n\n        # Only pre-load E (SAR) or E+H (SAPD) \u2014 same field types we'll combine\n        # FieldCache only supports one field_type at a time, so load each separately\n        field_caches = {}\n        for ft in field_types:\n            self._log(f\"  Pre-loading {ft}-fields from {len(h5_paths)} files...\", level=\"progress\", log_type=\"info\")\n            field_caches[ft] = FieldCache(\n                h5_paths=[str(p) for p in h5_paths],\n                field_type=ft,\n                low_memory=low_memory_mode,\n                slab_cache_gb=slab_cache_gb,\n            )\n            mode = \"streaming\" if field_caches[ft].streaming_mode else \"memory\"\n            self._log(f\"    {ft}-field cache ready ({mode} mode)\", level=\"progress\", log_type=\"info\")\n\n        # Create outer progress bar for candidates\n        candidates_pbar = tqdm(\n            enumerate(candidates, start=1),\n            total=len(candidates),\n            desc=\"Combining fields\",\n            unit=\"candidate\",\n            leave=False,\n        )\n\n        for i, candidate in candidates_pbar:\n            candidates_pbar.set_description(f\"Combining fields (candidate {i}/{len(candidates)})\")\n\n            if full_volume:\n                # Full-volume combination \u2014 uses pre-loaded cache if in memory mode\n                combined_path = self._combine_fields_for_candidate(\n                    _CombineRequest(\n                        h5_paths=h5_paths,\n                        candidate=candidate,\n                        output_dir=output_dir,\n                        candidate_idx=i,\n                        cube_size_mm=cube_size_mm,\n                        combine_chunk_size=combine_chunk_size,\n                        full_volume=True,\n                        field_types=field_types,\n                        field_caches=field_caches,\n                    )\n                )\n                combined_h5_paths.append(combined_path)\n            else:\n                # Sliced combination with component progress bar\n                n_components = len(field_types) * 3  # 3 spatial components per field type\n                with tqdm(\n                    total=n_components,\n                    desc=f\"  Candidate #{i}\",\n                    unit=\"component\",\n                    leave=False,\n                ) as components_pbar:\n                    combined_path = self._combine_fields_for_candidate(\n                        _CombineRequest(\n                            h5_paths=h5_paths,\n                            candidate=candidate,\n                            output_dir=output_dir,\n                            candidate_idx=i,\n                            cube_size_mm=cube_size_mm,\n                            progress_bar=components_pbar,\n                            field_types=field_types,\n                        )\n                    )\n                    combined_h5_paths.append(combined_path)\n\n        candidates_pbar.close()\n\n        # Clean up field caches (closes file handles in streaming mode)\n        for fc in field_caches.values():\n            fc.close()\n\n    # Step 3: Extract dosimetric metric for each candidate\n    metric_key = \"peak_sar_10g_W_kg\" if extraction_metric == \"sar\" else \"peak_sapd_w_m2\"\n    metric_unit = \"W/kg\" if extraction_metric == \"sar\" else \"W/m2\"\n    subtask_name = \"auto_induced_extract_sar\" if extraction_metric == \"sar\" else \"auto_induced_extract_sapd\"\n\n    with self.study.subtask(subtask_name):\n        extraction_results = []\n        for i, combined_h5 in enumerate(combined_h5_paths):\n            if combined_h5 and combined_h5.exists():\n                # Each candidate gets its own output subdirectory\n                candidate_output_dir = Path(output_dir) / f\"candidate_{i + 1:02d}\"\n                candidate_output_dir.mkdir(parents=True, exist_ok=True)\n\n                if extraction_metric == \"sar\":\n                    result = self._extract_sar(\n                        combined_h5=combined_h5,\n                        candidate_idx=i + 1,\n                        candidate=candidates[i],\n                        input_h5=input_h5,\n                        candidate_output_dir=candidate_output_dir,\n                        save_intermediate_files=save_intermediate_files,\n                    )\n                else:\n                    result = self._extract_sapd(\n                        combined_h5=combined_h5,\n                        candidate_idx=i + 1,\n                        candidate=candidates[i],\n                        cube_size_mm=cube_size_mm,\n                        input_h5=input_h5,\n                        save_intermediate_files=save_intermediate_files,\n                    )\n                extraction_results.append(result)\n\n                # Log per-candidate progress\n                metric_val = result.get(metric_key)\n                metric_str = f\"{metric_val:.4e} {metric_unit}\" if metric_val else \"ERROR\"\n                self._log(\n                    f\"    Candidate #{i + 1}/{len(candidates)}: {metric_str}\",\n                    level=\"progress\",\n                    log_type=\"info\",\n                )\n            else:\n                extraction_results.append({\"error\": f\"Combined H5 not found: {combined_h5}\"})\n\n    # Find worst case\n    worst_case = self._find_worst_case(extraction_results, metric_key=metric_key)\n\n    if worst_case and worst_case.get(metric_key):\n        metric_label = \"SAR 10g\" if extraction_metric == \"sar\" else \"SAPD\"\n        self._log(\n            f\"  - Worst-case {metric_label}: {worst_case[metric_key]:.4e} {metric_unit} (candidate #{worst_case.get('candidate_idx')})\",\n            level=\"progress\",\n            log_type=\"success\",\n        )\n\n    # Export proxy-metric correlation data\n    correlation_data = []\n    metric_col = \"sar_10g_W_kg\" if extraction_metric == \"sar\" else \"sapd_w_m2\"\n    for i, (candidate, ext_result) in enumerate(zip(candidates, extraction_results)):\n        proxy_score = candidate.get(\"hotspot_score\", candidate.get(\"metric_sum\", 0.0))\n        metric_value = ext_result.get(metric_key)\n        if metric_value is not None:\n            entry = {\n                \"candidate_idx\": i + 1,\n                \"voxel_x\": candidate[\"voxel_idx\"][0],\n                \"voxel_y\": candidate[\"voxel_idx\"][1],\n                \"voxel_z\": candidate[\"voxel_idx\"][2],\n                \"proxy_score\": proxy_score,\n                metric_col: metric_value,\n            }\n            # Add distance to skin if available\n            if \"distance_to_skin_mm\" in candidate:\n                entry[\"distance_to_skin_mm\"] = candidate[\"distance_to_skin_mm\"]\n            correlation_data.append(entry)\n    if correlation_data:\n        import csv\n\n        corr_filename = f\"proxy_{extraction_metric}_correlation.csv\"\n        corr_path = Path(output_dir) / corr_filename\n        with open(corr_path, \"w\", newline=\"\") as f:\n            writer = csv.DictWriter(f, fieldnames=correlation_data[0].keys())\n            writer.writeheader()\n            writer.writerows(correlation_data)\n        self.verbose_logger.info(f\"  Exported proxy-{extraction_metric.upper()} correlation to {corr_path.name}\")\n\n    return {\n        \"phantom\": self.phantom_name,\n        \"frequency_mhz\": self.freq,\n        \"extraction_metric\": extraction_metric,\n        \"candidates\": candidates,\n        \"combined_h5_files\": [str(p) for p in combined_h5_paths if p],\n        \"extraction_results\": extraction_results,\n        \"worst_case\": worst_case,\n    }\n</code></pre>"},{"location":"reference/api_reference/#cleaner","title":"Cleaner","text":""},{"location":"reference/api_reference/#goliat.extraction.cleaner.Cleaner","title":"goliat.extraction.cleaner.Cleaner","text":"<pre><code>Cleaner(parent: ResultsExtractor)\n</code></pre> <p>Manages deletion of simulation files to free disk space.</p> <p>Deletes output files, input files, and/or project files based on config. Useful for long-running studies where disk space is limited.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>ResultsExtractor</code> <p>Parent ResultsExtractor instance.</p> required Source code in <code>goliat/extraction/cleaner.py</code> <pre><code>def __init__(self, parent: \"ResultsExtractor\"):\n    \"\"\"Sets up the cleaner.\n\n    Args:\n        parent: Parent ResultsExtractor instance.\n    \"\"\"\n    self.parent = parent\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.cleaner.Cleaner-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.cleaner.Cleaner.cleanup_simulation_files","title":"cleanup_simulation_files","text":"<pre><code>cleanup_simulation_files()\n</code></pre> <p>Deletes simulation files based on auto_cleanup config.</p> <p>Removes files matching specified patterns (output/input H5 files, project files). Only runs if cleanup is enabled in config.</p> Source code in <code>goliat/extraction/cleaner.py</code> <pre><code>def cleanup_simulation_files(self):\n    \"\"\"Deletes simulation files based on auto_cleanup config.\n\n    Removes files matching specified patterns (output/input H5 files,\n    project files). Only runs if cleanup is enabled in config.\n    \"\"\"\n    cleanup_types = self.parent.config.get_auto_cleanup_previous_results()\n    if not cleanup_types:\n        return\n\n    if self.parent.study is None:\n        self.parent._log(\"  - WARNING: Study object is not available. Skipping cleanup.\", log_type=\"warning\")\n        return\n\n    project_path = self.parent.study.project_manager.project_path\n    if not project_path:\n        self.parent._log(\"  - WARNING: Project path is not set. Skipping cleanup.\", log_type=\"warning\")\n        return\n    project_dir = os.path.dirname(project_path)\n    project_filename = os.path.basename(project_path)\n    results_dir = os.path.join(project_dir, project_filename + \"_Results\")\n\n    # Map cleanup types to file patterns and directories\n    file_patterns = {\n        \"output\": (results_dir, \"*_Output.h5\", \"output\"),\n        \"input\": (results_dir, \"*_Input.h5\", \"input\"),\n        \"smash\": (project_dir, \"*.smash\", \"project\"),\n    }\n\n    total_deleted = self._delete_files(cleanup_types, file_patterns)\n\n    if total_deleted &gt; 0:\n        self.parent._log(\n            f\"  - Cleaned up {total_deleted} file(s) to save disk space.\",\n            level=\"progress\",\n            log_type=\"info\",\n        )\n</code></pre>"},{"location":"reference/api_reference/#field-combiner","title":"Field Combiner","text":""},{"location":"reference/api_reference/#goliat.extraction.field_combiner.FieldCombineConfig","title":"goliat.extraction.field_combiner.FieldCombineConfig  <code>dataclass</code>","text":"<pre><code>FieldCombineConfig(h5_paths: Sequence[Path], weights: ndarray, template_h5_path: Path, output_h5_path: Path, field_types: Sequence[str] = ('E', 'H'))\n</code></pre> <p>Configuration for field combination operations.</p>"},{"location":"reference/api_reference/#field-reader","title":"Field Reader","text":""},{"location":"reference/api_reference/#goliat.extraction.field_reader","title":"goliat.extraction.field_reader","text":"<p>Utilities for reading E/H fields from Sim4Life _Output.h5 files.</p> <p>Supports memory-efficient reading for auto-induced exposure calculations: - Read fields at specific voxel indices (skin-only extraction) - Read fields in z-slab chunks (for full-field combination) - Handle Yee grid staggering (Nx-1, Ny-1, Nz-1 per component)</p>"},{"location":"reference/api_reference/#goliat.extraction.field_reader-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.field_reader.find_overall_field_group","title":"find_overall_field_group","text":"<pre><code>find_overall_field_group(f: File) -&gt; Optional[str]\n</code></pre> <p>Find the FieldGroup containing 'Overall Field'.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>File</code> <p>Open h5py File object.</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Path to the FieldGroup (e.g., 'FieldGroups/0') or None if not found.</p> Source code in <code>goliat/extraction/field_reader.py</code> <pre><code>def find_overall_field_group(f: h5py.File) -&gt; Optional[str]:\n    \"\"\"Find the FieldGroup containing 'Overall Field'.\n\n    Args:\n        f: Open h5py File object.\n\n    Returns:\n        Path to the FieldGroup (e.g., 'FieldGroups/0') or None if not found.\n    \"\"\"\n    if \"FieldGroups\" not in f:\n        return None\n\n    for fg_key in f[\"FieldGroups\"].keys():\n        obj_path = f\"FieldGroups/{fg_key}/_Object\"\n        if obj_path in f:\n            name_attr = f[obj_path].attrs.get(\"name\", b\"\")\n            if isinstance(name_attr, bytes):\n                name_attr = name_attr.decode(\"utf-8\")\n            if name_attr == \"Overall Field\":\n                return f\"FieldGroups/{fg_key}\"\n\n    return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.field_reader.get_field_path","title":"get_field_path","text":"<pre><code>get_field_path(fg_path: str, field_type: str = 'E') -&gt; str\n</code></pre> <p>Get the HDF5 path for E or H field data.</p> <p>Parameters:</p> Name Type Description Default <code>fg_path</code> <code>str</code> <p>Path to the FieldGroup.</p> required <code>field_type</code> <code>str</code> <p>'E' for electric field, 'H' for magnetic field.</p> <code>'E'</code> <p>Returns:</p> Type Description <code>str</code> <p>Path to the field's Snapshots/0 group containing comp0/comp1/comp2.</p> Source code in <code>goliat/extraction/field_reader.py</code> <pre><code>def get_field_path(fg_path: str, field_type: str = \"E\") -&gt; str:\n    \"\"\"Get the HDF5 path for E or H field data.\n\n    Args:\n        fg_path: Path to the FieldGroup.\n        field_type: 'E' for electric field, 'H' for magnetic field.\n\n    Returns:\n        Path to the field's Snapshots/0 group containing comp0/comp1/comp2.\n    \"\"\"\n    field_name = f\"EM {field_type}(x,y,z,f0)\"\n    return f\"{fg_path}/AllFields/{field_name}/_Object/Snapshots/0\"\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.field_reader.read_field_component","title":"read_field_component","text":"<pre><code>read_field_component(f: File, field_path: str, component: int, z_slice: Optional[slice] = None) -&gt; np.ndarray\n</code></pre> <p>Read a single field component as complex array.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>File</code> <p>Open h5py File object.</p> required <code>field_path</code> <code>str</code> <p>Path to the Snapshots/0 group.</p> required <code>component</code> <code>int</code> <p>0, 1, or 2 for x, y, z component.</p> required <code>z_slice</code> <code>Optional[slice]</code> <p>Optional slice for z-axis (for chunked reading).</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ndarray</code> <p>Complex64 array of shape (Nx, Ny, Nz) or (Nx, Ny, Nz_chunk).</p> <code>Note</code> <code>ndarray</code> <p>Dimensions vary due to Yee staggering.</p> Source code in <code>goliat/extraction/field_reader.py</code> <pre><code>def read_field_component(\n    f: h5py.File,\n    field_path: str,\n    component: int,\n    z_slice: Optional[slice] = None,\n) -&gt; np.ndarray:\n    \"\"\"Read a single field component as complex array.\n\n    Args:\n        f: Open h5py File object.\n        field_path: Path to the Snapshots/0 group.\n        component: 0, 1, or 2 for x, y, z component.\n        z_slice: Optional slice for z-axis (for chunked reading).\n\n    Returns:\n        Complex64 array of shape (Nx, Ny, Nz) or (Nx, Ny, Nz_chunk).\n        Note: Dimensions vary due to Yee staggering.\n    \"\"\"\n    comp_name = f\"comp{component}\"\n    dataset = f[f\"{field_path}/{comp_name}\"]\n\n    if z_slice is not None:\n        # Dataset shape is (Nx, Ny, Nz, 2) where last dim is [real, imag]\n        data = dataset[:, :, z_slice, :]\n    else:\n        data = dataset[:]\n\n    # Convert to complex\n    return data[..., 0] + 1j * data[..., 1]\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.field_reader.read_field_at_indices","title":"read_field_at_indices","text":"<pre><code>read_field_at_indices(h5_path: Union[str, Path], indices: ndarray, field_type: str = 'E') -&gt; np.ndarray\n</code></pre> <p>Read field values at specific voxel indices.</p> <p>Optimized for reading fields only at skin voxel locations. Uses single-point h5py reads for small N, vectorized reads for large N.</p> <p>Parameters:</p> Name Type Description Default <code>h5_path</code> <code>Union[str, Path]</code> <p>Path to _Output.h5 file.</p> required <code>indices</code> <code>ndarray</code> <p>Array of shape (N, 3) with [ix, iy, iz] indices.</p> required <code>field_type</code> <code>str</code> <p>'E' or 'H'.</p> <code>'E'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Complex64 array of shape (N, 3) with [Ex, Ey, Ez] or [Hx, Hy, Hz].</p> Note <p>Due to Yee staggering, we use the voxel center approximation. For component i, data shape is (N-1) in dimension i. We clamp indices to valid range.</p> Source code in <code>goliat/extraction/field_reader.py</code> <pre><code>def read_field_at_indices(\n    h5_path: Union[str, Path],\n    indices: np.ndarray,\n    field_type: str = \"E\",\n) -&gt; np.ndarray:\n    \"\"\"Read field values at specific voxel indices.\n\n    Optimized for reading fields only at skin voxel locations.\n    Uses single-point h5py reads for small N, vectorized reads for large N.\n\n    Args:\n        h5_path: Path to _Output.h5 file.\n        indices: Array of shape (N, 3) with [ix, iy, iz] indices.\n        field_type: 'E' or 'H'.\n\n    Returns:\n        Complex64 array of shape (N, 3) with [Ex, Ey, Ez] or [Hx, Hy, Hz].\n\n    Note:\n        Due to Yee staggering, we use the voxel center approximation.\n        For component i, data shape is (N-1) in dimension i.\n        We clamp indices to valid range.\n    \"\"\"\n    result = np.zeros((len(indices), 3), dtype=np.complex64)\n    n_points = len(indices)\n\n    with h5py.File(h5_path, \"r\") as f:\n        fg_path = find_overall_field_group(f)\n        if fg_path is None:\n            raise ValueError(f\"No 'Overall Field' found in {h5_path}\")\n\n        field_path = get_field_path(fg_path, field_type)\n\n        for comp in range(3):\n            dataset = f[f\"{field_path}/comp{comp}\"]\n            shape = dataset.shape[:3]  # (Nx, Ny, Nz) for this component\n\n            # Clamp indices to valid range for this component\n            # Component 0 (Ex): shape is (Nx-1, Ny, Nz)\n            # Component 1 (Ey): shape is (Nx, Ny-1, Nz)\n            # Component 2 (Ez): shape is (Nx, Ny, Nz-1)\n            ix = np.minimum(indices[:, 0], shape[0] - 1)\n            iy = np.minimum(indices[:, 1], shape[1] - 1)\n            iz = np.minimum(indices[:, 2], shape[2] - 1)\n\n            if n_points &lt;= 100:\n                # For small N: read points directly from disk (avoids loading GB arrays)\n                # h5py supports single-point indexing without loading full dataset\n                for j in range(n_points):\n                    data = dataset[int(ix[j]), int(iy[j]), int(iz[j]), :]\n                    result[j, comp] = data[0] + 1j * data[1]\n            else:\n                # For large N: read full array (vectorized indexing is faster)\n                full_data = dataset[:]  # Shape: (Nx, Ny, Nz, 2)\n                data = full_data[ix, iy, iz, :]  # Shape: (N, 2)\n                result[:, comp] = data[:, 0] + 1j * data[:, 1]\n\n    return result\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.field_reader.read_field_chunk","title":"read_field_chunk","text":"<pre><code>read_field_chunk(h5_path: Union[str, Path], z_start: int, z_end: int, field_type: str = 'E') -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n</code></pre> <p>Read a z-slab chunk of the field.</p> <p>For memory-efficient full-field combination.</p> <p>Parameters:</p> Name Type Description Default <code>h5_path</code> <code>Union[str, Path]</code> <p>Path to _Output.h5 file.</p> required <code>z_start</code> <code>int</code> <p>Start z-index (inclusive).</p> required <code>z_end</code> <code>int</code> <p>End z-index (exclusive).</p> required <code>field_type</code> <code>str</code> <p>'E' or 'H'.</p> <code>'E'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Tuple of (comp0, comp1, comp2) complex64 arrays.</p> <code>ndarray</code> <p>Shapes vary due to Yee staggering:</p> <code>ndarray</code> <ul> <li>comp0: (Nx-1, Ny, z_end-z_start)</li> </ul> <code>Tuple[ndarray, ndarray, ndarray]</code> <ul> <li>comp1: (Nx, Ny-1, z_end-z_start)</li> </ul> <code>Tuple[ndarray, ndarray, ndarray]</code> <ul> <li>comp2: (Nx, Ny, z_end-z_start-1) - one less in z!</li> </ul> Source code in <code>goliat/extraction/field_reader.py</code> <pre><code>def read_field_chunk(\n    h5_path: Union[str, Path],\n    z_start: int,\n    z_end: int,\n    field_type: str = \"E\",\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Read a z-slab chunk of the field.\n\n    For memory-efficient full-field combination.\n\n    Args:\n        h5_path: Path to _Output.h5 file.\n        z_start: Start z-index (inclusive).\n        z_end: End z-index (exclusive).\n        field_type: 'E' or 'H'.\n\n    Returns:\n        Tuple of (comp0, comp1, comp2) complex64 arrays.\n        Shapes vary due to Yee staggering:\n        - comp0: (Nx-1, Ny, z_end-z_start)\n        - comp1: (Nx, Ny-1, z_end-z_start)\n        - comp2: (Nx, Ny, z_end-z_start-1) - one less in z!\n    \"\"\"\n    with h5py.File(h5_path, \"r\") as f:\n        fg_path = find_overall_field_group(f)\n        if fg_path is None:\n            raise ValueError(f\"No 'Overall Field' found in {h5_path}\")\n\n        field_path = get_field_path(fg_path, field_type)\n        z_slice = slice(z_start, z_end)\n\n        components = []\n        for comp in range(3):\n            # For comp2 (Ez), the z-dimension is Nz-1, so adjust slice\n            if comp == 2:\n                # Clamp to valid range\n                dataset = f[f\"{field_path}/comp{comp}\"]\n                max_z = dataset.shape[2]\n                z_slice_adj = slice(z_start, min(z_end, max_z))\n                data = read_field_component(f, field_path, comp, z_slice_adj)\n            else:\n                data = read_field_component(f, field_path, comp, z_slice)\n            components.append(data)\n\n    return tuple(components)\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.field_reader.read_full_field","title":"read_full_field","text":"<pre><code>read_full_field(h5_path: Union[str, Path], field_type: str = 'E') -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n</code></pre> <p>Read the entire E or H field.</p> <p>Warning: Can be very memory intensive (~2GB for typical phantom).</p> <p>Parameters:</p> Name Type Description Default <code>h5_path</code> <code>Union[str, Path]</code> <p>Path to _Output.h5 file.</p> required <code>field_type</code> <code>str</code> <p>'E' or 'H'.</p> <code>'E'</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>Tuple of (comp0, comp1, comp2) complex64 arrays.</p> Source code in <code>goliat/extraction/field_reader.py</code> <pre><code>def read_full_field(\n    h5_path: Union[str, Path],\n    field_type: str = \"E\",\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Read the entire E or H field.\n\n    Warning: Can be very memory intensive (~2GB for typical phantom).\n\n    Args:\n        h5_path: Path to _Output.h5 file.\n        field_type: 'E' or 'H'.\n\n    Returns:\n        Tuple of (comp0, comp1, comp2) complex64 arrays.\n    \"\"\"\n    with h5py.File(h5_path, \"r\") as f:\n        fg_path = find_overall_field_group(f)\n        if fg_path is None:\n            raise ValueError(f\"No 'Overall Field' found in {h5_path}\")\n\n        field_path = get_field_path(fg_path, field_type)\n\n        components = []\n        for comp in range(3):\n            data = read_field_component(f, field_path, comp)\n            components.append(data)\n\n    return tuple(components)\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.field_reader.get_field_shape","title":"get_field_shape","text":"<pre><code>get_field_shape(h5_path: Union[str, Path]) -&gt; Tuple[int, int, int]\n</code></pre> <p>Get the grid shape from an _Output.h5 file.</p> <p>Returns the node count (Nx, Ny, Nz), not voxel count. Field components have shapes (Nx-1, Ny, Nz), etc. due to Yee grid.</p> <p>Parameters:</p> Name Type Description Default <code>h5_path</code> <code>Union[str, Path]</code> <p>Path to _Output.h5 file.</p> required <p>Returns:</p> Type Description <code>Tuple[int, int, int]</code> <p>Tuple (Nx, Ny, Nz) - node counts.</p> Source code in <code>goliat/extraction/field_reader.py</code> <pre><code>def get_field_shape(h5_path: Union[str, Path]) -&gt; Tuple[int, int, int]:\n    \"\"\"Get the grid shape from an _Output.h5 file.\n\n    Returns the node count (Nx, Ny, Nz), not voxel count.\n    Field components have shapes (Nx-1, Ny, Nz), etc. due to Yee grid.\n\n    Args:\n        h5_path: Path to _Output.h5 file.\n\n    Returns:\n        Tuple (Nx, Ny, Nz) - node counts.\n    \"\"\"\n    with h5py.File(h5_path, \"r\") as f:\n        fg_path = find_overall_field_group(f)\n        if fg_path is None:\n            raise ValueError(f\"No 'Overall Field' found in {h5_path}\")\n\n        field_path = get_field_path(fg_path, \"E\")\n        # comp0 has shape (Nx-1, Ny, Nz, 2), so Nx = shape[0] + 1\n        shape = f[f\"{field_path}/comp0\"].shape\n        return (shape[0] + 1, shape[1], shape[2])\n</code></pre>"},{"location":"reference/api_reference/#focus-optimizer","title":"Focus Optimizer","text":""},{"location":"reference/api_reference/#goliat.extraction.focus_optimizer.FieldCache","title":"goliat.extraction.focus_optimizer.FieldCache","text":"<pre><code>FieldCache(h5_paths: Sequence[Union[str, Path]], field_type: str = 'E', low_memory: Optional[bool] = None, slab_cache_gb: float = DEFAULT_SLAB_CACHE_GB)\n</code></pre> <p>Cache for pre-loaded E-field data from multiple H5 files.</p> <p>Supports three modes: - Memory mode (default): Load all fields into RAM for fast access.   Best when you have enough RAM to hold all field data (~3 min). - Streaming mode (optimized): Uses slab-based LRU cache for efficient   disk access. Much faster than naive streaming (~10-30 min vs 42 hours). - Legacy streaming mode: Single-point reads (extremely slow, deprecated).</p> <p>Mode is automatically selected based on available RAM, or can be forced via the low_memory parameter.</p> <p>Parameters:</p> Name Type Description Default <code>h5_paths</code> <code>Sequence[Union[str, Path]]</code> <p>Paths to _Output.h5 files.</p> required <code>field_type</code> <code>str</code> <p>'E' or 'H'.</p> <code>'E'</code> <code>low_memory</code> <code>Optional[bool]</code> <p>If True, use streaming mode (no pre-loading). If False, always use memory mode (may cause paging on low-RAM). If None (default), auto-detect based on available RAM.</p> <code>None</code> <code>slab_cache_gb</code> <code>float</code> <p>Size of slab LRU cache in GB (only for streaming mode).</p> <code>DEFAULT_SLAB_CACHE_GB</code> Source code in <code>goliat/extraction/field_cache.py</code> <pre><code>def __init__(\n    self,\n    h5_paths: Sequence[Union[str, Path]],\n    field_type: str = \"E\",\n    low_memory: Optional[bool] = None,\n    slab_cache_gb: float = DEFAULT_SLAB_CACHE_GB,\n):\n    \"\"\"Initialize the field cache.\n\n    Args:\n        h5_paths: Paths to _Output.h5 files.\n        field_type: 'E' or 'H'.\n        low_memory: If True, use streaming mode (no pre-loading).\n            If False, always use memory mode (may cause paging on low-RAM).\n            If None (default), auto-detect based on available RAM.\n        slab_cache_gb: Size of slab LRU cache in GB (only for streaming mode).\n    \"\"\"\n    self.h5_paths = [str(p) for p in h5_paths]\n    self.field_type = field_type\n    self.fields: Dict[str, List[np.ndarray]] = {}\n    self.shapes: Dict[str, Tuple[int, int, int]] = {}\n    self.slab_cache_gb = slab_cache_gb\n\n    self._slab_cache: Optional[SlabLRUCache] = None\n    self._open_files: Dict[str, h5py.File] = {}\n    self._field_paths: Dict[str, str] = {}\n\n    logger = logging.getLogger(\"progress\")\n\n    available_gb = _get_available_memory_gb()\n    estimated_gb = _estimate_cache_size_gb(h5_paths)\n    has_enough_ram = available_gb &lt; 0 or estimated_gb &lt;= available_gb - self.MIN_HEADROOM_GB\n\n    if low_memory is None:\n        self.streaming_mode = not has_enough_ram\n    else:\n        self.streaming_mode = low_memory\n\n    if available_gb &gt; 0:\n        logger.info(f\"  Memory check: {estimated_gb:.1f} GB needed, {available_gb:.1f} GB available\")\n\n    if self.streaming_mode:\n        logger.info(\n            f\"  Using OPTIMIZED STREAMING mode with {slab_cache_gb:.1f} GB slab cache\\n\"\n            f\"  This is ~100x faster than naive streaming. \"\n            f\"For fastest processing, use a machine with &gt;{estimated_gb + self.MIN_HEADROOM_GB:.0f} GB RAM.\"\n        )\n        self._init_streaming_mode()\n    else:\n        if not has_enough_ram:\n            warning_msg = (\n                f\"\\n{'=' * 70}\\n\"\n                f\"  WARNING: Insufficient RAM for field cache!\\n\"\n                f\"  - Cache size: {estimated_gb:.1f} GB\\n\"\n                f\"  - Available RAM: {available_gb:.1f} GB\\n\"\n                f\"  - Recommended: {estimated_gb + self.MIN_HEADROOM_GB:.1f} GB\\n\"\n                f\"\\n\"\n                f\"  This may cause severe slowdowns due to disk paging.\\n\"\n                f\"  Consider:\\n\"\n                f\"    1. Closing other applications to free RAM\\n\"\n                f\"    2. Running on a machine with more RAM\\n\"\n                f\"    3. Reducing n_samples in config\\n\"\n                f\"    4. Setting low_memory_mode=true in config\\n\"\n                f\"{'=' * 70}\\n\"\n            )\n            logger.warning(warning_msg)\n            warnings.warn(\n                f\"Field cache ({estimated_gb:.1f} GB) exceeds available RAM ({available_gb:.1f} GB). Expect severe slowdowns.\",\n                ResourceWarning,\n                stacklevel=2,\n            )\n\n        logger.info(f\"  Pre-loading {field_type}-fields from {len(h5_paths)} files...\")\n        t0 = time.perf_counter()\n\n        for h5_path in tqdm(self.h5_paths, desc=f\"Loading {field_type}-fields\"):\n            self._load_field(h5_path)\n\n        total_mb = sum(sum(c.nbytes for c in comps) for comps in self.fields.values()) / 1e6\n        logger.info(f\"  [timing] Field cache loaded: {time.perf_counter() - t0:.2f}s, {total_mb:.0f} MB\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.focus_optimizer.FieldCache-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.focus_optimizer.FieldCache.read_at_indices","title":"read_at_indices","text":"<pre><code>read_at_indices(h5_path: str, indices: ndarray) -&gt; np.ndarray\n</code></pre> <p>Read field values at specific indices.</p> <p>In memory mode, reads from pre-loaded cached data. In streaming mode, uses slab-based caching for efficiency.</p> <p>Parameters:</p> Name Type Description Default <code>h5_path</code> <code>str</code> <p>Which file to read from.</p> required <code>indices</code> <code>ndarray</code> <p>(N, 3) array of [ix, iy, iz] indices.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>(N, 3) complex array of field values.</p> Source code in <code>goliat/extraction/field_cache.py</code> <pre><code>def read_at_indices(self, h5_path: str, indices: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Read field values at specific indices.\n\n    In memory mode, reads from pre-loaded cached data.\n    In streaming mode, uses slab-based caching for efficiency.\n\n    Args:\n        h5_path: Which file to read from.\n        indices: (N, 3) array of [ix, iy, iz] indices.\n\n    Returns:\n        (N, 3) complex array of field values.\n    \"\"\"\n    if self.streaming_mode:\n        return self._read_at_indices_streaming_optimized(h5_path, indices)\n    else:\n        return self._read_at_indices_memory(h5_path, indices)\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.focus_optimizer.FieldCache.get_cache_stats","title":"get_cache_stats","text":"<pre><code>get_cache_stats() -&gt; Optional[Dict[str, float]]\n</code></pre> <p>Get slab cache statistics (streaming mode only).</p> Source code in <code>goliat/extraction/field_cache.py</code> <pre><code>def get_cache_stats(self) -&gt; Optional[Dict[str, float]]:\n    \"\"\"Get slab cache statistics (streaming mode only).\"\"\"\n    if self._slab_cache is not None:\n        return self._slab_cache.get_stats()\n    return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.focus_optimizer.FieldCache.close","title":"close","text":"<pre><code>close()\n</code></pre> <p>Close open file handles (streaming mode cleanup).</p> Source code in <code>goliat/extraction/field_cache.py</code> <pre><code>def close(self):\n    \"\"\"Close open file handles (streaming mode cleanup).\"\"\"\n    for f in self._open_files.values():\n        try:\n            f.close()\n        except Exception:\n            pass\n    self._open_files.clear()\n</code></pre>"},{"location":"reference/api_reference/#json-encoder","title":"Json Encoder","text":""},{"location":"reference/api_reference/#goliat.extraction.json_encoder.NumpyArrayEncoder","title":"goliat.extraction.json_encoder.NumpyArrayEncoder","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>JSON encoder that handles NumPy types.</p> <p>Converts numpy arrays and numeric types to Python built-ins so they can be serialized to JSON.</p>"},{"location":"reference/api_reference/#goliat.extraction.json_encoder.NumpyArrayEncoder-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.json_encoder.NumpyArrayEncoder.default","title":"default","text":"<pre><code>default(o: Any) -&gt; Any\n</code></pre> <p>Converts NumPy types to JSON-serializable Python types.</p> Source code in <code>goliat/extraction/json_encoder.py</code> <pre><code>def default(self, o: Any) -&gt; Any:\n    \"\"\"Converts NumPy types to JSON-serializable Python types.\"\"\"\n    if isinstance(o, np.ndarray):\n        return o.tolist()\n    if isinstance(o, np.integer):\n        return int(o)\n    if isinstance(o, np.floating):\n        return float(o)\n    return super().default(o)\n</code></pre>"},{"location":"reference/api_reference/#power-extractor","title":"Power Extractor","text":""},{"location":"reference/api_reference/#goliat.extraction.power_extractor.PowerExtractor","title":"goliat.extraction.power_extractor.PowerExtractor","text":"<pre><code>PowerExtractor(parent: ResultsExtractor, results_data: dict)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Extracts input power and power balance from simulation results.</p> <p>For near-field, reads power from port sensors. For far-field, calculates theoretical power from plane wave parameters. Also extracts power balance to verify energy conservation.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>ResultsExtractor</code> <p>Parent ResultsExtractor instance.</p> required <code>results_data</code> <code>dict</code> <p>Dict to store extracted power data.</p> required Source code in <code>goliat/extraction/power_extractor.py</code> <pre><code>def __init__(self, parent: \"ResultsExtractor\", results_data: dict):\n    \"\"\"Sets up the power extractor.\n\n    Args:\n        parent: Parent ResultsExtractor instance.\n        results_data: Dict to store extracted power data.\n    \"\"\"\n    self.parent = parent\n    self.config = parent.config\n    self.simulation = parent.simulation\n    self.study_type = parent.study_type\n    self.placement_name = parent.placement_name\n    self.frequency_mhz = parent.frequency_mhz\n    self.verbose_logger = parent.verbose_logger\n    self.progress_logger = parent.progress_logger\n    self.gui = parent.gui\n    self.results_data = results_data\n\n    import s4l_v1.document\n\n    self.document = s4l_v1.document\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.power_extractor.PowerExtractor-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.power_extractor.PowerExtractor.extract_input_power","title":"extract_input_power","text":"<pre><code>extract_input_power(simulation_extractor: Extractor)\n</code></pre> <p>Extracts input power, delegating to study-type specific methods.</p> <p>Parameters:</p> Name Type Description Default <code>simulation_extractor</code> <code>Extractor</code> <p>Results extractor from the simulation.</p> required Source code in <code>goliat/extraction/power_extractor.py</code> <pre><code>def extract_input_power(self, simulation_extractor: \"analysis.Extractor\"):  # type: ignore\n    \"\"\"Extracts input power, delegating to study-type specific methods.\n\n    Args:\n        simulation_extractor: Results extractor from the simulation.\n    \"\"\"\n    self._log(\"    - Extract input power...\", level=\"progress\", log_type=\"progress\")\n\n    try:\n        elapsed = 0.0\n        if self.parent.study:\n            with self.parent.study.profiler.subtask(\"extract_input_power\"):  # type: ignore\n                if self.study_type == \"far_field\":\n                    self._extract_far_field_power(simulation_extractor)\n                else:\n                    self._extract_near_field_power(simulation_extractor)\n\n            elapsed = self.parent.study.profiler.subtask_times[\"extract_input_power\"][-1]\n\n        self._log(f\"      - Subtask 'extract_input_power' done in {elapsed:.2f}s\", log_type=\"verbose\")\n        self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n    except Exception as e:\n        self._log(\n            f\"  - ERROR: An exception occurred during input power extraction: {e}\",\n            level=\"progress\",\n            log_type=\"error\",\n        )\n        self.verbose_logger.error(traceback.format_exc())\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.power_extractor.PowerExtractor.extract_power_balance","title":"extract_power_balance","text":"<pre><code>extract_power_balance(simulation_extractor: Extractor)\n</code></pre> <p>Extracts power balance to verify energy conservation.</p> <p>Power balance is a sanity check: the power going into the simulation should equal the power coming out (as losses and radiation). This helps catch numerical errors or convergence issues.</p> <p>The balance is calculated as: balance = (P_out / P_in) \u00d7 100%</p> <p>Where P_out includes: - Dielectric losses (power absorbed by materials) - Radiated power (power escaping the simulation volume)</p> <p>For far-field studies, uses the theoretical input power (from plane wave calculation) rather than extracted power, since plane waves don't have a traditional \"input port\" sensor.</p> <p>A balance close to 100% indicates good energy conservation. Values significantly different suggest convergence issues or numerical errors.</p> <p>Parameters:</p> Name Type Description Default <code>simulation_extractor</code> <code>Extractor</code> <p>Results extractor from the simulation.</p> required Source code in <code>goliat/extraction/power_extractor.py</code> <pre><code>def extract_power_balance(self, simulation_extractor: \"analysis.Extractor\"):  # type: ignore\n    \"\"\"Extracts power balance to verify energy conservation.\n\n    Power balance is a sanity check: the power going into the simulation should\n    equal the power coming out (as losses and radiation). This helps catch\n    numerical errors or convergence issues.\n\n    The balance is calculated as: balance = (P_out / P_in) \u00d7 100%\n\n    Where P_out includes:\n    - Dielectric losses (power absorbed by materials)\n    - Radiated power (power escaping the simulation volume)\n\n    For far-field studies, uses the theoretical input power (from plane wave\n    calculation) rather than extracted power, since plane waves don't have a\n    traditional \"input port\" sensor.\n\n    A balance close to 100% indicates good energy conservation. Values significantly\n    different suggest convergence issues or numerical errors.\n\n    Args:\n        simulation_extractor: Results extractor from the simulation.\n    \"\"\"\n    self._log(\"    - Extract power balance...\", level=\"progress\", log_type=\"progress\")\n    try:\n        elapsed = 0.0\n        if self.parent.study:\n            with self.parent.study.profiler.subtask(\"extract_power_balance\"):  # type: ignore\n                em_sensor_extractor = simulation_extractor[\"Overall Field\"]\n                power_balance_extractor = em_sensor_extractor.Outputs[\"Power Balance\"]\n                power_balance_extractor.Update()\n\n                power_balance_data = {\n                    key: power_balance_extractor.Data.DataSimpleDataCollection.FieldValue(key, 0)\n                    for key in power_balance_extractor.Data.DataSimpleDataCollection.Keys()\n                    if key != \"Balance\"\n                }\n\n                if self.parent.study_type == \"far_field\" and \"input_power_W\" in self.results_data:\n                    power_balance_data[\"Pin\"] = self.results_data[\"input_power_W\"]\n                    self._log(\n                        f\"    - Overwriting Pin with theoretical value: {float(power_balance_data['Pin']):.4e} W\",\n                        log_type=\"info\",\n                    )\n\n                pin = power_balance_data.get(\"Pin\", 0.0)\n                p_out = power_balance_data.get(\"DielLoss\", 0.0) + power_balance_data.get(\"RadPower\", 0.0)\n                balance = 100 * (p_out / pin) if pin &gt; 1e-9 else float(\"nan\")\n\n                power_balance_data[\"Balance\"] = balance\n                self._log(f\"    - Final Balance: {balance:.2f}%\", log_type=\"highlight\")\n                self.results_data[\"power_balance\"] = power_balance_data\n\n            elapsed = self.parent.study.profiler.subtask_times[\"extract_power_balance\"][-1]\n        self._log(f\"      - Subtask 'extract_power_balance' done in {elapsed:.2f}s\", log_type=\"verbose\")\n        self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    except Exception as e:\n        self._log(f\"  - WARNING: Could not extract power balance: {e}\", log_type=\"warning\")\n        self.verbose_logger.error(traceback.format_exc())\n</code></pre>"},{"location":"reference/api_reference/#reporter","title":"Reporter","text":""},{"location":"reference/api_reference/#goliat.extraction.reporter.Reporter","title":"goliat.extraction.reporter.Reporter","text":"<pre><code>Reporter(parent: ResultsExtractor)\n</code></pre> <p>Generates and saves detailed reports from extraction results.</p> <p>Creates Pickle files for programmatic access and HTML files for human readability. Includes SAR statistics, tissue groups, and peak SAR details.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>ResultsExtractor</code> <p>Parent ResultsExtractor instance.</p> required Source code in <code>goliat/extraction/reporter.py</code> <pre><code>def __init__(self, parent: \"ResultsExtractor\"):\n    \"\"\"Sets up the reporter.\n\n    Args:\n        parent: Parent ResultsExtractor instance.\n    \"\"\"\n    self.parent = parent\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.reporter.Reporter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.reporter.Reporter.save_reports","title":"save_reports","text":"<pre><code>save_reports(df: DataFrame, tissue_groups: dict, group_sar_stats: dict, results_data: dict)\n</code></pre> <p>Saves Pickle and HTML reports to the results directory.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with detailed SAR statistics per tissue.</p> required <code>tissue_groups</code> <code>dict</code> <p>Dict mapping group names to tissue lists.</p> required <code>group_sar_stats</code> <code>dict</code> <p>Dict with aggregated SAR stats per group.</p> required <code>results_data</code> <code>dict</code> <p>Dict with summary results and metadata.</p> required Source code in <code>goliat/extraction/reporter.py</code> <pre><code>def save_reports(\n    self,\n    df: pd.DataFrame,\n    tissue_groups: dict,\n    group_sar_stats: dict,\n    results_data: dict,\n):\n    \"\"\"Saves Pickle and HTML reports to the results directory.\n\n    Args:\n        df: DataFrame with detailed SAR statistics per tissue.\n        tissue_groups: Dict mapping group names to tissue lists.\n        group_sar_stats: Dict with aggregated SAR stats per group.\n        results_data: Dict with summary results and metadata.\n    \"\"\"\n    results_dir = self._get_results_dir()\n    os.makedirs(results_dir, exist_ok=True)\n\n    self._save_pickle_report(results_dir, df, tissue_groups, group_sar_stats, results_data)\n    self._save_html_report(results_dir, df, tissue_groups, group_sar_stats, results_data)\n</code></pre>"},{"location":"reference/api_reference/#resonance-extractor","title":"Resonance Extractor","text":""},{"location":"reference/api_reference/#goliat.extraction.resonance_extractor.ResonanceExtractor","title":"goliat.extraction.resonance_extractor.ResonanceExtractor","text":"<pre><code>ResonanceExtractor(parent: ResultsExtractor, results_data: dict)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Extracts antenna resonance frequency and detuning from Gaussian pulse results.</p> <p>Analyzes frequency-dependent accepted power to identify resonance peak and calculates detuning relative to nominal frequency.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>ResultsExtractor</code> <p>Parent ResultsExtractor instance.</p> required <code>results_data</code> <code>dict</code> <p>Dict to store extracted resonance data.</p> required Source code in <code>goliat/extraction/resonance_extractor.py</code> <pre><code>def __init__(self, parent: \"ResultsExtractor\", results_data: dict):\n    \"\"\"Sets up the resonance extractor.\n\n    Args:\n        parent: Parent ResultsExtractor instance.\n        results_data: Dict to store extracted resonance data.\n    \"\"\"\n    self.parent = parent\n    self.config = parent.config\n    self.frequency_mhz = parent.frequency_mhz\n    self.verbose_logger = parent.verbose_logger\n    self.progress_logger = parent.progress_logger\n    self.results_data = results_data\n    self.gui = parent.gui\n\n    import s4l_v1.document\n\n    self.document = s4l_v1.document\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.resonance_extractor.ResonanceExtractor-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.resonance_extractor.ResonanceExtractor.extract_resonance_frequency","title":"extract_resonance_frequency","text":"<pre><code>extract_resonance_frequency(simulation_extractor: Extractor)\n</code></pre> <p>Extract antenna resonant frequency from Gaussian pulse results.</p> <p>Analyzes frequency-dependent accepted power to identify resonance peak. Calculates detuning relative to nominal frequency.</p> <p>Parameters:</p> Name Type Description Default <code>simulation_extractor</code> <code>Extractor</code> <p>Results extractor from the simulation.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Contains resonant_freq_mhz, detuning_mhz, max_power_w, freq_resolution_mhz</p> Source code in <code>goliat/extraction/resonance_extractor.py</code> <pre><code>def extract_resonance_frequency(self, simulation_extractor: \"analysis.Extractor\"):  # type: ignore\n    \"\"\"Extract antenna resonant frequency from Gaussian pulse results.\n\n    Analyzes frequency-dependent accepted power to identify resonance peak.\n    Calculates detuning relative to nominal frequency.\n\n    Args:\n        simulation_extractor: Results extractor from the simulation.\n\n    Returns:\n        dict: Contains resonant_freq_mhz, detuning_mhz, max_power_w, freq_resolution_mhz\n    \"\"\"\n    try:\n        # Extract full frequency spectrum\n        input_power_extractor = simulation_extractor[\"Input Power\"]\n        self.document.AllAlgorithms.Add(input_power_extractor)\n        input_power_extractor.Update()\n\n        input_power_output = input_power_extractor.Outputs[\"EM Input Power(f)\"]\n        input_power_output.Update()\n\n        # Get continuous frequency data (automatically from FFT)\n        freq_axis_hz = input_power_output.Data.Axis  # Full freq array\n        power_data_w = input_power_output.Data.GetComponent(0)  # Power at each freq\n\n        # Convert to MHz\n        freq_axis_mhz = freq_axis_hz / 1e6\n\n        # Find resonant frequency (maximum accepted power)\n        max_idx = np.argmax(power_data_w)\n        resonant_freq_mhz = freq_axis_mhz[max_idx]\n        max_power_w = power_data_w[max_idx]\n\n        # Calculate detuning\n        freq_mhz = self.frequency_mhz\n        nominal_freq_mhz = float(freq_mhz if isinstance(freq_mhz, (int, float)) else np.mean(freq_mhz))\n        detuning_mhz = float(resonant_freq_mhz - nominal_freq_mhz)\n\n        # Calculate frequency resolution\n        if len(freq_axis_hz) &gt; 1:\n            freq_resolution_mhz = (freq_axis_hz[1] - freq_axis_hz[0]) / 1e6\n        else:\n            freq_resolution_mhz = 0.0\n\n        # Log results\n        self._log(f\"\\n{'=' * 80}\", log_type=\"highlight\")\n        self._log(\"  ANTENNA RESONANCE ANALYSIS\", log_type=\"highlight\")\n        self._log(f\"{'=' * 80}\", log_type=\"highlight\")\n        self._log(f\"  Nominal frequency: {nominal_freq_mhz} MHz\", log_type=\"info\")\n        self._log(f\"  Detected resonance: {resonant_freq_mhz:.2f} MHz\", log_type=\"highlight\")\n        self._log(\n            f\"  Detuning: {detuning_mhz:+.2f} MHz ({detuning_mhz / nominal_freq_mhz * 100:+.1f}%)\",\n            log_type=\"highlight\" if abs(detuning_mhz) &gt; 10 else \"info\",\n        )\n        self._log(f\"  Max power at resonance: {max_power_w * 1000:.2f} mW\", log_type=\"info\")\n        self._log(f\"  Frequency resolution: {freq_resolution_mhz:.2f} MHz\", log_type=\"info\")\n        self._log(f\"  Number of frequency points: {len(freq_axis_hz)}\", log_type=\"info\")\n        self._log(f\"{'=' * 80}\\n\", log_type=\"highlight\")\n\n        # Warning for severe detuning\n        if abs(detuning_mhz) &gt; 50:\n            self._log(\"\\n\" + \"!\" * 80, log_type=\"warning\")\n            self._log(\"  WARNING: SIGNIFICANT ANTENNA DETUNING DETECTED!\", log_type=\"warning\")\n            self._log(\n                f\"  The antenna has shifted {detuning_mhz:+.1f} MHz from nominal frequency.\",\n                log_type=\"warning\",\n            )\n            self._log(\"  Consider:\", log_type=\"warning\")\n            self._log(\n                f\"    1. Re-running simulation at detected resonance ({resonant_freq_mhz:.0f} MHz)\",\n                log_type=\"warning\",\n            )\n            self._log(\"    2. Verifying antenna design for this placement scenario\", log_type=\"warning\")\n            self._log(\n                \"    3. Checking if SAR pattern is affected by off-resonance operation\",\n                log_type=\"warning\",\n            )\n            self._log(\"!\" * 80 + \"\\n\", log_type=\"warning\")\n\n        # Store results\n        resonance_data = {\n            \"resonant_freq_mhz\": float(resonant_freq_mhz),\n            \"nominal_freq_mhz\": float(nominal_freq_mhz),\n            \"detuning_mhz\": float(detuning_mhz),\n            \"detuning_percent\": float(detuning_mhz / nominal_freq_mhz * 100),\n            \"max_power_w\": float(max_power_w),\n            \"freq_resolution_mhz\": float(freq_resolution_mhz),\n            \"num_freq_points\": int(len(freq_axis_hz)),\n            \"frequency_axis_mhz\": freq_axis_mhz.tolist(),  # For plotting\n            \"power_data_w\": power_data_w.tolist(),  # For plotting\n        }\n\n        # Clean up\n        self.document.AllAlgorithms.Remove(input_power_extractor)\n\n        return resonance_data\n\n    except Exception as e:\n        self._log(\n            f\"  - ERROR: An exception occurred during resonance extraction: {e}\",\n            log_type=\"error\",\n        )\n        self.verbose_logger.error(traceback.format_exc())\n        return None\n</code></pre>"},{"location":"reference/api_reference/#sapd-extractor","title":"Sapd Extractor","text":""},{"location":"reference/api_reference/#goliat.extraction.sapd_extractor.SapdExtractionContext","title":"goliat.extraction.sapd_extractor.SapdExtractionContext  <code>dataclass</code>","text":"<pre><code>SapdExtractionContext(center_m: Optional[List[float]] = None, sliced_h5_path: Optional[str] = None, sliced_extractor: Optional[Any] = None, active_extractor: Optional[Any] = None, em_sensor_extractor: Optional[Any] = None, model_to_grid_filter: Optional[Any] = None, sapd_evaluator: Optional[Any] = None)\n</code></pre> <p>Holds state during SAPD extraction to reduce method parameters.</p>"},{"location":"reference/api_reference/#sar-extractor","title":"Sar Extractor","text":""},{"location":"reference/api_reference/#goliat.extraction.sar_extractor.SarExtractor","title":"goliat.extraction.sar_extractor.SarExtractor","text":"<pre><code>SarExtractor(parent: ResultsExtractor, results_data: dict)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Extracts SAR statistics from simulation results.</p> <p>Uses Sim4Life's SarStatisticsEvaluator to compute mass-averaged SAR, peak spatial-average SAR (10g), and tissue-specific metrics. Groups tissues into logical groups (eyes, skin, brain) for analysis.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>ResultsExtractor</code> <p>Parent ResultsExtractor instance.</p> required <code>results_data</code> <code>dict</code> <p>Dict to store extracted SAR data.</p> required Source code in <code>goliat/extraction/sar_extractor.py</code> <pre><code>def __init__(self, parent: \"ResultsExtractor\", results_data: dict):\n    \"\"\"Sets up the SAR extractor.\n\n    Args:\n        parent: Parent ResultsExtractor instance.\n        results_data: Dict to store extracted SAR data.\n    \"\"\"\n    self.parent = parent\n    self.config = parent.config\n    self.simulation = parent.simulation\n    self.phantom_name = parent.phantom_name\n    self.placement_name = parent.placement_name\n    self.verbose_logger = parent.verbose_logger\n    self.progress_logger = parent.progress_logger\n    self.gui = parent.gui\n    self.results_data = results_data\n\n    import s4l_v1.analysis\n    import s4l_v1.document\n    import s4l_v1.units as units\n\n    self.analysis = s4l_v1.analysis\n    self.document = s4l_v1.document\n    self.units = units\n\n    self.tissue_grouper = TissueGrouper(self.config, self.phantom_name, self)\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.sar_extractor.SarExtractor-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.sar_extractor.SarExtractor.extract_sar_statistics","title":"extract_sar_statistics","text":"<pre><code>extract_sar_statistics(simulation_extractor: Extractor)\n</code></pre> <p>Extracts SAR statistics for all tissues.</p> <p>This is the main SAR extraction method that orchestrates the entire process. It uses Sim4Life's SarStatisticsEvaluator to compute standardized SAR metrics according to IEEE/IEC standards.</p> <p>The process: 1. Extracts the 'Overall Field' E-field data from simulation results 2. Creates a SarStatisticsEvaluator configured for 10g peak spatial-average SAR 3. Processes the evaluator output into a pandas DataFrame 4. Groups tissues into logical categories (eyes, skin, brain) 5. Calculates weighted-average SAR for each group (mass-weighted) 6. Extracts peak SAR details (location, coordinates, etc.) 7. Stores both per-tissue and group-level results</p> <p>The results include mass-averaged SAR, peak spatial-average SAR (10g), and tissue-specific metrics. For near-field studies, also extracts head/trunk SAR based on placement scenario. For far-field, extracts whole-body SAR.</p> <p>Parameters:</p> Name Type Description Default <code>simulation_extractor</code> <code>Extractor</code> <p>Results extractor from the simulation object.</p> required Source code in <code>goliat/extraction/sar_extractor.py</code> <pre><code>def extract_sar_statistics(self, simulation_extractor: \"analysis.Extractor\"):  # type: ignore\n    \"\"\"Extracts SAR statistics for all tissues.\n\n    This is the main SAR extraction method that orchestrates the entire process.\n    It uses Sim4Life's SarStatisticsEvaluator to compute standardized SAR metrics\n    according to IEEE/IEC standards.\n\n    The process:\n    1. Extracts the 'Overall Field' E-field data from simulation results\n    2. Creates a SarStatisticsEvaluator configured for 10g peak spatial-average SAR\n    3. Processes the evaluator output into a pandas DataFrame\n    4. Groups tissues into logical categories (eyes, skin, brain)\n    5. Calculates weighted-average SAR for each group (mass-weighted)\n    6. Extracts peak SAR details (location, coordinates, etc.)\n    7. Stores both per-tissue and group-level results\n\n    The results include mass-averaged SAR, peak spatial-average SAR (10g), and\n    tissue-specific metrics. For near-field studies, also extracts head/trunk SAR\n    based on placement scenario. For far-field, extracts whole-body SAR.\n\n    Args:\n        simulation_extractor: Results extractor from the simulation object.\n    \"\"\"\n    self._log(\"    - Extract SAR statistics...\", level=\"progress\", log_type=\"progress\")\n    try:\n        elapsed = 0.0\n        if self.parent.study:\n            with self.parent.study.profiler.subtask(\"extract_sar_statistics\"):  # type: ignore\n                em_sensor_extractor = self._setup_em_sensor_extractor(simulation_extractor)\n                try:\n                    results = self._evaluate_sar_statistics(em_sensor_extractor)\n\n                    if not results:\n                        return\n\n                    df = self._create_sar_dataframe(results)\n                    tissue_groups = self.tissue_grouper.group_tissues(df[\"Tissue\"].tolist())\n                    group_sar_stats = self._calculate_group_sar(df, tissue_groups)\n\n                    self._store_group_sar_results(group_sar_stats)\n                    self._store_all_regions_sar(df)\n                    self.extract_peak_sar_details(em_sensor_extractor)\n                    self._store_temporary_data(df, tissue_groups, group_sar_stats)\n                finally:\n                    try:\n                        self.document.AllAlgorithms.Remove(em_sensor_extractor)\n                    except Exception:\n                        pass\n\n            elapsed = self.parent.study.profiler.subtask_times[\"extract_sar_statistics\"][-1]\n        self._log(f\"      - Subtask 'extract_sar_statistics' done in {elapsed:.2f}s\", log_type=\"verbose\")\n        self._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    except Exception as e:\n        self._log(\n            f\"  - ERROR: An unexpected error during all-tissue SAR statistics extraction: {e}\",\n            level=\"progress\",\n            log_type=\"error\",\n        )\n        self.verbose_logger.error(traceback.format_exc())\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.sar_extractor.SarExtractor.extract_peak_sar_details","title":"extract_peak_sar_details","text":"<pre><code>extract_peak_sar_details(em_sensor_extractor: Extractor)\n</code></pre> <p>Extracts detailed metadata about the peak spatial-average SAR location.</p> <p>While the main SAR extraction gives per-tissue statistics, this method provides detailed information about where the absolute peak SAR occurs. This includes 3D coordinates, the tissue/organ containing the peak, mass of the 10g averaging volume, and other metadata.</p> <p>This information is useful for: - Understanding which anatomical region has the highest exposure - Verifying that peak SAR is in an expected location - Debugging unexpected SAR hotspots - Reporting peak exposure location in compliance documentation</p> <p>Uses Sim4Life's AverageSarFieldEvaluator configured for 10g spatial averaging to find the peak location according to IEEE/IEC 62704-1 standards.</p> <p>Parameters:</p> Name Type Description Default <code>em_sensor_extractor</code> <code>Extractor</code> <p>The 'Overall Field' results extractor containing                the SAR field data.</p> required Source code in <code>goliat/extraction/sar_extractor.py</code> <pre><code>def extract_peak_sar_details(self, em_sensor_extractor: \"analysis.Extractor\"):  # type: ignore\n    \"\"\"Extracts detailed metadata about the peak spatial-average SAR location.\n\n    While the main SAR extraction gives per-tissue statistics, this method\n    provides detailed information about where the absolute peak SAR occurs.\n    This includes 3D coordinates, the tissue/organ containing the peak, mass\n    of the 10g averaging volume, and other metadata.\n\n    This information is useful for:\n    - Understanding which anatomical region has the highest exposure\n    - Verifying that peak SAR is in an expected location\n    - Debugging unexpected SAR hotspots\n    - Reporting peak exposure location in compliance documentation\n\n    Uses Sim4Life's AverageSarFieldEvaluator configured for 10g spatial averaging\n    to find the peak location according to IEEE/IEC 62704-1 standards.\n\n    Args:\n        em_sensor_extractor: The 'Overall Field' results extractor containing\n                           the SAR field data.\n    \"\"\"\n    self._log(\"  - Extracting peak SAR details...\", log_type=\"progress\")\n    average_sar_field_evaluator = None\n    try:\n        inputs = [em_sensor_extractor.Outputs[\"SAR(x,y,z,f0)\"]]\n        average_sar_field_evaluator = self.analysis.em_evaluators.AverageSarFieldEvaluator(inputs=inputs)\n        average_sar_field_evaluator.TargetMass = 10.0, self.units.Unit(\"g\")\n        average_sar_field_evaluator.UpdateAttributes()\n        self.document.AllAlgorithms.Add(average_sar_field_evaluator)\n        average_sar_field_evaluator.Update()\n\n        peak_sar_output = average_sar_field_evaluator.Outputs[\"Peak Spatial SAR (psSAR) Results\"]\n        peak_sar_output.Update()  # type: ignore\n\n        data_collection = peak_sar_output.Data.DataSimpleDataCollection  # type: ignore\n\n        # data_collection may be a Sim4Life wrapper around a null JSON object.\n        # The Python truthiness check passes even for null-wrapped objects, so\n        # we must guard the Keys() call with its own try-except.\n        if data_collection is not None:\n            peak_sar_details = {}\n            try:\n                keys = list(data_collection.Keys())\n            except Exception:\n                # Sim4Life returns a null JSON wrapper when SAR is zero\n                # everywhere (e.g. combined field has no energy).\n                keys = []\n                self._log(\n                    \"  - WARNING: Peak SAR data collection is null (SAR may be zero everywhere).\",\n                    log_type=\"warning\",\n                )\n\n            for key in keys:\n                try:\n                    value = data_collection.FieldValue(key, 0)\n                    if value is not None:\n                        peak_sar_details[key] = value\n                except Exception:\n                    pass  # Skip keys that fail to extract\n\n            if peak_sar_details:\n                self.results_data[\"peak_sar_details\"] = peak_sar_details\n            else:\n                self._log(\n                    \"  - WARNING: Peak SAR data collection was empty after filtering None values.\",\n                    log_type=\"warning\",\n                )\n        else:\n            self._log(\n                \"  - WARNING: Could not extract peak SAR details (data collection is None).\",\n                log_type=\"warning\",\n            )\n\n    except Exception as e:\n        self._log(\n            f\"  - ERROR: An exception occurred during peak SAR detail extraction: {e}\",\n            log_type=\"error\",\n        )\n        self.verbose_logger.error(traceback.format_exc())\n    finally:\n        # Always remove the evaluator to avoid accumulating stale algorithms\n        # in AllAlgorithms across candidates (causes cascading state corruption).\n        if average_sar_field_evaluator is not None:\n            try:\n                self.document.AllAlgorithms.Remove(average_sar_field_evaluator)\n            except Exception:\n                pass\n</code></pre>"},{"location":"reference/api_reference/#sensor-extractor","title":"Sensor Extractor","text":""},{"location":"reference/api_reference/#goliat.extraction.sensor_extractor.SensorExtractor","title":"goliat.extraction.sensor_extractor.SensorExtractor","text":"<pre><code>SensorExtractor(parent: ResultsExtractor, results_data: dict)\n</code></pre> <p>Extracts time-domain E-field data from point sensors.</p> <p>Reads E-field measurements from sensors placed at simulation bbox corners, creates plots showing magnitude over time, and stores raw data in results.</p> <p>Parameters:</p> Name Type Description Default <code>parent</code> <code>ResultsExtractor</code> <p>Parent ResultsExtractor instance.</p> required <code>results_data</code> <code>dict</code> <p>Dict to store extracted data.</p> required Source code in <code>goliat/extraction/sensor_extractor.py</code> <pre><code>def __init__(self, parent: \"ResultsExtractor\", results_data: dict):\n    \"\"\"Sets up the sensor extractor.\n\n    Args:\n        parent: Parent ResultsExtractor instance.\n        results_data: Dict to store extracted data.\n    \"\"\"\n    self.parent = parent\n    self.results_data = results_data\n    self.verbose_logger = parent.verbose_logger\n    self.progress_logger = parent.progress_logger\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.sensor_extractor.SensorExtractor-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.sensor_extractor.SensorExtractor.extract_point_sensor_data","title":"extract_point_sensor_data","text":"<pre><code>extract_point_sensor_data(simulation_extractor: Extractor)\n</code></pre> <p>Extracts E-field data from all point sensors and generates plots.</p> <p>Iterates through configured sensors, extracts time-domain E-field components (Ex, Ey, Ez), calculates magnitude, and saves both plot and raw data.</p> <p>Parameters:</p> Name Type Description Default <code>simulation_extractor</code> <code>Extractor</code> <p>Results extractor from the simulation object.</p> required Source code in <code>goliat/extraction/sensor_extractor.py</code> <pre><code>def extract_point_sensor_data(self, simulation_extractor: \"analysis.Extractor\"):  # type: ignore\n    \"\"\"Extracts E-field data from all point sensors and generates plots.\n\n    Iterates through configured sensors, extracts time-domain E-field components\n    (Ex, Ey, Ez), calculates magnitude, and saves both plot and raw data.\n\n    Args:\n        simulation_extractor: Results extractor from the simulation object.\n    \"\"\"\n    self.parent._log(\"    - Extract point sensors...\", level=\"progress\", log_type=\"progress\")\n\n    try:\n        elapsed = 0.0\n        if self.parent.study:\n            with self.parent.study.profiler.subtask(\"extract_point_sensor_data\"):  # type: ignore\n                num_sensors = self.parent.config[\"simulation_parameters.number_of_point_sensors\"] or 0\n                if num_sensors == 0:\n                    return\n\n                plt.ioff()\n                plt.rcParams.update({\"text.usetex\": False})\n                fig, ax = plt.subplots()\n                ax.grid(True, which=\"major\", axis=\"y\", linestyle=\"--\")\n\n                point_source_order = self.parent.config[\"simulation_parameters.point_source_order\"] or []\n                point_sensor_results = {}\n\n                for i in range(num_sensors):  # type: ignore\n                    if i &gt;= len(point_source_order):  # type: ignore\n                        self.parent._log(\n                            f\"    - WARNING: Not enough entries in 'point_source_order' for sensor {i + 1}. Skipping.\",\n                            log_type=\"warning\",\n                        )\n                        continue\n\n                    corner_name = point_source_order[i]  # type: ignore\n                    full_sensor_name = f\"Point Sensor Entity {i + 1} ({corner_name})\"\n\n                    try:\n                        em_sensor_extractor = simulation_extractor[full_sensor_name]\n                        if not em_sensor_extractor:\n                            self.parent._log(\n                                f\"    - WARNING: Could not find sensor extractor for '{full_sensor_name}'\",\n                                log_type=\"warning\",\n                            )\n                            continue\n                    except Exception as e:\n                        self.parent._log(\n                            f\"    - WARNING: Could not retrieve sensor '{full_sensor_name}'. Error: {e}\",\n                            log_type=\"warning\",\n                        )\n                        continue\n\n                    self.parent.document.AllAlgorithms.Add(em_sensor_extractor)\n\n                    if \"EM E(t)\" not in em_sensor_extractor.Outputs:\n                        self.parent._log(\n                            f\"    - WARNING: 'EM E(t)' output not found for sensor '{full_sensor_name}'\",\n                            log_type=\"warning\",\n                        )\n                        self.parent.document.AllAlgorithms.Remove(em_sensor_extractor)\n                        continue\n\n                    em_output = em_sensor_extractor.Outputs[\"EM E(t)\"]\n                    em_output.Update()\n\n                    time_axis = em_output.Data.Axis\n                    ex, ey, ez = (em_output.Data.GetComponent(i) for i in range(3))\n                    label = corner_name.replace(\"_\", \" \").title()\n\n                    if time_axis is not None and time_axis.size &gt; 0:\n                        e_mag = np.sqrt(ex**2 + ey**2 + ez**2)\n                        ax.plot(time_axis, e_mag, label=label)\n                        point_sensor_results[label] = {\n                            \"time_s\": time_axis.tolist(),\n                            \"Ex_V_m\": ex.tolist(),\n                            \"Ey_V_m\": ey.tolist(),\n                            \"Ez_V_m\": ez.tolist(),\n                            \"E_mag_V_m\": e_mag.tolist(),\n                        }\n                    else:\n                        self.parent._log(\n                            f\"    - WARNING: No data found for sensor '{full_sensor_name}'\",\n                            log_type=\"warning\",\n                        )\n\n                    self.parent.document.AllAlgorithms.Remove(em_sensor_extractor)\n\n                if point_sensor_results:\n                    self.results_data[\"point_sensor_data\"] = point_sensor_results\n\n                self._save_plot(fig, ax)\n\n            elapsed = self.parent.study.profiler.subtask_times[\"extract_point_sensor_data\"][-1]\n        self.parent._log(f\"      - Subtask 'extract_point_sensor_data' done in {elapsed:.2f}s\", log_type=\"verbose\")\n        self.parent._log(f\"      - Done in {elapsed:.2f}s\", level=\"progress\", log_type=\"success\")\n\n    except Exception as e:\n        self.parent._log(\n            f\"  - ERROR: An exception occurred during point sensor data extraction: {e}\",\n            level=\"progress\",\n            log_type=\"error\",\n        )\n        self.verbose_logger.error(traceback.format_exc())\n</code></pre>"},{"location":"reference/api_reference/#tissue-grouping","title":"Tissue Grouping","text":""},{"location":"reference/api_reference/#goliat.extraction.tissue_grouping.TissueGrouper","title":"goliat.extraction.tissue_grouping.TissueGrouper","text":"<pre><code>TissueGrouper(config: Config, phantom_name: str, logger: LoggingMixin)\n</code></pre> <p>Handles grouping of tissues into logical categories for SAR analysis.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object for accessing material mappings.</p> required <code>phantom_name</code> <code>str</code> <p>Name of the phantom model.</p> required <code>logger</code> <code>LoggingMixin</code> <p>Logger instance for logging messages.</p> required Source code in <code>goliat/extraction/tissue_grouping.py</code> <pre><code>def __init__(self, config: \"Config\", phantom_name: str, logger: \"LoggingMixin\"):\n    \"\"\"Load material mapping for the given phantom.\n\n    Args:\n        config: Configuration object for accessing material mappings.\n        phantom_name: Name of the phantom model.\n        logger: Logger instance for logging messages.\n    \"\"\"\n    self.config = config\n    self.phantom_name = phantom_name\n    self.logger = logger\n</code></pre>"},{"location":"reference/api_reference/#goliat.extraction.tissue_grouping.TissueGrouper-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.extraction.tissue_grouping.TissueGrouper.group_tissues","title":"group_tissues","text":"<pre><code>group_tissues(available_tissues: list[str]) -&gt; dict[str, list[str]]\n</code></pre> <p>Groups tissues according to material_name_mapping.json.</p> <p>Simple matching: tissue_name -&gt; material_name -&gt; entity_name -&gt; check group.</p> <p>Parameters:</p> Name Type Description Default <code>available_tissues</code> <code>list[str]</code> <p>List of tissue names found in the simulation results.</p> required <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>Dict mapping group names to lists of tissue names that belong to that group.</p> <code>dict[str, list[str]]</code> <p>Empty groups are still included but with empty lists.</p> Source code in <code>goliat/extraction/tissue_grouping.py</code> <pre><code>def group_tissues(self, available_tissues: list[str]) -&gt; dict[str, list[str]]:\n    \"\"\"Groups tissues according to material_name_mapping.json.\n\n    Simple matching: tissue_name -&gt; material_name -&gt; entity_name -&gt; check group.\n\n    Args:\n        available_tissues: List of tissue names found in the simulation results.\n\n    Returns:\n        Dict mapping group names to lists of tissue names that belong to that group.\n        Empty groups are still included but with empty lists.\n    \"\"\"\n    material_mapping = self.config.get_material_mapping(self.phantom_name)\n\n    if \"_tissue_groups\" not in material_mapping:\n        return {}\n\n    return self._group_from_config(material_mapping, available_tissues)\n</code></pre>"},{"location":"reference/api_reference/#analysis","title":"Analysis","text":"<p>Classes for analyzing and visualizing simulation results.</p>"},{"location":"reference/api_reference/#analyze-simulation-stats","title":"Analyze Simulation Stats","text":""},{"location":"reference/api_reference/#goliat.analysis.analyze_simulation_stats","title":"goliat.analysis.analyze_simulation_stats","text":"<p>Analyze Near-Field simulation logs and create professional, client-ready visualizations.</p> <p>IMPROVEMENTS: - Strict filtering for Near Field simulations only. - Emojis removed to prevent font rendering errors. - \"High-End Engineering\" aesthetic (professional dark theme). - Dynamic layout scaling for lists with many items. - Robust text placement to avoid overlap.</p>"},{"location":"reference/api_reference/#goliat.analysis.analyze_simulation_stats-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.analyze_simulation_stats.find_all_verbose_logs","title":"find_all_verbose_logs","text":"<pre><code>find_all_verbose_logs(results_dir: str | Path) -&gt; list[Path]\n</code></pre> <p>Find all verbose.log files in the results directory.</p> Source code in <code>goliat/analysis/analyze_simulation_stats.py</code> <pre><code>def find_all_verbose_logs(results_dir: str | Path) -&gt; list[Path]:\n    \"\"\"Find all verbose.log files in the results directory.\"\"\"\n    results_dir = Path(results_dir)\n    return list(results_dir.rglob(\"verbose.log\"))\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.analyze_simulation_stats.parse_all_logs","title":"parse_all_logs","text":"<pre><code>parse_all_logs(log_files: list[Path], verbose: bool = True) -&gt; list[dict]\n</code></pre> <p>Parse all verbose.log files and return list of metrics.</p> Source code in <code>goliat/analysis/analyze_simulation_stats.py</code> <pre><code>def parse_all_logs(log_files: list[Path], verbose: bool = True) -&gt; list[dict]:\n    \"\"\"Parse all verbose.log files and return list of metrics.\"\"\"\n    all_metrics = []\n\n    for i, log_file in enumerate(log_files):\n        # STRICT FILTER: Only Near Field\n        if \"near_field\" not in log_file.parts:\n            continue\n\n        if verbose and i % 50 == 0:\n            logging.getLogger(\"progress\").info(f\"  Parsing: {i + 1}/{len(log_files)}...\", extra={\"log_type\": \"verbose\"})\n\n        try:\n            metrics = parse_verbose_log(log_file)\n\n            # Robust category extraction\n            parts = log_file.parts\n            category = {\"study_type\": \"near_field\", \"phantom\": \"unknown\", \"frequency\": \"unknown\", \"placement\": \"unknown\"}\n\n            try:\n                # Assuming structure: .../near_field/phantom/freq/placement/verbose.log\n                nf_index = parts.index(\"near_field\")\n                if nf_index + 3 &lt; len(parts):\n                    category[\"phantom\"] = parts[nf_index + 1]\n                    category[\"frequency\"] = parts[nf_index + 2]\n                    category[\"placement\"] = parts[nf_index + 3]\n            except ValueError:\n                pass\n\n            metrics[\"category\"] = category\n            all_metrics.append(metrics)\n\n        except Exception:\n            if verbose:\n                # print(f\"  Error parsing {log_file}: {e}\")\n                pass\n\n    if verbose:\n        logging.getLogger(\"progress\").info(f\"  Parsed {len(all_metrics)} Near-Field log files.\", extra={\"log_type\": \"progress\"})\n\n    return all_metrics\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.analyze_simulation_stats.compute_aggregate_stats","title":"compute_aggregate_stats","text":"<pre><code>compute_aggregate_stats(all_metrics: list[dict]) -&gt; dict\n</code></pre> <p>Compute aggregate statistics across all simulations.</p> Source code in <code>goliat/analysis/analyze_simulation_stats.py</code> <pre><code>def compute_aggregate_stats(all_metrics: list[dict]) -&gt; dict:\n    \"\"\"Compute aggregate statistics across all simulations.\"\"\"\n    stats = {\n        \"total_simulations\": len(all_metrics),\n        \"total_cells\": 0,\n        \"total_cells_with_pml\": 0,\n        \"total_edges\": 0,\n        \"total_iterations\": 0,\n        \"total_cell_iterations\": 0,\n        \"total_runtime_s\": 0,\n        \"total_materials\": [],  # Changed to list for JSON serialization\n        \"total_tissues\": [],  # Changed to list for JSON serialization\n        \"by_phantom\": defaultdict(lambda: {\"count\": 0, \"cells\": 0, \"iterations\": 0, \"cell_iterations\": 0, \"runtime_s\": 0}),\n        \"by_frequency\": defaultdict(lambda: {\"count\": 0, \"cells\": 0, \"iterations\": 0, \"cell_iterations\": 0, \"runtime_s\": 0}),\n        \"by_placement\": defaultdict(lambda: {\"count\": 0, \"cells\": 0, \"iterations\": 0, \"cell_iterations\": 0, \"runtime_s\": 0}),\n        \"iterations_list\": [],\n        \"cells_list\": [],\n        \"runtime_list\": [],\n        \"cell_iterations_list\": [],\n        \"peak_speed_list\": [],  # Peak MCells/s per simulation\n        \"avg_speed_list\": [],  # Avg MCells/s per simulation\n    }\n\n    unique_tissues = set()\n\n    for m in all_metrics:\n        # Extract values\n        cells = m.get(\"grid\", {}).get(\"total_cells_with_pml\", 0)\n        iterations = m.get(\"solver\", {}).get(\"iterations\", 0)\n        runtime = m.get(\"timing\", {}).get(\"total_wall_clock_s\", 0)\n        edges = m.get(\"edges\", {}).get(\"total_edges\", 0)\n        cell_iterations = cells * iterations if cells and iterations else 0\n\n        # Aggregate totals\n        stats[\"total_cells_with_pml\"] += cells\n        stats[\"total_cells\"] += m.get(\"grid\", {}).get(\"total_cells\", 0)\n        stats[\"total_edges\"] += edges\n        stats[\"total_iterations\"] += iterations\n        stats[\"total_cell_iterations\"] += cell_iterations\n        stats[\"total_runtime_s\"] += runtime\n\n        # Track materials/tissues\n        for tissue in m.get(\"materials\", {}).get(\"tissues\", []):\n            unique_tissues.add(tissue.get(\"name\", \"\"))\n\n        # Lists for distributions\n        stats[\"iterations_list\"].append(iterations)\n        stats[\"cells_list\"].append(cells)\n        stats[\"runtime_list\"].append(runtime)\n        stats[\"cell_iterations_list\"].append(cell_iterations)\n\n        # Speed metrics from summary\n        summary = m.get(\"summary\", {})\n        if summary.get(\"peak_mcells_per_s\"):\n            stats[\"peak_speed_list\"].append(summary[\"peak_mcells_per_s\"])\n        if summary.get(\"avg_mcells_per_s\"):\n            stats[\"avg_speed_list\"].append(summary[\"avg_mcells_per_s\"])\n\n        # By category\n        cat = m.get(\"category\", {})\n\n        if cat.get(\"phantom\"):\n            p = stats[\"by_phantom\"][cat[\"phantom\"]]\n            p[\"count\"] += 1\n            p[\"cells\"] += cells\n            p[\"iterations\"] += iterations\n            p[\"cell_iterations\"] += cell_iterations\n            p[\"runtime_s\"] += runtime\n\n        if cat.get(\"frequency\"):\n            freq = cat[\"frequency\"]\n            f = stats[\"by_frequency\"][freq]\n            f[\"count\"] += 1\n            f[\"cells\"] += cells\n            f[\"iterations\"] += iterations\n            f[\"cell_iterations\"] += cell_iterations\n            f[\"runtime_s\"] += runtime\n\n        if cat.get(\"placement\"):\n            # Group by placement type more cleanly\n            placement = cat[\"placement\"]\n            pl = stats[\"by_placement\"][placement]\n            pl[\"count\"] += 1\n            pl[\"cells\"] += cells\n            pl[\"iterations\"] += iterations\n            pl[\"cell_iterations\"] += cell_iterations\n            pl[\"runtime_s\"] += runtime\n\n    stats[\"unique_tissue_count\"] = len(unique_tissues)\n    stats[\"total_tissues\"] = list(unique_tissues)\n\n    # Convert defaultdicts to simple dicts\n    stats[\"by_phantom\"] = {k: dict(v) for k, v in stats[\"by_phantom\"].items()}\n    stats[\"by_frequency\"] = {k: dict(v) for k, v in stats[\"by_frequency\"].items()}\n    stats[\"by_placement\"] = {k: dict(v) for k, v in stats[\"by_placement\"].items()}\n\n    return stats\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.analyze_simulation_stats.format_large_number","title":"format_large_number","text":"<pre><code>format_large_number(n: float, precision: int = 1) -&gt; str\n</code></pre> <p>Format large numbers with K/M/B suffixes.</p> Source code in <code>goliat/analysis/analyze_simulation_stats.py</code> <pre><code>def format_large_number(n: float, precision: int = 1) -&gt; str:\n    \"\"\"Format large numbers with K/M/B suffixes.\"\"\"\n    if n &gt;= 1e15:\n        return f\"{n / 1e15:.{precision}f} Quadrillion\"\n    elif n &gt;= 1e12:\n        return f\"{n / 1e12:.{precision}f} Trillion\"\n    elif n &gt;= 1e9:\n        return f\"{n / 1e9:.{precision}f} Billion\"\n    elif n &gt;= 1e6:\n        return f\"{n / 1e6:.{precision}f} Million\"\n    elif n &gt;= 1e3:\n        return f\"{n / 1e3:.{precision}f} K\"\n    else:\n        return f\"{n:.{precision}f}\"\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.analyze_simulation_stats.set_custom_style","title":"set_custom_style","text":"<pre><code>set_custom_style()\n</code></pre> <p>Set a professional, high-contrast engineering dark style.</p> Source code in <code>goliat/analysis/analyze_simulation_stats.py</code> <pre><code>def set_custom_style():\n    \"\"\"Set a professional, high-contrast engineering dark style.\"\"\"\n    plt.style.use(\"seaborn-v0_8-darkgrid\")\n\n    # Colors suitable for \"Engineering/Simulation\" look (Deep Blues, Bright Cyans, Warm Accents)\n    bg_color = \"#0e1117\"\n    paper_color = \"#0e1117\"\n    text_color = \"#e0e0e0\"  # Softer white\n    grid_color = \"#262730\"\n\n    # Updated Palette - Less aggressive, more \"Scientific\"\n    primary_blue = \"#2E86C1\"  # Strong, professional blue\n    cyan_bright = \"#00BFA5\"  # Teal/Cyan for distinction\n    alert_orange = \"#FF7043\"  # Softer than red, for highlights\n    soft_purple = \"#9b59b6\"\n    slate_grey = \"#607D8B\"\n    gold_accent = \"#F1C40F\"\n\n    plt.rcParams.update(\n        {\n            \"figure.facecolor\": paper_color,\n            \"axes.facecolor\": bg_color,\n            \"axes.edgecolor\": grid_color,\n            \"axes.labelcolor\": text_color,\n            \"text.color\": text_color,\n            \"xtick.color\": text_color,\n            \"ytick.color\": text_color,\n            \"grid.color\": grid_color,\n            \"grid.alpha\": 0.6,\n            \"figure.figsize\": (12, 7),\n            \"font.size\": 12,\n            \"axes.labelsize\": 13,\n            \"axes.titlesize\": 16,\n            \"xtick.labelsize\": 11,\n            \"ytick.labelsize\": 11,\n            \"font.family\": \"sans-serif\",  # Ensure standard font\n        }\n    )\n\n    return [primary_blue, cyan_bright, alert_orange, soft_purple, slate_grey, gold_accent]\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.analyze_simulation_stats.create_visualizations","title":"create_visualizations","text":"<pre><code>create_visualizations(stats: dict, output_dir: str | Path)\n</code></pre> <p>Create all visualizations with rigorous layout checks.</p> Source code in <code>goliat/analysis/analyze_simulation_stats.py</code> <pre><code>def create_visualizations(stats: dict, output_dir: str | Path):\n    \"\"\"Create all visualizations with rigorous layout checks.\"\"\"\n    output_dir = Path(output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    colors = set_custom_style()\n\n    # 01. COMPUTATIONAL SCALE\n    fig, ax = plt.subplots(figsize=(14, 8))\n\n    labels = [\"Cells Computed\", \"Edges Computed\", \"Grid Cells (PML)\", \"Time Steps\"]\n    values = [stats[\"total_cell_iterations\"], stats[\"total_edges\"], stats[\"total_cells_with_pml\"], stats[\"total_iterations\"]]\n\n    y_pos = np.arange(len(labels))\n    # Use the blue/teal/purple palette\n    bar_colors = [colors[2], colors[0], colors[1], colors[5]]\n\n    ax.barh(y_pos, values, color=bar_colors, height=0.6, alpha=0.9)\n\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels(labels, fontweight=\"bold\")\n    ax.set_xscale(\"log\")\n    ax.set_title(f\"Simulation Campaign Scale ({stats['total_simulations']} Runs)\", pad=20, fontweight=\"bold\")\n    ax.set_xlabel(\"Count (Log Scale)\")\n    ax.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n\n    # Text labels placed strictly outside for readability\n    for i, v in enumerate(values):\n        ax.text(v * 1.5, i, f\" {format_large_number(v, 2)}\", va=\"center\", fontweight=\"bold\", color=\"white\")\n\n    ax.set_xlim(right=max(values) * 50)\n\n    plt.tight_layout()\n    fig.savefig(output_dir / \"01_computational_scale.png\", dpi=200, bbox_inches=\"tight\")\n    plt.close(fig)\n\n    # 02. DETAILED PLACEMENT ANALYSIS\n    placements = sorted(stats[\"by_placement\"].keys())\n    # Clean names\n    display_names = [p.replace(\"by_\", \"\").replace(\"front_of_\", \"\").replace(\"_\", \" \").title() for p in placements]\n    values = [stats[\"by_placement\"][p][\"cell_iterations\"] for p in placements]\n\n    # Sort\n    if values:\n        sorted_pack = sorted(zip(values, display_names), reverse=False)\n        values = [x[0] for x in sorted_pack]\n        display_names = [x[1] for x in sorted_pack]\n\n    dynamic_height = max(8, len(values) * 0.4)\n    fig, ax = plt.subplots(figsize=(14, dynamic_height))\n\n    # Main bars in primary blue\n    ax.barh(range(len(values)), values, color=colors[0], alpha=0.85)\n\n    ax.set_yticks(range(len(values)))\n    ax.set_yticklabels(display_names)\n    ax.set_xlabel(\"Computational Cost (Cells Computed)\")\n    ax.set_title(\"Computational Load by Antenna Placement\", pad=20, fontweight=\"bold\")\n    ax.grid(True, axis=\"x\", alpha=0.3)\n\n    max_val = max(values) if values else 1\n    for i, v in enumerate(values):\n        label_text = f\"{format_large_number(v)}\"\n        if v &gt; max_val * 0.2:\n            ax.text(v - (max_val * 0.02), i, label_text, va=\"center\", ha=\"right\", color=\"white\", fontweight=\"bold\")\n        else:\n            ax.text(v + (max_val * 0.01), i, label_text, va=\"center\", ha=\"left\", color=\"#dddddd\", fontweight=\"bold\")\n\n    plt.tight_layout()\n    fig.savefig(output_dir / \"02_placement_cost.png\", dpi=200, bbox_inches=\"tight\")\n    plt.close(fig)\n\n    # 03. PHANTOM &amp; FREQUENCY\n    phantom_list = sorted(stats[\"by_phantom\"].keys())\n\n    # Filter out Duke if it somehow snuck in with 0 stats, but keep if real\n    # Only keep phantoms with &gt; 0 cell iterations to be safe\n    phantom_list = [p for p in phantom_list if stats[\"by_phantom\"][p][\"cell_iterations\"] &gt; 0]\n\n    freq_list = sorted(stats[\"by_frequency\"].keys(), key=lambda x: int(m.group()) if (m := re.search(r\"\\d+\", x)) else 0)\n\n    fig = plt.figure(figsize=(16, 8))\n    gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1], wspace=0.3)\n\n    # Phantoms\n    ax0 = plt.subplot(gs[0])\n    p_values = [stats[\"by_phantom\"][p][\"cell_iterations\"] for p in phantom_list]\n\n    # Nice bar colors\n    ax0.bar(phantom_list, p_values, color=colors[3], alpha=0.9)\n    ax0.set_title(\"Load by Phantom\", fontweight=\"bold\")\n    ax0.set_ylabel(\"Cells Computed\")\n    ax0.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f\"{x / 1e12:.0f}T\"))\n    ax0.grid(True, axis=\"y\", alpha=0.3)\n\n    # Value labels\n    for i, v in enumerate(p_values):\n        ax0.text(i, v, f\"{v / 1e12:.1f}T\", ha=\"center\", va=\"bottom\", fontweight=\"bold\", color=\"white\")\n\n    # Frequencies\n    ax1 = plt.subplot(gs[1])\n    f_values = [stats[\"by_frequency\"][f][\"cell_iterations\"] for f in freq_list]\n    ax1.bar(freq_list, f_values, color=colors[1], alpha=0.9)\n    ax1.set_title(\"Load by Frequency\", fontweight=\"bold\")\n    ax1.tick_params(axis=\"x\", rotation=45)\n    ax1.grid(True, axis=\"y\", alpha=0.3)\n\n    plt.tight_layout()\n    fig.savefig(output_dir / \"03_phantom_freq_breakdown.png\", dpi=200, bbox_inches=\"tight\")\n    plt.close(fig)\n\n    # 04. CLIENT INFOGRAPHIC (Enhanced)\n    fig = plt.figure(figsize=(18, 10))\n    fig.patch.set_facecolor(\"#0e1117\")\n\n    # Compute additional metrics\n    peak_speed_gcells_s = max(stats[\"peak_speed_list\"]) / 1000 if stats[\"peak_speed_list\"] else 0\n    avg_runtime_min = (stats[\"total_runtime_s\"] / stats[\"total_simulations\"]) / 60 if stats[\"total_simulations\"] &gt; 0 else 0\n    num_placements = len(stats[\"by_placement\"])\n\n    # Get frequency range\n    freq_list_sorted = sorted(stats[\"by_frequency\"].keys(), key=lambda x: int(m.group()) if (m := re.search(r\"\\d+\", x)) else 0)\n    if freq_list_sorted:\n        freq_range = f\"{freq_list_sorted[0]} - {freq_list_sorted[-1]}\"\n    else:\n        freq_range = \"N/A\"\n\n    # Title Area\n    gs = gridspec.GridSpec(5, 4, height_ratios=[0.15, 0.28, 0.28, 0.28, 0.08], hspace=0.15)\n    ax_title = plt.subplot(gs[0, :])\n    ax_title.axis(\"off\")\n    ax_title.text(0.5, 0.5, \"NEAR FIELD COMPUTATIONAL CAMPAIGN\", ha=\"center\", va=\"center\", fontsize=30, color=colors[1], fontweight=\"bold\")\n\n    # Row 1: Hero Stats (Large)\n    hero_stats = [\n        (\"TOTAL RUNS\", f\"{stats['total_simulations']}\", colors[0]),\n        (\"CELLS COMPUTED\", f\"{stats['total_cell_iterations'] / 1e15:.2f} Quadrillion\", colors[2]),\n        (\"COMPUTE TIME\", f\"{stats['total_runtime_s'] / 3600:.0f} Hours\", colors[1]),\n        (\"PEAK SPEED\", f\"{peak_speed_gcells_s:.1f} GCells/s\", colors[5]),\n    ]\n\n    for i, (k, v, c) in enumerate(hero_stats):\n        ax = plt.subplot(gs[1, i])\n        ax.axis(\"off\")\n        ax.text(0.5, 0.6, v, ha=\"center\", va=\"center\", fontsize=24, fontweight=\"bold\", color=c)\n        ax.text(0.5, 0.3, k, ha=\"center\", va=\"center\", fontsize=11, fontweight=\"bold\", color=\"#aaaaaa\")\n\n    # Row 2: Grid &amp; Data Stats\n    row2_stats = [\n        (\"Grid Cells\", f\"{stats['total_cells_with_pml'] / 1e9:.1f} Billion\", \"#ffffff\"),\n        (\"Data Edges\", f\"{stats['total_edges'] / 1e9:.1f} Billion\", \"#ffffff\"),\n        (\"Time Steps\", f\"{stats['total_iterations'] / 1e6:.1f} Million\", \"#ffffff\"),\n        (\"Avg Sim Time\", f\"{avg_runtime_min:.1f} min\", \"#ffffff\"),\n    ]\n\n    for i, (k, v, c) in enumerate(row2_stats):\n        ax = plt.subplot(gs[2, i])\n        ax.axis(\"off\")\n        rect = plt.Rectangle((0.1, 0.15), 0.8, 0.7, transform=ax.transAxes, fill=True, color=\"#1e222b\", zorder=0, alpha=0.8, lw=0)\n        ax.add_patch(rect)\n        ax.text(0.5, 0.6, v, ha=\"center\", va=\"center\", fontsize=18, fontweight=\"bold\", color=c)\n        ax.text(0.5, 0.35, k, ha=\"center\", va=\"center\", fontsize=11, color=\"#888888\")\n\n    # Row 3: Study Configuration\n    row3_stats = [\n        (\"Anatomical Models\", f\"{len(phantom_list)}\", \"#ffffff\"),\n        (\"Frequency Range\", freq_range, \"#ffffff\"),\n        (\"Antenna Placements\", f\"{num_placements}\", \"#ffffff\"),\n        (\"Tissues Modeled\", f\"{stats['unique_tissue_count']}\", \"#ffffff\"),\n    ]\n\n    for i, (k, v, c) in enumerate(row3_stats):\n        ax = plt.subplot(gs[3, i])\n        ax.axis(\"off\")\n        rect = plt.Rectangle((0.1, 0.15), 0.8, 0.7, transform=ax.transAxes, fill=True, color=\"#1e222b\", zorder=0, alpha=0.8, lw=0)\n        ax.add_patch(rect)\n        ax.text(0.5, 0.6, v, ha=\"center\", va=\"center\", fontsize=18, fontweight=\"bold\", color=c)\n        ax.text(0.5, 0.35, k, ha=\"center\", va=\"center\", fontsize=11, color=\"#888888\")\n\n    # Footer\n    ax_foot = plt.subplot(gs[4, :])\n    ax_foot.axis(\"off\")\n    ax_foot.text(\n        0.5,\n        0.5,\n        f\"Generated: {datetime.now().strftime('%Y-%m-%d')} | GOLIAT Solver Analysis\",\n        ha=\"center\",\n        va=\"center\",\n        fontsize=10,\n        color=\"#666666\",\n    )\n\n    plt.tight_layout()\n    fig.savefig(output_dir / \"00_summary_infographic.png\", dpi=200, bbox_inches=\"tight\")\n    plt.close(fig)\n\n    # 04. RUNTIME DISTRIBUTION (Restored)\n    if stats[\"runtime_list\"]:\n        fig, ax = plt.subplots(figsize=(14, 7))\n        # Convert to minutes\n        runtimes_min = [r / 60 for r in stats[\"runtime_list\"]]\n\n        ax.hist(runtimes_min, bins=30, color=colors[3], alpha=0.7, edgecolor=colors[3])\n        ax.set_title(\"Simulation Runtime Distribution\", pad=20, fontweight=\"bold\")\n        ax.set_xlabel(\"Runtime (Minutes)\")\n        ax.set_ylabel(\"Number of Simulations\")\n\n        # Add a text box with stats\n        avg_runtime = np.mean(runtimes_min)\n        total_hours = sum(runtimes_min) / 60\n        stats_text = f\"Total Time: {total_hours:.1f} Hours\\nAvg Runtime: {avg_runtime:.1f} min\\nMax Runtime: {max(runtimes_min):.1f} min\"\n\n        ax.text(\n            0.95,\n            0.95,\n            stats_text,\n            transform=ax.transAxes,\n            verticalalignment=\"top\",\n            horizontalalignment=\"right\",\n            bbox=dict(boxstyle=\"round\", facecolor=\"#1e222b\", alpha=0.8, edgecolor=colors[4]),\n            color=\"white\",\n            fontsize=12,\n        )\n\n        ax.grid(True, axis=\"y\", alpha=0.3)\n        plt.tight_layout()\n        fig.savefig(output_dir / \"04_runtime_distribution.png\", dpi=200, bbox_inches=\"tight\")\n        plt.close(fig)\n\n    # 05. SCATTER PLOT: GRID SIZE vs RUNTIME\n    if stats[\"cells_list\"] and stats[\"runtime_list\"]:\n        fig, ax = plt.subplots(figsize=(14, 8))\n\n        cells_m = [c / 1e6 for c in stats[\"cells_list\"]]\n        # Convert seconds to minutes\n        runtimes_min = [r / 60 for r in stats[\"runtime_list\"]]\n\n        # Scatter with alpha to show density\n        ax.scatter(cells_m, runtimes_min, c=colors[1], alpha=0.6, s=80, edgecolors=\"none\")\n\n        ax.set_title(\"Solver Performance: Grid Size vs Compute Time\", pad=20, fontweight=\"bold\")\n        ax.set_xlabel(\"Grid Size (Million Cells)\")\n        ax.set_ylabel(\"Compute Time (Minutes)\")\n        ax.set_xlim(left=0)\n        ax.set_ylim(bottom=0)\n        ax.grid(True, alpha=0.3)\n\n        # Add correlation text\n        if len(cells_m) &gt; 1:\n            try:\n                corr = np.corrcoef(cells_m, runtimes_min)[0, 1]\n                ax.text(\n                    0.05,\n                    0.95,\n                    f\"Correlation: {corr:.3f}\",\n                    transform=ax.transAxes,\n                    bbox=dict(boxstyle=\"round\", facecolor=\"#1e222b\", alpha=0.8),\n                    color=\"white\",\n                )\n            except Exception:\n                pass\n\n        plt.tight_layout()\n        fig.savefig(output_dir / \"05_solver_scaling.png\", dpi=200, bbox_inches=\"tight\")\n        plt.close(fig)\n\n    # 06. SPEED DISTRIBUTION PLOT\n    if stats[\"peak_speed_list\"]:\n        fig, ax = plt.subplots(figsize=(14, 7))\n\n        # Convert to GCells/s for readability\n        peak_speeds_gcells = [s / 1000 for s in stats[\"peak_speed_list\"]]\n\n        # Histogram of Peak Speeds\n        ax.hist(peak_speeds_gcells, bins=25, color=colors[2], alpha=0.8, edgecolor=colors[2])\n        ax.set_title(\"Solver Speed Distribution\", pad=15, fontweight=\"bold\")\n        ax.set_xlabel(\"Peak Speed (GCells/s)\")\n        ax.set_ylabel(\"Number of Simulations\")\n        ax.grid(True, axis=\"y\", alpha=0.3)\n\n        # Add stats annotation\n        max_speed = max(peak_speeds_gcells)\n        avg_peak = np.mean(peak_speeds_gcells)\n        stats_text = (\n            f\"Fastest: {max_speed:.2f} GCells/s\\nAvg Peak: {avg_peak:.2f} GCells/s\\nMin Peak: {min(peak_speeds_gcells):.2f} GCells/s\"\n        )\n        ax.axvline(max_speed, color=colors[5], linestyle=\"--\", linewidth=2, label=f\"Fastest: {max_speed:.2f}\")\n        ax.text(\n            0.95,\n            0.95,\n            stats_text,\n            transform=ax.transAxes,\n            verticalalignment=\"top\",\n            horizontalalignment=\"right\",\n            bbox=dict(boxstyle=\"round\", facecolor=\"#1e222b\", alpha=0.9, edgecolor=colors[5]),\n            color=\"white\",\n            fontsize=11,\n        )\n\n        plt.tight_layout()\n        fig.savefig(output_dir / \"06_speed_distribution.png\", dpi=200, bbox_inches=\"tight\")\n        plt.close(fig)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.analyze_simulation_stats.main","title":"main","text":"<pre><code>main()\n</code></pre> <p>CLI entry point. Parses logs and generates stats/plots.</p> Source code in <code>goliat/analysis/analyze_simulation_stats.py</code> <pre><code>def main():\n    \"\"\"CLI entry point. Parses logs and generates stats/plots.\"\"\"\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"results_dir\", nargs=\"?\", default=\"results\")\n    parser.add_argument(\"-o\", \"--output\", default=\"paper/simulation_stats\")\n    parser.add_argument(\"--json\", action=\"store_true\")\n    args = parser.parse_args()\n\n    log_files = find_all_verbose_logs(args.results_dir)\n    all_metrics = parse_all_logs(log_files)\n\n    if not all_metrics:\n        logging.getLogger(\"progress\").warning(\"  No Near-Field logs found.\", extra={\"log_type\": \"warning\"})\n        return\n\n    stats = compute_aggregate_stats(all_metrics)\n\n    logging.getLogger(\"progress\").info(f\"  Total Simulations: {stats['total_simulations']}\", extra={\"log_type\": \"info\"})\n    logging.getLogger(\"progress\").info(\n        f\"  Total Cell-Iterations: {format_large_number(stats['total_cell_iterations'])}\", extra={\"log_type\": \"info\"}\n    )\n\n    create_visualizations(stats, args.output)\n\n    if args.json:\n        json_path = Path(args.output) / \"nf_stats.json\"\n        # We need to filter out the large lists before dumping\n        json_stats = stats.copy()\n        json_stats[\"iterations_list\"] = []\n        json_stats[\"cells_list\"] = []\n        json_stats[\"runtime_list\"] = []\n        json_stats[\"cell_iterations_list\"] = []\n        json_stats[\"peak_speed_list\"] = []\n        json_stats[\"avg_speed_list\"] = []\n\n        with open(json_path, \"w\") as f:\n            json.dump(json_stats, f, indent=2)\n\n    logging.getLogger(\"progress\").info(f\"  Saved visualizations to: {args.output}/\", extra={\"log_type\": \"success\"})\n</code></pre>"},{"location":"reference/api_reference/#analyzer","title":"Analyzer","text":""},{"location":"reference/api_reference/#goliat.analysis.analyzer.Analyzer","title":"goliat.analysis.analyzer.Analyzer","text":"<pre><code>Analyzer(config: Config, phantom_name: str, strategy: BaseAnalysisStrategy, plot_format: str = 'pdf')\n</code></pre> <p>Analyzes simulation results using a strategy pattern.</p> <p>Delegates to strategy-specific implementations for loading results and generating plots. Handles unit conversion, caching, and report export.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required <code>phantom_name</code> <code>str</code> <p>Phantom model name being analyzed.</p> required <code>strategy</code> <code>BaseAnalysisStrategy</code> <p>Strategy implementation for analysis logic.</p> required <code>plot_format</code> <code>str</code> <p>Output format for plots ('pdf' or 'png'), default 'pdf'.</p> <code>'pdf'</code> Source code in <code>goliat/analysis/analyzer.py</code> <pre><code>def __init__(self, config: \"Config\", phantom_name: str, strategy: \"BaseAnalysisStrategy\", plot_format: str = \"pdf\"):\n    \"\"\"Sets up the analyzer with a strategy.\n\n    Args:\n        config: Configuration object.\n        phantom_name: Phantom model name being analyzed.\n        strategy: Strategy implementation for analysis logic.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.config = config\n    self.base_dir = config.base_dir\n    self.phantom_name = phantom_name\n    self.strategy = strategy\n    self.results_base_dir = self.strategy.get_results_base_dir()\n    self.plotter = Plotter(self.strategy.get_plots_dir(), phantom_name=self.phantom_name, plot_format=plot_format)\n    self.all_results = []\n    self.all_organ_results = []\n    # Will be populated from pickle files - contains actual tissue names from extraction\n    # This is the authoritative source, computed during extraction using material_name_mapping.json\n    self.tissue_group_composition = {}\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.analyzer.Analyzer-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.analyzer.Analyzer.run_analysis","title":"run_analysis","text":"<pre><code>run_analysis()\n</code></pre> <p>Runs complete analysis pipeline using the selected strategy.</p> <p>Loads results, converts units, exports reports, and generates plots. Delegates strategy-specific logic to the strategy instance.</p> Source code in <code>goliat/analysis/analyzer.py</code> <pre><code>def run_analysis(self):\n    \"\"\"Runs complete analysis pipeline using the selected strategy.\n\n    Loads results, converts units, exports reports, and generates plots.\n    Delegates strategy-specific logic to the strategy instance.\n    \"\"\"\n    logging.getLogger(\"progress\").info(\n        f\"--- Starting Results Analysis for Phantom: {self.phantom_name} ---\",\n        extra={\"log_type\": \"header\"},\n    )\n\n    # Check if we should load data or use cache instead\n    load_data = self.strategy.analysis_config.get(\"load_data\", True)\n\n    if not load_data:\n        logging.getLogger(\"progress\").info(\n            \"--- Skipping data loading phase, loading from cache ---\",\n            extra={\"log_type\": \"info\"},\n        )\n        results_df, all_organ_results_df = self._load_from_cache()\n        if results_df is None:\n            logging.getLogger(\"progress\").error(\n                \"--- Failed to load cached results. Run analysis with load_data=True first. ---\",\n                extra={\"log_type\": \"error\"},\n            )\n            return\n    else:\n        self.strategy.load_and_process_results(self)\n\n        if not self.all_results:\n            logging.getLogger(\"progress\").info(\"--- No results found to analyze. ---\", extra={\"log_type\": \"warning\"})\n            return\n\n        results_df = pd.DataFrame(self.all_results)\n        all_organ_results_df = pd.DataFrame(self.all_organ_results) if self.all_organ_results else pd.DataFrame()\n\n        results_df = self._convert_units_and_cache(results_df, all_organ_results_df)\n        self._export_reports(results_df, all_organ_results_df)\n\n    self.strategy.generate_plots(self, self.plotter, results_df, all_organ_results_df)\n\n    logging.getLogger(\"progress\").info(\"--- Analysis Finished ---\", extra={\"log_type\": \"success\"})\n</code></pre>"},{"location":"reference/api_reference/#base-strategy","title":"Base Strategy","text":""},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy","title":"goliat.analysis.base_strategy.BaseAnalysisStrategy","text":"<pre><code>BaseAnalysisStrategy(config: Config, phantom_name: str, analysis_config: dict | None = None)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for analysis strategies.</p> <p>Defines interface for loading results, calculating normalization factors, and generating plots. Subclasses implement study-type specific logic.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required <code>phantom_name</code> <code>str</code> <p>Phantom model name being analyzed.</p> required <code>analysis_config</code> <code>dict | None</code> <p>Optional dictionary with plot names as keys and boolean values.</p> <code>None</code> Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>def __init__(self, config: \"Config\", phantom_name: str, analysis_config: dict | None = None):\n    \"\"\"Sets up the analysis strategy.\n\n    Args:\n        config: Configuration object.\n        phantom_name: Phantom model name being analyzed.\n        analysis_config: Optional dictionary with plot names as keys and boolean values.\n    \"\"\"\n    self.config = config\n    self.phantom_name = phantom_name\n    self.base_dir = config.base_dir\n    self.analysis_config = analysis_config or {}\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy.should_generate_plot","title":"should_generate_plot","text":"<pre><code>should_generate_plot(plot_name: str) -&gt; bool\n</code></pre> <p>Checks if a plot should be generated based on the analysis config.</p> <p>Parameters:</p> Name Type Description Default <code>plot_name</code> <code>str</code> <p>Name of the plot to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the plot should be generated (default if not in config), False otherwise.</p> Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>def should_generate_plot(self, plot_name: str) -&gt; bool:\n    \"\"\"Checks if a plot should be generated based on the analysis config.\n\n    Args:\n        plot_name: Name of the plot to check.\n\n    Returns:\n        True if the plot should be generated (default if not in config), False otherwise.\n    \"\"\"\n    if not self.analysis_config:\n        return True  # Generate all plots if no config provided\n    return self.analysis_config.get(plot_name, True)  # Default to True if not specified\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy.get_expected_item_count","title":"get_expected_item_count","text":"<pre><code>get_expected_item_count() -&gt; int\n</code></pre> <p>Returns expected number of progress items for this phantom.</p> <p>This is used by the GUI to set an accurate progress bar maximum. Each item corresponds to one progress log message (Processing, Generating plot, etc.).</p> <p>Returns:</p> Type Description <code>int</code> <p>Expected number of items that will trigger progress updates.</p> Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>def get_expected_item_count(self) -&gt; int:\n    \"\"\"Returns expected number of progress items for this phantom.\n\n    This is used by the GUI to set an accurate progress bar maximum.\n    Each item corresponds to one progress log message (Processing, Generating plot, etc.).\n\n    Returns:\n        Expected number of items that will trigger progress updates.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement get_expected_item_count()\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy.get_results_base_dir","title":"get_results_base_dir","text":"<pre><code>get_results_base_dir() -&gt; str\n</code></pre> <p>Returns base directory path for results. Must be implemented by subclasses.</p> Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>def get_results_base_dir(self) -&gt; str:\n    \"\"\"Returns base directory path for results. Must be implemented by subclasses.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy.get_plots_dir","title":"get_plots_dir","text":"<pre><code>get_plots_dir() -&gt; str\n</code></pre> <p>Returns directory path for saving plots. Must be implemented by subclasses.</p> Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>def get_plots_dir(self) -&gt; str:\n    \"\"\"Returns directory path for saving plots. Must be implemented by subclasses.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy.load_and_process_results","title":"load_and_process_results  <code>abstractmethod</code>","text":"<pre><code>load_and_process_results(analyzer: Analyzer)\n</code></pre> <p>Loads and processes all simulation results.</p> <p>Iterates through configured scenarios and calls analyzer._process_single_result() for each one.</p> <p>Parameters:</p> Name Type Description Default <code>analyzer</code> <code>Analyzer</code> <p>Analyzer instance to process results with.</p> required Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>@abstractmethod\ndef load_and_process_results(self, analyzer: \"Analyzer\"):\n    \"\"\"Loads and processes all simulation results.\n\n    Iterates through configured scenarios and calls analyzer._process_single_result()\n    for each one.\n\n    Args:\n        analyzer: Analyzer instance to process results with.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy.get_normalization_factor","title":"get_normalization_factor  <code>abstractmethod</code>","text":"<pre><code>get_normalization_factor(frequency_mhz: int, simulated_power_w: float) -&gt; float\n</code></pre> <p>Calculates SAR normalization factor from simulated power.</p> <p>Parameters:</p> Name Type Description Default <code>frequency_mhz</code> <code>int</code> <p>Simulation frequency in MHz.</p> required <code>simulated_power_w</code> <code>float</code> <p>Input power from simulation in Watts.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Normalization factor to multiply SAR values by.</p> Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>@abstractmethod\ndef get_normalization_factor(self, frequency_mhz: int, simulated_power_w: float) -&gt; float:\n    \"\"\"Calculates SAR normalization factor from simulated power.\n\n    Args:\n        frequency_mhz: Simulation frequency in MHz.\n        simulated_power_w: Input power from simulation in Watts.\n\n    Returns:\n        Normalization factor to multiply SAR values by.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy.extract_data","title":"extract_data  <code>abstractmethod</code>","text":"<pre><code>extract_data(pickle_data: dict, frequency_mhz: int, placement_name: str, scenario_name: str, sim_power: float, norm_factor: float, sar_results: dict | None = None) -&gt; tuple[dict, list]\n</code></pre> <p>Extracts and structures data from a single simulation's result files.</p> <p>Parameters:</p> Name Type Description Default <code>pickle_data</code> <code>dict</code> <p>Data loaded from the .pkl result file.</p> required <code>frequency_mhz</code> <code>int</code> <p>Simulation frequency.</p> required <code>placement_name</code> <code>str</code> <p>Detailed placement name.</p> required <code>scenario_name</code> <code>str</code> <p>General scenario name.</p> required <code>sim_power</code> <code>float</code> <p>Simulated input power in Watts.</p> required <code>norm_factor</code> <code>float</code> <p>Normalization factor to apply.</p> required <code>sar_results</code> <code>dict | None</code> <p>Optional JSON results dict containing additional data like power balance.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[dict, list]</code> <p>Tuple of (main result entry dict, list of organ-specific entries).</p> Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>@abstractmethod\ndef extract_data(\n    self,\n    pickle_data: dict,\n    frequency_mhz: int,\n    placement_name: str,\n    scenario_name: str,\n    sim_power: float,\n    norm_factor: float,\n    sar_results: dict | None = None,\n) -&gt; tuple[dict, list]:\n    \"\"\"Extracts and structures data from a single simulation's result files.\n\n    Args:\n        pickle_data: Data loaded from the .pkl result file.\n        frequency_mhz: Simulation frequency.\n        placement_name: Detailed placement name.\n        scenario_name: General scenario name.\n        sim_power: Simulated input power in Watts.\n        norm_factor: Normalization factor to apply.\n        sar_results: Optional JSON results dict containing additional data like power balance.\n\n    Returns:\n        Tuple of (main result entry dict, list of organ-specific entries).\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy.apply_bug_fixes","title":"apply_bug_fixes  <code>abstractmethod</code>","text":"<pre><code>apply_bug_fixes(result_entry: dict) -&gt; dict\n</code></pre> <p>Applies workarounds for known data inconsistencies.</p> <p>Parameters:</p> Name Type Description Default <code>result_entry</code> <code>dict</code> <p>Data entry for a single simulation result.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Corrected result entry.</p> Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>@abstractmethod\ndef apply_bug_fixes(self, result_entry: dict) -&gt; dict:\n    \"\"\"Applies workarounds for known data inconsistencies.\n\n    Args:\n        result_entry: Data entry for a single simulation result.\n\n    Returns:\n        Corrected result entry.\n    \"\"\"\n    return result_entry\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy.calculate_summary_stats","title":"calculate_summary_stats  <code>abstractmethod</code>","text":"<pre><code>calculate_summary_stats(results_df: DataFrame) -&gt; pd.DataFrame\n</code></pre> <p>Calculates summary statistics from aggregated results.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with all aggregated simulation results.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with summary statistics.</p> Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>@abstractmethod\ndef calculate_summary_stats(self, results_df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Calculates summary statistics from aggregated results.\n\n    Args:\n        results_df: DataFrame with all aggregated simulation results.\n\n    Returns:\n        DataFrame with summary statistics.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.base_strategy.BaseAnalysisStrategy.generate_plots","title":"generate_plots  <code>abstractmethod</code>","text":"<pre><code>generate_plots(analyzer: Analyzer, plotter: Plotter, results_df: DataFrame, all_organ_results_df: DataFrame)\n</code></pre> <p>Generates study-type specific plots.</p> <p>Parameters:</p> Name Type Description Default <code>analyzer</code> <code>Analyzer</code> <p>Analyzer instance with aggregated data.</p> required <code>plotter</code> <code>Plotter</code> <p>Plotter instance for creating figures.</p> required <code>results_df</code> <code>DataFrame</code> <p>DataFrame with summary results.</p> required <code>all_organ_results_df</code> <code>DataFrame</code> <p>DataFrame with organ-level details.</p> required Source code in <code>goliat/analysis/base_strategy.py</code> <pre><code>@abstractmethod\ndef generate_plots(\n    self,\n    analyzer: \"Analyzer\",\n    plotter: \"Plotter\",\n    results_df: pd.DataFrame,\n    all_organ_results_df: pd.DataFrame,\n):\n    \"\"\"Generates study-type specific plots.\n\n    Args:\n        analyzer: Analyzer instance with aggregated data.\n        plotter: Plotter instance for creating figures.\n        results_df: DataFrame with summary results.\n        all_organ_results_df: DataFrame with organ-level details.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/api_reference/#compare","title":"Compare","text":""},{"location":"reference/api_reference/#goliat.analysis.compare","title":"goliat.analysis.compare","text":"<p>Compare UGent and CNR data from Excel files and create comparison plots.</p> <p>This module provides functionality to compare SAR data between different institutions (UGent and CNR) and create publication-quality comparison plots.</p>"},{"location":"reference/api_reference/#goliat.analysis.compare-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.compare.load_comparison_data","title":"load_comparison_data","text":"<pre><code>load_comparison_data(ugent_file: str, cnr_file: str) -&gt; pd.DataFrame\n</code></pre> <p>Load all data from both Excel files.</p> <p>Parameters:</p> Name Type Description Default <code>ugent_file</code> <code>str</code> <p>Path to UGent Excel file</p> required <code>cnr_file</code> <code>str</code> <p>Path to CNR Excel file</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Combined DataFrame with all data</p> Source code in <code>goliat/analysis/compare.py</code> <pre><code>def load_comparison_data(\n    ugent_file: str,\n    cnr_file: str,\n) -&gt; pd.DataFrame:\n    \"\"\"Load all data from both Excel files.\n\n    Args:\n        ugent_file: Path to UGent Excel file\n        cnr_file: Path to CNR Excel file\n\n    Returns:\n        Combined DataFrame with all data\n    \"\"\"\n    all_data = []\n\n    # Load UGent data\n    if os.path.exists(ugent_file):\n        logging.getLogger(\"progress\").info(\n            f\"Loading UGent data from: {ugent_file}\",\n            extra={\"log_type\": \"info\"},\n        )\n        xl_ugent = pd.ExcelFile(ugent_file)\n        for sheet_name in xl_ugent.sheet_names:\n            df = pd.read_excel(ugent_file, sheet_name=sheet_name)\n            parts = sheet_name.split(\"_\")\n            phantom = parts[0]\n            scenario = \"_\".join(parts[1:])\n            df[\"phantom\"] = phantom\n            df[\"institution\"] = \"UGent\"\n            df[\"scenario\"] = scenario\n            all_data.append(df)\n    else:\n        logging.getLogger(\"progress\").warning(\n            f\"UGent file not found: {ugent_file}\",\n            extra={\"log_type\": \"warning\"},\n        )\n\n    # Load CNR data\n    if os.path.exists(cnr_file):\n        logging.getLogger(\"progress\").info(\n            f\"Loading CNR data from: {cnr_file}\",\n            extra={\"log_type\": \"info\"},\n        )\n        xl_cnr = pd.ExcelFile(cnr_file)\n        for sheet_name in xl_cnr.sheet_names:\n            df = pd.read_excel(cnr_file, sheet_name=sheet_name)\n            parts = sheet_name.split(\"_\")\n            phantom = parts[0]\n            scenario = \"_\".join(parts[1:])\n            df[\"phantom\"] = phantom\n            df[\"institution\"] = \"CNR\"\n            df[\"scenario\"] = scenario\n            all_data.append(df)\n    else:\n        logging.getLogger(\"progress\").warning(\n            f\"CNR file not found: {cnr_file}\",\n            extra={\"log_type\": \"warning\"},\n        )\n\n    if not all_data:\n        return pd.DataFrame()\n\n    combined_df = pd.concat(all_data, ignore_index=True)\n    return combined_df\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.compare.create_comparison_plots","title":"create_comparison_plots","text":"<pre><code>create_comparison_plots(df: DataFrame, output_dir: Path, plot_format: str = 'pdf')\n</code></pre> <p>Create comparison plots for all metrics and scenarios.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Combined DataFrame with UGent and CNR data</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save plots</p> required <code>plot_format</code> <code>str</code> <p>Output format ('pdf' or 'png')</p> <code>'pdf'</code> Source code in <code>goliat/analysis/compare.py</code> <pre><code>def create_comparison_plots(\n    df: pd.DataFrame,\n    output_dir: Path,\n    plot_format: str = \"pdf\",\n):\n    \"\"\"Create comparison plots for all metrics and scenarios.\n\n    Args:\n        df: Combined DataFrame with UGent and CNR data\n        output_dir: Directory to save plots\n        plot_format: Output format ('pdf' or 'png')\n    \"\"\"\n    output_dir.mkdir(exist_ok=True, parents=True)\n\n    for scenario in SCENARIOS:\n        scenario_data = df[df[\"scenario\"] == scenario].copy()\n\n        if scenario_data.empty:\n            logging.getLogger(\"progress\").info(\n                f\"No data found for scenario: {scenario}\",\n                extra={\"log_type\": \"warning\"},\n            )\n            continue\n\n        for metric in METRICS:\n            if metric not in scenario_data.columns:\n                continue\n\n            metric_data = scenario_data[scenario_data[metric].notna()].copy()\n\n            if metric_data.empty:\n                continue\n\n            fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column\n\n            phantoms = metric_data[\"phantom\"].unique()\n\n            for phantom in sorted(phantoms):\n                phantom_data = metric_data[metric_data[\"phantom\"] == phantom]\n                institution = phantom_data[\"institution\"].iloc[0]\n\n                grouped = phantom_data.groupby(\"frequency_mhz\")[metric].agg([\"mean\", \"std\"])\n\n                x = grouped.index.values\n                y_mean = grouped[\"mean\"].values\n                y_std = grouped[\"std\"].values\n\n                label = f\"{phantom} ({institution})\"\n                color = INSTITUTION_COLORS.get(institution, \"gray\")\n                marker = PHANTOM_MARKERS.get(phantom, \"o\")\n\n                ax.errorbar(\n                    x,\n                    y_mean,\n                    yerr=y_std,\n                    marker=marker,\n                    linestyle=\"-\",\n                    label=label,\n                    color=color,\n                    markersize=4,\n                    capsize=2,\n                    capthick=1,\n                    linewidth=1.5,\n                )\n\n            ax.set_xlabel(\"Frequency (MHz)\")\n            ax.set_ylabel(metric)\n            ax.legend(loc=\"best\", fontsize=7)\n            ax.grid(True, alpha=0.3)\n            ax.set_ylim(bottom=0)\n\n            plt.tight_layout()\n\n            safe_metric = metric.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n            filename = f\"compare_{safe_metric}_{scenario}.{plot_format}\"\n            filepath = output_dir / filename\n\n            if plot_format == \"pdf\":\n                fig.savefig(filepath, bbox_inches=\"tight\", format=\"pdf\")\n            else:\n                fig.savefig(filepath, dpi=300, bbox_inches=\"tight\")\n\n            plt.close(fig)\n            logging.getLogger(\"progress\").info(\n                f\"  - Generated comparison plot: {filename}\",\n                extra={\"log_type\": \"success\"},\n            )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.compare.create_summary_comparison_plots","title":"create_summary_comparison_plots","text":"<pre><code>create_summary_comparison_plots(df: DataFrame, output_dir: Path, plot_format: str = 'pdf')\n</code></pre> <p>Create summary comparison plots across all scenarios.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Combined DataFrame with UGent and CNR data</p> required <code>output_dir</code> <code>Path</code> <p>Directory to save plots</p> required <code>plot_format</code> <code>str</code> <p>Output format ('pdf' or 'png')</p> <code>'pdf'</code> Source code in <code>goliat/analysis/compare.py</code> <pre><code>def create_summary_comparison_plots(\n    df: pd.DataFrame,\n    output_dir: Path,\n    plot_format: str = \"pdf\",\n):\n    \"\"\"Create summary comparison plots across all scenarios.\n\n    Args:\n        df: Combined DataFrame with UGent and CNR data\n        output_dir: Directory to save plots\n        plot_format: Output format ('pdf' or 'png')\n    \"\"\"\n    output_dir.mkdir(exist_ok=True, parents=True)\n\n    for metric in METRICS:\n        if metric not in df.columns:\n            continue\n\n        metric_data = df[df[metric].notna()].copy()\n\n        if metric_data.empty:\n            continue\n\n        # Create figure with 3 subplots (one per scenario)\n        fig, axes = plt.subplots(1, 3, figsize=(7, 2.5))\n\n        for idx, scenario in enumerate(SCENARIOS):\n            ax = axes[idx]\n            scenario_data = metric_data[metric_data[\"scenario\"] == scenario]\n\n            if scenario_data.empty:\n                ax.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n                ax.set_title(scenario.replace(\"_\", \" \").title())\n                continue\n\n            phantoms = scenario_data[\"phantom\"].unique()\n            for phantom in sorted(phantoms):\n                phantom_data = scenario_data[scenario_data[\"phantom\"] == phantom]\n                institution = phantom_data[\"institution\"].iloc[0]\n\n                grouped = phantom_data.groupby(\"frequency_mhz\")[metric].agg([\"mean\", \"std\"])\n\n                x = grouped.index.values\n                y_mean = grouped[\"mean\"].values\n                y_std = grouped[\"std\"].values\n\n                label = f\"{phantom}\"\n                color = INSTITUTION_COLORS.get(institution, \"gray\")\n                marker = PHANTOM_MARKERS.get(phantom, \"o\")\n                linestyle = \"-\" if institution == \"UGent\" else \"--\"\n\n                ax.errorbar(\n                    x,\n                    y_mean,\n                    yerr=y_std,\n                    marker=marker,\n                    linestyle=linestyle,\n                    label=label,\n                    color=color,\n                    markersize=3,\n                    capsize=1,\n                    capthick=0.5,\n                    linewidth=1,\n                )\n\n            ax.set_xlabel(\"Frequency (MHz)\")\n            if idx == 0:\n                ax.set_ylabel(metric.replace(\"_\", \" \"))\n            ax.set_title(scenario.replace(\"_\", \" \").title())\n            ax.legend(loc=\"best\", fontsize=6)\n            ax.grid(True, alpha=0.3)\n            ax.set_ylim(bottom=0)\n\n        plt.tight_layout()\n\n        safe_metric = metric.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n        filename = f\"compare_summary_{safe_metric}.{plot_format}\"\n        filepath = output_dir / filename\n\n        if plot_format == \"pdf\":\n            fig.savefig(filepath, bbox_inches=\"tight\", format=\"pdf\")\n        else:\n            fig.savefig(filepath, dpi=300, bbox_inches=\"tight\")\n\n        plt.close(fig)\n        logging.getLogger(\"progress\").info(\n            f\"  - Generated summary comparison plot: {filename}\",\n            extra={\"log_type\": \"success\"},\n        )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.compare.run_comparison","title":"run_comparison","text":"<pre><code>run_comparison(ugent_file: str, cnr_file: str, output_dir: str, plot_format: str = 'pdf')\n</code></pre> <p>Run the full comparison analysis.</p> <p>Parameters:</p> Name Type Description Default <code>ugent_file</code> <code>str</code> <p>Path to UGent Excel file</p> required <code>cnr_file</code> <code>str</code> <p>Path to CNR Excel file</p> required <code>output_dir</code> <code>str</code> <p>Directory to save comparison plots</p> required <code>plot_format</code> <code>str</code> <p>Output format ('pdf' or 'png')</p> <code>'pdf'</code> Source code in <code>goliat/analysis/compare.py</code> <pre><code>def run_comparison(\n    ugent_file: str,\n    cnr_file: str,\n    output_dir: str,\n    plot_format: str = \"pdf\",\n):\n    \"\"\"Run the full comparison analysis.\n\n    Args:\n        ugent_file: Path to UGent Excel file\n        cnr_file: Path to CNR Excel file\n        output_dir: Directory to save comparison plots\n        plot_format: Output format ('pdf' or 'png')\n    \"\"\"\n    # Apply white background style (overrides any dark mode from other modules)\n    _apply_comparison_style()\n\n    logging.getLogger(\"progress\").info(\n        \"=\" * 60,\n        extra={\"log_type\": \"header\"},\n    )\n    logging.getLogger(\"progress\").info(\n        \"   UGent vs CNR Data Comparison\",\n        extra={\"log_type\": \"header\"},\n    )\n    logging.getLogger(\"progress\").info(\n        \"=\" * 60,\n        extra={\"log_type\": \"header\"},\n    )\n\n    # Load data\n    df = load_comparison_data(ugent_file, cnr_file)\n\n    if df.empty:\n        logging.getLogger(\"progress\").error(\n            \"No data loaded. Please check file paths.\",\n            extra={\"log_type\": \"error\"},\n        )\n        return\n\n    logging.getLogger(\"progress\").info(\n        f\"Loaded {len(df)} total data points\",\n        extra={\"log_type\": \"success\"},\n    )\n    logging.getLogger(\"progress\").info(\n        f\"Phantoms: {list(df['phantom'].unique())}\",\n        extra={\"log_type\": \"info\"},\n    )\n    logging.getLogger(\"progress\").info(\n        f\"Institutions: {list(df['institution'].unique())}\",\n        extra={\"log_type\": \"info\"},\n    )\n    logging.getLogger(\"progress\").info(\n        f\"Scenarios: {list(df['scenario'].unique())}\",\n        extra={\"log_type\": \"info\"},\n    )\n\n    output_path = Path(output_dir)\n\n    # Create individual comparison plots\n    logging.getLogger(\"progress\").info(\n        \"\\nCreating individual comparison plots...\",\n        extra={\"log_type\": \"info\"},\n    )\n    create_comparison_plots(df, output_path, plot_format)\n\n    # Create summary plots\n    logging.getLogger(\"progress\").info(\n        \"\\nCreating summary comparison plots...\",\n        extra={\"log_type\": \"info\"},\n    )\n    create_summary_comparison_plots(df, output_path, plot_format)\n\n    logging.getLogger(\"progress\").info(\n        f\"\\nAll comparison plots saved to: {output_dir}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.compare.main","title":"main","text":"<pre><code>main()\n</code></pre> <p>Main entry point for CLI usage.</p> Source code in <code>goliat/analysis/compare.py</code> <pre><code>def main():\n    \"\"\"Main entry point for CLI usage.\"\"\"\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\"Compare UGent and CNR SAR data from Excel files\")\n    parser.add_argument(\n        \"--ugent-file\",\n        type=str,\n        default=\"results/near_field/Final_Data_UGent.xlsx\",\n        help=\"Path to UGent Excel file\",\n    )\n    parser.add_argument(\n        \"--cnr-file\",\n        type=str,\n        default=\"results/near_field/Final_Data_CNR.xlsx\",\n        help=\"Path to CNR Excel file\",\n    )\n    parser.add_argument(\n        \"-o\",\n        \"--output\",\n        type=str,\n        default=\"plots/comparison\",\n        help=\"Output directory for comparison plots\",\n    )\n    parser.add_argument(\n        \"--format\",\n        type=str,\n        choices=[\"pdf\", \"png\"],\n        default=\"pdf\",\n        help=\"Output format for plots\",\n    )\n    args = parser.parse_args()\n\n    # Setup basic logging if not in goliat context\n    from goliat.logging_manager import setup_loggers\n\n    setup_loggers()\n\n    run_comparison(\n        args.ugent_file,\n        args.cnr_file,\n        args.output,\n        args.format,\n    )\n</code></pre>"},{"location":"reference/api_reference/#create-excel-for-partners","title":"Create Excel For Partners","text":""},{"location":"reference/api_reference/#goliat.analysis.create_excel_for_partners","title":"goliat.analysis.create_excel_for_partners","text":"<p>Create Excel file matching CNR's Excel format for Thelonious and Eartha phantoms.</p>"},{"location":"reference/api_reference/#goliat.analysis.create_excel_for_partners-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.create_excel_for_partners.get_target_power_mapping","title":"get_target_power_mapping","text":"<pre><code>get_target_power_mapping(config_path: str) -&gt; dict[int, int]\n</code></pre> <p>Read target power values from config file for each frequency.</p> Source code in <code>goliat/analysis/create_excel_for_partners.py</code> <pre><code>def get_target_power_mapping(config_path: str) -&gt; dict[int, int]:\n    \"\"\"Read target power values from config file for each frequency.\"\"\"\n    with open(config_path, \"r\") as f:\n        config = json.load(f)\n\n    antenna_config = config.get(\"antenna_config\", {})\n    power_mapping = {}\n\n    for freq_str, freq_config in antenna_config.items():\n        if isinstance(freq_config, dict) and \"target_power_mW\" in freq_config:\n            frequency_mhz = int(freq_str)\n            power_mapping[frequency_mhz] = freq_config[\"target_power_mW\"]\n\n    return power_mapping\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.create_excel_for_partners.map_placement_name","title":"map_placement_name","text":"<pre><code>map_placement_name(placement: str, sheet_type: str) -&gt; str\n</code></pre> <p>Map placement names to match CNR's Excel format.</p> <p>Parameters:</p> Name Type Description Default <code>placement</code> <code>str</code> <p>Original placement name from CSV</p> required <code>sheet_type</code> <code>str</code> <p>One of 'fronteyes', 'belly', or 'cheek'</p> required <p>Returns:</p> Type Description <code>str</code> <p>Mapped placement name matching CNR's Excel format</p> Source code in <code>goliat/analysis/create_excel_for_partners.py</code> <pre><code>def map_placement_name(placement: str, sheet_type: str) -&gt; str:\n    \"\"\"Map placement names to match CNR's Excel format.\n\n    Args:\n        placement: Original placement name from CSV\n        sheet_type: One of 'fronteyes', 'belly', or 'cheek'\n\n    Returns:\n        Mapped placement name matching CNR's Excel format\n    \"\"\"\n    if sheet_type == \"fronteyes\":\n        # front_of_eyes_* placements stay the same\n        if placement.startswith(\"front_of_eyes_\"):\n            return placement\n    elif sheet_type == \"belly\":\n        # by_belly_* -&gt; belly_level_*\n        if placement.startswith(\"by_belly_\"):\n            return placement.replace(\"by_belly_\", \"belly_level_\")\n    elif sheet_type == \"cheek\":\n        # Map cheek placements to cheek_1, cheek_2, cheek_3, tilt_1, tilt_2, tilt_3\n        mapping = {\n            \"by_cheek_tragus_cheek_base\": \"cheek_1\",\n            \"by_cheek_tragus_cheek_up\": \"cheek_2\",\n            \"by_cheek_tragus_cheek_down\": \"cheek_3\",\n            \"by_cheek_tragus_tilt_base\": \"tilt_1\",\n            \"by_cheek_tragus_tilt_up\": \"tilt_2\",\n            \"by_cheek_tragus_tilt_down\": \"tilt_3\",\n        }\n        return mapping.get(placement, placement)\n\n    return placement\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.create_excel_for_partners.create_sheet_data","title":"create_sheet_data","text":"<pre><code>create_sheet_data(df: DataFrame, sheet_type: str, power_mapping: dict[int, int]) -&gt; pd.DataFrame\n</code></pre> <p>Create data for one sheet matching CNR's Excel format.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Source DataFrame from CSV</p> required <code>sheet_type</code> <code>str</code> <p>One of 'fronteyes', 'belly', or 'cheek'</p> required <code>power_mapping</code> <code>dict[int, int]</code> <p>Dictionary mapping frequency (MHz) to target power (mW)</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame formatted to match CNR's Excel sheet format</p> Source code in <code>goliat/analysis/create_excel_for_partners.py</code> <pre><code>def create_sheet_data(\n    df: pd.DataFrame,\n    sheet_type: str,\n    power_mapping: dict[int, int],\n) -&gt; pd.DataFrame:\n    \"\"\"Create data for one sheet matching CNR's Excel format.\n\n    Args:\n        df: Source DataFrame from CSV\n        sheet_type: One of 'fronteyes', 'belly', or 'cheek'\n        power_mapping: Dictionary mapping frequency (MHz) to target power (mW)\n\n    Returns:\n        DataFrame formatted to match CNR's Excel sheet format\n    \"\"\"\n    # Filter placements based on sheet type\n    if sheet_type == \"fronteyes\":\n        filtered_df = df[df[\"placement\"].str.startswith(\"front_of_eyes_\")].copy()\n    elif sheet_type == \"belly\":\n        filtered_df = df[df[\"placement\"].str.startswith(\"by_belly_\")].copy()\n    elif sheet_type == \"cheek\":\n        filtered_df = df[df[\"placement\"].str.startswith(\"by_cheek_tragus_\")].copy()\n    else:\n        raise ValueError(f\"Unknown sheet_type: {sheet_type}\")\n\n    if filtered_df.empty:\n        return pd.DataFrame()\n\n    # Map placement names to match CNR's Excel format\n    filtered_df[\"placement\"] = filtered_df[\"placement\"].apply(lambda x: map_placement_name(x, sheet_type))\n\n    # Create output DataFrame with column names matching CNR's Excel format\n    result_df = pd.DataFrame()\n    result_df[\"frequency_mhz\"] = filtered_df[\"frequency_mhz\"]\n    result_df[\"placement\"] = filtered_df[\"placement\"]\n\n    # Add Input Power column based on frequency (matching CNR's Excel format)\n    result_df[\"Input Power (mW)\"] = result_df[\"frequency_mhz\"].map(power_mapping)\n\n    # Map SAR columns to match CNR's Excel format\n    result_df[\"SAR_wholebody (mW/kg)\"] = filtered_df[\"SAR_whole_body\"]\n    result_df[\"SAR_head (mW/kg)\"] = filtered_df[\"SAR_head\"]\n    result_df[\"SAR_trunk (mW/kg)\"] = filtered_df[\"SAR_trunk\"]\n    result_df[\"psSAR10g_eyes (mW/kg)\"] = filtered_df[\"psSAR10g_eyes\"]\n    result_df[\"psSAR10g_skin (mW/kg)\"] = filtered_df[\"psSAR10g_skin\"]\n    result_df[\"psSAR10g_brain (mW/kg)\"] = filtered_df[\"psSAR10g_brain\"]\n\n    # Sort by frequency and placement\n    result_df = result_df.sort_values(by=[\"frequency_mhz\", \"placement\"]).reset_index(drop=True)\n\n    return result_df\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.create_excel_for_partners.create_cnr_excel","title":"create_cnr_excel","text":"<pre><code>create_cnr_excel(phantom_name: str, csv_path: str, config_path: str, output_path: str)\n</code></pre> <p>Create Excel file matching CNR's Excel format for a phantom.</p> <p>Parameters:</p> Name Type Description Default <code>phantom_name</code> <code>str</code> <p>Name of the phantom (e.g., 'thelonious', 'eartha')</p> required <code>csv_path</code> <code>str</code> <p>Path to normalized_results_detailed.csv</p> required <code>config_path</code> <code>str</code> <p>Path to config JSON file with antenna_config</p> required <code>output_path</code> <code>str</code> <p>Path where Excel file should be saved</p> required Source code in <code>goliat/analysis/create_excel_for_partners.py</code> <pre><code>def create_cnr_excel(\n    phantom_name: str,\n    csv_path: str,\n    config_path: str,\n    output_path: str,\n):\n    \"\"\"Create Excel file matching CNR's Excel format for a phantom.\n\n    Args:\n        phantom_name: Name of the phantom (e.g., 'thelonious', 'eartha')\n        csv_path: Path to normalized_results_detailed.csv\n        config_path: Path to config JSON file with antenna_config\n        output_path: Path where Excel file should be saved\n    \"\"\"\n    # Read CSV data\n    df = pd.read_csv(csv_path)\n\n    # Get power mapping from config\n    power_mapping = get_target_power_mapping(config_path)\n\n    # Create data for each sheet\n    sheet_fronteyes = create_sheet_data(df, \"fronteyes\", power_mapping)\n    sheet_belly = create_sheet_data(df, \"belly\", power_mapping)\n    sheet_cheek = create_sheet_data(df, \"cheek\", power_mapping)\n\n    # Create Excel file with multiple sheets\n    sheet_name = f\"{phantom_name.capitalize()}_fronteyes\"\n    belly_name = f\"{phantom_name.capitalize()}_belly\"\n    cheek_name = f\"{phantom_name.capitalize()}_cheek\"\n\n    with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n        # Write sheets in order: fronteyes (sheet 1), belly (sheet 2), cheek (sheet 3)\n        sheet_fronteyes.to_excel(writer, sheet_name=sheet_name, index=False)\n        sheet_belly.to_excel(writer, sheet_name=belly_name, index=False)\n        sheet_cheek.to_excel(writer, sheet_name=cheek_name, index=False)\n\n    print(f\"Created Excel file: {output_path}\")\n    print(f\"  - Sheet 1 ({sheet_name}): {len(sheet_fronteyes)} rows\")\n    print(f\"  - Sheet 2 ({belly_name}): {len(sheet_belly)} rows\")\n    print(f\"  - Sheet 3 ({cheek_name}): {len(sheet_cheek)} rows\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.create_excel_for_partners.main","title":"main","text":"<pre><code>main()\n</code></pre> <p>Main function to create a single Excel file matching CNR's Excel format for both phantoms.</p> Source code in <code>goliat/analysis/create_excel_for_partners.py</code> <pre><code>def main():\n    \"\"\"Main function to create a single Excel file matching CNR's Excel format for both phantoms.\"\"\"\n    # Paths\n    # __file__ is in goliat/goliat/analysis/, so we need to go up to goliat/\n    base_dir = Path(__file__).parent.parent.parent\n    results_dir = base_dir / \"results\" / \"near_field\"\n    config_path = base_dir / \"configs\" / \"near_field_config.json\"\n\n    phantoms = [\"thelonious\", \"eartha\"]\n\n    # Create a single Excel file with all sheets\n    output_path = results_dir / \"Final_Data_UGent.xlsx\"\n\n    # Get power mapping from config\n    power_mapping = get_target_power_mapping(str(config_path))\n\n    # Create Excel writer\n    with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n        for phantom_name in phantoms:\n            csv_path = results_dir / phantom_name / \"normalized_results_detailed.csv\"\n\n            if not csv_path.exists():\n                logging.getLogger(\"progress\").warning(f\"CSV file not found: {csv_path}\", extra={\"log_type\": \"warning\"})\n                continue\n\n            logging.getLogger(\"progress\").info(f\"  Processing: {phantom_name.capitalize()}...\", extra={\"log_type\": \"progress\"})\n\n            # Read CSV data\n            df = pd.read_csv(csv_path)\n\n            # Create data for each sheet\n            sheet_fronteyes = create_sheet_data(df, \"fronteyes\", power_mapping)\n            sheet_belly = create_sheet_data(df, \"belly\", power_mapping)\n            sheet_cheek = create_sheet_data(df, \"cheek\", power_mapping)\n\n            # Create sheet names\n            sheet_name_fronteyes = f\"{phantom_name.capitalize()}_fronteyes\"\n            sheet_name_belly = f\"{phantom_name.capitalize()}_belly\"\n            sheet_name_cheek = f\"{phantom_name.capitalize()}_cheek\"\n\n            # Write sheets\n            sheet_fronteyes.to_excel(writer, sheet_name=sheet_name_fronteyes, index=False)\n            sheet_belly.to_excel(writer, sheet_name=sheet_name_belly, index=False)\n            sheet_cheek.to_excel(writer, sheet_name=sheet_name_cheek, index=False)\n\n            # Add table formatting to each sheet\n            workbook = writer.book\n\n            # Format fronteyes sheet as table\n            if not sheet_fronteyes.empty:\n                ws_fronteyes = workbook[sheet_name_fronteyes]\n                _add_table_formatting(ws_fronteyes, sheet_fronteyes, sheet_name_fronteyes)\n                _auto_size_columns(ws_fronteyes, sheet_fronteyes)\n\n            # Format belly sheet as table\n            if not sheet_belly.empty:\n                ws_belly = workbook[sheet_name_belly]\n                _add_table_formatting(ws_belly, sheet_belly, sheet_name_belly)\n                _auto_size_columns(ws_belly, sheet_belly)\n\n            # Format cheek sheet as table\n            if not sheet_cheek.empty:\n                ws_cheek = workbook[sheet_name_cheek]\n                _add_table_formatting(ws_cheek, sheet_cheek, sheet_name_cheek)\n                _auto_size_columns(ws_cheek, sheet_cheek)\n\n            logging.getLogger(\"progress\").info(f\"    - {sheet_name_fronteyes}: {len(sheet_fronteyes)} rows\", extra={\"log_type\": \"verbose\"})\n            logging.getLogger(\"progress\").info(f\"    - {sheet_name_belly}: {len(sheet_belly)} rows\", extra={\"log_type\": \"verbose\"})\n            logging.getLogger(\"progress\").info(f\"    - {sheet_name_cheek}: {len(sheet_cheek)} rows\", extra={\"log_type\": \"verbose\"})\n\n    logging.getLogger(\"progress\").info(f\"  Created: {output_path.name}\", extra={\"log_type\": \"success\"})\n</code></pre>"},{"location":"reference/api_reference/#far-field-strategy","title":"Far Field Strategy","text":""},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy","title":"goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy","text":"<pre><code>FarFieldAnalysisStrategy(config: Config, phantom_name: str, analysis_config: dict | None = None)\n</code></pre> <p>               Bases: <code>BaseAnalysisStrategy</code></p> <p>Analysis strategy for far-field simulations.</p> <p>Handles result loading, normalization, and plot generation for far-field studies with incident directions and polarizations.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required <code>phantom_name</code> <code>str</code> <p>Phantom model name being analyzed.</p> required <code>analysis_config</code> <code>dict | None</code> <p>Optional dictionary with plot names as keys and boolean values.</p> <code>None</code> Source code in <code>goliat/analysis/far_field_strategy.py</code> <pre><code>def __init__(self, config: \"Config\", phantom_name: str, analysis_config: dict | None = None):\n    \"\"\"Initializes the far-field analysis strategy.\n\n    Args:\n        config: Configuration object.\n        phantom_name: Phantom model name being analyzed.\n        analysis_config: Optional dictionary with plot names as keys and boolean values.\n    \"\"\"\n    super().__init__(config, phantom_name, analysis_config)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy.get_results_base_dir","title":"get_results_base_dir","text":"<pre><code>get_results_base_dir() -&gt; str\n</code></pre> <p>Returns base directory for far-field results.</p> Source code in <code>goliat/analysis/far_field_strategy.py</code> <pre><code>def get_results_base_dir(self) -&gt; str:\n    \"\"\"Returns base directory for far-field results.\"\"\"\n    return os.path.join(self.base_dir, \"results\", \"far_field\", self.phantom_name)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy.get_plots_dir","title":"get_plots_dir","text":"<pre><code>get_plots_dir() -&gt; str\n</code></pre> <p>Returns directory for far-field plots.</p> Source code in <code>goliat/analysis/far_field_strategy.py</code> <pre><code>def get_plots_dir(self) -&gt; str:\n    \"\"\"Returns directory for far-field plots.\"\"\"\n    return os.path.join(self.base_dir, \"plots\", \"far_field\", self.phantom_name)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy.get_expected_item_count","title":"get_expected_item_count","text":"<pre><code>get_expected_item_count() -&gt; int\n</code></pre> <p>Returns expected number of progress items for this phantom.</p> <p>Returns the EXACT count of processing items (result files to be processed). If load_data is False (cache mode), returns 0 since no processing occurs. Plot items are not counted - the GUI handles this via dynamic maximum adjustment.</p> <p>Returns:</p> Type Description <code>int</code> <p>Exact number of result files that will trigger 'Processing:' log messages.</p> Source code in <code>goliat/analysis/far_field_strategy.py</code> <pre><code>def get_expected_item_count(self) -&gt; int:\n    \"\"\"Returns expected number of progress items for this phantom.\n\n    Returns the EXACT count of processing items (result files to be processed).\n    If load_data is False (cache mode), returns 0 since no processing occurs.\n    Plot items are not counted - the GUI handles this via dynamic maximum adjustment.\n\n    Returns:\n        Exact number of result files that will trigger 'Processing:' log messages.\n    \"\"\"\n    # If loading from cache, no \"Processing:\" messages are generated\n    if not self.analysis_config.get(\"load_data\", True):\n        return 0\n\n    frequencies = self.config[\"frequencies_mhz\"] or []\n    far_field_params = self.config[\"far_field_setup.environmental\"] or {}\n    incident_directions = far_field_params.get(\"incident_directions\", [])\n    polarizations = far_field_params.get(\"polarizations\", [])\n\n    num_frequencies = len(frequencies)\n    num_placements = len(incident_directions) * len(polarizations)\n\n    # Exact count: one progress item per result file processed\n    return num_frequencies * num_placements\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy.load_and_process_results","title":"load_and_process_results","text":"<pre><code>load_and_process_results(analyzer: Analyzer)\n</code></pre> <p>Iterates through far-field results and processes each one.</p> Source code in <code>goliat/analysis/far_field_strategy.py</code> <pre><code>def load_and_process_results(self, analyzer: \"Analyzer\"):\n    \"\"\"Iterates through far-field results and processes each one.\"\"\"\n    frequencies = self.config[\"frequencies_mhz\"]\n    far_field_params = self.config[\"far_field_setup.environmental\"]\n    if not far_field_params:\n        return\n    incident_directions = far_field_params.get(\"incident_directions\", [])\n    polarizations = far_field_params.get(\"polarizations\", [])\n\n    if not frequencies:\n        return\n\n    for freq in frequencies:\n        if not incident_directions:\n            continue\n        for direction_name in incident_directions:\n            if not polarizations:\n                continue\n            for polarization_name in polarizations:\n                placement_name = f\"environmental_{direction_name}_{polarization_name}\"\n                analyzer._process_single_result(freq, \"environmental\", placement_name, \"\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy.get_normalization_factor","title":"get_normalization_factor","text":"<pre><code>get_normalization_factor(frequency_mhz: int, simulated_power_w: float) -&gt; float\n</code></pre> <p>Returns normalization factor for far-field.</p> <p>Far-field simulations run at E = 1 V/m (power density = 1.326 mW/m\u00b2). To normalize to 1 W/m\u00b2 (our \"1 W\" convention for comparison with near-field), we scale by 754 (since SAR scales as E\u00b2, and E for 1 W/m\u00b2 is 27.46 V/m).</p> <p>See docs/technical/power_normalization_philosophy.md for full derivation.</p> Source code in <code>goliat/analysis/far_field_strategy.py</code> <pre><code>def get_normalization_factor(self, frequency_mhz: int, simulated_power_w: float) -&gt; float:\n    \"\"\"Returns normalization factor for far-field.\n\n    Far-field simulations run at E = 1 V/m (power density = 1.326 mW/m\u00b2).\n    To normalize to 1 W/m\u00b2 (our \"1 W\" convention for comparison with near-field),\n    we scale by 754 (since SAR scales as E\u00b2, and E for 1 W/m\u00b2 is 27.46 V/m).\n\n    See docs/technical/power_normalization_philosophy.md for full derivation.\n    \"\"\"\n    return 754.0\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy.extract_data","title":"extract_data","text":"<pre><code>extract_data(pickle_data: dict, frequency_mhz: int, placement_name: str, scenario_name: str, sim_power: float, norm_factor: float, sar_results: dict | None = None) -&gt; tuple[dict, list]\n</code></pre> <p>Extract and normalize SAR data from pickle file for far-field results.</p> Source code in <code>goliat/analysis/far_field_strategy.py</code> <pre><code>def extract_data(\n    self,\n    pickle_data: dict,\n    frequency_mhz: int,\n    placement_name: str,\n    scenario_name: str,\n    sim_power: float,\n    norm_factor: float,\n    sar_results: dict | None = None,\n) -&gt; tuple[dict, list]:\n    \"\"\"Extract and normalize SAR data from pickle file for far-field results.\"\"\"\n    summary_results = pickle_data.get(\"summary_results\", {})\n    grouped_stats = pickle_data.get(\"grouped_sar_stats\", {})\n    detailed_df = pickle_data.get(\"detailed_sar_stats\")\n\n    result_entry = {\n        \"frequency_mhz\": frequency_mhz,\n        \"placement\": placement_name,\n        \"scenario\": scenario_name,\n        \"input_power_w\": sim_power,\n        \"SAR_whole_body\": summary_results.get(\"whole_body_sar\", pd.NA) * norm_factor\n        if pd.notna(summary_results.get(\"whole_body_sar\"))\n        else pd.NA,\n        \"peak_sar\": summary_results.get(\"peak_sar_10g_W_kg\", pd.NA) * norm_factor\n        if pd.notna(summary_results.get(\"peak_sar_10g_W_kg\"))\n        else pd.NA,\n    }\n\n    # Extract psSAR10g for each tissue group (brain, eyes, skin, genitals)\n    # This mirrors the near-field strategy for symmetry\n    for group_name, stats in grouped_stats.items():\n        if isinstance(stats, dict):\n            key = f\"psSAR10g_{group_name.replace('_group', '')}\"\n            peak_sar = stats.get(\"peak_sar\", pd.NA)\n            result_entry[key] = peak_sar * norm_factor if pd.notna(peak_sar) else pd.NA\n\n    # Extract power balance data if available\n    power_balance = None\n    if sar_results and \"power_balance\" in sar_results:\n        power_balance = sar_results[\"power_balance\"]\n    elif summary_results and \"power_balance\" in summary_results:\n        power_balance = summary_results[\"power_balance\"]\n\n    if power_balance:\n        result_entry[\"power_balance_pct\"] = power_balance.get(\"Balance\", pd.NA)\n        result_entry[\"power_pin_W\"] = power_balance.get(\"Pin\", pd.NA)\n        result_entry[\"power_diel_loss_W\"] = power_balance.get(\"DielLoss\", pd.NA)\n        result_entry[\"power_rad_W\"] = power_balance.get(\"RadPower\", pd.NA)\n        result_entry[\"power_sibc_loss_W\"] = power_balance.get(\"SIBCLoss\", pd.NA)\n\n    organ_entries = []\n    if detailed_df is not None:\n        peak_sar_col = \"Peak Spatial-Average SAR[IEEE/IEC62704-1] (10g)\"\n        for _, row in detailed_df.iterrows():\n            organ_entry = {\n                \"frequency_mhz\": frequency_mhz,\n                \"placement\": placement_name,\n                \"scenario\": scenario_name,  # Added for symmetry with near-field\n                \"tissue\": _clean_tissue_name(row[\"Tissue\"]),  # Clean tissue name early\n                \"mass_avg_sar_mw_kg\": row[\"Mass-Averaged SAR\"] * norm_factor * 1000,\n                \"peak_sar_10g_mw_kg\": row.get(peak_sar_col, pd.NA) * norm_factor * 1000 if pd.notna(row.get(peak_sar_col)) else pd.NA,\n                \"min_local_sar_mw_kg\": row.get(\"Min. local SAR\", pd.NA) * norm_factor * 1000\n                if pd.notna(row.get(\"Min. local SAR\", pd.NA))\n                else pd.NA,\n                \"max_local_sar_mw_kg\": row.get(\"Max. local SAR\", pd.NA) * norm_factor * 1000\n                if pd.notna(row.get(\"Max. local SAR\", pd.NA))\n                else pd.NA,\n            }\n            # Add Total Mass, Total Volume, Total Loss, Max Loss Power Density if available\n            # (symmetric with near-field strategy)\n            if \"Total Mass\" in row.index:\n                organ_entry[\"Total Mass\"] = row[\"Total Mass\"]\n            if \"Total Volume\" in row.index:\n                organ_entry[\"Total Volume\"] = row[\"Total Volume\"]\n            if \"Total Loss\" in row.index:\n                organ_entry[\"Total Loss\"] = row[\"Total Loss\"]\n            if \"Max Loss Power Density\" in row.index:\n                organ_entry[\"Max Loss Power Density\"] = row[\"Max Loss Power Density\"]\n            # Add psSAR10g column name for compatibility (symmetric with near-field)\n            if peak_sar_col in row.index and pd.notna(row[peak_sar_col]):\n                organ_entry[\"psSAR10g\"] = row[peak_sar_col] * norm_factor * 1000\n            organ_entries.append(organ_entry)\n    return result_entry, organ_entries\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy.apply_bug_fixes","title":"apply_bug_fixes","text":"<pre><code>apply_bug_fixes(result_entry: dict) -&gt; dict\n</code></pre> <p>No bug fixes needed for far-field data.</p> Source code in <code>goliat/analysis/far_field_strategy.py</code> <pre><code>def apply_bug_fixes(self, result_entry: dict) -&gt; dict:\n    \"\"\"No bug fixes needed for far-field data.\"\"\"\n    return result_entry\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy.calculate_summary_stats","title":"calculate_summary_stats","text":"<pre><code>calculate_summary_stats(results_df: DataFrame) -&gt; pd.DataFrame\n</code></pre> <p>Calculates summary statistics for far-field results.</p> Source code in <code>goliat/analysis/far_field_strategy.py</code> <pre><code>def calculate_summary_stats(self, results_df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Calculates summary statistics for far-field results.\"\"\"\n    summary = results_df.groupby(\"frequency_mhz\").mean(numeric_only=True)\n    return pd.DataFrame(summary)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.far_field_strategy.FarFieldAnalysisStrategy.generate_plots","title":"generate_plots","text":"<pre><code>generate_plots(analyzer: Analyzer, plotter: Plotter, results_df: DataFrame, all_organ_results_df: DataFrame)\n</code></pre> <p>Generates all plots for far-field analysis.</p> <p>Includes bar charts, line plots, boxplots, heatmaps, ranking plots, CDF plots, correlation matrices, bubble plots, and tissue analysis.</p> Source code in <code>goliat/analysis/far_field_strategy.py</code> <pre><code>def generate_plots(\n    self,\n    analyzer: \"Analyzer\",\n    plotter: \"Plotter\",\n    results_df: pd.DataFrame,\n    all_organ_results_df: pd.DataFrame,\n):\n    \"\"\"Generates all plots for far-field analysis.\n\n    Includes bar charts, line plots, boxplots, heatmaps, ranking plots,\n    CDF plots, correlation matrices, bubble plots, and tissue analysis.\n    \"\"\"\n    logging.getLogger(\"progress\").info(\n        \"\\n--- Generating plots for far-field analysis ---\",\n        extra={\"log_type\": \"header\"},\n    )\n\n    # Add tissue group SAR columns to results_df\n    results_df = self._add_tissue_group_sar(results_df, all_organ_results_df, analyzer)\n\n    summary_stats = self.calculate_summary_stats(results_df)\n\n    # ============================================================================\n    # Basic Bar and Line Plots\n    # ============================================================================\n    if self.should_generate_plot(\"plot_whole_body_sar_bar\"):\n        plotter.plot_whole_body_sar_bar(summary_stats)\n    if self.should_generate_plot(\"plot_peak_sar_line\"):\n        plotter.plot_peak_sar_line(summary_stats)\n    if self.should_generate_plot(\"plot_far_field_distribution_boxplot\"):\n        plotter.plot_sar_distribution_boxplot_single(results_df, metric=\"SAR_whole_body\")\n        plotter.plot_sar_distribution_boxplot_single(results_df, metric=\"peak_sar\")\n        # Also generate boxplots for tissue groups (symmetric with near-field)\n        for metric in [\"SAR_brain\", \"SAR_eyes\", \"SAR_skin\", \"SAR_genitals\"]:\n            if metric in results_df.columns and results_df[metric].notna().any():\n                plotter.plot_sar_distribution_boxplot_single(results_df, metric=metric)\n        # Generate boxplots for psSAR10g metrics (symmetric with near-field)\n        pssar_columns = [col for col in results_df.columns if col.startswith(\"psSAR10g\")]\n        for metric in pssar_columns:\n            if results_df[metric].notna().any():\n                plotter.plot_sar_distribution_boxplot_single(results_df, metric=metric)\n\n    # Tissue group bar plots (symmetric with near-field: brain, eyes, skin, genitals)\n    if self.should_generate_plot(\"plot_average_sar_bar\"):\n        plotter.plot_average_sar_bar(\"environmental\", summary_stats, None, results_df)\n    if self.should_generate_plot(\"plot_average_pssar_bar\"):\n        plotter.plot_average_pssar_bar(\"environmental\", summary_stats, None, results_df)\n\n    # ============================================================================\n    # Far-field Direction vs Polarization Comparison (unique to far-field)\n    # ============================================================================\n    if self.should_generate_plot(\"plot_far_field_direction_polarization_summary\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating direction/polarization comparison heatmaps (frequency-averaged)...\",\n            extra={\"log_type\": \"info\"},\n        )\n        plotter.plot_far_field_direction_polarization_summary(results_df)\n\n    # Frequency-dependent line plots for direction/polarization comparison\n    if self.should_generate_plot(\"plot_far_field_direction_polarization_comparison\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating direction/polarization frequency-dependence comparison plots...\",\n            extra={\"log_type\": \"info\"},\n        )\n        plotter.plot_far_field_direction_polarization_comparison(results_df)\n\n    # ============================================================================\n    # Polarization Ratio Analysis (unique to far-field)\n    # ============================================================================\n    if self.should_generate_plot(\"plot_polarization_ratio\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating polarization ratio analysis plots...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Line plot: ratio vs frequency per direction (shows frequency evolution)\n        plotter.plot_polarization_ratio_lines(results_df)\n        # Frequency-averaged heatmap (quick overview)\n        plotter.plot_polarization_ratio_heatmap(results_df)\n        # Per-frequency heatmaps disabled due to memory concerns (9 figs per phantom)\n        # plotter.plot_polarization_ratio_heatmaps_per_frequency(results_df)\n\n    # ============================================================================\n    # Individual Variation Line Plots (one line per direction/polarization)\n    # ============================================================================\n    sar_columns_for_lines = [\"SAR_whole_body\", \"SAR_brain\", \"SAR_skin\", \"SAR_eyes\", \"SAR_genitals\"]\n    if self.should_generate_plot(\"plot_sar_line_individual_variations\"):\n        for metric_col in sar_columns_for_lines:\n            if metric_col in results_df.columns and results_df[metric_col].notna().any():\n                plotter.plot_sar_line_individual_variations(\n                    results_df,\n                    scenario_name=None,  # No scenario for far-field\n                    metric_column=metric_col,\n                )\n\n    # psSAR10g individual variation plots for tissue groups (symmetric with near-field)\n    pssar_columns = [col for col in results_df.columns if col.startswith(\"psSAR10g\")]\n    if self.should_generate_plot(\"plot_pssar_line_individual_variations\"):\n        for metric_col in pssar_columns:\n            if metric_col in results_df.columns and results_df[metric_col].notna().any():\n                plotter.plot_pssar_line_individual_variations(\n                    results_df,\n                    scenario_name=None,\n                    metric_column=metric_col,\n                )\n\n    # ============================================================================\n    # Heatmaps\n    # ============================================================================\n    # Check if required columns exist for full Min/Avg/Max heatmap (symmetric with NF)\n    required_cols = [\"min_local_sar_mw_kg\", \"mass_avg_sar_mw_kg\", \"max_local_sar_mw_kg\"]\n    missing_cols = [col for col in required_cols if col not in all_organ_results_df.columns]\n\n    if missing_cols:\n        logging.getLogger(\"progress\").warning(\n            f\"  - WARNING: Missing columns for full SAR heatmap: {missing_cols}. Using available columns.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        # Fallback: only use avg_sar if min/max not available\n        organ_sar_df = (\n            all_organ_results_df.groupby([\"tissue\", \"frequency_mhz\"]).agg(avg_sar=(\"mass_avg_sar_mw_kg\", \"mean\")).reset_index()\n        )\n    else:\n        # Full aggregation with min/avg/max (symmetric with NF)\n        organ_sar_df = (\n            all_organ_results_df.groupby([\"tissue\", \"frequency_mhz\"])\n            .agg(\n                min_sar=(\"min_local_sar_mw_kg\", \"mean\"),\n                avg_sar=(\"mass_avg_sar_mw_kg\", \"mean\"),\n                max_sar=(\"max_local_sar_mw_kg\", \"mean\"),\n            )\n            .reset_index()\n        )\n        # Drop rows where all SAR values are NA\n        organ_sar_df = organ_sar_df.dropna(subset=[\"min_sar\", \"avg_sar\", \"max_sar\"], how=\"all\")\n\n    organ_pssar_df = all_organ_results_df.groupby([\"tissue\", \"frequency_mhz\"])[\"peak_sar_10g_mw_kg\"].mean().reset_index()\n\n    group_summary_data = []\n    if analyzer.tissue_group_composition:\n        tissue_groups = {group_name: list(tissues) for group_name, tissues in analyzer.tissue_group_composition.items()}\n\n        for group_name, tissues in tissue_groups.items():\n            if not tissues:\n                continue\n            group_df = all_organ_results_df[all_organ_results_df[\"tissue\"].isin(tissues)]\n            if not group_df.empty:\n                summary = (\n                    group_df.groupby(\"frequency_mhz\")\n                    .agg(\n                        avg_sar=(\"mass_avg_sar_mw_kg\", \"mean\"),\n                        peak_sar_10g_mw_kg=(\"peak_sar_10g_mw_kg\", \"mean\"),\n                    )\n                    .reset_index()\n                )\n                summary[\"group\"] = group_name.replace(\"_group\", \"\").capitalize()\n                group_summary_data.append(summary)\n\n        group_summary_df = pd.concat(group_summary_data, ignore_index=True) if group_summary_data else pd.DataFrame()\n\n        if not group_summary_df.empty:\n            plotter_tissue_groups = {group_name: list(tissues) for group_name, tissues in analyzer.tissue_group_composition.items()}\n\n            if self.should_generate_plot(\"plot_peak_sar_heatmap\"):\n                plotter.plot_peak_sar_heatmap(\n                    pd.DataFrame(organ_sar_df),\n                    group_summary_df[[\"group\", \"frequency_mhz\", \"avg_sar\"]],\n                    plotter_tissue_groups,\n                    value_col=\"avg_sar\",\n                    title=\"Average SAR\",\n                )\n                plotter.plot_peak_sar_heatmap(\n                    pd.DataFrame(organ_pssar_df),\n                    group_summary_df[[\"group\", \"frequency_mhz\", \"peak_sar_10g_mw_kg\"]],\n                    plotter_tissue_groups,\n                    value_col=\"peak_sar_10g_mw_kg\",\n                    title=\"Peak SAR 10g\",\n                )\n            # SAR heatmap (symmetric with NF)\n            if self.should_generate_plot(\"plot_sar_heatmap\"):\n                plotter.plot_sar_heatmap(\n                    pd.DataFrame(organ_sar_df),\n                    group_summary_df[[\"group\", \"frequency_mhz\", \"avg_sar\"]],\n                    plotter_tissue_groups,\n                )\n\n    # ============================================================================\n    # SAR/psSAR Line Plots (symmetric with NF)\n    # ============================================================================\n    if self.should_generate_plot(\"plot_sar_line\"):\n        plotter.plot_sar_line(\"environmental\", summary_stats)\n    if self.should_generate_plot(\"plot_pssar_line\"):\n        plotter.plot_pssar_line(\"environmental\", summary_stats)\n\n    # ============================================================================\n    # SAR Distribution Boxplots (symmetric with NF)\n    # ============================================================================\n    if self.should_generate_plot(\"plot_sar_distribution_boxplots\"):\n        plotter.plot_sar_distribution_boxplots(\"environmental\", results_df)\n\n    # ============================================================================\n    # Power Balance Plots\n    # ============================================================================\n    if self.should_generate_plot(\"plot_power_balance_overview\"):\n        plotter.plot_power_balance_overview(results_df)\n    if self.should_generate_plot(\"plot_power_efficiency_trends\"):\n        plotter.plot_power_efficiency_trends(results_df, scenario_name=None)\n    if not all_organ_results_df.empty and self.should_generate_plot(\"plot_power_absorption_distribution\"):\n        if \"Total Loss\" in all_organ_results_df.columns:\n            plotter.plot_power_absorption_distribution(all_organ_results_df, scenario_name=None)\n        else:\n            logging.getLogger(\"progress\").warning(\n                \"  - WARNING: No 'Total Loss' data available for power absorption plot.\",\n                extra={\"log_type\": \"warning\"},\n            )\n\n    # ============================================================================\n    # Ranking Plots (Top 20 Tissues)\n    # ============================================================================\n    if not all_organ_results_df.empty and self.should_generate_plot(\"plot_top20_tissues_ranking\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating ranking plots (top 20 tissues)...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Top 20 by Max Local SAR (symmetric with near-field - same order as NF)\n        if \"max_local_sar_mw_kg\" in all_organ_results_df.columns:\n            plotter.plot_top20_tissues_ranking(all_organ_results_df, metric=\"max_local_sar_mw_kg\", scenario_name=None)\n        # Top 20 by Mass-Averaged SAR\n        plotter.plot_top20_tissues_ranking(all_organ_results_df, metric=\"mass_avg_sar_mw_kg\", scenario_name=None)\n        # Top 20 by Peak SAR 10g (far-field specific - peak_sar is the same as psSAR10g whole body)\n        if \"peak_sar_10g_mw_kg\" in all_organ_results_df.columns:\n            plotter.plot_top20_tissues_ranking(all_organ_results_df, metric=\"peak_sar_10g_mw_kg\", scenario_name=None)\n        # Top 20 by Total Loss (symmetric with near-field)\n        if \"Total Loss\" in all_organ_results_df.columns:\n            plotter.plot_top20_tissues_ranking(all_organ_results_df, metric=\"Total Loss\", scenario_name=None)\n\n    # ============================================================================\n    # CDF Plots\n    # ============================================================================\n    if self.should_generate_plot(\"plot_cdf\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating CDF plots...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Include both SAR and psSAR10g metrics for symmetry with near-field\n        sar_metrics = [col for col in results_df.columns if col.startswith(\"SAR_\")]\n        pssar_metrics = [col for col in results_df.columns if col.startswith(\"psSAR10g\")]\n        cdf_metrics = sar_metrics + pssar_metrics + ([\"peak_sar\"] if \"peak_sar\" in results_df.columns else [])\n        for metric in cdf_metrics:\n            if metric in results_df.columns and results_df[metric].notna().any():\n                # CDF grouped by frequency (symmetric with near-field per-scenario CDFs)\n                plotter.plot_cdf(results_df, metric, group_by=\"frequency_mhz\", scenario_name=None)\n\n        # Parse direction and polarization from placement for CDF grouping\n        # Add direction/polarization columns if not present\n        if \"direction\" not in results_df.columns or \"polarization\" not in results_df.columns:\n\n            def parse_placement(placement: str) -&gt; tuple:\n                direction_labels = {\n                    \"x_pos\": \"From left\",\n                    \"x_neg\": \"From right\",\n                    \"y_pos\": \"From back\",\n                    \"y_neg\": \"From front\",\n                    \"z_pos\": \"From below\",\n                    \"z_neg\": \"From above\",\n                }\n                parts = placement.replace(\"environmental_\", \"\").split(\"_\")\n                if len(parts) &gt;= 3:\n                    dir_key = f\"{parts[0]}_{parts[1]}\"\n                    direction = direction_labels.get(dir_key, f\"{parts[0]}{parts[1]}\")\n                    pol = \"Theta\" if parts[2] == \"theta\" else \"Phi\"\n                    return direction, pol\n                return placement, \"Unknown\"\n\n            results_df[[\"direction\", \"polarization\"]] = results_df[\"placement\"].apply(lambda x: pd.Series(parse_placement(x)))\n\n        # CDF grouped by direction (analogous to near-field per-scenario CDFs)\n        for metric in cdf_metrics:\n            if metric in results_df.columns and results_df[metric].notna().any():\n                plotter.plot_cdf(results_df, metric, group_by=\"direction\", scenario_name=None)\n\n        # CDF grouped by polarization\n        for metric in cdf_metrics:\n            if metric in results_df.columns and results_df[metric].notna().any():\n                plotter.plot_cdf(results_df, metric, group_by=\"polarization\", scenario_name=None)\n\n    # ============================================================================\n    # Correlation Plots\n    # ============================================================================\n    if self.should_generate_plot(\"plot_tissue_group_correlation_matrix\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating correlation matrix...\",\n            extra={\"log_type\": \"info\"},\n        )\n        plotter.plot_tissue_group_correlation_matrix(results_df, scenario_name=None)\n\n    # ============================================================================\n    # Bubble Plots (Mass vs SAR)\n    # ============================================================================\n    if not all_organ_results_df.empty and self.should_generate_plot(\"plot_bubble_mass_vs_sar\"):\n        if \"Total Mass\" in all_organ_results_df.columns:\n            logging.getLogger(\"progress\").info(\n                \"  - Generating bubble plots (mass vs SAR)...\",\n                extra={\"log_type\": \"info\"},\n            )\n            # Get unique frequencies for frequency-specific plots (symmetric with near-field)\n            frequencies = (\n                sorted(all_organ_results_df[\"frequency_mhz\"].dropna().unique())\n                if \"frequency_mhz\" in all_organ_results_df.columns\n                else []\n            )\n\n            # SAR columns to plot\n            sar_columns = [\"mass_avg_sar_mw_kg\"]\n            if \"peak_sar_10g_mw_kg\" in all_organ_results_df.columns:\n                sar_columns.append(\"peak_sar_10g_mw_kg\")\n            if \"max_local_sar_mw_kg\" in all_organ_results_df.columns:\n                sar_columns.append(\"max_local_sar_mw_kg\")\n\n            for sar_col in sar_columns:\n                # All frequencies combined\n                plotter.plot_bubble_mass_vs_sar(all_organ_results_df, sar_column=sar_col, scenario_name=None)\n\n                # Per-frequency variants (symmetric with near-field)\n                for freq in frequencies:\n                    plotter.plot_bubble_mass_vs_sar(\n                        all_organ_results_df,\n                        sar_column=sar_col,\n                        scenario_name=None,\n                        frequency_mhz=freq,\n                    )\n\n    # Interactive bubble plots (symmetric with NF)\n    if not all_organ_results_df.empty and self.should_generate_plot(\"plot_bubble_mass_vs_sar_interactive\"):\n        if \"Total Mass\" in all_organ_results_df.columns:\n            plotter.plot_bubble_mass_vs_sar_interactive(all_organ_results_df, sar_column=\"mass_avg_sar_mw_kg\", scenario_name=None)\n\n    # ============================================================================\n    # Penetration Depth Ratio (symmetric with NF)\n    # ============================================================================\n    if self.should_generate_plot(\"plot_penetration_depth_ratio\"):\n        # Pre-check columns for psSAR10g penetration ratio (symmetric with near-field)\n        if \"psSAR10g_brain\" in results_df.columns and \"psSAR10g_skin\" in results_df.columns:\n            plotter.plot_penetration_depth_ratio(results_df, scenario_name=None, metric_type=\"psSAR10g\")\n        # Pre-check columns for SAR penetration ratio (symmetric with near-field)\n        if \"SAR_brain\" in results_df.columns and \"SAR_skin\" in results_df.columns:\n            plotter.plot_penetration_depth_ratio(results_df, scenario_name=None, metric_type=\"SAR\")\n\n    # ============================================================================\n    # Max Local vs psSAR Scatter (symmetric with NF)\n    # ============================================================================\n    if not all_organ_results_df.empty and self.should_generate_plot(\"plot_max_local_vs_pssar10g_scatter\"):\n        if \"max_local_sar_mw_kg\" in all_organ_results_df.columns:\n            plotter.plot_max_local_vs_pssar10g_scatter(all_organ_results_df, scenario_name=None)\n        else:\n            logging.getLogger(\"progress\").warning(\n                \"  - WARNING: Missing 'max_local_sar_mw_kg' column for Max Local vs psSAR10g scatter plot.\",\n                extra={\"log_type\": \"warning\"},\n            )\n\n    # ============================================================================\n    # Tissue Analysis Plots\n    # ============================================================================\n    if not all_organ_results_df.empty:\n        # Tissue frequency response for top tissues\n        if self.should_generate_plot(\"plot_tissue_frequency_response\") and \"mass_avg_sar_mw_kg\" in all_organ_results_df.columns:\n            logging.getLogger(\"progress\").info(\n                \"  - Generating tissue frequency response plots...\",\n                extra={\"log_type\": \"info\"},\n            )\n            filtered_organs = all_organ_results_df[all_organ_results_df[\"tissue\"] != \"All Regions\"]\n            top_tissues = filtered_organs.groupby(\"tissue\")[\"mass_avg_sar_mw_kg\"].mean().nlargest(10).index.tolist()\n            for tissue in top_tissues:\n                plotter.plot_tissue_frequency_response(all_organ_results_df, tissue_name=tissue, scenario_name=None)\n        # Tissue mass/volume distribution (symmetric with NF)\n        if self.should_generate_plot(\"plot_tissue_mass_volume_distribution\"):\n            plotter.plot_tissue_mass_volume_distribution(all_organ_results_df, scenario_name=None)\n\n    # ============================================================================\n    # Spatial Plots (3D and 2D Peak Locations) - Symmetric with near-field\n    # ============================================================================\n    # Collect peak location data from all results (same as near-field)\n    peak_location_data = []\n    for result in analyzer.all_results:\n        if \"peak_sar_details\" in result:\n            peak_details = result[\"peak_sar_details\"]\n            if peak_details and isinstance(peak_details, dict):\n                peak_location_data.append(\n                    {\n                        \"PeakLocation\": peak_details.get(\"PeakLocation\", None),\n                        \"PeakCubeSideLength\": peak_details.get(\"PeakCubeSideLength\", None),\n                        \"PeakValue\": peak_details.get(\"PeakValue\", None),\n                        \"PeakCell\": peak_details.get(\"PeakCell\", None),\n                        \"placement\": result.get(\"placement\", \"\"),\n                        \"frequency_mhz\": result.get(\"frequency_mhz\", None),\n                        \"scenario\": result.get(\"scenario\", \"environmental\"),\n                    }\n                )\n\n    peak_location_df = pd.DataFrame(peak_location_data) if peak_location_data else pd.DataFrame()\n\n    if not peak_location_df.empty:\n        if self.should_generate_plot(\"plot_peak_location_3d_interactive\") or self.should_generate_plot(\n            \"plot_peak_location_2d_projections\"\n        ):\n            logging.getLogger(\"progress\").info(\n                \"  - Generating spatial plots (3D and 2D peak locations)...\",\n                extra={\"log_type\": \"info\"},\n            )\n\n            # Calculate consistent axis limits from all data\n            axis_limits = plotter.spatial._calculate_axis_limits(peak_location_df)\n\n            if self.should_generate_plot(\"plot_peak_location_3d_interactive\"):\n                plotter.plot_peak_location_3d_interactive(peak_location_df, scenario_name=None, axis_limits=axis_limits)\n\n            if self.should_generate_plot(\"plot_peak_location_2d_projections\"):\n                plotter.plot_peak_location_2d_projections(peak_location_df, scenario_name=None)\n\n    # ============================================================================\n    # Outlier Identification\n    # ============================================================================\n    if self.should_generate_plot(\"identify_outliers\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Identifying outliers...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Include both psSAR10g and SAR metrics for symmetry with near-field (psSAR10g first like NF)\n        pssar_outlier_metrics = [\n            \"psSAR10g_brain\",\n            \"psSAR10g_eyes\",\n            \"psSAR10g_skin\",\n            \"psSAR10g_genitals\",\n            \"psSAR10g_whole_body\",  # Added for symmetry with near-field\n        ]\n        sar_outlier_metrics = [\n            \"SAR_whole_body\",\n            \"peak_sar\",  # Far-field specific\n            \"SAR_brain\",\n            \"SAR_skin\",\n            \"SAR_eyes\",\n            \"SAR_genitals\",\n        ]\n        outlier_metrics = pssar_outlier_metrics + sar_outlier_metrics  # psSAR10g first like near-field\n        for metric in outlier_metrics:\n            if metric in results_df.columns and results_df[metric].notna().any():\n                outliers = plotter.identify_outliers(results_df, metric, scenario_name=None)\n                # Save CSV and log count (symmetric with near-field)\n                if outliers is not None and not outliers.empty:\n                    subdir = plotter._get_subdir(\"outliers\")\n                    filename = f\"outliers_{metric}.csv\"\n                    outliers.to_csv(os.path.join(subdir, filename), index=False)\n                    logging.getLogger(\"progress\").info(\n                        f\"    - Found {len(outliers)} outliers for {metric}\",\n                        extra={\"log_type\": \"info\"},\n                    )\n</code></pre>"},{"location":"reference/api_reference/#near-field-strategy","title":"Near Field Strategy","text":""},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy","title":"goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy","text":"<pre><code>NearFieldAnalysisStrategy(config: Config, phantom_name: str, analysis_config: dict | None = None)\n</code></pre> <p>               Bases: <code>BaseAnalysisStrategy</code></p> <p>Analysis strategy for near-field simulations.</p> <p>Handles result loading, normalization, and plot generation for near-field studies with placement scenarios, positions, and orientations.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Configuration object.</p> required <code>phantom_name</code> <code>str</code> <p>Phantom model name being analyzed.</p> required <code>analysis_config</code> <code>dict | None</code> <p>Optional dictionary with plot names as keys and boolean values.</p> <code>None</code> Source code in <code>goliat/analysis/near_field_strategy.py</code> <pre><code>def __init__(self, config: \"Config\", phantom_name: str, analysis_config: dict | None = None):\n    \"\"\"Initializes the near-field analysis strategy.\n\n    Args:\n        config: Configuration object.\n        phantom_name: Phantom model name being analyzed.\n        analysis_config: Optional dictionary with plot names as keys and boolean values.\n    \"\"\"\n    super().__init__(config, phantom_name, analysis_config)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy.get_results_base_dir","title":"get_results_base_dir","text":"<pre><code>get_results_base_dir() -&gt; str\n</code></pre> <p>Returns base directory for near-field results.</p> Source code in <code>goliat/analysis/near_field_strategy.py</code> <pre><code>def get_results_base_dir(self) -&gt; str:\n    \"\"\"Returns base directory for near-field results.\"\"\"\n    return os.path.join(self.base_dir, \"results\", \"near_field\", self.phantom_name)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy.get_plots_dir","title":"get_plots_dir","text":"<pre><code>get_plots_dir() -&gt; str\n</code></pre> <p>Returns directory for near-field plots.</p> Source code in <code>goliat/analysis/near_field_strategy.py</code> <pre><code>def get_plots_dir(self) -&gt; str:\n    \"\"\"Returns directory for near-field plots.\"\"\"\n    return os.path.join(self.base_dir, \"plots\", \"near_field\", self.phantom_name)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy.get_expected_item_count","title":"get_expected_item_count","text":"<pre><code>get_expected_item_count() -&gt; int\n</code></pre> <p>Returns expected number of progress items for this phantom.</p> <p>Returns the EXACT count of processing items (result files to be processed). If load_data is False (cache mode), returns 0 since no processing occurs. Plot items are not counted - the GUI handles this via dynamic maximum adjustment.</p> <p>Returns:</p> Type Description <code>int</code> <p>Exact number of result files that will trigger 'Processing:' log messages.</p> Source code in <code>goliat/analysis/near_field_strategy.py</code> <pre><code>def get_expected_item_count(self) -&gt; int:\n    \"\"\"Returns expected number of progress items for this phantom.\n\n    Returns the EXACT count of processing items (result files to be processed).\n    If load_data is False (cache mode), returns 0 since no processing occurs.\n    Plot items are not counted - the GUI handles this via dynamic maximum adjustment.\n\n    Returns:\n        Exact number of result files that will trigger 'Processing:' log messages.\n    \"\"\"\n    # If loading from cache, no \"Processing:\" messages are generated\n    if not self.analysis_config.get(\"load_data\", True):\n        return 0\n\n    antenna_config = self.config[\"antenna_config\"] or {}\n    placement_scenarios = self.config[\"placement_scenarios\"] or {}\n\n    num_frequencies = len(antenna_config)\n    num_placements = 0\n    for scenario_def in placement_scenarios.values():\n        if scenario_def:\n            positions = scenario_def.get(\"positions\", {})\n            orientations = scenario_def.get(\"orientations\", {})\n            num_placements += len(positions) * max(len(orientations), 1)\n\n    # Exact count: one progress item per result file processed\n    return num_frequencies * num_placements\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy.load_and_process_results","title":"load_and_process_results","text":"<pre><code>load_and_process_results(analyzer: Analyzer)\n</code></pre> <p>Iterates through near-field results and processes each one.</p> Source code in <code>goliat/analysis/near_field_strategy.py</code> <pre><code>def load_and_process_results(self, analyzer: \"Analyzer\"):\n    \"\"\"Iterates through near-field results and processes each one.\"\"\"\n    antenna_config = self.config[\"antenna_config\"] or {}\n    if not antenna_config:\n        return\n    frequencies = antenna_config.keys()\n    placement_scenarios = self.config[\"placement_scenarios\"]\n    if not placement_scenarios:\n        return\n\n    for freq in frequencies:\n        frequency_mhz = int(freq)\n        for scenario_name, scenario_def in placement_scenarios.items():\n            if not scenario_def:\n                continue\n            positions = scenario_def.get(\"positions\", {})\n            orientations = scenario_def.get(\"orientations\", {})\n            if not positions or not orientations:\n                continue\n            for pos_name in positions.keys():\n                for orient_name in orientations.keys():\n                    analyzer._process_single_result(frequency_mhz, scenario_name, pos_name, orient_name)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy.get_normalization_factor","title":"get_normalization_factor","text":"<pre><code>get_normalization_factor(frequency_mhz: int, simulated_power_w: float) -&gt; float\n</code></pre> <p>Calculates the normalization factor based on the target power.</p> <p>Parameters:</p> Name Type Description Default <code>frequency_mhz</code> <code>int</code> <p>The simulation frequency in MHz.</p> required <code>simulated_power_w</code> <code>float</code> <p>The input power from the simulation in Watts.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The calculated normalization factor, or 1.0 if not possible.</p> Source code in <code>goliat/analysis/near_field_strategy.py</code> <pre><code>def get_normalization_factor(self, frequency_mhz: int, simulated_power_w: float) -&gt; float:\n    \"\"\"Calculates the normalization factor based on the target power.\n\n    Args:\n        frequency_mhz: The simulation frequency in MHz.\n        simulated_power_w: The input power from the simulation in Watts.\n\n    Returns:\n        The calculated normalization factor, or 1.0 if not possible.\n    \"\"\"\n    antenna_configs = self.config[\"antenna_config\"] or {}\n    freq_config = antenna_configs.get(str(frequency_mhz), {})\n    target_power_mw = freq_config.get(\"target_power_mW\")\n    if target_power_mw is not None and pd.notna(simulated_power_w) and simulated_power_w &gt; 0:\n        target_power_w = target_power_mw / 1000.0\n        return target_power_w / simulated_power_w\n    return 1.0\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy.extract_data","title":"extract_data","text":"<pre><code>extract_data(pickle_data: dict, frequency_mhz: int, placement_name: str, scenario_name: str, sim_power: float, norm_factor: float, sar_results: dict | None = None) -&gt; tuple[dict, list]\n</code></pre> <p>Extracts and normalizes SAR data from a single near-field result.</p> <p>Parameters:</p> Name Type Description Default <code>pickle_data</code> <code>dict</code> <p>Data loaded from the .pkl result file.</p> required <code>frequency_mhz</code> <code>int</code> <p>The simulation frequency.</p> required <code>placement_name</code> <code>str</code> <p>The detailed name of the placement.</p> required <code>scenario_name</code> <code>str</code> <p>The general scenario name (e.g., 'by_cheek').</p> required <code>sim_power</code> <code>float</code> <p>The simulated input power in Watts.</p> required <code>norm_factor</code> <code>float</code> <p>The normalization factor to apply to SAR values.</p> required <code>sar_results</code> <code>dict | None</code> <p>Optional JSON results dict containing power balance data.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[dict, list]</code> <p>A tuple containing the main result entry and a list of organ-specific entries.</p> Source code in <code>goliat/analysis/near_field_strategy.py</code> <pre><code>def extract_data(\n    self,\n    pickle_data: dict,\n    frequency_mhz: int,\n    placement_name: str,\n    scenario_name: str,\n    sim_power: float,\n    norm_factor: float,\n    sar_results: dict | None = None,\n) -&gt; tuple[dict, list]:\n    \"\"\"Extracts and normalizes SAR data from a single near-field result.\n\n    Args:\n        pickle_data: Data loaded from the .pkl result file.\n        frequency_mhz: The simulation frequency.\n        placement_name: The detailed name of the placement.\n        scenario_name: The general scenario name (e.g., 'by_cheek').\n        sim_power: The simulated input power in Watts.\n        norm_factor: The normalization factor to apply to SAR values.\n        sar_results: Optional JSON results dict containing power balance data.\n\n    Returns:\n        A tuple containing the main result entry and a list of organ-specific entries.\n    \"\"\"\n    summary_results = pickle_data.get(\"summary_results\", {})\n    grouped_stats = pickle_data.get(\"grouped_sar_stats\", {})\n    detailed_df = pickle_data.get(\"detailed_sar_stats\")\n\n    # Check bounding_box setting from config to determine which SAR fields are valid\n    placement_scenarios = self.config[\"placement_scenarios\"] or {}\n    scenario_config = placement_scenarios.get(scenario_name, {}) if isinstance(placement_scenarios, dict) else {}\n    bounding_box_setting = scenario_config.get(\"bounding_box\", \"default\")\n\n    # Extract SAR values - prioritize JSON over pickle, and respect bounding_box setting\n    sar_head = pd.NA\n    sar_trunk = pd.NA\n    sar_whole_body = pd.NA\n\n    # If whole_body bounding box, only use whole_body_sar (ignore head/trunk from old pickle files)\n    if bounding_box_setting == \"whole_body\":\n        # Prefer JSON, fallback to pickle\n        sar_whole_body = sar_results.get(\"whole_body_sar\", pd.NA) if sar_results else pd.NA\n        if pd.isna(sar_whole_body):\n            sar_whole_body = summary_results.get(\"whole_body_sar\", pd.NA)\n    else:\n        # For head/trunk/default bounding boxes, extract head/trunk SAR\n        # Prefer JSON, fallback to pickle\n        if sar_results:\n            sar_head = sar_results.get(\"head_SAR\", pd.NA)\n            sar_trunk = sar_results.get(\"trunk_SAR\", pd.NA)\n        if pd.isna(sar_head):\n            sar_head = summary_results.get(\"head_SAR\", pd.NA)\n        if pd.isna(sar_trunk):\n            sar_trunk = summary_results.get(\"trunk_SAR\", pd.NA)\n\n        # Also check for whole_body_sar (might exist from old data)\n        if sar_results:\n            sar_whole_body = sar_results.get(\"whole_body_sar\", pd.NA)\n        if pd.isna(sar_whole_body):\n            sar_whole_body = summary_results.get(\"whole_body_sar\", pd.NA)\n\n    result_entry = {\n        \"frequency_mhz\": frequency_mhz,\n        \"placement\": placement_name,\n        \"scenario\": scenario_name,\n        \"input_power_w\": sim_power,\n        \"SAR_head\": sar_head * norm_factor if pd.notna(sar_head) else pd.NA,\n        \"SAR_trunk\": sar_trunk * norm_factor if pd.notna(sar_trunk) else pd.NA,\n        \"SAR_whole_body\": sar_whole_body * norm_factor if pd.notna(sar_whole_body) else pd.NA,\n    }\n    for group_name, stats in grouped_stats.items():\n        key = f\"psSAR10g_{group_name.replace('_group', '')}\"\n        result_entry[key] = stats.get(\"peak_sar\", pd.NA) * norm_factor\n\n    # Extract power balance data if available\n    power_balance = None\n    if sar_results and \"power_balance\" in sar_results:\n        power_balance = sar_results[\"power_balance\"]\n    elif summary_results and \"power_balance\" in summary_results:\n        power_balance = summary_results[\"power_balance\"]\n\n    if power_balance:\n        result_entry[\"power_balance_pct\"] = power_balance.get(\"Balance\", pd.NA)\n        result_entry[\"power_pin_W\"] = power_balance.get(\"Pin\", pd.NA)\n        result_entry[\"power_diel_loss_W\"] = power_balance.get(\"DielLoss\", pd.NA)\n        result_entry[\"power_rad_W\"] = power_balance.get(\"RadPower\", pd.NA)\n        result_entry[\"power_sibc_loss_W\"] = power_balance.get(\"SIBCLoss\", pd.NA)\n\n    organ_entries = []\n    if detailed_df is not None:\n        peak_sar_col = \"Peak Spatial-Average SAR[IEEE/IEC62704-1] (10g)\"\n        for _, row in detailed_df.iterrows():\n            organ_entry = {\n                \"frequency_mhz\": frequency_mhz,\n                \"placement\": placement_name,\n                \"scenario\": scenario_name,\n                \"tissue\": _clean_tissue_name(row[\"Tissue\"]),  # Clean tissue name early\n                \"mass_avg_sar_mw_kg\": row[\"Mass-Averaged SAR\"] * norm_factor * 1000,\n                \"peak_sar_10g_mw_kg\": row.get(peak_sar_col, pd.NA) * norm_factor * 1000\n                if pd.notna(row.get(peak_sar_col, pd.NA))\n                else pd.NA,\n                \"min_local_sar_mw_kg\": row.get(\"Min. local SAR\", pd.NA) * norm_factor * 1000\n                if pd.notna(row.get(\"Min. local SAR\", pd.NA))\n                else pd.NA,\n                \"max_local_sar_mw_kg\": row.get(\"Max. local SAR\", pd.NA) * norm_factor * 1000\n                if pd.notna(row.get(\"Max. local SAR\", pd.NA))\n                else pd.NA,\n            }\n            # Add Total Mass, Total Volume, Total Loss, Max Loss Power Density if available\n            if \"Total Mass\" in row.index:\n                organ_entry[\"Total Mass\"] = row[\"Total Mass\"]\n            if \"Total Volume\" in row.index:\n                organ_entry[\"Total Volume\"] = row[\"Total Volume\"]\n            if \"Total Loss\" in row.index:\n                organ_entry[\"Total Loss\"] = row[\"Total Loss\"]\n            if \"Max Loss Power Density\" in row.index:\n                organ_entry[\"Max Loss Power Density\"] = row[\"Max Loss Power Density\"]\n            # Add psSAR10g column name for compatibility\n            if peak_sar_col in row.index and pd.notna(row[peak_sar_col]):\n                organ_entry[\"psSAR10g\"] = row[peak_sar_col] * norm_factor * 1000\n            organ_entries.append(organ_entry)\n    return result_entry, organ_entries\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy.apply_bug_fixes","title":"apply_bug_fixes","text":"<pre><code>apply_bug_fixes(result_entry: dict) -&gt; dict\n</code></pre> <p>Applies a workaround for Head SAR being miscategorized as Trunk SAR.</p> <p>NOTE: This method is deprecated for whole_body bounding box scenarios. For whole_body scenarios, SAR_head and SAR_trunk should remain NA.</p> <p>Parameters:</p> Name Type Description Default <code>result_entry</code> <code>dict</code> <p>The data entry for a single simulation result.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>The corrected result entry.</p> Source code in <code>goliat/analysis/near_field_strategy.py</code> <pre><code>def apply_bug_fixes(self, result_entry: dict) -&gt; dict:\n    \"\"\"Applies a workaround for Head SAR being miscategorized as Trunk SAR.\n\n    NOTE: This method is deprecated for whole_body bounding box scenarios.\n    For whole_body scenarios, SAR_head and SAR_trunk should remain NA.\n\n    Args:\n        result_entry: The data entry for a single simulation result.\n\n    Returns:\n        The corrected result entry.\n    \"\"\"\n    # Skip bug fix if whole_body_sar is present (indicates whole_body bounding box)\n    if pd.notna(result_entry.get(\"SAR_whole_body\")):\n        # For whole_body scenarios, ensure head/trunk are NA\n        result_entry[\"SAR_head\"] = pd.NA\n        result_entry[\"SAR_trunk\"] = pd.NA\n        return result_entry\n\n    # Original bug fix logic for head/trunk bounding boxes\n    placement = result_entry.get(\"placement\", \"\").lower()\n    if placement.startswith(\"front_of_eyes\") or placement.startswith(\"by_cheek\"):\n        sar_head = result_entry.get(\"SAR_head\")\n        sar_trunk = result_entry.get(\"SAR_trunk\")\n        if bool(pd.isna(sar_head)) and bool(pd.notna(sar_trunk)):\n            result_entry[\"SAR_head\"] = sar_trunk\n            result_entry[\"SAR_trunk\"] = pd.NA\n    return result_entry\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy.calculate_summary_stats","title":"calculate_summary_stats","text":"<pre><code>calculate_summary_stats(results_df: DataFrame) -&gt; pd.DataFrame\n</code></pre> <p>Calculates summary statistics, including completion progress.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with all aggregated simulation results.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame with mean SAR values and a 'progress' column.</p> Source code in <code>goliat/analysis/near_field_strategy.py</code> <pre><code>def calculate_summary_stats(self, results_df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Calculates summary statistics, including completion progress.\n\n    Args:\n        results_df: DataFrame with all aggregated simulation results.\n\n    Returns:\n        A DataFrame with mean SAR values and a 'progress' column.\n    \"\"\"\n    placement_scenarios = self.config[\"placement_scenarios\"]\n    placements_per_scenario = {}\n    logging.getLogger(\"progress\").info(\n        \"\\n--- Calculating Total Possible Placements per Scenario ---\",\n        extra={\"log_type\": \"header\"},\n    )\n    if placement_scenarios:\n        for name, definition in placement_scenarios.items():\n            if not definition:\n                continue\n            total = len(definition.get(\"positions\", {})) * len(definition.get(\"orientations\", {}))\n            placements_per_scenario[name] = total\n            logging.getLogger(\"progress\").info(f\"- Scenario '{name}': {total} placements\", extra={\"log_type\": \"info\"})\n\n    summary_stats = results_df.groupby([\"scenario\", \"frequency_mhz\"]).mean(numeric_only=True)\n    completion_counts = results_df.groupby([\"scenario\", \"frequency_mhz\"]).size()\n\n    # Define a mapping function that safely handles potential missing keys\n    def get_progress(idx):\n        \"\"\"Return 'completed/total' string for a (scenario, freq) index.\"\"\"\n        # Index is a tuple (scenario, frequency)\n        if isinstance(idx, tuple) and len(idx) == 2:\n            scenario_name, _ = idx\n        else:\n            scenario_name = idx\n        completed = completion_counts.get(idx, 0)\n        total = placements_per_scenario.get(scenario_name, 0)\n        return f\"{completed}/{total}\"\n\n    if not summary_stats.empty:\n        summary_stats[\"progress\"] = summary_stats.index.map(get_progress)  # type: ignore\n    return pd.DataFrame(summary_stats)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.near_field_strategy.NearFieldAnalysisStrategy.generate_plots","title":"generate_plots","text":"<pre><code>generate_plots(analyzer: Analyzer, plotter: Plotter, results_df: DataFrame, all_organ_results_df: DataFrame)\n</code></pre> <p>Generates all plots for the near-field analysis.</p> <p>Includes bar charts for average SAR, line plots for psSAR, and boxplots for SAR distribution.</p> <p>Parameters:</p> Name Type Description Default <code>analyzer</code> <code>Analyzer</code> <p>The main analyzer instance.</p> required <code>plotter</code> <code>Plotter</code> <p>The plotter instance for generating plots.</p> required <code>results_df</code> <code>DataFrame</code> <p>DataFrame with main aggregated results.</p> required <code>all_organ_results_df</code> <code>DataFrame</code> <p>DataFrame with detailed organ-level results.</p> required Source code in <code>goliat/analysis/near_field_strategy.py</code> <pre><code>def generate_plots(\n    self,\n    analyzer: \"Analyzer\",\n    plotter: \"Plotter\",\n    results_df: pd.DataFrame,\n    all_organ_results_df: pd.DataFrame,\n):\n    \"\"\"Generates all plots for the near-field analysis.\n\n    Includes bar charts for average SAR, line plots for psSAR, and boxplots\n    for SAR distribution.\n\n    Args:\n        analyzer: The main analyzer instance.\n        plotter: The plotter instance for generating plots.\n        results_df: DataFrame with main aggregated results.\n        all_organ_results_df: DataFrame with detailed organ-level results.\n    \"\"\"\n    # Aggregate organ-level SAR by tissue groups and merge into results_df\n    # Uses tissue_group_composition from pickle files if available\n    results_df = self._add_tissue_group_sar(results_df, all_organ_results_df, analyzer)\n\n    scenarios_with_results = results_df[\"scenario\"].unique()\n    summary_stats = self.calculate_summary_stats(results_df)\n\n    # ============================================================================\n    # Aggregated Plots (symmetric with far-field)\n    # ============================================================================\n    # These plots aggregate data across ALL scenarios for overall trends\n    if self.should_generate_plot(\"plot_whole_body_sar_bar\"):\n        # Aggregate summary stats across scenarios by frequency\n        freq_summary = summary_stats.groupby(\"frequency_mhz\").mean(numeric_only=True)\n        if \"SAR_whole_body\" in freq_summary.columns:\n            plotter.plot_whole_body_sar_bar(freq_summary)\n\n    if self.should_generate_plot(\"plot_peak_sar_line\"):\n        # Aggregate summary stats across scenarios by frequency\n        freq_summary = summary_stats.groupby(\"frequency_mhz\").mean(numeric_only=True)\n        if \"peak_sar\" in freq_summary.columns:\n            plotter.plot_peak_sar_line(freq_summary)\n\n    for scenario_name in scenarios_with_results:\n        logging.getLogger(\"progress\").info(\n            f\"\\n--- Generating plots for scenario: {scenario_name} ---\",\n            extra={\"log_type\": \"header\"},\n        )\n        scenario_results_df = results_df[results_df[\"scenario\"] == scenario_name]\n        if scenario_name in summary_stats.index:\n            scenario_summary_stats = summary_stats.loc[scenario_name]\n            avg_results = scenario_summary_stats.drop(columns=[\"progress\"])\n            progress_info = scenario_summary_stats[\"progress\"]\n            if self.should_generate_plot(\"plot_average_sar_bar\"):\n                plotter.plot_average_sar_bar(scenario_name, pd.DataFrame(avg_results), pd.Series(progress_info), scenario_results_df)\n            if self.should_generate_plot(\"plot_average_pssar_bar\"):\n                plotter.plot_average_pssar_bar(scenario_name, pd.DataFrame(avg_results), pd.Series(progress_info), scenario_results_df)\n            if self.should_generate_plot(\"plot_sar_line\"):\n                plotter.plot_sar_line(scenario_name, pd.DataFrame(avg_results))\n            if self.should_generate_plot(\"plot_pssar_line\"):\n                plotter.plot_pssar_line(scenario_name, pd.DataFrame(avg_results))\n        if self.should_generate_plot(\"plot_sar_distribution_boxplots\"):\n            plotter.plot_sar_distribution_boxplots(scenario_name, pd.DataFrame(scenario_results_df))\n\n        # Individual variation line plots (one line per placement/direction/polarization)\n        # Include all SAR and psSAR10g metrics for symmetry\n        pssar_columns = [col for col in scenario_results_df.columns if col.startswith(\"psSAR10g\")]\n        sar_columns_for_lines = [\"SAR_head\", \"SAR_trunk\", \"SAR_whole_body\", \"SAR_brain\", \"SAR_skin\", \"SAR_eyes\", \"SAR_genitals\"]\n        # Plot SAR metrics using SAR-specific function\n        if self.should_generate_plot(\"plot_sar_line_individual_variations\"):\n            for metric_col in sar_columns_for_lines:\n                if metric_col in scenario_results_df.columns:\n                    plotter.plot_sar_line_individual_variations(\n                        results_df,\n                        scenario_name=scenario_name,\n                        metric_column=metric_col,\n                    )\n        # Plot psSAR10g metrics using psSAR10g-specific function\n        if self.should_generate_plot(\"plot_pssar_line_individual_variations\"):\n            for metric_col in pssar_columns:\n                if metric_col in scenario_results_df.columns:\n                    plotter.plot_pssar_line_individual_variations(\n                        results_df,\n                        scenario_name=scenario_name,\n                        metric_column=metric_col,\n                    )\n\n    # Generate heatmap with all tissues (Min/Avg/Max SAR)\n    if not all_organ_results_df.empty and analyzer.tissue_group_composition:\n        # Check if required columns exist\n        required_cols = [\"min_local_sar_mw_kg\", \"mass_avg_sar_mw_kg\", \"max_local_sar_mw_kg\"]\n        missing_cols = [col for col in required_cols if col not in all_organ_results_df.columns]\n\n        if missing_cols:\n            logging.getLogger(\"progress\").warning(\n                f\"  - WARNING: Missing columns for SAR heatmap: {missing_cols}. Skipping heatmap.\",\n                extra={\"log_type\": \"warning\"},\n            )\n        else:\n            # Prepare organ-level data with min/avg/max SAR\n            # Aggregate across all placements to get mean values per tissue and frequency\n            organ_sar_df = (\n                all_organ_results_df.groupby([\"tissue\", \"frequency_mhz\"])\n                .agg(\n                    min_sar=(\"min_local_sar_mw_kg\", \"mean\"),\n                    avg_sar=(\"mass_avg_sar_mw_kg\", \"mean\"),\n                    max_sar=(\"max_local_sar_mw_kg\", \"mean\"),\n                )\n                .reset_index()\n            )\n\n            # Drop rows where all SAR values are NA (pandas mean() returns NaN if all values are NaN)\n            organ_sar_df = organ_sar_df.dropna(subset=[\"min_sar\", \"avg_sar\", \"max_sar\"], how=\"all\")\n\n            # Prepare group-level summary data\n            tissue_groups = {group_name: list(tissues) for group_name, tissues in analyzer.tissue_group_composition.items()}\n\n            group_summary_data = []\n            for group_name, tissues in tissue_groups.items():\n                if not tissues:\n                    continue\n\n                # Filter organs belonging to this group\n                group_df = all_organ_results_df[all_organ_results_df[\"tissue\"].isin(tissues)]\n\n                if not group_df.empty:\n                    summary = group_df.groupby(\"frequency_mhz\").agg(avg_sar=(\"mass_avg_sar_mw_kg\", \"mean\")).reset_index()\n                    summary[\"group\"] = group_name.replace(\"_group\", \"\").capitalize()\n                    group_summary_data.append(summary)\n\n            group_summary_df = pd.concat(group_summary_data, ignore_index=True) if group_summary_data else pd.DataFrame()\n\n            if not organ_sar_df.empty and not group_summary_df.empty:\n                # Use tissue_group_composition for plotter (convert sets to lists)\n                plotter_tissue_groups = {group_name: list(tissues) for group_name, tissues in analyzer.tissue_group_composition.items()}\n\n                if self.should_generate_plot(\"plot_sar_heatmap\"):\n                    logging.getLogger(\"progress\").info(\n                        \"\\n--- Generating SAR heatmap (all tissues) ---\",\n                        extra={\"log_type\": \"header\"},\n                    )\n                    plotter.plot_sar_heatmap(\n                        pd.DataFrame(organ_sar_df),\n                        pd.DataFrame(group_summary_df),\n                        plotter_tissue_groups,\n                    )\n\n                # Also generate psSAR10g heatmap if data is available\n                if \"peak_sar_10g_mw_kg\" in all_organ_results_df.columns and self.should_generate_plot(\"plot_peak_sar_heatmap\"):\n                    organ_pssar_df = (\n                        all_organ_results_df.groupby([\"tissue\", \"frequency_mhz\"])\n                        .agg(peak_sar_10g_mw_kg=(\"peak_sar_10g_mw_kg\", \"mean\"))\n                        .reset_index()\n                    )\n                    organ_pssar_df = plotter._filter_all_regions(organ_pssar_df, tissue_column=\"tissue\")\n\n                    group_pssar_summary_data = []\n                    for group_name, tissues in tissue_groups.items():\n                        if not tissues:\n                            continue\n                        group_df = all_organ_results_df[all_organ_results_df[\"tissue\"].isin(tissues)]\n                        if not group_df.empty:\n                            summary = (\n                                group_df.groupby(\"frequency_mhz\").agg(peak_sar_10g_mw_kg=(\"peak_sar_10g_mw_kg\", \"mean\")).reset_index()\n                            )\n                            summary[\"group\"] = group_name.replace(\"_group\", \"\").capitalize()\n                            group_pssar_summary_data.append(summary)\n\n                    group_pssar_summary_df = (\n                        pd.concat(group_pssar_summary_data, ignore_index=True) if group_pssar_summary_data else pd.DataFrame()\n                    )\n\n                    if not organ_pssar_df.empty and not group_pssar_summary_df.empty:\n                        if self.should_generate_plot(\"plot_peak_sar_heatmap\"):\n                            logging.getLogger(\"progress\").info(\n                                \"\\n--- Generating psSAR10g heatmap (all tissues) ---\",\n                                extra={\"log_type\": \"header\"},\n                            )\n                            plotter.plot_peak_sar_heatmap(\n                                pd.DataFrame(organ_pssar_df),\n                                pd.DataFrame(group_pssar_summary_df),\n                                plotter_tissue_groups,\n                                value_col=\"peak_sar_10g_mw_kg\",\n                                title=\"Peak SAR 10g\",\n                            )\n            else:\n                logging.getLogger(\"progress\").warning(\n                    \"  - WARNING: Insufficient data for SAR heatmap (empty organ or group data).\",\n                    extra={\"log_type\": \"warning\"},\n                )\n\n    # Generate power balance plots for all results\n    if self.should_generate_plot(\"plot_power_balance_overview\"):\n        plotter.plot_power_balance_overview(results_df)\n\n    # ============================================================================\n    # Additional Analysis Plots\n    # ============================================================================\n\n    logging.getLogger(\"progress\").info(\n        \"\\n--- Generating additional analysis plots ---\",\n        extra={\"log_type\": \"header\"},\n    )\n\n    # Collect peak location data from all results\n    peak_location_data = []\n    for result in analyzer.all_results:\n        if \"peak_sar_details\" in result:\n            peak_details = result[\"peak_sar_details\"]\n            if peak_details and isinstance(peak_details, dict):\n                peak_location_data.append(\n                    {\n                        \"PeakLocation\": peak_details.get(\"PeakLocation\", None),\n                        \"PeakCubeSideLength\": peak_details.get(\"PeakCubeSideLength\", None),\n                        \"PeakValue\": peak_details.get(\"PeakValue\", None),\n                        \"PeakCell\": peak_details.get(\"PeakCell\", None),\n                        \"placement\": result.get(\"placement\", \"\"),\n                        \"frequency_mhz\": result.get(\"frequency_mhz\", None),\n                        \"scenario\": result.get(\"scenario\", \"\"),\n                    }\n                )\n\n    peak_location_df = pd.DataFrame(peak_location_data) if peak_location_data else pd.DataFrame()\n\n    # ============================================================================\n    # Spatial Plots\n    # ============================================================================\n    if not peak_location_df.empty:\n        if self.should_generate_plot(\"plot_peak_location_3d_interactive\") or self.should_generate_plot(\n            \"plot_peak_location_2d_projections\"\n        ):\n            logging.getLogger(\"progress\").info(\n                \"  - Generating spatial plots (3D and 2D peak locations)...\",\n                extra={\"log_type\": \"info\"},\n            )\n            # First create aggregated plot with all scenarios\n            # Calculate axis limits from all data\n            axis_limits = plotter.spatial._calculate_axis_limits(peak_location_df)\n            # Create aggregated plot\n            if self.should_generate_plot(\"plot_peak_location_3d_interactive\"):\n                plotter.plot_peak_location_3d_interactive(peak_location_df, scenario_name=None, axis_limits=axis_limits)\n\n            # Per-scenario spatial plots with inherited axis limits\n            for scenario in peak_location_df[\"scenario\"].unique():\n                scenario_peak_data = peak_location_df[peak_location_df[\"scenario\"] == scenario].copy()\n                if not scenario_peak_data.empty and self.should_generate_plot(\"plot_peak_location_3d_interactive\"):\n                    plotter.plot_peak_location_3d_interactive(scenario_peak_data, scenario_name=scenario, axis_limits=axis_limits)\n                if self.should_generate_plot(\"plot_peak_location_2d_projections\"):\n                    plotter.plot_peak_location_2d_projections(peak_location_df, scenario_name=scenario)\n\n    # ============================================================================\n    # Correlation Plots\n    # ============================================================================\n    if self.should_generate_plot(\"plot_correlation_head_vs_eye_sar\") or self.should_generate_plot(\n        \"plot_tissue_group_correlation_matrix\"\n    ):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating correlation plots...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Head vs Eye SAR correlation (for front_of_eyes scenario)\n        if \"front_of_eyes\" in scenarios_with_results and self.should_generate_plot(\"plot_correlation_head_vs_eye_sar\"):\n            plotter.plot_correlation_head_vs_eye_sar(results_df, scenario_name=\"front_of_eyes\")\n        # Tissue group correlation matrix (per scenario only - averaging across scenarios doesn't make sense)\n        if self.should_generate_plot(\"plot_tissue_group_correlation_matrix\"):\n            for scenario in scenarios_with_results:\n                plotter.plot_tissue_group_correlation_matrix(results_df, scenario_name=scenario)\n\n    # ============================================================================\n    # Bubble Plots (Mass vs SAR)\n    # ============================================================================\n    if not all_organ_results_df.empty and (\n        self.should_generate_plot(\"plot_bubble_mass_vs_sar\") or self.should_generate_plot(\"plot_bubble_mass_vs_sar_interactive\")\n    ):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating bubble plots (mass vs SAR)...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Note: Total Mass, Total Volume, etc. should be included in organ_entries from extract_data\n\n        # Get unique frequencies for frequency-specific plots\n        frequencies = (\n            sorted(all_organ_results_df[\"frequency_mhz\"].dropna().unique()) if \"frequency_mhz\" in all_organ_results_df.columns else []\n        )\n\n        # SAR columns to plot\n        sar_columns = [\"mass_avg_sar_mw_kg\"]\n        if \"psSAR10g\" in all_organ_results_df.columns:\n            sar_columns.append(\"psSAR10g\")\n        elif \"peak_sar_10g_mw_kg\" in all_organ_results_df.columns:\n            all_organ_results_df[\"psSAR10g\"] = all_organ_results_df[\"peak_sar_10g_mw_kg\"]\n            sar_columns.append(\"psSAR10g\")\n        if \"max_local_sar_mw_kg\" in all_organ_results_df.columns:\n            sar_columns.append(\"max_local_sar_mw_kg\")\n\n        for sar_col in sar_columns:\n            # Per-scenario variants only (averaging across scenarios doesn't make sense)\n            for scenario in scenarios_with_results:\n                # Per-scenario (all frequencies)\n                if self.should_generate_plot(\"plot_bubble_mass_vs_sar\"):\n                    plotter.plot_bubble_mass_vs_sar(\n                        all_organ_results_df,\n                        sar_column=sar_col,\n                        scenario_name=scenario,\n                    )\n\n                    # Per-scenario AND per-frequency variants\n                    for freq in frequencies:\n                        plotter.plot_bubble_mass_vs_sar(\n                            all_organ_results_df,\n                            sar_column=sar_col,\n                            scenario_name=scenario,\n                            frequency_mhz=freq,\n                        )\n\n                # Interactive plot per scenario\n                if self.should_generate_plot(\"plot_bubble_mass_vs_sar_interactive\"):\n                    plotter.plot_bubble_mass_vs_sar_interactive(\n                        all_organ_results_df,\n                        sar_column=sar_col,\n                        scenario_name=scenario,\n                    )\n\n    # ============================================================================\n    # Ranking Plots\n    # ============================================================================\n    if not all_organ_results_df.empty and self.should_generate_plot(\"plot_top20_tissues_ranking\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating ranking plots (top 20 tissues)...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Per-scenario variants only (averaging across scenarios doesn't make sense)\n        for scenario in scenarios_with_results:\n            if \"max_local_sar_mw_kg\" in all_organ_results_df.columns:\n                plotter.plot_top20_tissues_ranking(\n                    all_organ_results_df,\n                    metric=\"max_local_sar_mw_kg\",\n                    scenario_name=scenario,\n                )\n            # Top 20 by Mass-Averaged SAR\n            plotter.plot_top20_tissues_ranking(\n                all_organ_results_df,\n                metric=\"mass_avg_sar_mw_kg\",\n                scenario_name=scenario,\n            )\n            # Top 20 by Total Loss (if available)\n            if \"Total Loss\" in all_organ_results_df.columns:\n                plotter.plot_top20_tissues_ranking(\n                    all_organ_results_df,\n                    metric=\"Total Loss\",\n                    scenario_name=scenario,\n                )\n\n    # ============================================================================\n    # Power Plots\n    # ============================================================================\n    if self.should_generate_plot(\"plot_power_efficiency_trends\") or self.should_generate_plot(\"plot_power_absorption_distribution\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating power analysis plots...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Power efficiency trends (per scenario only - averaging across scenarios doesn't make sense)\n        if self.should_generate_plot(\"plot_power_efficiency_trends\"):\n            for scenario in scenarios_with_results:\n                plotter.plot_power_efficiency_trends(results_df, scenario_name=scenario)\n\n        # Power absorption distribution (per scenario only - averaging across scenarios doesn't make sense)\n        if self.should_generate_plot(\"plot_power_absorption_distribution\") and not all_organ_results_df.empty:\n            if \"Total Loss\" in all_organ_results_df.columns:\n                for scenario in scenarios_with_results:\n                    plotter.plot_power_absorption_distribution(all_organ_results_df, scenario_name=scenario)\n            else:\n                logging.getLogger(\"progress\").warning(\n                    \"  - WARNING: No 'Total Loss' data available for power absorption plot.\",\n                    extra={\"log_type\": \"warning\"},\n                )\n\n    # ============================================================================\n    # Penetration Depth Plot\n    # ============================================================================\n    if self.should_generate_plot(\"plot_penetration_depth_ratio\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating penetration depth plot...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Penetration depth ratio (per scenario only - averaging across scenarios doesn't make sense)\n        # Generate both psSAR10g and SAR versions for symmetry\n        if \"psSAR10g_brain\" in results_df.columns and \"psSAR10g_skin\" in results_df.columns:\n            for scenario in scenarios_with_results:\n                plotter.plot_penetration_depth_ratio(results_df, scenario_name=scenario, metric_type=\"psSAR10g\")\n        if \"SAR_brain\" in results_df.columns and \"SAR_skin\" in results_df.columns:\n            for scenario in scenarios_with_results:\n                plotter.plot_penetration_depth_ratio(results_df, scenario_name=scenario, metric_type=\"SAR\")\n\n    # ============================================================================\n    # Tissue Analysis Plots\n    # ============================================================================\n    if not all_organ_results_df.empty and (\n        self.should_generate_plot(\"plot_max_local_vs_pssar10g_scatter\")\n        or self.should_generate_plot(\"plot_tissue_mass_volume_distribution\")\n        or self.should_generate_plot(\"plot_tissue_frequency_response\")\n    ):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating tissue analysis plots...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Max Local SAR vs psSAR10g scatter (per scenario only - averaging across scenarios doesn't make sense)\n        if self.should_generate_plot(\"plot_max_local_vs_pssar10g_scatter\") and \"max_local_sar_mw_kg\" in all_organ_results_df.columns:\n            for scenario in scenarios_with_results:\n                plotter.plot_max_local_vs_pssar10g_scatter(all_organ_results_df, scenario_name=scenario)\n\n        # Tissue mass/volume distribution (per scenario only - averaging across scenarios doesn't make sense)\n        if (\n            self.should_generate_plot(\"plot_tissue_mass_volume_distribution\")\n            and \"Total Mass\" in all_organ_results_df.columns\n            and \"Total Volume\" in all_organ_results_df.columns\n        ):\n            for scenario in scenarios_with_results:\n                plotter.plot_tissue_mass_volume_distribution(all_organ_results_df, scenario_name=scenario)\n\n        # Tissue frequency response for top tissues (per scenario only - averaging across scenarios doesn't make sense)\n        if self.should_generate_plot(\"plot_tissue_frequency_response\") and \"mass_avg_sar_mw_kg\" in all_organ_results_df.columns:\n            # Filter out 'All Regions' before selecting top tissues\n            filtered_organs = all_organ_results_df[all_organ_results_df[\"tissue\"] != \"All Regions\"]\n            for scenario in scenarios_with_results:\n                # Get top tissues per scenario\n                scenario_organs = filtered_organs[filtered_organs[\"scenario\"] == scenario]\n                top_tissues = scenario_organs.groupby(\"tissue\")[\"mass_avg_sar_mw_kg\"].mean().nlargest(10).index.tolist()\n                for tissue in top_tissues:\n                    plotter.plot_tissue_frequency_response(all_organ_results_df, tissue_name=tissue, scenario_name=scenario)\n\n    # ============================================================================\n    # CDF Plots\n    # ============================================================================\n    if self.should_generate_plot(\"plot_cdf\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Generating CDF plots...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Get all available metrics for CDF plots\n        cdf_metrics = []\n        sar_metrics = [col for col in results_df.columns if col.startswith(\"SAR_\")]\n        pssar_metrics = [col for col in results_df.columns if col.startswith(\"psSAR10g_\")]\n        cdf_metrics.extend(sar_metrics)\n        cdf_metrics.extend(pssar_metrics)\n\n        # Generate CDF plots with various grouping options\n        for metric in cdf_metrics:\n            if metric not in results_df.columns:\n                continue\n\n            # CDF grouped by scenario (shows all scenarios together for comparison)\n            plotter.plot_cdf(results_df, metric, group_by=\"scenario\")\n\n            # Per-scenario CDFs grouped by frequency\n            for scenario in scenarios_with_results:\n                plotter.plot_cdf(results_df, metric, group_by=\"frequency_mhz\", scenario_name=scenario)\n\n            # Note: Single CDF (all data) and per-frequency CDFs removed - averaging across scenarios doesn't make sense\n\n    # ============================================================================\n    # Outlier Identification\n    # ============================================================================\n    if self.should_generate_plot(\"identify_outliers\"):\n        logging.getLogger(\"progress\").info(\n            \"  - Identifying outliers...\",\n            extra={\"log_type\": \"info\"},\n        )\n        # Include all SAR and psSAR10g metrics for symmetry\n        outlier_metrics = [\n            \"psSAR10g_brain\",\n            \"psSAR10g_eyes\",\n            \"psSAR10g_skin\",\n            \"psSAR10g_genitals\",\n            \"psSAR10g_whole_body\",\n            \"SAR_head\",\n            \"SAR_trunk\",\n            \"SAR_whole_body\",\n            \"SAR_brain\",\n            \"SAR_skin\",\n            \"SAR_eyes\",\n            \"SAR_genitals\",\n        ]\n        for metric in outlier_metrics:\n            if metric in results_df.columns and results_df[metric].notna().any():\n                outliers = plotter.identify_outliers(results_df, metric)\n                if outliers is not None and not outliers.empty:\n                    # Save outliers to CSV\n                    subdir = plotter._get_subdir(\"outliers\")\n                    filename = f\"outliers_{metric}.csv\"\n                    outliers.to_csv(os.path.join(subdir, filename), index=False)\n                    logging.getLogger(\"progress\").info(\n                        f\"    - Found {len(outliers)} outliers for {metric}\",\n                        extra={\"log_type\": \"info\"},\n                    )\n\n    logging.getLogger(\"progress\").info(\n        \"\\n--- Analysis plots generation complete ---\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#parallel-plot-executor","title":"Parallel Plot Executor","text":""},{"location":"reference/api_reference/#goliat.analysis.parallel_plot_executor.ParallelPlotExecutor","title":"goliat.analysis.parallel_plot_executor.ParallelPlotExecutor","text":"<pre><code>ParallelPlotExecutor(max_workers: int | None = None)\n</code></pre> <p>Executes plot generation tasks in parallel using process pool.</p> <p>Uses ProcessPoolExecutor for plot generation tasks to ensure full isolation of matplotlib state, avoiding thread-safety issues with rcParams and backends.</p> <p>Parameters:</p> Name Type Description Default <code>max_workers</code> <code>int | None</code> <p>Maximum number of worker processes. If None, uses default         (typically os.cpu_count()).</p> <code>None</code> Source code in <code>goliat/analysis/parallel_plot_executor.py</code> <pre><code>def __init__(self, max_workers: int | None = None):\n    \"\"\"Initialize parallel plot executor.\n\n    Args:\n        max_workers: Maximum number of worker processes. If None, uses default\n                    (typically os.cpu_count()).\n    \"\"\"\n    if max_workers is None:\n        # Default: use CPU count but ensure at least 1, cap at 16 to avoid excessive memory usage\n        # Plotting can be memory intensive with large DataFrames\n        max_workers = min(16, (os.cpu_count() or 1))\n    self.max_workers = max_workers\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.parallel_plot_executor.ParallelPlotExecutor-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.parallel_plot_executor.ParallelPlotExecutor.execute_plots","title":"execute_plots","text":"<pre><code>execute_plots(plot_tasks: list[tuple[Callable, tuple, dict]], task_descriptions: list[str] | None = None)\n</code></pre> <p>Execute multiple plot generation tasks in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>plot_tasks</code> <code>list[tuple[Callable, tuple, dict]]</code> <p>List of (function, args_tuple, kwargs_dict) tuples.</p> required <code>task_descriptions</code> <code>list[str] | None</code> <p>Optional list of task descriptions for logging.               If None, uses function names.</p> <code>None</code> <p>Returns:</p> Type Description <p>List of results (or exceptions) in completion order.</p> Source code in <code>goliat/analysis/parallel_plot_executor.py</code> <pre><code>def execute_plots(\n    self,\n    plot_tasks: list[tuple[Callable, tuple, dict]],\n    task_descriptions: list[str] | None = None,\n):\n    \"\"\"Execute multiple plot generation tasks in parallel.\n\n    Args:\n        plot_tasks: List of (function, args_tuple, kwargs_dict) tuples.\n        task_descriptions: Optional list of task descriptions for logging.\n                          If None, uses function names.\n\n    Returns:\n        List of results (or exceptions) in completion order.\n    \"\"\"\n    if not plot_tasks:\n        return []\n\n    if task_descriptions is None:\n        task_descriptions = [f\"{func.__name__}\" for func, _, _ in plot_tasks]\n\n    results = []\n    completed_count = 0\n    total_tasks = len(plot_tasks)\n\n    # Use ProcessPoolExecutor for isolation\n    with ProcessPoolExecutor(max_workers=self.max_workers) as executor:\n        # Submit all tasks\n        future_to_task = {}\n        for (func, args, kwargs), desc in zip(plot_tasks, task_descriptions):\n            # Submit the top-level wrapper function with the actual function as the first arg\n            future = executor.submit(_execute_plot_task, func, *args, **kwargs)\n            future_to_task[future] = desc\n\n        # Process completed tasks\n        for future in as_completed(future_to_task):\n            task_desc = future_to_task[future]\n            completed_count += 1\n            try:\n                result = future.result()\n                results.append((task_desc, result, None))\n                logging.getLogger(\"progress\").info(\n                    f\"  - Completed plot ({completed_count}/{total_tasks}): {task_desc}\",\n                    extra={\"log_type\": \"success\"},\n                )\n            except Exception as e:\n                results.append((task_desc, None, e))\n                logging.getLogger(\"progress\").error(\n                    f\"  - ERROR in plot '{task_desc}': {str(e)}\",\n                    extra={\"log_type\": \"error\"},\n                )\n\n    return results\n</code></pre>"},{"location":"reference/api_reference/#parse-verbose-log","title":"Parse Verbose Log","text":""},{"location":"reference/api_reference/#goliat.analysis.parse_verbose_log","title":"goliat.analysis.parse_verbose_log","text":"<p>Parse verbose.log files to extract simulation metrics into JSON format.</p> <p>This script extracts all key metrics from GOLIAT/Sim4Life verbose logs for reporting and analysis purposes.</p>"},{"location":"reference/api_reference/#goliat.analysis.parse_verbose_log-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.parse_verbose_log.parse_verbose_log","title":"parse_verbose_log","text":"<pre><code>parse_verbose_log(log_path: str | Path) -&gt; dict[str, Any]\n</code></pre> <p>Parse a verbose.log file and extract all simulation metrics.</p> <p>Parameters:</p> Name Type Description Default <code>log_path</code> <code>str | Path</code> <p>Path to the verbose.log file</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing all extracted metrics</p> Source code in <code>goliat/analysis/parse_verbose_log.py</code> <pre><code>def parse_verbose_log(log_path: str | Path) -&gt; dict[str, Any]:\n    \"\"\"\n    Parse a verbose.log file and extract all simulation metrics.\n\n    Args:\n        log_path: Path to the verbose.log file\n\n    Returns:\n        Dictionary containing all extracted metrics\n    \"\"\"\n    log_path = Path(log_path)\n\n    if not log_path.exists():\n        raise FileNotFoundError(f\"Log file not found: {log_path}\")\n\n    content = log_path.read_text(encoding=\"utf-8\", errors=\"replace\")\n\n    metrics = {\n        \"metadata\": _extract_metadata(content, log_path),\n        \"phantom\": _extract_phantom_info(content),\n        \"grid\": _extract_grid_info(content),\n        \"boundaries\": _extract_boundary_info(content),\n        \"materials\": _extract_materials_info(content),\n        \"solver\": _extract_solver_info(content),\n        \"timing\": _extract_timing_info(content),\n        \"hardware\": _extract_hardware_info(content),\n        \"simulation\": _extract_simulation_info(content),\n        \"edges\": _extract_edge_statistics(content),\n        \"sensors\": _extract_sensor_info(content),\n        \"sources\": _extract_source_info(content),\n        \"results\": _extract_results_info(content),\n        \"_content\": content,  # Store for speed extraction in _compute_summary\n    }\n\n    # Add computed summary statistics\n    metrics[\"summary\"] = _compute_summary(metrics)\n\n    # Remove _content to save memory (it's huge)\n    del metrics[\"_content\"]\n\n    return metrics\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.parse_verbose_log.parse_and_save","title":"parse_and_save","text":"<pre><code>parse_and_save(log_path: str | Path, output_path: str | Path | None = None) -&gt; Path\n</code></pre> <p>Parse a verbose.log file and save metrics to JSON.</p> <p>Parameters:</p> Name Type Description Default <code>log_path</code> <code>str | Path</code> <p>Path to the verbose.log file</p> required <code>output_path</code> <code>str | Path | None</code> <p>Optional output path for JSON. Defaults to same directory as log.</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved JSON file</p> Source code in <code>goliat/analysis/parse_verbose_log.py</code> <pre><code>def parse_and_save(log_path: str | Path, output_path: str | Path | None = None) -&gt; Path:\n    \"\"\"\n    Parse a verbose.log file and save metrics to JSON.\n\n    Args:\n        log_path: Path to the verbose.log file\n        output_path: Optional output path for JSON. Defaults to same directory as log.\n\n    Returns:\n        Path to the saved JSON file\n    \"\"\"\n    log_path = Path(log_path)\n\n    if output_path is None:\n        output_path = log_path.parent / \"simulation_metrics.json\"\n    else:\n        output_path = Path(output_path)\n\n    metrics = parse_verbose_log(log_path)\n\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(metrics, f, indent=2, ensure_ascii=False)\n\n    print(f\"Metrics saved to: {output_path}\")\n    return output_path\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.parse_verbose_log.main","title":"main","text":"<pre><code>main()\n</code></pre> <p>Main entry point for CLI usage.</p> Source code in <code>goliat/analysis/parse_verbose_log.py</code> <pre><code>def main():\n    \"\"\"Main entry point for CLI usage.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Parse verbose.log files to extract simulation metrics\")\n    parser.add_argument(\"log_path\", type=str, help=\"Path to the verbose.log file\")\n    parser.add_argument(\n        \"-o\", \"--output\", type=str, default=None, help=\"Output path for JSON file (default: simulation_metrics.json in same directory)\"\n    )\n    parser.add_argument(\"--pretty\", action=\"store_true\", help=\"Print metrics to console in pretty format\")\n\n    args = parser.parse_args()\n\n    output_path = parse_and_save(args.log_path, args.output)\n\n    if args.pretty:\n        with open(output_path, \"r\") as f:\n            metrics = json.load(f)\n        print(\"\\n\" + \"=\" * 60)\n        print(\"SIMULATION METRICS SUMMARY\")\n        print(\"=\" * 60)\n\n        if \"summary\" in metrics:\n            for key, value in metrics[\"summary\"].items():\n                print(f\"  {key}: {value}\")\n</code></pre>"},{"location":"reference/api_reference/#plotter","title":"Plotter","text":""},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter","title":"goliat.analysis.plotter.Plotter","text":"<pre><code>Plotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates publication-ready plots from simulation results.</p> <p>Creates bar charts, line plots, boxplots, and heatmaps for SAR analysis. All plots are saved to the configured plots directory.</p> <p>Uses composition to delegate to specialized plot modules for better organization.</p> <p>Parameters:</p> Name Type Description Default <code>plots_dir</code> <code>str</code> <p>Directory where all plots will be saved.</p> required <code>phantom_name</code> <code>str | None</code> <p>Optional phantom model name for titles.</p> <code>None</code> <code>plot_format</code> <code>str</code> <p>Output format for plots ('pdf' or 'png'), default 'pdf'.</p> <code>'pdf'</code> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Sets up the plotter and creates output directory.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    super().__init__(plots_dir, phantom_name, plot_format)\n    os.makedirs(self.plots_dir, exist_ok=True)\n\n    # Initialize specialized plot modules\n    self.bar = BarPlotter(plots_dir, phantom_name, plot_format)\n    self.line = LinePlotter(plots_dir, phantom_name, plot_format)\n    self.boxplot = BoxplotPlotter(plots_dir, phantom_name, plot_format)\n    self.heatmap = HeatmapPlotter(plots_dir, phantom_name, plot_format)\n    self.spatial = SpatialPlotter(plots_dir, phantom_name, plot_format)\n    self.correlation = CorrelationPlotter(plots_dir, phantom_name, plot_format)\n    self.bubble = BubblePlotter(plots_dir, phantom_name, plot_format)\n    self.ranking = RankingPlotter(plots_dir, phantom_name, plot_format)\n    self.power = PowerPlotter(plots_dir, phantom_name, plot_format)\n    self.penetration = PenetrationPlotter(plots_dir, phantom_name, plot_format)\n    self.tissue_analysis = TissueAnalysisPlotter(plots_dir, phantom_name, plot_format)\n    self.cdf = CdfPlotter(plots_dir, phantom_name, plot_format)\n    self.outliers = OutliersPlotter(plots_dir, phantom_name, plot_format)\n\n    logging.getLogger(\"progress\").info(\n        f\"--- Plots will be saved to '{self.plots_dir}' directory. ---\",\n        extra={\"log_type\": \"info\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_average_sar_bar","title":"plot_average_sar_bar","text":"<pre><code>plot_average_sar_bar(*args, **kwargs)\n</code></pre> <p>Creates a bar chart of average SAR values by frequency.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_average_sar_bar(self, *args, **kwargs):\n    \"\"\"Creates a bar chart of average SAR values by frequency.\"\"\"\n    return self.bar.plot_average_sar_bar(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_average_pssar_bar","title":"plot_average_pssar_bar","text":"<pre><code>plot_average_pssar_bar(*args, **kwargs)\n</code></pre> <p>Creates a bar chart of average psSAR10g values by frequency.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_average_pssar_bar(self, *args, **kwargs):\n    \"\"\"Creates a bar chart of average psSAR10g values by frequency.\"\"\"\n    return self.bar.plot_average_pssar_bar(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_whole_body_sar_bar","title":"plot_whole_body_sar_bar","text":"<pre><code>plot_whole_body_sar_bar(*args, **kwargs)\n</code></pre> <p>Creates a bar chart of average whole-body SAR by frequency.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_whole_body_sar_bar(self, *args, **kwargs):\n    \"\"\"Creates a bar chart of average whole-body SAR by frequency.\"\"\"\n    return self.bar.plot_whole_body_sar_bar(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_peak_sar_line","title":"plot_peak_sar_line","text":"<pre><code>plot_peak_sar_line(*args, **kwargs)\n</code></pre> <p>Plots peak SAR trend across frequencies.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_peak_sar_line(self, *args, **kwargs):\n    \"\"\"Plots peak SAR trend across frequencies.\"\"\"\n    return self.line.plot_peak_sar_line(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_pssar_line","title":"plot_pssar_line","text":"<pre><code>plot_pssar_line(*args, **kwargs)\n</code></pre> <p>Plots average psSAR10g trends for tissue groups by frequency.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_pssar_line(self, *args, **kwargs):\n    \"\"\"Plots average psSAR10g trends for tissue groups by frequency.\"\"\"\n    return self.line.plot_pssar_line(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_sar_line","title":"plot_sar_line","text":"<pre><code>plot_sar_line(*args, **kwargs)\n</code></pre> <p>Plots average SAR trends for tissue groups by frequency.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_sar_line(self, *args, **kwargs):\n    \"\"\"Plots average SAR trends for tissue groups by frequency.\"\"\"\n    return self.line.plot_sar_line(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_pssar_line_individual_variations","title":"plot_pssar_line_individual_variations","text":"<pre><code>plot_pssar_line_individual_variations(*args, **kwargs)\n</code></pre> <p>Plots individual variation lines for each placement variation.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_pssar_line_individual_variations(self, *args, **kwargs):\n    \"\"\"Plots individual variation lines for each placement variation.\"\"\"\n    return self.line.plot_pssar_line_individual_variations(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_sar_line_individual_variations","title":"plot_sar_line_individual_variations","text":"<pre><code>plot_sar_line_individual_variations(*args, **kwargs)\n</code></pre> <p>Plots individual variation lines for SAR metrics.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_sar_line_individual_variations(self, *args, **kwargs):\n    \"\"\"Plots individual variation lines for SAR metrics.\"\"\"\n    return self.line.plot_sar_line_individual_variations(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_far_field_direction_polarization_lines","title":"plot_far_field_direction_polarization_lines","text":"<pre><code>plot_far_field_direction_polarization_lines(*args, **kwargs)\n</code></pre> <p>Creates line plots showing frequency dependence for far-field direction/polarization.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_far_field_direction_polarization_lines(self, *args, **kwargs):\n    \"\"\"Creates line plots showing frequency dependence for far-field direction/polarization.\"\"\"\n    return self.line.plot_far_field_direction_polarization_lines(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_far_field_direction_polarization_comparison","title":"plot_far_field_direction_polarization_comparison","text":"<pre><code>plot_far_field_direction_polarization_comparison(*args, **kwargs)\n</code></pre> <p>Generates frequency-dependent comparison plots for all direction/polarization combos.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_far_field_direction_polarization_comparison(self, *args, **kwargs):\n    \"\"\"Generates frequency-dependent comparison plots for all direction/polarization combos.\"\"\"\n    return self.line.plot_far_field_direction_polarization_comparison(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_sar_distribution_boxplots","title":"plot_sar_distribution_boxplots","text":"<pre><code>plot_sar_distribution_boxplots(*args, **kwargs)\n</code></pre> <p>Creates boxplots showing SAR value distributions across placements.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_sar_distribution_boxplots(self, *args, **kwargs):\n    \"\"\"Creates boxplots showing SAR value distributions across placements.\"\"\"\n    return self.boxplot.plot_sar_distribution_boxplots(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_sar_distribution_boxplot_single","title":"plot_sar_distribution_boxplot_single","text":"<pre><code>plot_sar_distribution_boxplot_single(*args, **kwargs)\n</code></pre> <p>Creates a single boxplot showing distribution of one metric across frequencies.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_sar_distribution_boxplot_single(self, *args, **kwargs):\n    \"\"\"Creates a single boxplot showing distribution of one metric across frequencies.\"\"\"\n    return self.boxplot.plot_sar_distribution_boxplot_single(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_sar_heatmap","title":"plot_sar_heatmap","text":"<pre><code>plot_sar_heatmap(*args, **kwargs)\n</code></pre> <p>Creates a combined heatmap showing Min/Avg/Max SAR per tissue and frequency.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_sar_heatmap(self, *args, **kwargs):\n    \"\"\"Creates a combined heatmap showing Min/Avg/Max SAR per tissue and frequency.\"\"\"\n    return self.heatmap.plot_sar_heatmap(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_peak_sar_heatmap","title":"plot_peak_sar_heatmap","text":"<pre><code>plot_peak_sar_heatmap(*args, **kwargs)\n</code></pre> <p>Creates a heatmap for peak SAR values across tissues and frequencies.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_peak_sar_heatmap(self, *args, **kwargs):\n    \"\"\"Creates a heatmap for peak SAR values across tissues and frequencies.\"\"\"\n    return self.heatmap.plot_peak_sar_heatmap(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_far_field_direction_polarization_heatmap","title":"plot_far_field_direction_polarization_heatmap","text":"<pre><code>plot_far_field_direction_polarization_heatmap(*args, **kwargs)\n</code></pre> <p>Creates a heatmap comparing SAR across incident directions and polarizations.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_far_field_direction_polarization_heatmap(self, *args, **kwargs):\n    \"\"\"Creates a heatmap comparing SAR across incident directions and polarizations.\"\"\"\n    return self.heatmap.plot_far_field_direction_polarization_heatmap(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_far_field_direction_polarization_summary","title":"plot_far_field_direction_polarization_summary","text":"<pre><code>plot_far_field_direction_polarization_summary(*args, **kwargs)\n</code></pre> <p>Creates a multi-panel summary of SAR across directions/polarizations.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_far_field_direction_polarization_summary(self, *args, **kwargs):\n    \"\"\"Creates a multi-panel summary of SAR across directions/polarizations.\"\"\"\n    return self.heatmap.plot_far_field_direction_polarization_summary(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_peak_location_3d_interactive","title":"plot_peak_location_3d_interactive","text":"<pre><code>plot_peak_location_3d_interactive(*args, **kwargs)\n</code></pre> <p>Creates an interactive 3D plot of peak SAR locations.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_peak_location_3d_interactive(self, *args, **kwargs):\n    \"\"\"Creates an interactive 3D plot of peak SAR locations.\"\"\"\n    return self.spatial.plot_peak_location_3d_interactive(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_peak_location_2d_projections","title":"plot_peak_location_2d_projections","text":"<pre><code>plot_peak_location_2d_projections(*args, **kwargs)\n</code></pre> <p>Creates 2D scatter plots showing peak locations projected onto XY, XZ, YZ planes.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_peak_location_2d_projections(self, *args, **kwargs):\n    \"\"\"Creates 2D scatter plots showing peak locations projected onto XY, XZ, YZ planes.\"\"\"\n    return self.spatial.plot_peak_location_2d_projections(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_correlation_head_vs_eye_sar","title":"plot_correlation_head_vs_eye_sar","text":"<pre><code>plot_correlation_head_vs_eye_sar(*args, **kwargs)\n</code></pre> <p>Creates scatter plot showing correlation between Head SAR and Eye psSAR10g.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_correlation_head_vs_eye_sar(self, *args, **kwargs):\n    \"\"\"Creates scatter plot showing correlation between Head SAR and Eye psSAR10g.\"\"\"\n    return self.correlation.plot_correlation_head_vs_eye_sar(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_tissue_group_correlation_matrix","title":"plot_tissue_group_correlation_matrix","text":"<pre><code>plot_tissue_group_correlation_matrix(*args, **kwargs)\n</code></pre> <p>Creates heatmap showing correlation coefficients between tissue group SAR values.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_tissue_group_correlation_matrix(self, *args, **kwargs):\n    \"\"\"Creates heatmap showing correlation coefficients between tissue group SAR values.\"\"\"\n    return self.correlation.plot_tissue_group_correlation_matrix(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_bubble_mass_vs_sar","title":"plot_bubble_mass_vs_sar","text":"<pre><code>plot_bubble_mass_vs_sar(*args, **kwargs)\n</code></pre> <p>Creates bubble plot showing how tissue mass affects SAR values.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_bubble_mass_vs_sar(self, *args, **kwargs):\n    \"\"\"Creates bubble plot showing how tissue mass affects SAR values.\"\"\"\n    return self.bubble.plot_bubble_mass_vs_sar(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_bubble_mass_vs_sar_interactive","title":"plot_bubble_mass_vs_sar_interactive","text":"<pre><code>plot_bubble_mass_vs_sar_interactive(*args, **kwargs)\n</code></pre> <p>Creates an interactive bubble plot with common axis limits across frequencies.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_bubble_mass_vs_sar_interactive(self, *args, **kwargs):\n    \"\"\"Creates an interactive bubble plot with common axis limits across frequencies.\"\"\"\n    return self.bubble.plot_bubble_mass_vs_sar_interactive(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_top20_tissues_ranking","title":"plot_top20_tissues_ranking","text":"<pre><code>plot_top20_tissues_ranking(*args, **kwargs)\n</code></pre> <p>Creates horizontal bar chart showing top 20 tissues ranked by various metrics.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_top20_tissues_ranking(self, *args, **kwargs):\n    \"\"\"Creates horizontal bar chart showing top 20 tissues ranked by various metrics.\"\"\"\n    return self.ranking.plot_top20_tissues_ranking(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_power_efficiency_trends","title":"plot_power_efficiency_trends","text":"<pre><code>plot_power_efficiency_trends(*args, **kwargs)\n</code></pre> <p>Creates line plot showing antenna efficiency and power component percentages.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_power_efficiency_trends(self, *args, **kwargs):\n    \"\"\"Creates line plot showing antenna efficiency and power component percentages.\"\"\"\n    return self.power.plot_power_efficiency_trends(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_power_absorption_distribution","title":"plot_power_absorption_distribution","text":"<pre><code>plot_power_absorption_distribution(*args, **kwargs)\n</code></pre> <p>Creates pie chart or stacked bar chart showing power distribution across tissue groups.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_power_absorption_distribution(self, *args, **kwargs):\n    \"\"\"Creates pie chart or stacked bar chart showing power distribution across tissue groups.\"\"\"\n    return self.power.plot_power_absorption_distribution(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_power_balance_overview","title":"plot_power_balance_overview","text":"<pre><code>plot_power_balance_overview(*args, **kwargs)\n</code></pre> <p>Creates power balance overview heatmap with all components.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_power_balance_overview(self, *args, **kwargs):\n    \"\"\"Creates power balance overview heatmap with all components.\"\"\"\n    return self.power.plot_power_balance_overview(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_penetration_depth_ratio","title":"plot_penetration_depth_ratio","text":"<pre><code>plot_penetration_depth_ratio(*args, **kwargs)\n</code></pre> <p>Creates line plot showing SAR penetration depth ratio (Brain/Skin) vs frequency.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_penetration_depth_ratio(self, *args, **kwargs):\n    \"\"\"Creates line plot showing SAR penetration depth ratio (Brain/Skin) vs frequency.\"\"\"\n    return self.penetration.plot_penetration_depth_ratio(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_max_local_vs_pssar10g_scatter","title":"plot_max_local_vs_pssar10g_scatter","text":"<pre><code>plot_max_local_vs_pssar10g_scatter(*args, **kwargs)\n</code></pre> <p>Creates scatter plot showing relationship between Max Local SAR and psSAR10g.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_max_local_vs_pssar10g_scatter(self, *args, **kwargs):\n    \"\"\"Creates scatter plot showing relationship between Max Local SAR and psSAR10g.\"\"\"\n    return self.tissue_analysis.plot_max_local_vs_pssar10g_scatter(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_tissue_frequency_response","title":"plot_tissue_frequency_response","text":"<pre><code>plot_tissue_frequency_response(*args, **kwargs)\n</code></pre> <p>Creates line plot showing how a specific tissue responds across frequencies.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_tissue_frequency_response(self, *args, **kwargs):\n    \"\"\"Creates line plot showing how a specific tissue responds across frequencies.\"\"\"\n    return self.tissue_analysis.plot_tissue_frequency_response(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_tissue_mass_volume_distribution","title":"plot_tissue_mass_volume_distribution","text":"<pre><code>plot_tissue_mass_volume_distribution(*args, **kwargs)\n</code></pre> <p>Creates histograms and scatter plot showing tissue mass and volume distributions.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_tissue_mass_volume_distribution(self, *args, **kwargs):\n    \"\"\"Creates histograms and scatter plot showing tissue mass and volume distributions.\"\"\"\n    return self.tissue_analysis.plot_tissue_mass_volume_distribution(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_cdf","title":"plot_cdf","text":"<pre><code>plot_cdf(*args, **kwargs)\n</code></pre> <p>Creates CDF plot for a metric with optional aggregation by independent variables.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_cdf(self, *args, **kwargs):\n    \"\"\"Creates CDF plot for a metric with optional aggregation by independent variables.\"\"\"\n    return self.cdf.plot_cdf(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.identify_outliers","title":"identify_outliers","text":"<pre><code>identify_outliers(*args, **kwargs)\n</code></pre> <p>Identifies and visualizes outliers in SAR metrics.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def identify_outliers(self, *args, **kwargs):\n    \"\"\"Identifies and visualizes outliers in SAR metrics.\"\"\"\n    return self.outliers.identify_outliers(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_cross_phantom_comparison","title":"plot_cross_phantom_comparison","text":"<pre><code>plot_cross_phantom_comparison(*args, **kwargs)\n</code></pre> <p>Plots SAR vs frequency comparing different phantoms.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_cross_phantom_comparison(self, *args, **kwargs):\n    \"\"\"Plots SAR vs frequency comparing different phantoms.\"\"\"\n    return self.line.plot_cross_phantom_comparison(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_polarization_ratio_lines","title":"plot_polarization_ratio_lines","text":"<pre><code>plot_polarization_ratio_lines(*args, **kwargs)\n</code></pre> <p>Plots theta/phi polarization ratio vs frequency for each direction.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_polarization_ratio_lines(self, *args, **kwargs):\n    \"\"\"Plots theta/phi polarization ratio vs frequency for each direction.\"\"\"\n    return self.line.plot_polarization_ratio_lines(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_polarization_ratio_heatmap","title":"plot_polarization_ratio_heatmap","text":"<pre><code>plot_polarization_ratio_heatmap(*args, **kwargs)\n</code></pre> <p>Plots frequency-averaged polarization ratio heatmap.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_polarization_ratio_heatmap(self, *args, **kwargs):\n    \"\"\"Plots frequency-averaged polarization ratio heatmap.\"\"\"\n    return self.heatmap.plot_polarization_ratio_heatmap(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plotter.Plotter.plot_polarization_ratio_heatmaps_per_frequency","title":"plot_polarization_ratio_heatmaps_per_frequency","text":"<pre><code>plot_polarization_ratio_heatmaps_per_frequency(*args, **kwargs)\n</code></pre> <p>Plots polarization ratio heatmaps for each frequency separately.</p> Source code in <code>goliat/analysis/plotter.py</code> <pre><code>def plot_polarization_ratio_heatmaps_per_frequency(self, *args, **kwargs):\n    \"\"\"Plots polarization ratio heatmaps for each frequency separately.\"\"\"\n    return self.heatmap.plot_polarization_ratio_heatmaps_per_frequency(*args, **kwargs)\n</code></pre>"},{"location":"reference/api_reference/#plots","title":"Plots","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.bar.BarPlotter","title":"goliat.analysis.plots.bar.BarPlotter","text":"<pre><code>BarPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates bar chart plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.bar.BarPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.bar.BarPlotter.plot_average_sar_bar","title":"plot_average_sar_bar","text":"<pre><code>plot_average_sar_bar(scenario_name: str, avg_results: DataFrame, progress_info: Series, scenario_results_df: DataFrame | None = None)\n</code></pre> <p>Creates a bar chart of average Head and Trunk SAR by frequency.</p> <p>Shows completion progress in x-axis labels. Used for near-field analysis.</p> <p>Parameters:</p> Name Type Description Default <code>scenario_name</code> <code>str</code> <p>Placement scenario name (e.g., 'by_cheek').</p> required <code>avg_results</code> <code>DataFrame</code> <p>DataFrame with average SAR values, indexed by frequency.</p> required <code>progress_info</code> <code>Series</code> <p>Series with completion counts like '\u215a' per frequency.</p> required Source code in <code>goliat/analysis/plots/bar.py</code> <pre><code>def plot_average_sar_bar(\n    self, scenario_name: str, avg_results: pd.DataFrame, progress_info: pd.Series, scenario_results_df: pd.DataFrame | None = None\n):\n    \"\"\"Creates a bar chart of average Head and Trunk SAR by frequency.\n\n    Shows completion progress in x-axis labels. Used for near-field analysis.\n\n    Args:\n        scenario_name: Placement scenario name (e.g., 'by_cheek').\n        avg_results: DataFrame with average SAR values, indexed by frequency.\n        progress_info: Series with completion counts like '5/6' per frequency.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n\n    # Select available columns - exclude SAR_whole_body (same as psSAR10g excludes whole_body)\n    sar_cols = []\n    legend_labels = []\n    sar_metrics_order = [\"SAR_head\", \"SAR_trunk\", \"SAR_brain\", \"SAR_skin\", \"SAR_eyes\", \"SAR_genitals\"]\n    for metric in sar_metrics_order:\n        if metric in avg_results.columns:\n            sar_cols.append(metric)\n            # Use trimmed legend labels (remove \"SAR\" since y-axis already says \"SAR\")\n            legend_labels.append(LEGEND_LABELS.get(metric, metric.replace(\"SAR_\", \"\").replace(\"_\", \" \").title()))\n\n    if sar_cols:\n        # Get frequencies for error bar calculation\n        if isinstance(avg_results.index, pd.MultiIndex):\n            frequencies = sorted(avg_results.index.get_level_values(\"frequency_mhz\").unique())\n        else:\n            frequencies = sorted(avg_results.index.unique())\n\n        # Calculate error bars from boxplot data if available, otherwise use std\n        error_bars_dict = {}\n        use_boxplot_errors = False\n        stds = None\n        if scenario_results_df is not None:\n            # Try to calculate boxplot-style error bars\n            for metric in sar_cols:\n                if metric in scenario_results_df.columns:\n                    lower_errors, upper_errors = self._calculate_boxplot_error_bars(scenario_results_df, metric, frequencies)\n                    # Convert to arrays matching avg_results index order\n                    lower_arr = []\n                    upper_arr = []\n                    for freq in frequencies:\n                        lower_arr.append(lower_errors.get(freq, 0))\n                        upper_arr.append(upper_errors.get(freq, 0))\n                    error_bars_dict[metric] = (np.array(lower_arr), np.array(upper_arr))\n                    use_boxplot_errors = True\n\n        if not use_boxplot_errors:\n            # Fall back to std\n            stds = avg_results[sar_cols].std(axis=0) if len(avg_results) &gt; 1 else pd.Series(0, index=sar_cols)\n            for metric in sar_cols:\n                error_bars_dict[metric] = stds[metric] if metric in stds.index else 0\n\n        # Plot bars\n        if use_boxplot_errors:\n            # Plot with asymmetric error bars - need to format as list of tuples\n            error_bars_list = []\n            for col in sar_cols:\n                if col in error_bars_dict and isinstance(error_bars_dict[col], tuple):\n                    error_bars_list.append(error_bars_dict[col])\n                else:\n                    error_bars_list.append(None)\n            avg_results[sar_cols].plot(\n                kind=\"bar\",\n                ax=ax,\n                color=self._get_academic_colors(len(sar_cols)),\n                yerr=error_bars_list if any(e is not None for e in error_bars_list) else None,\n                capsize=2,\n                error_kw={\"elinewidth\": 0.8, \"capthick\": 0.8},\n                legend=False,\n            )\n        elif len(avg_results) &gt; 1 and stds is not None:\n            avg_results[sar_cols].plot(\n                kind=\"bar\",\n                ax=ax,\n                color=self._get_academic_colors(len(sar_cols)),\n                yerr=stds,\n                capsize=2,\n                error_kw={\"elinewidth\": 0.8, \"capthick\": 0.8},\n                legend=False,\n            )\n        else:\n            avg_results[sar_cols].plot(kind=\"bar\", ax=ax, color=self._get_academic_colors(len(sar_cols)), legend=False)\n\n        # Handle both single-level and multi-level index\n        if isinstance(avg_results.index, pd.MultiIndex):\n            # Multi-level index: extract frequency from second level\n            progress_labels = [\n                f\"{freq}\\n({progress_info.get((scenario_name, freq), progress_info.get(freq, '0/0'))})\"\n                for scenario, freq in avg_results.index\n            ]\n        else:\n            # Single-level index: assume it's frequency\n            progress_labels = [str(freq) for freq in avg_results.index]\n        ax.set_xticklabels(progress_labels, rotation=0)\n\n        # Create title with phantom name and formatted scenario\n        base_title = \"Average normalized SAR for scenario\"\n        title_full = self._get_title_with_phantom(base_title, scenario_name)\n        # Don't set title on plot - will be in caption file\n        ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n        ax.set_ylabel(self._format_axis_label(\"Normalized SAR\", r\"mW kg$^{-1}$\"))\n\n        # Format legend labels to be human readable (e.g., psSAR10g_eyes -&gt; psSAR10g Eyes)\n        formatted_legend_labels = []\n        for label in legend_labels:\n            # Handle psSAR10g_eyes format - preserve psSAR10g capitalization\n            if \"pssar10g\" in label.lower() or \"psSAR10g\" in label:\n                # First fix any incorrect capitalization\n                label = label.replace(\"Pssar10g\", \"psSAR10g\").replace(\"Pssar\", \"psSAR\")\n                formatted_label = label.replace(\"psSAR10g\", \"psSAR10g \").replace(\"_\", \" \").title()\n                # Fix capitalization - ensure psSAR10g stays correct\n                formatted_label = formatted_label.replace(\"Pssar10g\", \"psSAR10g\").replace(\"Pssar\", \"psSAR\")\n            else:\n                formatted_label = (\n                    self._format_organ_name(label) if hasattr(self, \"_format_organ_name\") else label.replace(\"_\", \" \").title()\n                )\n            formatted_legend_labels.append(formatted_label)\n\n        # Move legend below plot - create handles manually to ensure we get all of them\n        from .line import LinePlotter\n        import matplotlib.patches as mpatches\n\n        line_plotter = LinePlotter(self.plots_dir, self.phantom_name, self.plot_format)\n        # Always create patches manually to ensure we have the correct number and colors\n        # This is more reliable than trying to extract from containers which may be incomplete\n        handles = []\n        # Get colors from academic color palette\n        colors = self._get_academic_colors(len(sar_cols))\n        for i, col in enumerate(sar_cols):\n            # Create a rectangle patch with the color from the academic palette\n            patch = mpatches.Patch(facecolor=colors[i], edgecolor=\"black\", linewidth=0.5)\n            handles.append(patch)\n        # Ensure handles and labels match exactly\n        if len(handles) != len(formatted_legend_labels):\n            logging.getLogger(\"progress\").warning(\n                f\"Mismatch: {len(handles)} handles but {len(formatted_legend_labels)} labels for SAR bar plot. \"\n                f\"Columns: {sar_cols}, Labels: {formatted_legend_labels}\",\n                extra={\"log_type\": \"warning\"},\n            )\n        # Use 2 columns for legend to ensure balanced layout (2x2 for 4 items)\n        n_cols = 2 if len(formatted_legend_labels) &gt;= 4 else min(3, len(formatted_legend_labels))\n        line_plotter._place_legend_below(\n            fig, ax, len(formatted_legend_labels), n_cols=n_cols, handles=handles, labels=formatted_legend_labels\n        )\n\n        # Add sample size annotation showing samples per bar (not number of bars)\n        # Calculate samples per frequency from scenario_results_df\n        if scenario_results_df is not None and not scenario_results_df.empty:\n            samples_per_freq = scenario_results_df.groupby(\"frequency_mhz\").size()\n            # Use the most common sample size (mode), or mean if all different\n            if len(samples_per_freq.unique()) == 1:\n                n_per_bar = samples_per_freq.iloc[0]\n            else:\n                n_per_bar = int(samples_per_freq.median())\n            ax.text(\n                0.95,\n                0.95,\n                f\"n = {n_per_bar}/bar\",\n                transform=ax.transAxes,\n                fontsize=8,\n                verticalalignment=\"top\",\n                horizontalalignment=\"right\",\n                bbox=dict(boxstyle=\"square,pad=0.4\", facecolor=\"white\", edgecolor=\"black\", linewidth=0.5, alpha=1.0),\n            )\n\n        # Set y-axis - simple 0 to max + 5%\n        y_max = ax.get_ylim()[1]\n        ax.set_ylim(0, y_max * 1.05)\n    else:\n        ax.text(0.5, 0.5, \"No SAR data available\", ha=\"center\", va=\"center\")\n        base_title = \"Average normalized SAR for scenario\"\n        title_full = self._get_title_with_phantom(base_title, scenario_name)\n        use_boxplot_errors = False\n\n    plt.tight_layout()\n    error_bar_note = (\n        \"Error bars show boxplot whiskers (IQR-based range)\"\n        if use_boxplot_errors\n        else \"Error bars indicate standard deviation when multiple data points are available\"\n    )\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The bar chart shows average normalized SAR values (Head, Trunk, Brain, Skin, Eyes, Genitals) across frequencies for the {self._format_scenario_name(scenario_name)} scenario for {phantom_name_formatted}. {error_bar_note}.\"\n    self._save_figure(fig, \"bar\", f\"average_sar_bar_{scenario_name}\", title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = avg_results[sar_cols].copy()\n    csv_data.index.name = \"frequency_mhz\"\n    self._save_csv_data(csv_data, \"bar\", f\"average_sar_bar_{scenario_name}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.bar.BarPlotter.plot_average_pssar_bar","title":"plot_average_pssar_bar","text":"<pre><code>plot_average_pssar_bar(scenario_name: str, avg_results: DataFrame, progress_info: Series, scenario_results_df: DataFrame | None = None)\n</code></pre> <p>Creates a bar chart of average psSAR10g values by frequency for a scenario.</p> <p>Symmetric counterpart to plot_average_sar_bar.</p> <p>Parameters:</p> Name Type Description Default <code>scenario_name</code> <code>str</code> <p>Placement scenario name (e.g., 'by_cheek').</p> required <code>avg_results</code> <code>DataFrame</code> <p>DataFrame with average psSAR10g values, indexed by frequency.</p> required <code>progress_info</code> <code>Series</code> <p>Series with completion counts like '\u215a' per frequency.</p> required Source code in <code>goliat/analysis/plots/bar.py</code> <pre><code>def plot_average_pssar_bar(\n    self, scenario_name: str, avg_results: pd.DataFrame, progress_info: pd.Series, scenario_results_df: pd.DataFrame | None = None\n):\n    \"\"\"Creates a bar chart of average psSAR10g values by frequency for a scenario.\n\n    Symmetric counterpart to plot_average_sar_bar.\n\n    Args:\n        scenario_name: Placement scenario name (e.g., 'by_cheek').\n        avg_results: DataFrame with average psSAR10g values, indexed by frequency.\n        progress_info: Series with completion counts like '5/6' per frequency.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n\n    # Select all psSAR10g columns for symmetry\n    pssar_cols = [col for col in avg_results.columns if col.startswith(\"psSAR10g\")]\n    pssar_cols.sort()  # Consistent ordering\n\n    if pssar_cols:\n        # Get frequencies for error bar calculation\n        if isinstance(avg_results.index, pd.MultiIndex):\n            frequencies = sorted(avg_results.index.get_level_values(\"frequency_mhz\").unique())\n        else:\n            frequencies = sorted(avg_results.index.unique())\n\n        # Calculate error bars from boxplot data if available, otherwise use std\n        error_bars_dict = {}\n        use_boxplot_errors = False\n        stds = None\n        if scenario_results_df is not None:\n            # Try to calculate boxplot-style error bars\n            for metric in pssar_cols:\n                if metric in scenario_results_df.columns:\n                    lower_errors, upper_errors = self._calculate_boxplot_error_bars(scenario_results_df, metric, frequencies)\n                    # Convert to arrays matching avg_results index order\n                    lower_arr = []\n                    upper_arr = []\n                    for freq in frequencies:\n                        lower_arr.append(lower_errors.get(freq, 0))\n                        upper_arr.append(upper_errors.get(freq, 0))\n                    error_bars_dict[metric] = (np.array(lower_arr), np.array(upper_arr))\n                    use_boxplot_errors = True\n\n        if not use_boxplot_errors:\n            # Fall back to std\n            stds = avg_results[pssar_cols].std(axis=0) if len(avg_results) &gt; 1 else pd.Series(0, index=pssar_cols)\n            for metric in pssar_cols:\n                error_bars_dict[metric] = stds[metric] if metric in stds.index else 0\n\n        # Plot bars\n        if use_boxplot_errors:\n            # Plot with asymmetric error bars - need to format as list of tuples\n            error_bars_list = []\n            for col in pssar_cols:\n                if col in error_bars_dict and isinstance(error_bars_dict[col], tuple):\n                    error_bars_list.append(error_bars_dict[col])\n                else:\n                    error_bars_list.append(None)\n            avg_results[pssar_cols].plot(\n                kind=\"bar\",\n                ax=ax,\n                color=self._get_academic_colors(len(pssar_cols)),\n                yerr=error_bars_list if any(e is not None for e in error_bars_list) else None,\n                capsize=2,\n                error_kw={\"elinewidth\": 0.8, \"capthick\": 0.8},\n                legend=False,\n            )\n        elif len(avg_results) &gt; 1 and stds is not None:\n            avg_results[pssar_cols].plot(\n                kind=\"bar\",\n                ax=ax,\n                color=self._get_academic_colors(len(pssar_cols)),\n                yerr=stds,\n                capsize=2,\n                error_kw={\"elinewidth\": 0.8, \"capthick\": 0.8},\n                legend=False,\n            )\n        else:\n            avg_results[pssar_cols].plot(kind=\"bar\", ax=ax, color=self._get_academic_colors(len(pssar_cols)), legend=False)\n\n        # Handle both single-level and multi-level index\n        if isinstance(avg_results.index, pd.MultiIndex):\n            # Multi-level index: extract frequency from second level\n            progress_labels = [\n                f\"{freq}\\n({progress_info.get((scenario_name, freq), progress_info.get(freq, '0/0'))})\"\n                for scenario, freq in avg_results.index\n            ]\n        else:\n            # Single-level index: assume it's frequency\n            progress_labels = [str(freq) for freq in avg_results.index]\n        ax.set_xticklabels(progress_labels, rotation=0)\n\n        # Create title with phantom name and formatted scenario\n        base_title = \"Average normalized psSAR10g for scenario\"\n        title_full = self._get_title_with_phantom(base_title, scenario_name)\n        # Don't set title on plot - will be in caption file\n        ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n        ax.set_ylabel(self._format_axis_label(\"Normalized psSAR10g\", r\"mW kg$^{-1}$\"))\n        # Use trimmed legend labels (remove \"psSAR10g\" since y-axis already says \"psSAR10g\")\n        legend_labels = [LEGEND_LABELS.get(col, col.replace(\"psSAR10g_\", \"\").replace(\"_\", \" \").title()) for col in pssar_cols]\n\n        # Format legend labels to be human readable (e.g., eyes -&gt; Eyes, whole_body -&gt; Whole Body)\n        formatted_legend_labels = []\n        for label in legend_labels:\n            if label is None:\n                continue\n            formatted_label = self._format_organ_name(label) if hasattr(self, \"_format_organ_name\") else label.replace(\"_\", \" \").title()\n            formatted_legend_labels.append(formatted_label)\n\n        # Move legend below plot - create handles manually to ensure we get all of them\n        from .line import LinePlotter\n        import matplotlib.patches as mpatches\n\n        line_plotter = LinePlotter(self.plots_dir, self.phantom_name, self.plot_format)\n        # Always create patches manually to ensure we have the correct number and colors\n        # This is more reliable than trying to extract from containers which may be incomplete\n        handles = []\n        # Get colors from academic color palette\n        colors = self._get_academic_colors(len(pssar_cols))\n        for i, col in enumerate(pssar_cols):\n            # Create a rectangle patch with the color from the academic palette\n            patch = mpatches.Patch(facecolor=colors[i], edgecolor=\"black\", linewidth=0.5)\n            handles.append(patch)\n        # Ensure handles and labels match exactly\n        if len(handles) != len(formatted_legend_labels):\n            logging.getLogger(\"progress\").warning(\n                f\"Mismatch: {len(handles)} handles but {len(formatted_legend_labels)} labels for psSAR10g bar plot. \"\n                f\"Columns: {pssar_cols}, Labels: {formatted_legend_labels}\",\n                extra={\"log_type\": \"warning\"},\n            )\n        # Use 2 columns for legend to ensure balanced layout (2x2 for 4 items)\n        n_cols = 2 if len(formatted_legend_labels) &gt;= 4 else min(3, len(formatted_legend_labels))\n        line_plotter._place_legend_below(\n            fig, ax, len(formatted_legend_labels), n_cols=n_cols, handles=handles, labels=formatted_legend_labels\n        )\n\n        # Add sample size annotation showing samples per bar (not number of bars)\n        # Calculate samples per frequency from scenario_results_df\n        if scenario_results_df is not None and not scenario_results_df.empty:\n            samples_per_freq = scenario_results_df.groupby(\"frequency_mhz\").size()\n            # Use the most common sample size (mode), or mean if all different\n            if len(samples_per_freq.unique()) == 1:\n                n_per_bar = samples_per_freq.iloc[0]\n            else:\n                n_per_bar = int(samples_per_freq.median())\n            ax.text(\n                0.95,\n                0.95,\n                f\"n = {n_per_bar}/bar\",\n                transform=ax.transAxes,\n                fontsize=8,\n                verticalalignment=\"top\",\n                horizontalalignment=\"right\",\n                bbox=dict(boxstyle=\"square,pad=0.4\", facecolor=\"white\", edgecolor=\"black\", linewidth=0.5, alpha=1.0),\n            )\n\n        # Set y-axis - simple 0 to max + 5%\n        y_max = ax.get_ylim()[1]\n        ax.set_ylim(0, y_max * 1.05)\n    else:\n        ax.text(0.5, 0.5, \"No psSAR10g data available\", ha=\"center\", va=\"center\")\n        base_title = \"Average normalized psSAR10g for scenario\"\n        title_full = self._get_title_with_phantom(base_title, scenario_name)\n        use_boxplot_errors = False\n\n    plt.tight_layout()\n    error_bar_note = (\n        \"Error bars show boxplot whiskers (IQR-based range)\"\n        if use_boxplot_errors\n        else \"Error bars indicate standard deviation when multiple data points are available\"\n    )\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The bar chart shows average normalized psSAR10g values (Eyes, Skin, Brain, Genitals, Whole Body) across frequencies for the {self._format_scenario_name(scenario_name)} scenario for {phantom_name_formatted}. {error_bar_note}.\"\n    self._save_figure(fig, \"bar\", f\"average_pssar_bar_{scenario_name}\", title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = avg_results[pssar_cols].copy()\n    csv_data.index.name = \"frequency_mhz\"\n    self._save_csv_data(csv_data, \"bar\", f\"average_pssar_bar_{scenario_name}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.bar.BarPlotter.plot_whole_body_sar_bar","title":"plot_whole_body_sar_bar","text":"<pre><code>plot_whole_body_sar_bar(avg_results: DataFrame)\n</code></pre> <p>Creates a bar chart of average whole-body SAR by frequency.</p> Source code in <code>goliat/analysis/plots/bar.py</code> <pre><code>def plot_whole_body_sar_bar(self, avg_results: pd.DataFrame):\n    \"\"\"Creates a bar chart of average whole-body SAR by frequency.\"\"\"\n    fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n    avg_results[\"SAR_whole_body\"].plot(kind=\"bar\", ax=ax, color=\"skyblue\")\n    ax.set_xticklabels(avg_results.index.get_level_values(\"frequency_mhz\"), rotation=0)\n    title_full = self._get_title_with_phantom(\"Average whole-body SAR\")\n    # Don't set title on plot - will be in caption file\n    ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n    ax.set_ylabel(self._format_axis_label(\"Normalized whole-body SAR\", r\"mW kg$^{-1}$\"))\n    # Set y-axis to start at 0 and go to max + 5%\n    y_max = ax.get_ylim()[1]\n    ax.set_ylim(0, y_max * 1.05)\n    plt.tight_layout()\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The bar chart shows average normalized whole-body SAR values across frequencies for {phantom_name_formatted}.\"\n    self._save_figure(fig, \"bar\", \"average_whole_body_sar_bar\", title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = avg_results[[\"SAR_whole_body\"]].copy()\n    csv_data.index.name = \"frequency_mhz\"\n    self._save_csv_data(csv_data, \"bar\", \"average_whole_body_sar_bar\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.base.BasePlotter","title":"goliat.analysis.plots.base.BasePlotter","text":"<pre><code>BasePlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>Base class for plot modules with shared utilities.</p> <p>Provides common helper methods for subdirectory management, data filtering, and title generation.</p> <p>Parameters:</p> Name Type Description Default <code>plots_dir</code> <code>str</code> <p>Directory where all plots will be saved.</p> required <code>phantom_name</code> <code>str | None</code> <p>Optional phantom model name for titles.</p> <code>None</code> <code>plot_format</code> <code>str</code> <p>Output format for plots ('pdf' or 'png'), default 'pdf'.</p> <code>'pdf'</code> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.base.BasePlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.boxplot.BoxplotPlotter","title":"goliat.analysis.plots.boxplot.BoxplotPlotter","text":"<pre><code>BoxplotPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates boxplot plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.boxplot.BoxplotPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.boxplot.BoxplotPlotter.plot_sar_distribution_boxplots","title":"plot_sar_distribution_boxplots","text":"<pre><code>plot_sar_distribution_boxplots(scenario_name: str, scenario_results_df: DataFrame)\n</code></pre> <p>Creates boxplots showing SAR value distributions across frequencies.</p> <p>Generates separate boxplots for each SAR and psSAR10g metric. Shows spread and outliers for each frequency. Used by near-field analysis which generates multiple plots per scenario.</p> <p>Parameters:</p> Name Type Description Default <code>scenario_name</code> <code>str</code> <p>Placement scenario name.</p> required <code>scenario_results_df</code> <code>DataFrame</code> <p>DataFrame with detailed results for all placements.</p> required Source code in <code>goliat/analysis/plots/boxplot.py</code> <pre><code>def plot_sar_distribution_boxplots(self, scenario_name: str, scenario_results_df: pd.DataFrame):\n    \"\"\"Creates boxplots showing SAR value distributions across frequencies.\n\n    Generates separate boxplots for each SAR and psSAR10g metric.\n    Shows spread and outliers for each frequency. Used by near-field analysis\n    which generates multiple plots per scenario.\n\n    Args:\n        scenario_name: Placement scenario name.\n        scenario_results_df: DataFrame with detailed results for all placements.\n    \"\"\"\n    pssar_columns = [col for col in scenario_results_df.columns if col.startswith(\"psSAR10g\")]\n    # Include all SAR metrics for symmetry with psSAR10g\n    sar_metrics_for_boxplot = [\n        \"SAR_head\",\n        \"SAR_trunk\",\n        \"SAR_whole_body\",\n        \"SAR_brain\",\n        \"SAR_skin\",\n        \"SAR_eyes\",\n        \"SAR_genitals\",\n    ] + pssar_columns\n    for metric in sar_metrics_for_boxplot:\n        if metric not in scenario_results_df.columns:\n            continue\n        if not scenario_results_df[metric].dropna().empty:\n            fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n            sns.boxplot(data=scenario_results_df, x=\"frequency_mhz\", y=metric, ax=ax, **self._get_boxplot_kwargs())\n            metric_label = METRIC_LABELS.get(metric, metric)\n            base_title = f\"distribution of normalized {metric_label} for scenario\"\n            title_full = self._get_title_with_phantom(base_title, scenario_name)\n            # Don't set title on plot - will be in caption file\n            ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n            ax.set_ylabel(self._format_axis_label(\"Normalized SAR\", r\"mW kg$^{-1}$\"))\n\n            # Add sample size annotation - use max samples per boxplot\n\n            unique_freqs = sorted(scenario_results_df[\"frequency_mhz\"].unique())\n            max_n = 0\n            for freq in unique_freqs:\n                freq_data = scenario_results_df[scenario_results_df[\"frequency_mhz\"] == freq][metric].dropna()\n                n_freq = len(freq_data)\n                if n_freq &gt; max_n:\n                    max_n = n_freq\n\n            if max_n &gt; 0:\n                ax.text(\n                    0.95,\n                    0.95,\n                    f\"n = {max_n}\",\n                    transform=ax.transAxes,\n                    fontsize=8,\n                    verticalalignment=\"top\",\n                    horizontalalignment=\"right\",\n                    bbox=dict(boxstyle=\"square,pad=0.4\", facecolor=\"white\", edgecolor=\"black\", linewidth=0.5, alpha=1.0),\n                )\n\n            # Set y-axis to start at 0 and go to max + 5%\n            y_max = ax.get_ylim()[1]\n            ax.set_ylim(0, y_max * 1.05)\n            plt.tight_layout()\n\n            phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n            caption = f\"The boxplot shows the distribution of normalized {metric_label} values across different frequencies for the {self._format_scenario_name(scenario_name)} scenario for {phantom_name_formatted}. Each box spans from the first quartile (Q1) to the third quartile (Q3), with the median line shown inside the box. The whiskers extend to show the range of the data, and points beyond the whiskers are outliers.\"\n            self._save_figure(fig, \"boxplot\", f\"boxplot_{metric}_{scenario_name}\", title=title_full, caption=caption, dpi=300)\n\n            # Save CSV data\n            csv_data = scenario_results_df[[\"frequency_mhz\", metric]].copy()\n            self._save_csv_data(csv_data, \"boxplot\", f\"boxplot_{metric}_{scenario_name}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.boxplot.BoxplotPlotter.plot_sar_distribution_boxplot_single","title":"plot_sar_distribution_boxplot_single","text":"<pre><code>plot_sar_distribution_boxplot_single(results_df: DataFrame, metric: str = 'SAR_whole_body', scenario_name: str | None = None)\n</code></pre> <p>Creates a single boxplot showing distribution of one metric across frequencies.</p> <p>Generates one boxplot for a specified metric. Shows spread and outliers for each frequency. Used by far-field analysis which calls this per-metric. Symmetric counterpart to plot_sar_distribution_boxplots.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with detailed results.</p> required <code>metric</code> <code>str</code> <p>Column name of the SAR metric to plot.</p> <code>'SAR_whole_body'</code> <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filename (default: None uses 'all').</p> <code>None</code> Source code in <code>goliat/analysis/plots/boxplot.py</code> <pre><code>def plot_sar_distribution_boxplot_single(\n    self, results_df: pd.DataFrame, metric: str = \"SAR_whole_body\", scenario_name: str | None = None\n):\n    \"\"\"Creates a single boxplot showing distribution of one metric across frequencies.\n\n    Generates one boxplot for a specified metric. Shows spread and outliers\n    for each frequency. Used by far-field analysis which calls this per-metric.\n    Symmetric counterpart to plot_sar_distribution_boxplots.\n\n    Args:\n        results_df: DataFrame with detailed results.\n        metric: Column name of the SAR metric to plot.\n        scenario_name: Optional scenario name for filename (default: None uses 'all').\n    \"\"\"\n    if metric not in results_df.columns or results_df[metric].dropna().empty:\n        logging.getLogger(\"progress\").warning(\n            f\"  - WARNING: No data for metric '{metric}' to generate boxplot.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n    sns.boxplot(data=results_df, x=\"frequency_mhz\", y=metric, ax=ax, **self._get_boxplot_kwargs())\n    metric_label = METRIC_LABELS.get(metric, metric)\n    base_title = f\"distribution of normalized {metric_label}\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n    # Don't set title on plot - will be in caption file\n    ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n    ax.set_ylabel(self._format_axis_label(\"Normalized SAR\", r\"mW kg$^{-1}$\"))\n\n    # Add sample size annotation - use max samples per boxplot (symmetric with near-field)\n    unique_freqs = sorted(results_df[\"frequency_mhz\"].unique())\n    max_n = 0\n    for freq in unique_freqs:\n        freq_data = results_df[results_df[\"frequency_mhz\"] == freq][metric].dropna()\n        n_freq = len(freq_data)\n        if n_freq &gt; max_n:\n            max_n = n_freq\n\n    if max_n &gt; 0:\n        ax.text(\n            0.95,\n            0.95,\n            f\"n = {max_n}\",\n            transform=ax.transAxes,\n            fontsize=8,\n            verticalalignment=\"top\",\n            horizontalalignment=\"right\",\n            bbox=dict(boxstyle=\"square,pad=0.4\", facecolor=\"white\", edgecolor=\"black\", linewidth=0.5, alpha=1.0),\n        )\n\n    # Set y-axis to start at 0 and go to max + 5%\n    y_max = ax.get_ylim()[1]\n    ax.set_ylim(0, y_max * 1.05)\n    plt.tight_layout()\n\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    scenario_str = f\" for the {self._format_scenario_name(scenario_name)} scenario\" if scenario_name else \"\"\n    caption = f\"The boxplot shows the distribution of normalized {metric_label} values across different frequencies{scenario_str} for {phantom_name_formatted}. Each box spans from the first quartile (Q1) to the third quartile (Q3), with the median line shown inside the box. The whiskers extend to show the range of the data, and points beyond the whiskers are outliers.\"\n    filename_base = f\"boxplot_{metric}_{scenario_name or 'all'}\"\n    self._save_figure(fig, \"boxplot\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data (symmetric with near-field)\n    csv_data = results_df[[\"frequency_mhz\", metric]].copy()\n    self._save_csv_data(csv_data, \"boxplot\", filename_base)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.bubble.BubblePlotter","title":"goliat.analysis.plots.bubble.BubblePlotter","text":"<pre><code>BubblePlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates bubble plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.bubble.BubblePlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.bubble.BubblePlotter.plot_bubble_mass_vs_sar","title":"plot_bubble_mass_vs_sar","text":"<pre><code>plot_bubble_mass_vs_sar(organ_results_df: DataFrame, sar_column: str = 'mass_avg_sar_mw_kg', scenario_name: str | None = None, frequency_mhz: int | None = None)\n</code></pre> <p>Creates bubble plot showing how tissue mass affects SAR values.</p> <p>Parameters:</p> Name Type Description Default <code>organ_results_df</code> <code>DataFrame</code> <p>DataFrame with columns: ['tissue', 'Total Mass', 'Total Volume',           sar_column, 'frequency_mhz']</p> required <code>sar_column</code> <code>str</code> <p>Column name for SAR values (default: 'mass_avg_sar_mw_kg').</p> <code>'mass_avg_sar_mw_kg'</code> <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> <code>frequency_mhz</code> <code>int | None</code> <p>Optional frequency for filtering.</p> <code>None</code> Source code in <code>goliat/analysis/plots/bubble.py</code> <pre><code>def plot_bubble_mass_vs_sar(\n    self,\n    organ_results_df: pd.DataFrame,\n    sar_column: str = \"mass_avg_sar_mw_kg\",\n    scenario_name: str | None = None,\n    frequency_mhz: int | None = None,\n):\n    \"\"\"Creates bubble plot showing how tissue mass affects SAR values.\n\n    Args:\n        organ_results_df: DataFrame with columns: ['tissue', 'Total Mass', 'Total Volume',\n                      sar_column, 'frequency_mhz']\n        sar_column: Column name for SAR values (default: 'mass_avg_sar_mw_kg').\n        scenario_name: Optional scenario name for filtering.\n        frequency_mhz: Optional frequency for filtering.\n    \"\"\"\n    if organ_results_df.empty:\n        return\n\n    plot_df = organ_results_df.copy()\n    # Filter out 'All Regions' - it's a whole-body aggregate, not a real tissue\n    plot_df = self._filter_all_regions(plot_df, tissue_column=\"tissue\")\n\n    # Filter by frequency if provided\n    if frequency_mhz is not None:\n        plot_df = plot_df[plot_df[\"frequency_mhz\"] == frequency_mhz].copy()\n\n    # Check required columns\n    required_cols = [\"tissue\", \"Total Mass\", \"Total Volume\", sar_column]\n    missing_cols = [col for col in required_cols if col not in plot_df.columns]\n    if missing_cols:\n        logging.getLogger(\"progress\").warning(\n            f\"Missing columns for bubble plot: {missing_cols}\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Remove rows with missing data\n    plot_df = plot_df.dropna(subset=required_cols)\n    plot_df = plot_df[plot_df[\"Total Mass\"] &gt; 0]\n    plot_df = plot_df[plot_df[sar_column] &gt; 0]\n\n    if plot_df.empty:\n        return\n\n    # Aggregate by tissue (mean across placements if multiple)\n    if \"placement\" in plot_df.columns:\n        plot_df = (\n            plot_df.groupby(\"tissue\")\n            .agg(\n                {\n                    \"Total Mass\": \"mean\",\n                    \"Total Volume\": \"mean\",\n                    sar_column: \"mean\",\n                    \"frequency_mhz\": \"first\",\n                }\n            )\n            .reset_index()\n        )\n\n    # Only create log-scale version on x-axis (removed linear version)\n    # Use IEEE single-column width (3.5 inches)\n    fig_log, ax_log = plt.subplots(figsize=(3.5, 4.8))  # IEEE single-column width, taller for legend\n\n    # Scale bubble size - use power of 0.75 (between sqrt and linear) for moderate scaling\n    volumes_log = plot_df[\"Total Volume\"].values\n    vol_min_log, vol_max_log = volumes_log.min(), volumes_log.max()\n    if vol_max_log &gt; vol_min_log:\n        normalized_volumes_log = (volumes_log - vol_min_log) / (vol_max_log - vol_min_log)\n        bubble_sizes_log = np.power(normalized_volumes_log, 0.75) * 50 + 10  # Scale to 10-60 range\n    else:\n        bubble_sizes_log = np.full(len(volumes_log), 30)  # Default size if all same\n\n    # Scatter plot without colorbar (volume shown by bubble size only)\n    ax_log.scatter(\n        plot_df[sar_column],\n        plot_df[\"Total Mass\"],\n        s=bubble_sizes_log,\n        c=\"gray\",  # Single color - volume shown by size only\n        alpha=0.7,\n        edgecolors=\"black\",\n        linewidth=0.5,\n    )\n\n    ax_log.set_xscale(\"log\")\n    ax_log.set_yscale(\"log\")\n    # Format SAR column name properly (preserve SAR and psSAR10g acronyms)\n    sar_display = sar_column.replace(\"_mw_kg\", \"\").replace(\"_\", \" \")\n    # Capitalize properly, preserving SAR and psSAR10g acronyms\n    sar_words = sar_display.split()\n    sar_formatted = []\n    for word in sar_words:\n        word_lower = word.lower()\n        # Check for psSAR10g in any capitalization variation and fix it\n        if \"pssar10g\" in word_lower:\n            # Replace any variation (pssar10g, Pssar10g, PSSAR10G, etc.) with psSAR10g\n            sar_formatted.append(\"psSAR10g\")\n        elif word.upper() == \"SAR\":\n            sar_formatted.append(\"SAR\")\n        else:\n            sar_formatted.append(word.capitalize())\n    sar_display_final = \" \".join(sar_formatted)\n    # Final safety check: replace any incorrect psSAR10g capitalization in the final string\n    sar_display_final = sar_display_final.replace(\"Pssar10g\", \"psSAR10g\").replace(\"PSSAR10g\", \"psSAR10g\").replace(\"Pssar\", \"psSAR\")\n    ax_log.set_xlabel(f\"{sar_display_final} (mW kg$^{{-1}}$)\")\n    ax_log.set_ylabel(\"Total Mass (kg)\")\n\n    # Add extra space to x-axis max value for label visibility\n    x_min, x_max = ax_log.get_xlim()\n    ax_log.set_xlim(x_min, x_max * 1.15)  # Add 15% extra space on right\n\n    ax_log.grid(True, alpha=0.3)\n\n    # Add bubble size legend with updated scaling\n    volumes_legend = plot_df[\"Total Volume\"].values\n    vol_min_legend, vol_max_legend = volumes_legend.min(), volumes_legend.max()\n    if vol_max_legend &gt; vol_min_legend:\n        # Use quantiles for legend sizes\n        q25 = plot_df[\"Total Volume\"].quantile(0.25)\n        q75 = plot_df[\"Total Volume\"].quantile(0.75)\n        vol_max_legend_val = plot_df[\"Total Volume\"].max()\n\n        # Normalize and apply power scaling\n        def scale_volume(v):\n            \"\"\"Map volume to marker size with power scaling for  better visual spread.\"\"\"\n            normalized = (v - vol_min_legend) / (vol_max_legend - vol_min_legend) if vol_max_legend &gt; vol_min_legend else 0.5\n            return np.power(normalized, 0.75) * 50 + 10\n\n        sizes_for_legend = [scale_volume(q25), scale_volume(q75), scale_volume(vol_max_legend_val)]\n        labels_for_legend = [f\"{q25 * 1e6:.1e} m$^3$\", f\"{q75 * 1e6:.1e} m$^3$\", f\"{vol_max_legend_val * 1e6:.1e} m$^3$\"]\n    else:\n        sizes_for_legend = [30]\n        labels_for_legend = [f\"{vol_min_legend * 1e6:.1e} m$^3$\"]\n\n    legend_elements_log = [\n        plt.scatter([], [], s=s, c=\"gray\", alpha=0.7, edgecolors=\"black\", linewidth=0.5, label=label)\n        for s, label in zip(sizes_for_legend, labels_for_legend)\n    ]\n    # Place legend below the plot\n    legend_log = ax_log.legend(\n        handles=legend_elements_log,\n        title=\"Bubble Size (Volume)\",\n        loc=\"upper center\",\n        bbox_to_anchor=(0.5, -0.15),\n        ncol=len(legend_elements_log),\n        fontsize=8,\n        frameon=True,\n        fancybox=False,\n        shadow=False,\n        edgecolor=\"black\",\n        facecolor=\"white\",\n        framealpha=1.0,\n    )\n    legend_log.get_frame().set_linewidth(0.5)\n    # Adjust figure to accommodate legend\n    fig_log.subplots_adjust(bottom=0.2)\n\n    # Label ALL tissues/organ with smaller fontsize\n    for _, row in plot_df.iterrows():\n        tissue_clean = self._format_organ_name(row[\"tissue\"])\n        ax_log.annotate(\n            tissue_clean,\n            (row[sar_column], row[\"Total Mass\"]),\n            fontsize=5,  # Reduced from 6 to 5\n            alpha=0.8,\n            textcoords=\"offset points\",\n            xytext=(3, 3),\n            ha=\"left\",\n            bbox=dict(boxstyle=\"square,pad=0.2\", facecolor=\"white\", alpha=0.7, edgecolor=\"gray\", linewidth=0.3),  # No rounded corners\n        )\n\n    plt.tight_layout()\n\n    # Create safe filename from sar_column\n    sar_name_safe = sar_column.replace(\"_mw_kg\", \"\").replace(\"_\", \"_\")\n    filename_base_log = f\"bubble_mass_vs_{sar_name_safe}_{scenario_name or 'all'}_{frequency_mhz or 'all'}MHz_log\"\n\n    # Remove title from plot - will be in caption file\n    ax_log.set_title(\"\")  # Remove title\n\n    base_title_log = \"Tissue Mass vs SAR Bubble Plot (Log Scale)\"\n    title_full_log = self._get_title_with_phantom(base_title_log, scenario_name)\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption_log = f\"The bubble plot shows tissue mass vs {sar_display_final} with bubble size proportional to tissue volume (log scale on both axes) for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario{f' at {frequency_mhz} MHz' if frequency_mhz else ''} for {phantom_name_formatted}.\"\n\n    filename_log = self._save_figure(fig_log, \"bubble\", filename_base_log, title=title_full_log, caption=caption_log, dpi=300)\n\n    # Save CSV data\n    csv_data = plot_df[[\"tissue\", \"Total Mass\", \"Total Volume\", sar_column, \"frequency_mhz\"]].copy()\n    self._save_csv_data(csv_data, \"bubble\", filename_base_log)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated bubble plot (log scale): {filename_log}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.bubble.BubblePlotter.plot_bubble_mass_vs_sar_interactive","title":"plot_bubble_mass_vs_sar_interactive","text":"<pre><code>plot_bubble_mass_vs_sar_interactive(organ_results_df: DataFrame, sar_column: str = 'mass_avg_sar_mw_kg', scenario_name: str | None = None)\n</code></pre> <p>Creates an interactive bubble plot (plotly) with common axis limits across frequencies.</p> <p>Uses Plotly for interactive visualization (not affected by scienceplots).</p> <p>Parameters:</p> Name Type Description Default <code>organ_results_df</code> <code>DataFrame</code> <p>DataFrame with columns: ['tissue', 'Total Mass', 'Total Volume',           sar_column, 'frequency_mhz', 'placement']</p> required <code>sar_column</code> <code>str</code> <p>Column name for SAR values (default: 'mass_avg_sar_mw_kg').</p> <code>'mass_avg_sar_mw_kg'</code> <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> Source code in <code>goliat/analysis/plots/bubble.py</code> <pre><code>def plot_bubble_mass_vs_sar_interactive(\n    self,\n    organ_results_df: pd.DataFrame,\n    sar_column: str = \"mass_avg_sar_mw_kg\",\n    scenario_name: str | None = None,\n):\n    \"\"\"Creates an interactive bubble plot (plotly) with common axis limits across frequencies.\n\n    Uses Plotly for interactive visualization (not affected by scienceplots).\n\n    Args:\n        organ_results_df: DataFrame with columns: ['tissue', 'Total Mass', 'Total Volume',\n                      sar_column, 'frequency_mhz', 'placement']\n        sar_column: Column name for SAR values (default: 'mass_avg_sar_mw_kg').\n        scenario_name: Optional scenario name for filtering.\n    \"\"\"\n    try:\n        import plotly.graph_objects as go\n        from plotly.subplots import make_subplots\n    except ImportError:\n        logging.getLogger(\"progress\").warning(\n            \"Plotly not available. Skipping interactive bubble plot. Install with: pip install plotly\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    if organ_results_df.empty:\n        return\n\n    plot_df = organ_results_df.copy()\n    # Filter out 'All Regions'\n    plot_df = self._filter_all_regions(plot_df, tissue_column=\"tissue\")\n\n    if scenario_name:\n        plot_df = plot_df[plot_df[\"scenario\"] == scenario_name].copy()\n\n    # Check required columns\n    required_cols = [\"tissue\", \"Total Mass\", \"Total Volume\", sar_column, \"frequency_mhz\"]\n    missing_cols = [col for col in required_cols if col not in plot_df.columns]\n    if missing_cols:\n        logging.getLogger(\"progress\").warning(\n            f\"Missing columns for interactive bubble plot: {missing_cols}\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Remove rows with missing data\n    plot_df = plot_df.dropna(subset=required_cols)\n    plot_df = plot_df[plot_df[\"Total Mass\"] &gt; 0]\n    plot_df = plot_df[plot_df[sar_column] &gt; 0]\n\n    if plot_df.empty:\n        return\n\n    # Get common axis limits across all frequencies\n    x_min = plot_df[sar_column].min()\n    x_max = plot_df[sar_column].max()\n    y_min = plot_df[\"Total Mass\"].min()\n    y_max = plot_df[\"Total Mass\"].max()\n\n    # Format SAR column name properly (preserve SAR and psSAR10g acronyms)\n    sar_display = sar_column.replace(\"_mw_kg\", \"\").replace(\"_\", \" \")\n    # Capitalize properly, preserving SAR and psSAR10g acronyms\n    sar_words = sar_display.split()\n    sar_formatted = []\n    for word in sar_words:\n        word_lower = word.lower()\n        # Check for psSAR10g in any capitalization variation and fix it\n        if \"pssar10g\" in word_lower:\n            # Replace any variation (pssar10g, Pssar10g, PSSAR10G, etc.) with psSAR10g\n            sar_formatted.append(\"psSAR10g\")\n        elif word.upper() == \"SAR\":\n            sar_formatted.append(\"SAR\")\n        else:\n            sar_formatted.append(word.capitalize())\n    sar_display_final = \" \".join(sar_formatted)\n    # Final safety check: replace any incorrect psSAR10g capitalization in the final string\n    sar_display_final = sar_display_final.replace(\"Pssar10g\", \"psSAR10g\").replace(\"PSSAR10g\", \"psSAR10g\").replace(\"Pssar\", \"psSAR\")\n\n    # Get unique frequencies\n    frequencies = sorted(plot_df[\"frequency_mhz\"].unique())\n\n    # Create subplots - one per frequency\n    n_freqs = len(frequencies)\n    cols = min(3, n_freqs)\n    rows = (n_freqs + cols - 1) // cols\n\n    fig = make_subplots(\n        rows=rows,\n        cols=cols,\n        subplot_titles=[f\"{freq} MHz\" for freq in frequencies],\n        horizontal_spacing=0.1,\n        vertical_spacing=0.12,\n    )\n\n    # Color scale for frequencies\n    colorscale = \"Jet\"\n\n    for idx, freq in enumerate(frequencies):\n        freq_data = plot_df[plot_df[\"frequency_mhz\"] == freq].copy()\n\n        # Aggregate by tissue (mean across placements if multiple)\n        if \"placement\" in freq_data.columns:\n            freq_data = (\n                freq_data.groupby(\"tissue\")\n                .agg(\n                    {\n                        \"Total Mass\": \"mean\",\n                        \"Total Volume\": \"mean\",\n                        sar_column: \"mean\",\n                    }\n                )\n                .reset_index()\n            )\n\n        row = (idx // cols) + 1\n        col = (idx % cols) + 1\n\n        # Scale bubble size - use power of 0.75 (between sqrt and linear) for moderate scaling\n        volumes = freq_data[\"Total Volume\"].values\n        # Normalize volumes to 0-1 range, then apply power scaling\n        vol_min, vol_max = volumes.min(), volumes.max()\n        if vol_max &gt; vol_min:\n            normalized_volumes = (volumes - vol_min) / (vol_max - vol_min)\n            bubble_sizes = np.power(normalized_volumes, 0.75) * 50 + 10  # Scale to 10-60 range\n        else:\n            bubble_sizes = np.full(len(volumes), 30)  # Default size if all same\n\n        fig.add_trace(\n            go.Scatter(\n                x=freq_data[sar_column],\n                y=freq_data[\"Total Mass\"],\n                mode=\"markers\",\n                marker=dict(\n                    size=bubble_sizes,\n                    sizemode=\"diameter\",\n                    sizeref=1.0,  # Direct size reference\n                    sizemin=4,\n                    color=freq,\n                    colorscale=colorscale,\n                    showscale=(idx == 0),\n                    colorbar=dict(title=\"Frequency (MHz)\") if idx == 0 else None,\n                    line=dict(width=0.5, color=\"black\"),\n                ),\n                text=[self._format_organ_name(t) for t in freq_data[\"tissue\"]],\n                hovertemplate=\"&lt;b&gt;%{text}&lt;/b&gt;&lt;br&gt;\"\n                + f\"{sar_display_final}: %{{x:.2f}} mW/kg&lt;br&gt;\"\n                + \"Mass: %{y:.4f} kg&lt;br&gt;\"\n                + \"Volume: %{marker.size:.2e} m\u00b3&lt;extra&gt;&lt;/extra&gt;\",\n                name=f\"{freq} MHz\",\n                showlegend=False,\n            ),\n            row=row,\n            col=col,\n        )\n\n        # Set common axis limits\n        fig.update_xaxes(\n            type=\"log\",\n            range=[np.log10(x_min * 0.9), np.log10(x_max * 1.1)],\n            title_text=f\"{sar_display_final} (mW/kg)\",\n            row=row,\n            col=col,\n        )\n        fig.update_yaxes(\n            type=\"log\",\n            range=[np.log10(y_min * 0.9), np.log10(y_max * 1.1)],\n            title_text=\"Total Mass (kg)\",\n            row=row,\n            col=col,\n        )\n\n    # Update layout\n    base_title = \"Tissue Mass vs SAR Bubble Plot (Interactive)\"\n    title_with_phantom = self._get_title_with_phantom(base_title, scenario_name)\n    # Don't set title on plot - will be in caption file\n    fig.update_layout(\n        title=\"\",\n        height=300 * rows,\n        showlegend=False,\n    )\n\n    subdir = self._get_subdir(\"bubble\")\n    sar_name_safe = sar_column.replace(\"_mw_kg\", \"\").replace(\"_\", \"_\")\n    filename = f\"bubble_mass_vs_{sar_name_safe}_{scenario_name or 'all'}_interactive.html\"\n    fig.write_html(os.path.join(subdir, filename))\n\n    # Create caption file for HTML plot\n    caption_filename = filename.replace(\".html\", \".txt\")\n    caption_path = os.path.join(subdir, caption_filename)\n    # Format SAR column name properly for caption (preserve SAR and psSAR10g acronyms)\n    sar_display_interactive = sar_column.replace(\"_mw_kg\", \"\").replace(\"_\", \" \")\n    sar_words_interactive = sar_display_interactive.split()\n    sar_formatted_interactive = []\n    for word in sar_words_interactive:\n        word_lower = word.lower()\n        # Check for psSAR10g in any capitalization variation and fix it\n        if \"pssar10g\" in word_lower:\n            # Replace any variation (pssar10g, Pssar10g, PSSAR10G, etc.) with psSAR10g\n            sar_formatted_interactive.append(\"psSAR10g\")\n        elif word.upper() == \"SAR\":\n            sar_formatted_interactive.append(\"SAR\")\n        else:\n            sar_formatted_interactive.append(word.capitalize())\n    sar_display_final_interactive = \" \".join(sar_formatted_interactive)\n    # Final safety check: replace any incorrect psSAR10g capitalization in the final string\n    sar_display_final_interactive = (\n        sar_display_final_interactive.replace(\"Pssar10g\", \"psSAR10g\").replace(\"PSSAR10g\", \"psSAR10g\").replace(\"Pssar\", \"psSAR\")\n    )\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"Interactive bubble plot showing tissue mass vs {sar_display_final_interactive} with bubble size proportional to tissue volume (log scale on both axes) for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario for {phantom_name_formatted}. Each subplot corresponds to a different frequency, with common axis limits for comparison.\"\n    with open(caption_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(f\"Title: {title_with_phantom}\\n\\n\")\n        f.write(f\"Caption: {caption}\\n\")\n\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated interactive bubble plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.cdf.CdfPlotter","title":"goliat.analysis.plots.cdf.CdfPlotter","text":"<pre><code>CdfPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates CDF plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.cdf.CdfPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.cdf.CdfPlotter.plot_cdf","title":"plot_cdf","text":"<pre><code>plot_cdf(results_df: DataFrame, metric: str, group_by: str | list[str] | None = None, scenario_name: str | None = None, frequency_mhz: int | None = None)\n</code></pre> <p>Creates CDF plot for a metric with optional aggregation by independent variables.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with simulation results.</p> required <code>metric</code> <code>str</code> <p>Column name for the metric to plot.</p> required <code>group_by</code> <code>str | list[str] | None</code> <p>Column name(s) to group by for multiple CDF lines (e.g., 'scenario', 'frequency_mhz', 'placement').      Can be a single string or list of strings. If None, plots single CDF.</p> <code>None</code> <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> <code>frequency_mhz</code> <code>int | None</code> <p>Optional frequency for filtering.</p> <code>None</code> Source code in <code>goliat/analysis/plots/cdf.py</code> <pre><code>def plot_cdf(\n    self,\n    results_df: pd.DataFrame,\n    metric: str,\n    group_by: str | list[str] | None = None,\n    scenario_name: str | None = None,\n    frequency_mhz: int | None = None,\n):\n    \"\"\"Creates CDF plot for a metric with optional aggregation by independent variables.\n\n    Args:\n        results_df: DataFrame with simulation results.\n        metric: Column name for the metric to plot.\n        group_by: Column name(s) to group by for multiple CDF lines (e.g., 'scenario', 'frequency_mhz', 'placement').\n                 Can be a single string or list of strings. If None, plots single CDF.\n        scenario_name: Optional scenario name for filtering.\n        frequency_mhz: Optional frequency for filtering.\n    \"\"\"\n    if metric not in results_df.columns:\n        logging.getLogger(\"progress\").warning(\n            f\"Metric '{metric}' not found for CDF plot.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    plot_df = results_df.copy()\n\n    # Filter by scenario if provided\n    if scenario_name:\n        plot_df = plot_df[plot_df[\"scenario\"] == scenario_name].copy()\n\n    # Filter by frequency if provided\n    if frequency_mhz is not None:\n        plot_df = plot_df[plot_df[\"frequency_mhz\"] == frequency_mhz].copy()\n\n    # Remove missing values\n    plot_df = plot_df.dropna(subset=[metric])\n    plot_df = plot_df[plot_df[metric] &gt; 0]  # Only positive values\n\n    if plot_df.empty:\n        return\n\n    fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n\n    # If group_by is specified, create multiple CDF lines\n    if group_by:\n        if isinstance(group_by, str):\n            group_by = [group_by]\n\n        # Get unique combinations of grouping variables\n        if all(col in plot_df.columns for col in group_by):\n            groups = plot_df.groupby(group_by)\n\n            # Generate colors and linestyles for each group using academic palettes\n            n_groups = len(groups)\n            colors = self._get_academic_colors(n_groups)\n            linestyles = self._get_academic_linestyles(n_groups)\n\n            formatted_labels = []\n            handles_list = []\n            for idx, ((group_vals, group_df), color) in enumerate(zip(groups, colors)):\n                if isinstance(group_vals, tuple):\n                    # Format each value to be human readable\n                    formatted_vals = []\n                    for col, val in zip(group_by, group_vals):\n                        # Format value based on column type\n                        if col == \"frequency_mhz\":\n                            formatted_vals.append(f\"{val} MHz\")\n                        elif col == \"scenario\":\n                            val_formatted = (\n                                self._format_organ_name(str(val))\n                                if hasattr(self, \"_format_organ_name\")\n                                else str(val).replace(\"_\", \" \").title()\n                            )\n                            formatted_vals.append(val_formatted)\n                        else:\n                            val_formatted = (\n                                self._format_organ_name(str(val))\n                                if hasattr(self, \"_format_organ_name\")\n                                else str(val).replace(\"_\", \" \").title()\n                            )\n                            formatted_vals.append(val_formatted)\n                    label = \" | \".join(formatted_vals)\n                else:\n                    # Format single value\n                    if group_by[0] == \"frequency_mhz\":\n                        label = f\"{group_vals} MHz\"\n                    elif group_by[0] == \"scenario\":\n                        label = (\n                            self._format_organ_name(str(group_vals))\n                            if hasattr(self, \"_format_organ_name\")\n                            else str(group_vals).replace(\"_\", \" \").title()\n                        )\n                    else:\n                        label = (\n                            self._format_organ_name(str(group_vals))\n                            if hasattr(self, \"_format_organ_name\")\n                            else str(group_vals).replace(\"_\", \" \").title()\n                        )\n\n                formatted_labels.append(label)\n\n                # Calculate CDF\n                sorted_values = np.sort(group_df[metric].values)\n                n = len(sorted_values)\n                y = np.arange(1, n + 1) / n\n\n                line = ax.plot(sorted_values, y, label=label, linewidth=2, color=color, linestyle=linestyles[idx], alpha=0.8)\n                handles_list.append(line[0])\n\n            # Place legend below plot - use 2 columns for frequencies or when there are 4 items\n            from .line import LinePlotter\n\n            line_plotter = LinePlotter(self.plots_dir, self.phantom_name, self.plot_format)\n            # Use 2 columns for frequencies, or when there are 4 items for balanced layout\n            n_cols = (\n                2\n                if (\n                    (isinstance(group_by, list) and \"frequency_mhz\" in group_by)\n                    or (isinstance(group_by, str) and group_by == \"frequency_mhz\")\n                    or len(formatted_labels) == 4\n                )\n                else min(3, len(formatted_labels))\n            )\n            line_plotter._place_legend_below(\n                fig, ax, len(formatted_labels), n_cols=n_cols, handles=handles_list, labels=formatted_labels\n            )\n\n            # Add n= label - use max sample size across groups\n            max_n = max(len(group_df) for _, group_df in groups)\n            ax.text(\n                0.95,\n                0.95,\n                f\"n = {max_n}\",\n                transform=ax.transAxes,\n                fontsize=8,\n                verticalalignment=\"top\",\n                horizontalalignment=\"right\",\n                bbox=dict(boxstyle=\"square,pad=0.4\", facecolor=\"white\", edgecolor=\"black\", linewidth=0.5, alpha=1.0),\n            )\n        else:\n            # Fallback: single CDF\n            sorted_values = np.sort(plot_df[metric].values)\n            n = len(sorted_values)\n            y = np.arange(1, n + 1) / n\n            ax.plot(sorted_values, y, linewidth=2)\n    else:\n        # Single CDF\n        sorted_values = np.sort(plot_df[metric].values)\n        n = len(sorted_values)\n        y = np.arange(1, n + 1) / n\n        ax.plot(sorted_values, y, linewidth=2)\n\n    metric_label = METRIC_LABELS.get(metric, metric.replace(\"_\", \" \").title())\n    ax.set_xlabel(f\"{metric_label} (mW kg$^{{-1}}$)\")\n    ax.set_ylabel(\"Cumulative Probability\")\n\n    # xlim should start at 0\n    if ax.get_lines():\n        x_max = 0\n        for line in ax.get_lines():\n            x_data = line.get_xdata()\n            if len(x_data) &gt; 0:\n                x_max = max(x_max, x_data.max())\n        ax.set_xlim(0, x_max * 1.05)\n\n    # For CDF plots, y-axis should start at first y value (not 0) and go to 1.0\n    y_min = 0.0  # Default value\n    if ax.get_lines():\n        # Get all y values from plotted lines\n        y_min = 1.0\n        for line in ax.get_lines():\n            y_data = line.get_ydata()\n            if len(y_data) &gt; 0:\n                y_min = min(y_min, y_data[0])\n        ax.set_ylim(y_min, 1.0)\n    else:\n        # Fallback if no lines\n        ax.set_ylim(0, 1.0)\n\n    # Add inset for \"all scenarios, all frequencies\" plots to zoom in on non-outliers\n    # Detect if this is an \"all_allMHz\" plot (scenario_name is None and frequency_mhz is None)\n    is_all_all_plot = scenario_name is None and frequency_mhz is None and group_by\n\n    if is_all_all_plot and ax.get_lines() and len(ax.get_lines()) &gt; 1:\n        from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n\n        # Get max x value for each line to detect outlier\n        line_maxes = []\n        for line in ax.get_lines():\n            x_data = line.get_xdata()\n            if len(x_data) &gt; 0:\n                line_maxes.append((x_data.max(), line))\n\n        if len(line_maxes) &gt;= 2:\n            # Sort by max value\n            line_maxes.sort(key=lambda x: x[0], reverse=True)\n            max_val = line_maxes[0][0]\n            second_max = line_maxes[1][0]\n\n            # Check if there's an outlier (max is &gt; 2x the second highest)\n            if max_val &gt; second_max * 2.0:\n                # Create inset zoomed to the non-outlier range\n                ax_inset = inset_axes(ax, width=\"40%\", height=\"40%\", loc=\"lower right\", borderpad=1.5)\n\n                # Replot all lines in the inset with reduced linewidth\n                colors = self._get_academic_colors(len(ax.get_lines()))\n                linestyles = self._get_academic_linestyles(len(ax.get_lines()))\n                for idx, line in enumerate(ax.get_lines()):\n                    x_data = line.get_xdata()\n                    y_data = line.get_ydata()\n                    ax_inset.plot(x_data, y_data, linewidth=1, color=colors[idx], linestyle=linestyles[idx], alpha=0.8)\n\n                # Set inset limits to zoom on non-outlier data (up to 95th percentile of second highest)\n                # Use second_max * 1.1 as max x to include some margin\n                inset_x_max = second_max * 1.1\n                ax_inset.set_xlim(0, inset_x_max)\n                ax_inset.set_ylim(y_min, 1.0)\n                ax_inset.tick_params(labelsize=6)\n                ax_inset.grid(True, alpha=0.3)\n                ax_inset.set_title(\"Zoomed (excl. outlier)\", fontsize=7, pad=2)\n\n    # Add n= label for single CDF\n    if not group_by:\n        n_samples = len(plot_df)\n        ax.text(\n            0.95,\n            0.95,\n            f\"n = {n_samples}\",\n            transform=ax.transAxes,\n            fontsize=8,\n            verticalalignment=\"top\",\n            horizontalalignment=\"right\",\n            bbox=dict(boxstyle=\"square,pad=0.4\", facecolor=\"white\", edgecolor=\"black\", linewidth=0.5, alpha=1.0),\n        )\n\n    ax.grid(True, alpha=0.3, which=\"both\")\n\n    # Create title with phantom name - format as sentence without colons or underscores\n    metric_label = METRIC_LABELS.get(metric, metric.replace(\"_\", \" \").title())\n    # Format scenario name to remove underscores\n    formatted_scenario = self._format_scenario_name(scenario_name) if scenario_name else None\n    # Build title parts - no colon, flow as sentence\n    if formatted_scenario:\n        if frequency_mhz:\n            base_title = f\"cumulative distribution function for {metric_label} in {formatted_scenario} scenario at {frequency_mhz} MHz\"\n        else:\n            base_title = f\"cumulative distribution function for {metric_label} in {formatted_scenario} scenario\"\n    else:\n        if frequency_mhz:\n            base_title = f\"cumulative distribution function for {metric_label} at {frequency_mhz} MHz\"\n        else:\n            base_title = f\"cumulative distribution function for {metric_label}\"\n    title_full = self._get_title_with_phantom(base_title)\n    # Don't set title on plot - will be in caption file\n\n    plt.tight_layout()\n\n    metric_safe = metric.replace(\"SAR\", \"\").replace(\"psSAR10g_\", \"\").replace(\"_\", \"_\")\n    group_suffix = \"_\".join(group_by) if group_by else \"all\"\n    scenario_suffix = scenario_name or \"all\"\n    freq_suffix = f\"{frequency_mhz}MHz\" if frequency_mhz else \"allMHz\"\n    filename_base = f\"cdf_{metric_safe}_{group_suffix}_{scenario_suffix}_{freq_suffix}\"\n    # Format group_by for caption - replace underscores and format nicely\n    if group_by:\n        if isinstance(group_by, str):\n            group_by_list = [group_by]\n        else:\n            group_by_list = group_by\n        # Format each group_by item - replace frequency_mhz with frequency, format others\n        formatted_groups = []\n        for gb in group_by_list:\n            if gb == \"frequency_mhz\":\n                formatted_groups.append(\"frequency\")\n            elif gb == \"scenario\":\n                formatted_groups.append(\"scenario\")\n            else:\n                # Format other group_by columns nicely\n                formatted_groups.append(gb.replace(\"_\", \" \"))\n        group_text = \", \".join(formatted_groups)\n        group_suffix_text = f\"Grouped by {group_text}.\"\n    else:\n        group_suffix_text = \"\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The cumulative distribution function (CDF) plot shows the probability distribution of {metric_label} values for {phantom_name_formatted}. {group_suffix_text}\"\n    filename = self._save_figure(fig, \"cdf\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data - save the raw plot data\n    csv_data = plot_df[[metric]].copy()\n    if group_by:\n        if isinstance(group_by, str):\n            group_by = [group_by]\n        for col in group_by:\n            if col in plot_df.columns:\n                csv_data[col] = plot_df[col]\n    self._save_csv_data(csv_data, \"cdf\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated CDF plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.correlation.CorrelationPlotter","title":"goliat.analysis.plots.correlation.CorrelationPlotter","text":"<pre><code>CorrelationPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates correlation plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.correlation.CorrelationPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.correlation.CorrelationPlotter.plot_correlation_head_vs_eye_sar","title":"plot_correlation_head_vs_eye_sar","text":"<pre><code>plot_correlation_head_vs_eye_sar(results_df: DataFrame, scenario_name: str = 'front_of_eyes')\n</code></pre> <p>Creates scatter plot showing correlation between Head SAR and Eye psSAR10g with linear regression.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with columns: ['SAR_head', 'psSAR10g_eyes', 'frequency_mhz', 'scenario']</p> required <code>scenario_name</code> <code>str</code> <p>Scenario to filter for (default: 'front_of_eyes').</p> <code>'front_of_eyes'</code> Source code in <code>goliat/analysis/plots/correlation.py</code> <pre><code>def plot_correlation_head_vs_eye_sar(\n    self,\n    results_df: pd.DataFrame,\n    scenario_name: str = \"front_of_eyes\",\n):\n    \"\"\"Creates scatter plot showing correlation between Head SAR and Eye psSAR10g with linear regression.\n\n    Args:\n        results_df: DataFrame with columns: ['SAR_head', 'psSAR10g_eyes', 'frequency_mhz', 'scenario']\n        scenario_name: Scenario to filter for (default: 'front_of_eyes').\n    \"\"\"\n    from scipy import stats\n\n    if scenario_name:\n        plot_df = results_df[results_df[\"scenario\"] == scenario_name].copy()\n    else:\n        plot_df = results_df.copy()\n\n    plot_df[\"SAR_head\"] = pd.to_numeric(plot_df[\"SAR_head\"], errors=\"coerce\")\n    plot_df[\"psSAR10g_eyes\"] = pd.to_numeric(plot_df[\"psSAR10g_eyes\"], errors=\"coerce\")\n    correlation_df = plot_df.dropna(subset=[\"SAR_head\", \"psSAR10g_eyes\"])\n\n    if correlation_df.empty:\n        logging.getLogger(\"progress\").warning(\n            f\"No valid data for correlation plot (scenario: {scenario_name})\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Perform linear regression\n    slope, intercept, r_value, p_value, std_err = stats.linregress(correlation_df[\"SAR_head\"], correlation_df[\"psSAR10g_eyes\"])\n    r_squared = r_value**2\n\n    fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n\n    # Scatter plot colored by frequency\n    if \"frequency_mhz\" in correlation_df.columns:\n        scatter = ax.scatter(\n            correlation_df[\"SAR_head\"],\n            correlation_df[\"psSAR10g_eyes\"],\n            c=correlation_df[\"frequency_mhz\"],\n            cmap=\"jet\",\n            s=30,\n            alpha=0.7,\n        )\n        cbar = plt.colorbar(scatter, ax=ax)\n        cbar.set_label(\"Frequency (MHz)\")\n    else:\n        ax.scatter(correlation_df[\"SAR_head\"], correlation_df[\"psSAR10g_eyes\"], s=30, alpha=0.7)\n\n    # Plot regression line\n    x_vals = np.array(ax.get_xlim())\n    y_vals = intercept + slope * x_vals\n    ax.plot(x_vals, y_vals, \"--\", color=\"red\", linewidth=2, label=f\"Linear Fit (R\u00b2={r_squared:.4f})\")\n\n    formatted_scenario = self._format_scenario_name(scenario_name)\n    base_title = \"correlation between head SAR and eye psSAR10g\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n    # Don't set title on plot - will be in caption file\n    ax.set_xlabel(self._format_axis_label(\"Normalized head SAR\", r\"mW kg$^{-1}$\"))\n    ax.set_ylabel(self._format_axis_label(\"Normalized psSAR10g eyes\", r\"mW kg$^{-1}$\"))\n\n    # Add R\u00b2 value annotation\n    ax.text(\n        0.98,\n        0.98,\n        f\"R\u00b2 = {r_squared:.4f}\\np = {p_value:.4f}\",\n        transform=ax.transAxes,\n        fontsize=8,\n        verticalalignment=\"top\",\n        horizontalalignment=\"right\",\n        bbox=dict(boxstyle=\"square\", facecolor=\"white\", edgecolor=\"black\", linewidth=0.5, pad=0.3),\n    )\n\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n\n    plt.tight_layout()\n\n    filename_base = f\"correlation_head_vs_eye_sar_{scenario_name}\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The scatter plot shows the correlation between normalized head SAR and normalized eye psSAR10g values for the {formatted_scenario} scenario for {phantom_name_formatted}. Points are colored by frequency. The red dashed line shows the linear fit with R\u00b2 and p-value annotations.\"\n    filename = self._save_figure(fig, \"correlation\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = correlation_df[[\"SAR_head\", \"psSAR10g_eyes\"]].copy()\n    if \"frequency_mhz\" in correlation_df.columns:\n        csv_data[\"frequency_mhz\"] = correlation_df[\"frequency_mhz\"]\n    self._save_csv_data(csv_data, \"correlation\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated correlation plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.correlation.CorrelationPlotter.plot_tissue_group_correlation_matrix","title":"plot_tissue_group_correlation_matrix","text":"<pre><code>plot_tissue_group_correlation_matrix(results_df: DataFrame, scenario_name: str | None = None)\n</code></pre> <p>Creates heatmap showing correlation coefficients between different tissue group SAR values.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with tissue group SAR columns (SAR_eyes, SAR_brain, etc.)</p> required <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> Source code in <code>goliat/analysis/plots/correlation.py</code> <pre><code>def plot_tissue_group_correlation_matrix(\n    self,\n    results_df: pd.DataFrame,\n    scenario_name: str | None = None,\n):\n    \"\"\"Creates heatmap showing correlation coefficients between different tissue group SAR values.\n\n    Args:\n        results_df: DataFrame with tissue group SAR columns (SAR_eyes, SAR_brain, etc.)\n        scenario_name: Optional scenario name for filtering.\n    \"\"\"\n    # Filter by scenario if provided\n    if scenario_name:\n        plot_df = results_df[results_df[\"scenario\"] == scenario_name].copy()\n    else:\n        plot_df = results_df.copy()\n\n    # Find all SAR columns\n    sar_cols = [col for col in plot_df.columns if col.startswith(\"SAR_\") or col.startswith(\"psSAR10g_\")]\n    sar_cols = [col for col in sar_cols if col in plot_df.columns]\n\n    # Exclude columns that are all NaN\n    valid_sar_cols = []\n    for col in sar_cols:\n        if not plot_df[col].isna().all():\n            valid_sar_cols.append(col)\n\n    if len(valid_sar_cols) &lt; 2:\n        logging.getLogger(\"progress\").warning(\n            \"Not enough valid SAR columns for correlation matrix.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Convert pd.NA to np.nan and drop rows with all NaN\n    sar_data = plot_df[valid_sar_cols].copy()\n    sar_data = sar_data.replace(pd.NA, np.nan)\n    sar_data = sar_data.dropna(how=\"all\")\n\n    if sar_data.empty or len(sar_data) &lt; 2:\n        logging.getLogger(\"progress\").warning(\n            \"Not enough valid data for correlation matrix.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Calculate correlation matrix (only numeric columns)\n    # Use pairwise deletion to handle missing values better\n    correlation_matrix = sar_data.corr(method=\"pearson\", min_periods=2)\n\n    # Create human-readable labels for columns\n    def get_human_readable_label(col_name):\n        \"\"\"Convert column name to human-readable label.\"\"\"\n        # Try METRIC_LABELS first (full labels)\n        if col_name in METRIC_LABELS:\n            return METRIC_LABELS[col_name]\n        # Try LEGEND_LABELS (trimmed labels)\n        if col_name in LEGEND_LABELS:\n            label = LEGEND_LABELS[col_name]\n            # Add \"SAR\" or \"psSAR10g\" prefix if needed for clarity\n            if col_name.startswith(\"SAR_\"):\n                return f\"{label} SAR\"\n            elif col_name.startswith(\"psSAR10g_\"):\n                return f\"psSAR10g {label}\"\n            return label\n        # Fallback: format the column name\n        return col_name.replace(\"SAR_\", \"\").replace(\"psSAR10g_\", \"psSAR10g \").replace(\"_\", \" \").title()\n\n    # Rename columns and index with human-readable labels\n    correlation_matrix_labeled = correlation_matrix.copy()\n    readable_labels = [get_human_readable_label(col) for col in correlation_matrix.columns]\n    correlation_matrix_labeled.columns = readable_labels\n    correlation_matrix_labeled.index = readable_labels\n\n    # Create heatmap\n    fig, ax = plt.subplots(figsize=(7.16, 5.5))  # IEEE two-column width for correlation matrix\n    sns.heatmap(\n        correlation_matrix_labeled,\n        annot=True,\n        fmt=\".3f\",\n        cmap=\"RdBu_r\",\n        center=0,\n        vmin=-1,\n        vmax=1,\n        square=True,\n        linewidths=0.5,\n        cbar_kws={\"label\": \"Correlation Coefficient\"},\n        ax=ax,\n    )\n\n    base_title = \"tissue group correlation matrix\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n    # Don't set title on plot - will be in caption file\n    plt.tight_layout()\n\n    filename_base = f\"correlation_matrix_tissue_groups_{scenario_name}\" if scenario_name else \"correlation_matrix_tissue_groups\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The heatmap shows Pearson correlation coefficients between different tissue group SAR values for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario for {phantom_name_formatted}. Values range from -1 (perfect negative correlation) to +1 (perfect positive correlation).\"\n    filename = self._save_figure(fig, \"correlation\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    self._save_csv_data(correlation_matrix, \"correlation\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated correlation matrix: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.heatmap.HeatmapPlotter","title":"goliat.analysis.plots.heatmap.HeatmapPlotter","text":"<pre><code>HeatmapPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates heatmap plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.heatmap.HeatmapPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.heatmap.HeatmapPlotter.plot_sar_heatmap","title":"plot_sar_heatmap","text":"<pre><code>plot_sar_heatmap(organ_df: DataFrame, group_df: DataFrame, tissue_groups: dict)\n</code></pre> <p>Creates separate heatmaps for Min, Avg, and Max SAR per tissue and frequency.</p> <p>Generates three separate heatmaps instead of a combined summary. Each heatmap has two panels: top shows individual tissues, bottom shows group summaries. Uses log-scale colormap for better visibility.</p> Source code in <code>goliat/analysis/plots/heatmap.py</code> <pre><code>def plot_sar_heatmap(self, organ_df: pd.DataFrame, group_df: pd.DataFrame, tissue_groups: dict):\n    \"\"\"Creates separate heatmaps for Min, Avg, and Max SAR per tissue and frequency.\n\n    Generates three separate heatmaps instead of a combined summary.\n    Each heatmap has two panels: top shows individual tissues, bottom shows group summaries.\n    Uses log-scale colormap for better visibility.\n    \"\"\"\n    # Generate separate heatmaps for min, avg, and max\n    self._plot_sar_heatmap_single(organ_df, group_df, tissue_groups, \"min_sar\", \"Min\")\n    self._plot_sar_heatmap_single(organ_df, group_df, tissue_groups, \"avg_sar\", \"Avg\")\n    self._plot_sar_heatmap_single(organ_df, group_df, tissue_groups, \"max_sar\", \"Max\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.heatmap.HeatmapPlotter.plot_peak_sar_heatmap","title":"plot_peak_sar_heatmap","text":"<pre><code>plot_peak_sar_heatmap(organ_df: DataFrame, group_df: DataFrame, tissue_groups: dict, value_col: str = 'peak_sar_10g_mw_kg', title: str = 'Peak SAR')\n</code></pre> <p>Creates a heatmap for peak SAR values across tissues and frequencies.</p> <p>Similar structure to plot_sar_heatmap but focused on peak SAR metrics. Shows individual tissues and group summaries in separate panels. 'All Regions' is excluded as it's a whole-body aggregate, not a real tissue.</p> <p>Parameters:</p> Name Type Description Default <code>organ_df</code> <code>DataFrame</code> <p>DataFrame with organ-level peak SAR data.</p> required <code>group_df</code> <code>DataFrame</code> <p>DataFrame with group-level summaries.</p> required <code>tissue_groups</code> <code>dict</code> <p>Dict mapping groups to tissue lists.</p> required <code>value_col</code> <code>str</code> <p>Column name containing the peak SAR values.</p> <code>'peak_sar_10g_mw_kg'</code> <code>title</code> <code>str</code> <p>Title for the plot.</p> <code>'Peak SAR'</code> Source code in <code>goliat/analysis/plots/heatmap.py</code> <pre><code>def plot_peak_sar_heatmap(\n    self,\n    organ_df: pd.DataFrame,\n    group_df: pd.DataFrame,\n    tissue_groups: dict,\n    value_col: str = \"peak_sar_10g_mw_kg\",\n    title: str = \"Peak SAR\",\n):\n    \"\"\"Creates a heatmap for peak SAR values across tissues and frequencies.\n\n    Similar structure to plot_sar_heatmap but focused on peak SAR metrics.\n    Shows individual tissues and group summaries in separate panels.\n    'All Regions' is excluded as it's a whole-body aggregate, not a real tissue.\n\n    Args:\n        organ_df: DataFrame with organ-level peak SAR data.\n        group_df: DataFrame with group-level summaries.\n        tissue_groups: Dict mapping groups to tissue lists.\n        value_col: Column name containing the peak SAR values.\n        title: Title for the plot.\n    \"\"\"\n    # Filter out 'All Regions' - it's a whole-body aggregate, not a real tissue\n    organ_df = self._filter_all_regions(organ_df, tissue_column=\"tissue\")\n\n    # Clean and format tissue names before pivoting (remove phantom identifiers and format for display)\n    organ_df_clean = organ_df.copy()\n    organ_df_clean[\"tissue\"] = organ_df_clean[\"tissue\"].apply(lambda x: self._format_organ_name(x))\n\n    organ_pivot = organ_df_clean.pivot_table(index=\"tissue\", columns=\"frequency_mhz\", values=value_col)\n    organ_pivot = organ_pivot.loc[(organ_pivot &gt; 0.01).any(axis=1)]\n    mean_organ_sar = organ_pivot.mean(axis=1).sort_values(ascending=False)\n    organ_pivot = organ_pivot.reindex(mean_organ_sar.index)\n\n    group_pivot = group_df.pivot_table(index=\"group\", columns=\"frequency_mhz\", values=value_col)\n    if isinstance(group_pivot, pd.DataFrame) and not group_pivot.empty:\n        mean_group_sar = group_pivot.mean(axis=1)\n        if isinstance(mean_group_sar, pd.Series):\n            mean_group_sar = mean_group_sar.sort_values(ascending=False)\n            group_pivot = group_pivot.reindex(mean_group_sar.index)\n\n    if organ_pivot.empty:\n        return\n\n    # Use two-column width for wide heatmaps, scale height dynamically based on content\n    # Calculate height: base height + height per row (with reduced row height for compact cells)\n    min_row_height = 0.25  # Reduced from 0.35 - minimum inches per row for readability\n    base_height = 2.0  # Base height for titles, spacing, group summary\n    organ_height = max(len(organ_pivot) * min_row_height, len(organ_pivot) * 0.08)  # Reduced from 0.12 - dynamic per-row height\n    group_height = max(len(group_pivot) * 0.25, 0.8) if not group_pivot.empty else 0  # Reduced from 0.4 and 1.0\n    total_height = base_height + organ_height + group_height\n    fig = plt.figure(figsize=(7.16, total_height))\n    gs = gridspec.GridSpec(\n        2,\n        2,\n        height_ratios=[len(organ_pivot), len(group_pivot) + 1],\n        width_ratios=[0.95, 0.05],\n        hspace=0.1,\n    )\n    ax_organ = fig.add_subplot(gs[0, 0])\n    ax_group = fig.add_subplot(gs[1, 0])\n    cbar_ax = fig.add_subplot(gs[:, 1])\n\n    # Create title with phantom name\n    base_title = f\"{title} (mW kg$^{{-1}}$) per tissue\"\n    title_with_phantom = self._get_title_with_phantom(base_title)\n\n    # Plot organ heatmap without title\n    sns.heatmap(\n        organ_pivot,\n        ax=ax_organ,\n        annot=True,\n        fmt=\".2f\",\n        cmap=\"jet\",\n        linewidths=0.5,\n        norm=LogNorm(vmin=organ_pivot[organ_pivot &gt; 0].min().min(), vmax=organ_pivot.max().max()),\n        cbar=True,\n        cbar_ax=cbar_ax,\n        xticklabels=False,  # Remove x tickmarks\n        yticklabels=True,  # Keep y labels but reduce fontsize\n        square=False,  # Allow rectangular cells for more compact vertical layout\n    )\n    ax_organ.set_xlabel(\"\")\n    ax_organ.set_ylabel(\"Tissue\")\n    ax_organ.tick_params(labelsize=6, which=\"minor\", length=0)  # Reduced fontsize, no minor ticks\n\n    # Color tissue labels by group\n    group_colors_peak = {\"eyes\": \"red\", \"skin\": \"green\", \"brain\": \"blue\", \"genitals\": \"purple\"}\n    tissue_to_group = {}\n    for group, tissues in tissue_groups.items():\n        for tissue in tissues:\n            tissue_clean = self._format_organ_name(tissue)\n            tissue_to_group[tissue_clean] = group.lower().replace(\"_group\", \"\").replace(\"group\", \"\")\n\n    for tick_label in ax_organ.get_yticklabels():\n        tissue_name = tick_label.get_text()\n        group_name = tissue_to_group.get(tissue_name, \"\")\n        if group_name in group_colors_peak:\n            tick_label.set_color(group_colors_peak[group_name])\n        tick_label.set_fontsize(6)  # Reduced fontsize\n\n    # Plot group summary without title\n    sns.heatmap(\n        group_pivot,\n        ax=ax_group,\n        annot=True,\n        fmt=\".2f\",\n        cmap=\"jet\",\n        linewidths=0.5,\n        norm=LogNorm(vmin=group_pivot[group_pivot &gt; 0].min().min(), vmax=group_pivot.max().max()) if not group_pivot.empty else None,\n        cbar=False,\n        xticklabels=False,  # Remove x tickmarks\n        yticklabels=True,  # Keep y labels but reduce fontsize\n        square=False,  # Allow rectangular cells for more compact vertical layout\n    )\n    ax_group.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n    ax_group.set_ylabel(\"\")\n    ax_group.tick_params(labelsize=6, which=\"minor\", length=0)  # Reduced fontsize, no minor ticks\n    # Color group labels\n    for tick_label in ax_group.get_yticklabels():\n        tick_label.set_rotation(0)\n        group_name = tick_label.get_text().lower().replace(\"_group\", \"\").replace(\"group\", \"\")\n        if group_name in group_colors_peak:\n            tick_label.set_color(group_colors_peak[group_name])\n        tick_label.set_fontsize(6)  # Reduced fontsize\n\n    plt.tight_layout(rect=(0, 0, 0.95, 0.98))\n    filename_base = f\"heatmap_{value_col}_summary\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The heatmap shows {title} values per tissue across frequencies for {phantom_name_formatted}. The top panel shows individual tissues, and the bottom panel shows organ group summaries. Tissues are colored by group (red=eyes, green=skin, blue=brain, purple=genitals).\"\n    filename = self._save_figure(fig, \"heatmap\", filename_base, title=title_with_phantom, caption=caption, dpi=300)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated {title} heatmap: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n\n    # Also create HTML version\n    try:\n        import plotly.graph_objects as go\n        from plotly.subplots import make_subplots\n\n        # Create HTML version\n        fig_html = make_subplots(\n            rows=2,\n            cols=1,\n            subplot_titles=[\"\", \"\"],  # Remove subplot titles\n            vertical_spacing=0.15,\n        )\n\n        # Organ heatmap\n        z_min_organ = organ_pivot[organ_pivot &gt; 0].min().min() if (organ_pivot &gt; 0).any().any() else 0.01\n        z_max_organ = organ_pivot.max().max()\n        fig_html.add_trace(\n            go.Heatmap(\n                z=organ_pivot.values,\n                x=organ_pivot.columns.tolist(),\n                y=organ_pivot.index.tolist(),\n                colorscale=\"Jet\",\n                zmin=z_min_organ,\n                zmax=z_max_organ,\n                colorbar=dict(title=f\"{title} (mW/kg)\", len=0.5, y=0.75),\n                text=organ_pivot.values,\n                texttemplate=\"%{text:.2f}\",\n                textfont={\"size\": 8},\n            ),\n            row=1,\n            col=1,\n        )\n\n        # Group heatmap\n        if not group_pivot.empty:\n            z_min_group = group_pivot[group_pivot &gt; 0].min().min() if (group_pivot &gt; 0).any().any() else 0.01\n            z_max_group = group_pivot.max().max()\n            fig_html.add_trace(\n                go.Heatmap(\n                    z=group_pivot.values,\n                    x=group_pivot.columns.tolist(),\n                    y=group_pivot.index.tolist(),\n                    colorscale=\"Jet\",\n                    zmin=z_min_group,\n                    zmax=z_max_group,\n                    colorbar=dict(title=f\"{title} (mW/kg)\", len=0.5, y=0.25),\n                    text=group_pivot.values,\n                    texttemplate=\"%{text:.2f}\",\n                    textfont={\"size\": 10},\n                ),\n                row=2,\n                col=1,\n            )\n\n        fig_html.update_layout(\n            title=self._get_title_with_phantom(f\"{title} per tissue\"),\n            height=600 + len(organ_pivot) * 15,\n        )\n\n        subdir = self._get_subdir(\"heatmap\")\n        html_filename = f\"heatmap_{value_col}_summary.html\"\n        fig_html.write_html(os.path.join(subdir, html_filename))\n        logging.getLogger(\"progress\").info(\n            f\"  - Generated {title} heatmap (HTML): {html_filename}\",\n            extra={\"log_type\": \"success\"},\n        )\n    except ImportError:\n        logging.getLogger(\"progress\").warning(\n            \"Plotly not available. Skipping HTML heatmap. Install with: pip install plotly\",\n            extra={\"log_type\": \"warning\"},\n        )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.heatmap.HeatmapPlotter.plot_far_field_direction_polarization_heatmap","title":"plot_far_field_direction_polarization_heatmap","text":"<pre><code>plot_far_field_direction_polarization_heatmap(results_df: DataFrame, metric: str = 'SAR_whole_body', frequency_mhz: int | None = None)\n</code></pre> <p>Creates a heatmap comparing SAR values across incident directions and polarizations.</p> <p>This visualization is specific to far-field analysis where simulations are run for different incident wave directions (from left, right, front, back, above, below) and polarizations (theta, phi). The heatmap shows where SAR is highest and lowest.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with 'placement' column containing direction/polarization info.</p> required <code>metric</code> <code>str</code> <p>SAR metric to plot (default: 'SAR_whole_body').</p> <code>'SAR_whole_body'</code> <code>frequency_mhz</code> <code>int | None</code> <p>Optional frequency to filter. If None, averages across all frequencies.</p> <code>None</code> Source code in <code>goliat/analysis/plots/heatmap.py</code> <pre><code>def plot_far_field_direction_polarization_heatmap(\n    self,\n    results_df: pd.DataFrame,\n    metric: str = \"SAR_whole_body\",\n    frequency_mhz: int | None = None,\n):\n    \"\"\"Creates a heatmap comparing SAR values across incident directions and polarizations.\n\n    This visualization is specific to far-field analysis where simulations are run\n    for different incident wave directions (from left, right, front, back, above, below) and polarizations\n    (theta, phi). The heatmap shows where SAR is highest and lowest.\n\n    Args:\n        results_df: DataFrame with 'placement' column containing direction/polarization info.\n        metric: SAR metric to plot (default: 'SAR_whole_body').\n        frequency_mhz: Optional frequency to filter. If None, averages across all frequencies.\n    \"\"\"\n    if metric not in results_df.columns or results_df[metric].dropna().empty:\n        logging.getLogger(\"progress\").warning(\n            f\"  - WARNING: No data for metric '{metric}' to generate direction/polarization heatmap.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Parse placement column to extract direction and polarization\n    df = results_df.copy()\n\n    def parse_placement(placement: str) -&gt; tuple[str, str]:\n        \"\"\"Parse placement string like 'environmental_x_pos_theta' to ('From left', 'Theta').\"\"\"\n        # Direction labels describe where the wave is coming FROM (not propagation direction)\n        direction_labels = {\n            \"x_pos\": \"From left\",\n            \"x_neg\": \"From right\",\n            \"y_pos\": \"From back\",\n            \"y_neg\": \"From front\",\n            \"z_pos\": \"From below\",\n            \"z_neg\": \"From above\",\n        }\n        parts = placement.replace(\"environmental_\", \"\").split(\"_\")\n        if len(parts) &gt;= 3:\n            dir_key = f\"{parts[0]}_{parts[1]}\"\n            direction = direction_labels.get(dir_key, f\"{parts[0].upper()}{'+' if parts[1] == 'pos' else '-'}\")\n            pol = \"Theta\" if parts[2] == \"theta\" else \"Phi\"\n            return direction, pol\n        return placement, \"Unknown\"\n\n    df[[\"direction\", \"polarization\"]] = df[\"placement\"].apply(lambda x: pd.Series(parse_placement(x)))\n\n    # Filter by frequency if specified\n    if frequency_mhz is not None:\n        df = df[df[\"frequency_mhz\"] == frequency_mhz]\n        freq_suffix = f\"_{frequency_mhz}MHz\"\n    else:\n        freq_suffix = \"_allMHz\"\n\n    if df.empty:\n        logging.getLogger(\"progress\").warning(\n            f\"  - WARNING: No data after filtering for heatmap (metric={metric}, freq={frequency_mhz}).\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Create pivot table: direction x polarization\n    # If multiple frequencies, take the mean\n    pivot = df.pivot_table(\n        index=\"direction\",\n        columns=\"polarization\",\n        values=metric,\n        aggfunc=\"mean\",\n    )\n\n    # Reorder directions for logical display\n    direction_order = [\"From left\", \"From right\", \"From back\", \"From front\", \"From below\", \"From above\"]\n    pivot = pivot.reindex([d for d in direction_order if d in pivot.index])\n\n    # Reorder polarizations (Theta, Phi)\n    pol_order = [\"Theta\", \"Phi\"]\n    pivot = pivot[[p for p in pol_order if p in pivot.columns]]\n\n    if pivot.empty:\n        logging.getLogger(\"progress\").warning(\n            \"  - WARNING: Empty pivot table for direction/polarization heatmap.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Create figure - compact size since we only have 6x2 cells\n    fig, ax = plt.subplots(figsize=(3.5, 4.0))\n\n    # Use a diverging colormap centered on the mean\n    vmin = pivot.min().min()\n    vmax = pivot.max().max()\n\n    # Use log scale if values span more than 2 orders of magnitude\n    use_log = vmax / vmin &gt; 100 if vmin &gt; 0 else False\n\n    if use_log:\n        from matplotlib.colors import LogNorm\n\n        norm = LogNorm(vmin=vmin, vmax=vmax)\n    else:\n        norm = None\n\n    sns.heatmap(\n        pivot,\n        ax=ax,\n        annot=True,\n        fmt=\".1f\",\n        cmap=\"RdYlGn_r\",  # Red=high SAR, Green=low SAR\n        linewidths=1.0,\n        linecolor=\"white\",\n        cbar_kws={\"label\": f\"{self._format_organ_name(metric)} (mW/kg)\"},\n        norm=norm,\n        square=True,\n    )\n\n    # Styling\n    ax.set_xlabel(\"Polarization\", fontsize=9)\n    ax.set_ylabel(\"Incident Direction\", fontsize=9)\n    ax.tick_params(labelsize=8)\n\n    # Rotate y-axis labels for better readability\n    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n\n    plt.tight_layout()\n\n    # Create title and caption\n    from .base import METRIC_LABELS\n\n    metric_label = METRIC_LABELS.get(metric, metric)\n    freq_text = f\"at {frequency_mhz} MHz\" if frequency_mhz else \"averaged across all frequencies\"\n    base_title = f\"far-field {metric_label} by incident direction and polarization {freq_text}\"\n    title_full = self._get_title_with_phantom(base_title)\n\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = (\n        f\"The heatmap compares normalized {metric_label} values for {phantom_name_formatted} \"\n        f\"across different far-field incident wave directions (from left, right, front, back, above, below) and polarizations (Theta, Phi) \"\n        f\"{freq_text}. Red indicates higher SAR absorption, green indicates lower SAR absorption. \"\n        f\"This visualization helps identify which exposure configurations result in the highest and lowest SAR values.\"\n    )\n\n    filename_base = f\"heatmap_direction_polarization_{metric}{freq_suffix}\"\n    filename = self._save_figure(fig, \"heatmap\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    self._save_csv_data(pivot, \"heatmap\", filename_base)\n\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated direction/polarization heatmap: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n\n    return filename\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.heatmap.HeatmapPlotter.plot_far_field_direction_polarization_summary","title":"plot_far_field_direction_polarization_summary","text":"<pre><code>plot_far_field_direction_polarization_summary(results_df: DataFrame, metrics: list[str] | None = None)\n</code></pre> <p>Creates a multi-panel summary comparing SAR metrics across directions/polarizations.</p> <p>Generates both individual metric heatmaps and a combined multi-panel figure.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with 'placement' column containing direction/polarization info.</p> required <code>metrics</code> <code>list[str] | None</code> <p>List of metrics to plot. If None, plots common metrics.</p> <code>None</code> Source code in <code>goliat/analysis/plots/heatmap.py</code> <pre><code>def plot_far_field_direction_polarization_summary(\n    self,\n    results_df: pd.DataFrame,\n    metrics: list[str] | None = None,\n):\n    \"\"\"Creates a multi-panel summary comparing SAR metrics across directions/polarizations.\n\n    Generates both individual metric heatmaps and a combined multi-panel figure.\n\n    Args:\n        results_df: DataFrame with 'placement' column containing direction/polarization info.\n        metrics: List of metrics to plot. If None, plots common metrics.\n    \"\"\"\n    if metrics is None:\n        # Default metrics to plot - includes tissue group SAR and psSAR10g metrics\n        possible_metrics = [\n            # Whole-body and peak metrics\n            \"SAR_whole_body\",\n            \"peak_sar\",\n            # SAR tissue groups (average SAR per tissue group)\n            \"SAR_brain\",\n            \"SAR_skin\",\n            \"SAR_eyes\",\n            \"SAR_genitals\",\n            # psSAR10g metrics (peak spatial-average SAR)\n            \"psSAR10g_brain\",\n            \"psSAR10g_skin\",\n            \"psSAR10g_eyes\",\n            \"psSAR10g_genitals\",\n        ]\n        metrics = [m for m in possible_metrics if m in results_df.columns and results_df[m].notna().any()]\n\n    if not metrics:\n        logging.getLogger(\"progress\").warning(\n            \"  - WARNING: No valid metrics for direction/polarization summary.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Generate individual heatmaps for each metric\n    for metric in metrics:\n        self.plot_far_field_direction_polarization_heatmap(results_df, metric=metric)\n\n    # Create a multi-panel combined figure\n    self._plot_far_field_direction_polarization_combined(results_df, metrics)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.heatmap.HeatmapPlotter.plot_polarization_ratio_heatmap","title":"plot_polarization_ratio_heatmap","text":"<pre><code>plot_polarization_ratio_heatmap(results_df: DataFrame, metrics: list[str] | None = None)\n</code></pre> <p>Plots heatmap of theta/phi polarization ratio for each direction and metric.</p> <p>Creates a heatmap showing frequency-averaged polarization ratios. Ratios &gt; 1.0 indicate theta dominates; &lt; 1.0 indicates phi dominates.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with placement column containing direction and polarization info.</p> required <code>metrics</code> <code>list[str] | None</code> <p>List of metrics to analyze. If None, uses common metrics.</p> <code>None</code> Source code in <code>goliat/analysis/plots/heatmap.py</code> <pre><code>def plot_polarization_ratio_heatmap(\n    self,\n    results_df: pd.DataFrame,\n    metrics: list[str] | None = None,\n):\n    \"\"\"Plots heatmap of theta/phi polarization ratio for each direction and metric.\n\n    Creates a heatmap showing frequency-averaged polarization ratios.\n    Ratios &gt; 1.0 indicate theta dominates; &lt; 1.0 indicates phi dominates.\n\n    Args:\n        results_df: DataFrame with placement column containing direction and polarization info.\n        metrics: List of metrics to analyze. If None, uses common metrics.\n    \"\"\"\n    if results_df.empty:\n        return\n\n    # Parse placement to extract direction and polarization\n    def parse_placement(placement: str) -&gt; tuple[str | None, str | None]:\n        parts = placement.split(\"_\")\n        if len(parts) &gt;= 4:\n            direction = f\"{parts[1]}_{parts[2]}\"  # e.g., \"x_pos\"\n            pol = parts[3]  # \"theta\" or \"phi\"\n            return direction, pol\n        return None, None\n\n    df = results_df.copy()\n    df[[\"direction\", \"polarization\"]] = df[\"placement\"].apply(lambda x: pd.Series(parse_placement(x)))\n    df = df.dropna(subset=[\"direction\", \"polarization\"])\n\n    if df.empty:\n        return\n\n    if metrics is None:\n        possible_metrics = [\"SAR_whole_body\", \"psSAR10g_brain\", \"psSAR10g_eyes\", \"psSAR10g_skin\", \"psSAR10g_genitals\"]\n        metrics = [m for m in possible_metrics if m in df.columns and df[m].notna().any()]\n\n    if not metrics:\n        return\n\n    # Direction display names and order (human-readable: describes where wave comes FROM)\n    direction_names = {\n        \"x_pos\": \"From left\",\n        \"x_neg\": \"From right\",\n        \"y_pos\": \"From back\",\n        \"y_neg\": \"From front\",\n        \"z_pos\": \"From below\",\n        \"z_neg\": \"From above\",\n    }\n\n    direction_order = [\"x_pos\", \"x_neg\", \"y_pos\", \"y_neg\", \"z_pos\", \"z_neg\"]\n    available_directions = [d for d in direction_order if d in df[\"direction\"].unique()]\n\n    # Compute ratio for each direction and metric (averaged across frequencies)\n    ratio_data = {}\n    for direction in available_directions:\n        dir_df = df[df[\"direction\"] == direction]\n        direction_ratios = {}\n\n        for metric in metrics:\n            if metric not in dir_df.columns:\n                continue\n\n            pivot = dir_df.pivot_table(values=metric, index=\"frequency_mhz\", columns=\"polarization\", aggfunc=\"mean\")\n\n            if \"theta\" not in pivot.columns or \"phi\" not in pivot.columns:\n                continue\n\n            # Average ratio across frequencies\n            ratios = pivot[\"theta\"] / pivot[\"phi\"]\n            avg_ratio = ratios.mean()\n            direction_ratios[metric] = avg_ratio\n\n        if direction_ratios:\n            ratio_data[direction_names.get(direction, direction)] = direction_ratios\n\n    if not ratio_data:\n        return\n\n    # Create DataFrame for heatmap\n    ratio_df = pd.DataFrame(ratio_data).T\n\n    # Rename columns for display\n    metric_labels = {\n        \"SAR_whole_body\": \"Whole Body\",\n        \"SAR_brain\": \"Brain\",\n        \"SAR_eyes\": \"Eyes\",\n        \"SAR_skin\": \"Skin\",\n        \"SAR_genitals\": \"Genitals\",\n        \"psSAR10g_brain\": \"Brain\",\n        \"psSAR10g_eyes\": \"Eyes\",\n        \"psSAR10g_skin\": \"Skin\",\n        \"psSAR10g_genitals\": \"Genitals\",\n    }\n    ratio_df = ratio_df.rename(columns=metric_labels)\n\n    # Reorder rows\n    row_order = [\"From left\", \"From right\", \"From back\", \"From front\", \"From below\", \"From above\"]\n    ratio_df = ratio_df.reindex([r for r in row_order if r in ratio_df.index])\n\n    # Create figure - IEEE single-column width\n    fig, ax = plt.subplots(figsize=(3.5, 3.0))\n\n    # Colormap starting from 0, centered at 1.0\n    from matplotlib.colors import TwoSlopeNorm\n\n    vmin = 0.0  # Start from 0\n    vmax = max(ratio_df.max().max(), 2.0)  # Ensure we show at least up to 2.0\n    vcenter = 1.0\n\n    norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n\n    sns.heatmap(\n        ratio_df,\n        ax=ax,\n        annot=True,\n        fmt=\".2f\",\n        cmap=\"RdBu_r\",  # Red for theta dominates (&gt;1), Blue for phi dominates (&lt;1)\n        norm=norm,\n        linewidths=0.5,\n        cbar_kws={\"label\": \"Polarization Ratio (Theta/Phi)\"},\n    )\n\n    ax.set_xlabel(\"Tissue Group\", fontsize=10)\n    ax.set_ylabel(\"Incident Direction\", fontsize=10)\n    ax.tick_params(axis=\"both\", labelsize=9, which=\"both\")\n    ax.minorticks_off()  # Remove minor ticks\n\n    plt.tight_layout()\n\n    # Save\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    title = self._get_title_with_phantom(\"Polarization Ratio (Theta/Phi) by Direction\")\n    caption = (\n        f\"Heatmap showing the theta/phi polarization ratio for {phantom_name_formatted}, \"\n        f\"averaged across all frequencies. \"\n        f\"Ratio &gt; 1.0 (red) indicates theta polarization gives higher SAR. \"\n        f\"Ratio &lt; 1.0 (blue) indicates phi polarization dominates. \"\n        f\"Note: These are frequency-averaged values; significant frequency-dependent variations exist.\"\n    )\n\n    filename = self._save_figure(fig, \"heatmap\", \"heatmap_polarization_ratio\", title=title, caption=caption, dpi=200)\n\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated polarization ratio heatmap: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.heatmap.HeatmapPlotter.plot_polarization_ratio_heatmaps_per_frequency","title":"plot_polarization_ratio_heatmaps_per_frequency","text":"<pre><code>plot_polarization_ratio_heatmaps_per_frequency(results_df: DataFrame, metrics: list[str] | None = None)\n</code></pre> <p>Plots polarization ratio heatmaps for each frequency separately.</p> <p>Creates individual heatmaps showing theta/phi ratios for each frequency, allowing detailed analysis of frequency-dependent polarization effects.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with placement column containing direction and polarization info.</p> required <code>metrics</code> <code>list[str] | None</code> <p>List of metrics to analyze. If None, uses common metrics.</p> <code>None</code> Source code in <code>goliat/analysis/plots/heatmap.py</code> <pre><code>def plot_polarization_ratio_heatmaps_per_frequency(\n    self,\n    results_df: pd.DataFrame,\n    metrics: list[str] | None = None,\n):\n    \"\"\"Plots polarization ratio heatmaps for each frequency separately.\n\n    Creates individual heatmaps showing theta/phi ratios for each frequency,\n    allowing detailed analysis of frequency-dependent polarization effects.\n\n    Args:\n        results_df: DataFrame with placement column containing direction and polarization info.\n        metrics: List of metrics to analyze. If None, uses common metrics.\n    \"\"\"\n    if results_df.empty:\n        return\n\n    # Parse placement to extract direction and polarization\n    def parse_placement(placement: str) -&gt; tuple[str | None, str | None]:\n        parts = placement.split(\"_\")\n        if len(parts) &gt;= 4:\n            direction = f\"{parts[1]}_{parts[2]}\"\n            pol = parts[3]\n            return direction, pol\n        return None, None\n\n    df = results_df.copy()\n    df[[\"direction\", \"polarization\"]] = df[\"placement\"].apply(lambda x: pd.Series(parse_placement(x)))\n    df = df.dropna(subset=[\"direction\", \"polarization\"])\n\n    if df.empty:\n        return\n\n    if metrics is None:\n        possible_metrics = [\"SAR_whole_body\", \"psSAR10g_brain\", \"psSAR10g_eyes\", \"psSAR10g_skin\", \"psSAR10g_genitals\"]\n        metrics = [m for m in possible_metrics if m in df.columns and df[m].notna().any()]\n\n    if not metrics:\n        return\n\n    frequencies = sorted(df[\"frequency_mhz\"].unique())\n\n    direction_names = {\n        \"x_pos\": \"From left\",\n        \"x_neg\": \"From right\",\n        \"y_pos\": \"From back\",\n        \"y_neg\": \"From front\",\n        \"z_pos\": \"From below\",\n        \"z_neg\": \"From above\",\n    }\n    direction_order = [\"x_pos\", \"x_neg\", \"y_pos\", \"y_neg\", \"z_pos\", \"z_neg\"]\n    available_directions = [d for d in direction_order if d in df[\"direction\"].unique()]\n\n    metric_labels = {\n        \"SAR_whole_body\": \"Whole Body\",\n        \"SAR_brain\": \"Brain\",\n        \"SAR_eyes\": \"Eyes\",\n        \"SAR_skin\": \"Skin\",\n        \"SAR_genitals\": \"Genitals\",\n        \"psSAR10g_brain\": \"Brain\",\n        \"psSAR10g_eyes\": \"Eyes\",\n        \"psSAR10g_skin\": \"Skin\",\n        \"psSAR10g_genitals\": \"Genitals\",\n    }\n\n    from matplotlib.colors import TwoSlopeNorm\n\n    for freq in frequencies:\n        freq_df = df[df[\"frequency_mhz\"] == freq]\n\n        # Compute ratio for each direction and metric\n        ratio_data = {}\n        for direction in available_directions:\n            dir_df = freq_df[freq_df[\"direction\"] == direction]\n            direction_ratios = {}\n\n            for metric in metrics:\n                if metric not in dir_df.columns:\n                    continue\n\n                theta_val = dir_df[dir_df[\"polarization\"] == \"theta\"][metric].mean()\n                phi_val = dir_df[dir_df[\"polarization\"] == \"phi\"][metric].mean()\n\n                if pd.notna(theta_val) and pd.notna(phi_val) and phi_val != 0:\n                    direction_ratios[metric] = theta_val / phi_val\n\n            if direction_ratios:\n                ratio_data[direction_names.get(direction, direction)] = direction_ratios\n\n        if not ratio_data:\n            continue\n\n        ratio_df = pd.DataFrame(ratio_data).T\n        ratio_df = ratio_df.rename(columns=metric_labels)\n        row_order = [\"From left\", \"From right\", \"From back\", \"From front\", \"From below\", \"From above\"]\n        ratio_df = ratio_df.reindex([r for r in row_order if r in ratio_df.index])\n\n        # Create figure - use IEEE single-column width for proper font scaling\n        fig, ax = plt.subplots(figsize=(3.5, 3.0))\n\n        # Colormap starting from 0, centered at 1.0\n        vmin = 0.0\n        vmax = max(ratio_df.max().max(), 2.0)\n        vcenter = 1.0\n\n        norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n\n        sns.heatmap(\n            ratio_df,\n            ax=ax,\n            annot=True,\n            fmt=\".2f\",\n            cmap=\"RdBu_r\",\n            norm=norm,\n            linewidths=0.5,\n            cbar_kws={\"label\": \"Polarization Ratio (Theta/Phi)\"},\n            annot_kws={\"fontsize\": 8},\n        )\n\n        ax.set_xlabel(\"Tissue Group\", fontsize=9)\n        ax.set_ylabel(\"Incident Direction\", fontsize=9)\n        ax.set_title(f\"{int(freq)} MHz\", fontsize=10, fontweight=\"bold\")\n        ax.tick_params(axis=\"both\", labelsize=8, which=\"both\")\n        ax.minorticks_off()  # Remove minor ticks\n\n        plt.tight_layout()\n\n        filename = f\"heatmap_polarization_ratio_{int(freq)}MHz\"\n        self._save_figure(fig, \"heatmap\", filename, dpi=200)\n\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated {len(frequencies)} per-frequency polarization ratio heatmaps\",\n        extra={\"log_type\": \"info\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter","title":"goliat.analysis.plots.line.LinePlotter","text":"<pre><code>LinePlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates line plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter.plot_peak_sar_line","title":"plot_peak_sar_line","text":"<pre><code>plot_peak_sar_line(summary_stats: DataFrame)\n</code></pre> <p>Plots peak SAR trend across frequencies for far-field analysis.</p> Source code in <code>goliat/analysis/plots/line.py</code> <pre><code>def plot_peak_sar_line(self, summary_stats: pd.DataFrame):\n    \"\"\"Plots peak SAR trend across frequencies for far-field analysis.\"\"\"\n    fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n    title_full = self._get_title_with_phantom(\"average peak SAR (10g) across all tissues\")\n    if \"peak_sar\" in summary_stats.columns:\n        summary_stats[\"peak_sar\"].plot(kind=\"line\", marker=\"o\", ax=ax, color=\"purple\")\n        # Don't set title on plot - will be in caption file\n        ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n        ax.set_ylabel(self._format_axis_label(\"Normalized peak SAR\", r\"mW kg$^{-1}$\"))\n        ax.set_xticks(summary_stats.index)\n        # Rotate x-axis labels only for actual simulated frequencies (1450, 2140, 2450, etc.)\n        # Check if frequencies are actual simulated values (not auto-generated)\n        freq_values = summary_stats.index.tolist()\n        simulated_freqs = [1450, 2140, 2450]\n        if freq_values and any(isinstance(f, (int, float)) and f in simulated_freqs for f in freq_values):\n            plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n            self._adjust_slanted_tick_labels(ax)\n        ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n        # Set y-axis to start at 0 and go to max + 5%\n        y_max = ax.get_ylim()[1]\n        ax.set_ylim(0, y_max * 1.05)\n    else:\n        ax.text(0.5, 0.5, \"No Peak SAR data found\", ha=\"center\", va=\"center\")\n    plt.tight_layout()\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The line plot shows the trend of average peak SAR (10g) values across all tissues as a function of frequency for {phantom_name_formatted}.\"\n    self._save_figure(fig, \"line\", \"line_peak_sar_summary\", title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = summary_stats[[\"peak_sar\"]].copy() if \"peak_sar\" in summary_stats.columns else pd.DataFrame()\n    csv_data.index.name = \"frequency_mhz\"\n    if not csv_data.empty:\n        self._save_csv_data(csv_data, \"line\", \"line_peak_sar_summary\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter.plot_pssar_line","title":"plot_pssar_line","text":"<pre><code>plot_pssar_line(scenario_name: str, avg_results: DataFrame)\n</code></pre> <p>Plots average psSAR10g trends for tissue groups by frequency.</p> <p>Shows how peak spatial-average SAR varies with frequency for eyes, skin, and brain groups.</p> <p>Parameters:</p> Name Type Description Default <code>scenario_name</code> <code>str</code> <p>Placement scenario name.</p> required <code>avg_results</code> <code>DataFrame</code> <p>DataFrame with average psSAR10g values.</p> required Source code in <code>goliat/analysis/plots/line.py</code> <pre><code>def plot_pssar_line(self, scenario_name: str, avg_results: pd.DataFrame):\n    \"\"\"Plots average psSAR10g trends for tissue groups by frequency.\n\n    Shows how peak spatial-average SAR varies with frequency for eyes,\n    skin, and brain groups.\n\n    Args:\n        scenario_name: Placement scenario name.\n        avg_results: DataFrame with average psSAR10g values.\n    \"\"\"\n    pssar_columns = [col for col in avg_results.columns if col.startswith(\"psSAR10g\")]\n    base_title = \"average normalized psSAR10g for scenario\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n\n    # Calculate dynamic height based on legend size\n    n_items = len(pssar_columns) if pssar_columns else 0\n    legend_height = self._calculate_legend_height(n_items, n_cols=3) if n_items &gt; 0 else 0\n    base_height = 2.5  # Base plot height\n    total_height = base_height + legend_height\n\n    fig, ax = plt.subplots(figsize=(3.5, total_height))  # IEEE single-column width, dynamic height\n    if pssar_columns:\n        colors = self._get_academic_colors(len(pssar_columns))\n        linestyles = self._get_academic_linestyles(len(pssar_columns))\n        markers = self._get_academic_markers(len(pssar_columns))\n        for idx, col in enumerate(pssar_columns):\n            avg_results[col].plot(\n                kind=\"line\",\n                marker=markers[idx],\n                linestyle=linestyles[idx],\n                ax=ax,\n                color=colors[idx],\n                label=LEGEND_LABELS.get(col, col),\n            )\n        # Don't set title on plot - will be in caption file\n        ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n        ax.set_ylabel(self._format_axis_label(\"Normalized psSAR10g\", r\"mW kg$^{-1}$\"))\n        legend_labels = [label for col in pssar_columns if (label := LEGEND_LABELS.get(col, col)) is not None]\n        # Use 2 columns for legend when there are 4 items to ensure balanced layout\n        n_cols = 2 if len(legend_labels) == 4 else min(3, len(legend_labels))\n        # Place legend below in grid format (will get handles/labels from ax)\n        self._place_legend_below(fig, ax, len(legend_labels), n_cols=n_cols)\n        ax.set_xticks(avg_results.index)\n        # Rotate frequency labels (always rotate when x-axis is Frequency)\n        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n        self._adjust_slanted_tick_labels(ax)\n        # Set y-axis to start at 0 and go to max + 5%\n        y_max = ax.get_ylim()[1]\n        ax.set_ylim(0, y_max * 1.05)\n    else:\n        ax.text(0.5, 0.5, \"No psSAR10g data found\", ha=\"center\", va=\"center\")\n    plt.tight_layout()\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The line plot shows average normalized psSAR10g trends for different tissue groups (Eyes, Skin, Brain, Genitals, Whole Body) across frequencies for the {self._format_scenario_name(scenario_name)} scenario for {phantom_name_formatted}.\"\n    self._save_figure(fig, \"line\", f\"pssar10g_line_{scenario_name}\", title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = avg_results[pssar_columns].copy()\n    csv_data.index.name = \"frequency_mhz\"\n    self._save_csv_data(csv_data, \"line\", f\"pssar10g_line_{scenario_name}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter.plot_sar_line","title":"plot_sar_line","text":"<pre><code>plot_sar_line(scenario_name: str, avg_results: DataFrame)\n</code></pre> <p>Plots average SAR trends for tissue groups by frequency.</p> <p>Symmetric counterpart to plot_pssar_line.</p> <p>Parameters:</p> Name Type Description Default <code>scenario_name</code> <code>str</code> <p>Placement scenario name.</p> required <code>avg_results</code> <code>DataFrame</code> <p>DataFrame with average SAR values.</p> required Source code in <code>goliat/analysis/plots/line.py</code> <pre><code>def plot_sar_line(self, scenario_name: str, avg_results: pd.DataFrame):\n    \"\"\"Plots average SAR trends for tissue groups by frequency.\n\n    Symmetric counterpart to plot_pssar_line.\n\n    Args:\n        scenario_name: Placement scenario name.\n        avg_results: DataFrame with average SAR values.\n    \"\"\"\n    sar_columns = [col for col in avg_results.columns if col.startswith(\"SAR_\")]\n    base_title = \"average normalized SAR for scenario\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n\n    # Calculate dynamic height based on legend size\n    n_items = len(sar_columns) if sar_columns else 0\n    legend_height = self._calculate_legend_height(n_items, n_cols=3) if n_items &gt; 0 else 0\n    base_height = 2.5  # Base plot height\n    total_height = base_height + legend_height\n\n    fig, ax = plt.subplots(figsize=(3.5, total_height))  # IEEE single-column width, dynamic height\n    if sar_columns:\n        colors = self._get_academic_colors(len(sar_columns))\n        linestyles = self._get_academic_linestyles(len(sar_columns))\n        markers = self._get_academic_markers(len(sar_columns))\n        for idx, col in enumerate(sar_columns):\n            avg_results[col].plot(\n                kind=\"line\",\n                marker=markers[idx],\n                linestyle=linestyles[idx],\n                ax=ax,\n                color=colors[idx],\n                label=LEGEND_LABELS.get(col, col),\n            )\n        # Don't set title on plot - will be in caption file\n        ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n        ax.set_ylabel(self._format_axis_label(\"Normalized SAR\", r\"mW kg$^{-1}$\"))\n        # Use trimmed legend labels (remove \"SAR\" since y-axis already says \"SAR\")\n        legend_labels = [LEGEND_LABELS.get(col, col.replace(\"SAR_\", \"\").replace(\"_\", \" \").title()) for col in sar_columns]\n        # Use 2 columns for legend when there are 4 items to ensure balanced layout\n        n_cols = 2 if len(legend_labels) == 4 else min(3, len(legend_labels))\n        # Place legend below in grid format (will get handles/labels from ax)\n        self._place_legend_below(fig, ax, len(legend_labels), n_cols=n_cols)\n        ax.set_xticks(avg_results.index)\n        # Rotate frequency labels (always rotate when x-axis is Frequency)\n        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n        self._adjust_slanted_tick_labels(ax)\n        # Set y-axis to start at 0 and go to max + 5%\n        y_max = ax.get_ylim()[1]\n        ax.set_ylim(0, y_max * 1.05)\n    else:\n        ax.text(0.5, 0.5, \"No SAR data found\", ha=\"center\", va=\"center\")\n    plt.tight_layout()\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The line plot shows average normalized SAR trends for different tissue groups (Head, Trunk, Whole-Body, Brain, Skin, Eyes, Genitals) across frequencies for the {self._format_scenario_name(scenario_name)} scenario for {phantom_name_formatted}.\"\n    self._save_figure(fig, \"line\", f\"sar_line_{scenario_name}\", title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = avg_results[sar_columns].copy()\n    csv_data.index.name = \"frequency_mhz\"\n    self._save_csv_data(csv_data, \"line\", f\"sar_line_{scenario_name}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter.plot_pssar_line_individual_variations","title":"plot_pssar_line_individual_variations","text":"<pre><code>plot_pssar_line_individual_variations(results_df: DataFrame, scenario_name: str, metric_column: str = 'psSAR10g_eyes')\n</code></pre> <p>Plots individual variation lines for each placement/direction/polarization.</p> <p>Similar to boxplots but shows individual lines instead of aggregating variability. Each placement variation gets its own line with a legend entry.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with detailed results including 'placement' column.</p> required <code>scenario_name</code> <code>str</code> <p>Scenario name for filtering.</p> required <code>metric_column</code> <code>str</code> <p>Column name for the metric to plot (e.g., 'psSAR10g_eyes').</p> <code>'psSAR10g_eyes'</code> Source code in <code>goliat/analysis/plots/line.py</code> <pre><code>def plot_pssar_line_individual_variations(\n    self,\n    results_df: pd.DataFrame,\n    scenario_name: str,\n    metric_column: str = \"psSAR10g_eyes\",\n):\n    \"\"\"Plots individual variation lines for each placement/direction/polarization.\n\n    Similar to boxplots but shows individual lines instead of aggregating variability.\n    Each placement variation gets its own line with a legend entry.\n\n    Args:\n        results_df: DataFrame with detailed results including 'placement' column.\n        scenario_name: Scenario name for filtering.\n        metric_column: Column name for the metric to plot (e.g., 'psSAR10g_eyes').\n    \"\"\"\n    if metric_column not in results_df.columns:\n        logging.getLogger(\"progress\").warning(\n            f\"Column '{metric_column}' not found for individual variation plot.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Filter by scenario\n    plot_df = results_df[results_df[\"scenario\"] == scenario_name].copy()\n\n    if plot_df.empty:\n        return\n\n    # Group by frequency and placement\n    if \"placement\" not in plot_df.columns:\n        logging.getLogger(\"progress\").warning(\n            \"No 'placement' column found for individual variation plot.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Get unique placements\n    placements = sorted(plot_df[\"placement\"].unique())\n\n    # Create pivot table: frequency vs placement\n    pivot_data = plot_df.pivot_table(\n        index=\"frequency_mhz\",\n        columns=\"placement\",\n        values=metric_column,\n        aggfunc=\"mean\",\n    )\n\n    if pivot_data.empty:\n        return\n\n    # Calculate dynamic height based on legend size\n    # Use 2 columns for legend layout\n    n_items = len(placements)\n    n_cols = 2  # Always use 2 columns for legend\n    legend_height = self._calculate_legend_height(n_items, n_cols=n_cols)\n    # Use IEEE standard single-column width (3.5 inches) - height will be adjusted dynamically\n    # Base height for proper font rendering at IEEE single-column width\n    base_height = 2.5\n    total_height = base_height + legend_height\n\n    fig, ax = plt.subplots(figsize=(3.5, total_height))  # IEEE single-column width (3.5\"), dynamic height\n\n    # Plot each placement as a separate line\n\n    colors = self._get_academic_colors(len(placements))\n    linestyles = self._get_academic_linestyles(len(placements))\n    markers = self._get_academic_markers(len(placements))\n    for idx, placement in enumerate(placements):\n        if placement in pivot_data.columns:\n            # Format placement name to be human readable\n            placement_formatted = (\n                self._format_organ_name(placement) if hasattr(self, \"_format_organ_name\") else placement.replace(\"_\", \" \").title()\n            )\n            ax.plot(\n                pivot_data.index,\n                pivot_data[placement],\n                marker=markers[idx],\n                linestyle=linestyles[idx],\n                label=placement_formatted,\n                linewidth=1.5,\n                markersize=4,\n                color=colors[idx],\n                alpha=0.7,\n            )\n\n    ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n    metric_label = METRIC_LABELS.get(metric_column, metric_column)\n    ax.set_ylabel(self._format_axis_label(metric_label, r\"mW kg$^{-1}$\"))\n    formatted_scenario = self._format_scenario_name(scenario_name) if scenario_name else None\n    if formatted_scenario:\n        base_title = f\"individual variations for {metric_label} in {formatted_scenario} scenario\"\n    else:\n        base_title = f\"individual variations for {metric_label}\"\n    title_full = self._get_title_with_phantom(base_title)\n    # Don't set title on plot - will be in caption file\n    # Place legend below in grid format\n    self._place_legend_below(fig, ax, n_items, n_cols=n_cols)\n\n    # Rotate frequency labels (always rotate when x-axis is Frequency)\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n    self._adjust_slanted_tick_labels(ax)\n\n    ax.grid(True, alpha=0.3)\n    # Set y-axis to start at 0 and go to max + 5%\n    y_max = ax.get_ylim()[1]\n    ax.set_ylim(0, y_max * 1.05)\n\n    plt.tight_layout()\n\n    metric_safe = metric_column.replace(\"SAR_\", \"\").replace(\"psSAR10g_\", \"\").replace(\"_\", \"_\")\n    prefix = \"sar\" if metric_column.startswith(\"SAR_\") else \"pssar10g\"\n    filename_base = f\"{prefix}_line_individual_{metric_safe}_{scenario_name}\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The line plot shows individual variation lines for each placement/direction/polarization combination for {metric_label} across frequencies in the {self._format_scenario_name(scenario_name)} scenario for {phantom_name_formatted}. Each line represents a specific placement variation.\"\n    filename = self._save_figure(fig, \"line\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = pivot_data.copy()\n    csv_data.index.name = \"frequency_mhz\"\n    self._save_csv_data(csv_data, \"line\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated individual variation line plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter.plot_sar_line_individual_variations","title":"plot_sar_line_individual_variations","text":"<pre><code>plot_sar_line_individual_variations(results_df: DataFrame, scenario_name: str, metric_column: str = 'SAR_head')\n</code></pre> <p>Plots individual variation lines for SAR metrics.</p> <p>Symmetric counterpart to plot_pssar_line_individual_variations for SAR metrics.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with detailed results including 'placement' column.</p> required <code>scenario_name</code> <code>str</code> <p>Scenario name for filtering.</p> required <code>metric_column</code> <code>str</code> <p>Column name for the SAR metric to plot (e.g., 'SAR_head').</p> <code>'SAR_head'</code> Source code in <code>goliat/analysis/plots/line.py</code> <pre><code>def plot_sar_line_individual_variations(\n    self,\n    results_df: pd.DataFrame,\n    scenario_name: str,\n    metric_column: str = \"SAR_head\",\n):\n    \"\"\"Plots individual variation lines for SAR metrics.\n\n    Symmetric counterpart to plot_pssar_line_individual_variations for SAR metrics.\n\n    Args:\n        results_df: DataFrame with detailed results including 'placement' column.\n        scenario_name: Scenario name for filtering.\n        metric_column: Column name for the SAR metric to plot (e.g., 'SAR_head').\n    \"\"\"\n    # Delegate to the generic function\n    self.plot_pssar_line_individual_variations(results_df, scenario_name, metric_column)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter.plot_far_field_direction_polarization_lines","title":"plot_far_field_direction_polarization_lines","text":"<pre><code>plot_far_field_direction_polarization_lines(results_df: DataFrame, metric: str = 'SAR_whole_body', group_by: str = 'direction')\n</code></pre> <p>Creates line plots showing frequency dependence for far-field direction/polarization.</p> <p>This visualization shows how SAR varies with frequency for each direction/polarization combination, enabling comparison of frequency-dependent effects.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with 'placement' column containing direction/polarization info.</p> required <code>metric</code> <code>str</code> <p>SAR metric to plot (default: 'SAR_whole_body').</p> <code>'SAR_whole_body'</code> <code>group_by</code> <code>str</code> <p>How to group lines - 'direction' (one line per direction, panels for polarization),       'polarization' (one line per polarization, panels for direction),       or 'both' (all combinations on one plot).</p> <code>'direction'</code> Source code in <code>goliat/analysis/plots/line.py</code> <pre><code>def plot_far_field_direction_polarization_lines(\n    self,\n    results_df: pd.DataFrame,\n    metric: str = \"SAR_whole_body\",\n    group_by: str = \"direction\",  # \"direction\", \"polarization\", or \"both\"\n):\n    \"\"\"Creates line plots showing frequency dependence for far-field direction/polarization.\n\n    This visualization shows how SAR varies with frequency for each direction/polarization\n    combination, enabling comparison of frequency-dependent effects.\n\n    Args:\n        results_df: DataFrame with 'placement' column containing direction/polarization info.\n        metric: SAR metric to plot (default: 'SAR_whole_body').\n        group_by: How to group lines - 'direction' (one line per direction, panels for polarization),\n                  'polarization' (one line per polarization, panels for direction),\n                  or 'both' (all combinations on one plot).\n    \"\"\"\n    if metric not in results_df.columns or results_df[metric].dropna().empty:\n        logging.getLogger(\"progress\").warning(\n            f\"  - WARNING: No data for metric '{metric}' for direction/polarization line plot.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Parse placement column to extract direction and polarization\n    df = results_df.copy()\n\n    def parse_placement(placement: str) -&gt; tuple[str, str]:\n        \"\"\"Parse placement string like 'environmental_x_pos_theta' to ('From left', 'Theta').\"\"\"\n        # Direction labels describe where the wave is coming FROM (not propagation direction)\n        direction_labels = {\n            \"x_pos\": \"From left\",\n            \"x_neg\": \"From right\",\n            \"y_pos\": \"From back\",\n            \"y_neg\": \"From front\",\n            \"z_pos\": \"From below\",\n            \"z_neg\": \"From above\",\n        }\n        parts = placement.replace(\"environmental_\", \"\").split(\"_\")\n        if len(parts) &gt;= 3:\n            dir_key = f\"{parts[0]}_{parts[1]}\"\n            direction = direction_labels.get(dir_key, f\"{parts[0].upper()}{'+' if parts[1] == 'pos' else '-'}\")\n            pol = \"Theta\" if parts[2] == \"theta\" else \"Phi\"\n            return direction, pol\n        return placement, \"Unknown\"\n\n    df[[\"direction\", \"polarization\"]] = df[\"placement\"].apply(lambda x: pd.Series(parse_placement(x)))\n\n    # Get metric label\n    metric_label = METRIC_LABELS.get(metric, metric)\n\n    if group_by == \"both\":\n        # All direction/polarization combinations on one plot\n        self._plot_far_field_all_combinations(df, metric, metric_label)\n    elif group_by == \"direction\":\n        # One panel per polarization, lines for each direction\n        self._plot_far_field_by_polarization(df, metric, metric_label)\n    else:  # group_by == \"polarization\"\n        # One panel per direction, lines for each polarization\n        self._plot_far_field_by_direction(df, metric, metric_label)\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter.plot_far_field_direction_polarization_comparison","title":"plot_far_field_direction_polarization_comparison","text":"<pre><code>plot_far_field_direction_polarization_comparison(results_df: DataFrame, metrics: list[str] | None = None)\n</code></pre> <p>Generates frequency-dependent comparison plots for all direction/polarization combos.</p> <p>Creates multiple line plots showing how SAR varies with frequency for different direction/polarization combinations.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with 'placement' column containing direction/polarization info.</p> required <code>metrics</code> <code>list[str] | None</code> <p>List of metrics to plot. If None, uses common metrics.</p> <code>None</code> Source code in <code>goliat/analysis/plots/line.py</code> <pre><code>def plot_far_field_direction_polarization_comparison(\n    self,\n    results_df: pd.DataFrame,\n    metrics: list[str] | None = None,\n):\n    \"\"\"Generates frequency-dependent comparison plots for all direction/polarization combos.\n\n    Creates multiple line plots showing how SAR varies with frequency for different\n    direction/polarization combinations.\n\n    Args:\n        results_df: DataFrame with 'placement' column containing direction/polarization info.\n        metrics: List of metrics to plot. If None, uses common metrics.\n    \"\"\"\n    if metrics is None:\n        # Include both SAR tissue groups and psSAR10g metrics\n        # SAR tissue groups are added during analysis via _add_tissue_group_sar()\n        possible_metrics = [\n            # Whole-body and peak metrics\n            \"SAR_whole_body\",\n            \"peak_sar\",\n            # SAR tissue groups (average SAR per tissue group)\n            \"SAR_brain\",\n            \"SAR_skin\",\n            \"SAR_eyes\",\n            \"SAR_genitals\",\n            # psSAR10g metrics (peak spatial-average SAR)\n            \"psSAR10g_brain\",\n            \"psSAR10g_skin\",\n            \"psSAR10g_eyes\",\n            \"psSAR10g_genitals\",\n        ]\n        metrics = [m for m in possible_metrics if m in results_df.columns and results_df[m].notna().any()]\n\n    if not metrics:\n        logging.getLogger(\"progress\").warning(\n            \"  - WARNING: No valid metrics for direction/polarization comparison.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    logging.getLogger(\"progress\").info(\n        \"  - Generating direction/polarization frequency comparison plots...\",\n        extra={\"log_type\": \"info\"},\n    )\n\n    for metric in metrics:\n        # Generate the \"by polarization\" view - most useful for comparing directions\n        self.plot_far_field_direction_polarization_lines(results_df, metric=metric, group_by=\"direction\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter.plot_cross_phantom_comparison","title":"plot_cross_phantom_comparison","text":"<pre><code>plot_cross_phantom_comparison(all_phantom_data: dict[str, DataFrame], metrics: list[str] | None = None)\n</code></pre> <p>Plots SAR vs frequency comparing different phantoms.</p> <p>Creates line plots showing how SAR varies with frequency for each phantom, revealing age/body-size dependent absorption patterns.</p> <p>Parameters:</p> Name Type Description Default <code>all_phantom_data</code> <code>dict[str, DataFrame]</code> <p>Dictionary mapping phantom names to their results DataFrames.</p> required <code>metrics</code> <code>list[str] | None</code> <p>List of metrics to plot. If None, uses common metrics.</p> <code>None</code> Source code in <code>goliat/analysis/plots/line.py</code> <pre><code>def plot_cross_phantom_comparison(\n    self,\n    all_phantom_data: dict[str, pd.DataFrame],\n    metrics: list[str] | None = None,\n):\n    \"\"\"Plots SAR vs frequency comparing different phantoms.\n\n    Creates line plots showing how SAR varies with frequency for each phantom,\n    revealing age/body-size dependent absorption patterns.\n\n    Args:\n        all_phantom_data: Dictionary mapping phantom names to their results DataFrames.\n        metrics: List of metrics to plot. If None, uses common metrics.\n    \"\"\"\n    if not all_phantom_data:\n        logging.getLogger(\"progress\").warning(\n            \"  - WARNING: No phantom data for cross-phantom comparison.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    if metrics is None:\n        # Default metrics - check what's available in first phantom\n        first_df = list(all_phantom_data.values())[0]\n        possible_metrics = [\n            \"SAR_whole_body\",\n            \"SAR_brain\",\n            \"SAR_eyes\",\n            \"SAR_skin\",\n            \"SAR_genitals\",\n        ]\n        metrics = [m for m in possible_metrics if m in first_df.columns and first_df[m].notna().any()]\n\n    if not metrics:\n        return\n\n    # Phantom display names: simplified (Adult/Child Male/Female)\n    phantom_info = {\n        \"duke\": (\"Duke\", \"Adult male\"),\n        \"ella\": (\"Ella\", \"Adult female\"),\n        \"eartha\": (\"Eartha\", \"Child female\"),\n        \"thelonious\": (\"Thelonious\", \"Child male\"),\n    }\n\n    # Use standard academic colors: black, red, dark blue, purple\n    academic_colors = self._get_academic_colors(4)\n    phantom_colors = {\n        \"duke\": academic_colors[0],  # black (adult male)\n        \"ella\": academic_colors[2],  # dark blue (adult female)\n        \"eartha\": academic_colors[3],  # purple (child female)\n        \"thelonious\": academic_colors[1],  # red (child male)\n    }\n\n    # Use standard academic markers and linestyles\n    academic_markers = self._get_academic_markers(4)\n    academic_linestyles = self._get_academic_linestyles(4)\n    phantom_markers = {\n        \"duke\": academic_markers[0],  # circle\n        \"ella\": academic_markers[1],  # square\n        \"eartha\": academic_markers[2],  # triangle\n        \"thelonious\": academic_markers[3],  # diamond\n    }\n    phantom_linestyles = {\n        \"duke\": academic_linestyles[0],  # solid\n        \"ella\": academic_linestyles[1],  # dashed\n        \"eartha\": academic_linestyles[2],  # dotted\n        \"thelonious\": academic_linestyles[3],  # dashdot\n    }\n\n    for metric in metrics:\n        # Create figure - IEEE single-column width\n        fig, ax = plt.subplots(figsize=(3.5, 2.5))\n\n        # Combine data from all phantoms\n        for phantom_name, df in all_phantom_data.items():\n            if metric not in df.columns or df[metric].isna().all():\n                continue\n\n            # Compute statistics per frequency: mean, 25th, 75th percentile\n            freq_stats = df.groupby(\"frequency_mhz\")[metric].agg([\"mean\", lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)])\n            freq_stats.columns = [\"mean\", \"p25\", \"p75\"]\n\n            display_name, description = phantom_info.get(phantom_name.lower(), (phantom_name.capitalize(), \"\"))\n            label = f\"{display_name} ({description})\" if description else display_name\n            color = phantom_colors.get(phantom_name.lower(), \"gray\")\n\n            # Plot line with markers and linestyle\n            ax.plot(\n                freq_stats.index,\n                freq_stats[\"mean\"].values,\n                marker=phantom_markers.get(phantom_name.lower(), \"o\"),\n                linestyle=phantom_linestyles.get(phantom_name.lower(), \"solid\"),\n                color=color,\n                label=label,\n                linewidth=1.5,\n                markersize=5,\n            )\n\n            # Add 25-75th percentile whiskers (simple error bars)\n            ax.errorbar(\n                freq_stats.index,\n                freq_stats[\"mean\"].values,\n                yerr=[freq_stats[\"mean\"] - freq_stats[\"p25\"], freq_stats[\"p75\"] - freq_stats[\"mean\"]],\n                fmt=\"none\",  # No markers, just error bars\n                color=color,\n                capsize=3,\n                capthick=0.7,\n                elinewidth=0.7,\n                alpha=0.8,\n            )\n\n        # Format axes\n        ax.set_xlabel(\"Frequency (MHz)\", fontsize=9)\n        metric_label = METRIC_LABELS.get(metric, metric.replace(\"_\", \" \").title())\n        ax.set_ylabel(f\"{metric_label} (mW/kg)\", fontsize=9)\n        ax.tick_params(axis=\"both\", labelsize=8)\n\n        # Y-axis starts from 0\n        ax.set_ylim(bottom=0)\n\n        # Set x-axis to log scale if frequencies span wide range\n        frequencies = list(all_phantom_data.values())[0][\"frequency_mhz\"].unique()\n        if max(frequencies) / min(frequencies) &gt; 5:\n            ax.set_xscale(\"log\")\n            ax.set_xticks(sorted(frequencies))\n            ax.set_xticklabels([str(int(f)) for f in sorted(frequencies)], rotation=45, ha=\"right\")\n\n        ax.grid(True, alpha=0.3, linestyle=\"--\")\n        ax.legend(fontsize=7, loc=\"upper right\", frameon=True, fancybox=False, edgecolor=\"black\")\n\n        plt.tight_layout()\n\n        # Save\n        filename = f\"line_cross_phantom_{metric}\"\n        title = self._get_title_with_phantom(f\"Cross-Phantom Comparison: {metric_label}\")\n        caption = (\n            f\"Cross-phantom comparison of {metric_label.lower()} as a function of frequency. \"\n            f\"Lines show means across all incident directions and polarizations. \"\n            f\"Whiskers indicate 25th-75th percentile range. \"\n            f\"Children show approximately 1.5-2\u00d7 higher absorption than adults.\"\n        )\n        self._save_figure(fig, \"line\", filename, title=title, caption=caption, dpi=300)\n\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated {len(metrics)} cross-phantom comparison plots\",\n        extra={\"log_type\": \"info\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.line.LinePlotter.plot_polarization_ratio_lines","title":"plot_polarization_ratio_lines","text":"<pre><code>plot_polarization_ratio_lines(results_df: DataFrame, metrics: list[str] | None = None)\n</code></pre> <p>Plots theta/phi polarization ratio vs frequency for each direction.</p> <p>Shows how the polarization sensitivity changes with frequency for different incident directions. This is unique to far-field analysis.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with placement column containing direction and polarization info.</p> required <code>metrics</code> <code>list[str] | None</code> <p>List of metrics to analyze. If None, uses common metrics.</p> <code>None</code> Source code in <code>goliat/analysis/plots/line.py</code> <pre><code>def plot_polarization_ratio_lines(\n    self,\n    results_df: pd.DataFrame,\n    metrics: list[str] | None = None,\n):\n    \"\"\"Plots theta/phi polarization ratio vs frequency for each direction.\n\n    Shows how the polarization sensitivity changes with frequency for different\n    incident directions. This is unique to far-field analysis.\n\n    Args:\n        results_df: DataFrame with placement column containing direction and polarization info.\n        metrics: List of metrics to analyze. If None, uses common metrics.\n    \"\"\"\n    if results_df.empty:\n        return\n\n    # Parse placement to extract direction and polarization\n    def parse_placement(placement: str) -&gt; tuple[str | None, str | None]:\n        parts = placement.split(\"_\")\n        if len(parts) &gt;= 4:\n            direction = f\"{parts[1]}_{parts[2]}\"  # e.g., \"x_pos\"\n            pol = parts[3]  # \"theta\" or \"phi\"\n            return direction, pol\n        return None, None\n\n    df = results_df.copy()\n    df[[\"direction\", \"polarization\"]] = df[\"placement\"].apply(lambda x: pd.Series(parse_placement(x)))\n    df = df.dropna(subset=[\"direction\", \"polarization\"])\n\n    if df.empty:\n        return\n\n    if metrics is None:\n        possible_metrics = [\"SAR_whole_body\", \"psSAR10g_brain\", \"psSAR10g_eyes\", \"psSAR10g_skin\", \"psSAR10g_genitals\"]\n        metrics = [m for m in possible_metrics if m in df.columns and df[m].notna().any()]\n\n    if not metrics:\n        return\n\n    # Direction display names (human-readable: describes where wave comes FROM)\n    direction_names = {\n        \"x_pos\": \"From left\",\n        \"x_neg\": \"From right\",\n        \"y_pos\": \"From back\",\n        \"y_neg\": \"From front\",\n        \"z_pos\": \"From below\",\n        \"z_neg\": \"From above\",\n    }\n\n    direction_order = [\"x_pos\", \"x_neg\", \"y_pos\", \"y_neg\", \"z_pos\", \"z_neg\"]\n    available_directions = [d for d in direction_order if d in df[\"direction\"].unique()]\n\n    # Use standard academic colors, markers, and linestyles for metrics\n    academic_colors = self._get_academic_colors(5)\n    academic_markers = self._get_academic_markers(5)\n    academic_linestyles = self._get_academic_linestyles(5)\n    metrics_list = [\"SAR_whole_body\", \"psSAR10g_brain\", \"psSAR10g_eyes\", \"psSAR10g_skin\", \"psSAR10g_genitals\"]\n    metric_colors = {m: academic_colors[i] for i, m in enumerate(metrics_list)}\n    metric_markers = {m: academic_markers[i] for i, m in enumerate(metrics_list)}\n    metric_linestyles = {m: academic_linestyles[i] for i, m in enumerate(metrics_list)}\n\n    # First pass: compute global max ratio across all panels\n    global_max_ratio = 0.0\n    all_ratios = {}\n    for direction in available_directions[:6]:\n        dir_df = df[df[\"direction\"] == direction]\n        all_ratios[direction] = {}\n        for metric in metrics:\n            if metric not in dir_df.columns:\n                continue\n            pivot = dir_df.pivot_table(values=metric, index=\"frequency_mhz\", columns=\"polarization\", aggfunc=\"mean\")\n            if \"theta\" in pivot.columns and \"phi\" in pivot.columns:\n                ratio = pivot[\"theta\"] / pivot[\"phi\"]\n                ratio = ratio.dropna()\n                if not ratio.empty:\n                    all_ratios[direction][metric] = ratio\n                    global_max_ratio = max(global_max_ratio, ratio.max())\n\n    # Add some headroom to max\n    y_max = max(global_max_ratio * 1.1, 1.5)\n\n    # Create 2x3 panel figure - IEEE single-column width\n    fig = plt.figure(figsize=(3.5, 4.5))\n    gs = fig.add_gridspec(2, 3, hspace=0.45, wspace=0.3, bottom=0.18)\n\n    legend_handles = []\n    legend_labels = []\n\n    for panel_idx, direction in enumerate(available_directions[:6]):\n        row = panel_idx // 3\n        col = panel_idx % 3\n        ax = fig.add_subplot(gs[row, col])\n\n        for metric in metrics:\n            if direction not in all_ratios or metric not in all_ratios[direction]:\n                continue\n\n            ratio = all_ratios[direction][metric]\n            color = metric_colors.get(metric, \"gray\")\n            marker = metric_markers.get(metric, \"o\")\n            linestyle = metric_linestyles.get(metric, \"solid\")\n            label = metric.replace(\"SAR_\", \"\").replace(\"psSAR10g_\", \"\").replace(\"_\", \" \").title()\n\n            (line,) = ax.plot(\n                ratio.index,\n                ratio.values,\n                marker=marker,\n                linestyle=linestyle,\n                color=color,\n                linewidth=1.0,\n                markersize=3,\n            )\n\n            # Collect legend items only once (from first panel)\n            if panel_idx == 0:\n                legend_handles.append(line)\n                legend_labels.append(label)\n\n        # Reference line at ratio=1.0\n        ax.axhline(y=1.0, color=\"gray\", linestyle=\"--\", linewidth=0.8, alpha=0.7)\n\n        # Formatting\n        ax.set_title(direction_names.get(direction, direction), fontsize=9)\n        ax.set_xlabel(\"Frequency (MHz)\", fontsize=8)\n        if col == 0:\n            ax.set_ylabel(\"Theta/Phi Ratio\", fontsize=8)\n        ax.tick_params(axis=\"both\", labelsize=7)\n\n        # Y-axis: start from 0, use global max\n        ax.set_ylim(0, y_max)\n\n        # Log scale for x-axis\n        frequencies = sorted(df[\"frequency_mhz\"].unique())\n        if len(frequencies) &gt; 1 and max(frequencies) / min(frequencies) &gt; 5:\n            ax.set_xscale(\"log\")\n            ax.set_xticks(frequencies)\n            ax.set_xticklabels([str(int(f)) for f in frequencies], rotation=45, ha=\"right\", fontsize=6)\n\n        ax.grid(True, alpha=0.3, linestyle=\"--\")\n\n    # Add shared legend below all subplots\n    fig.legend(\n        legend_handles,\n        legend_labels,\n        loc=\"lower center\",\n        ncol=len(legend_labels),\n        fontsize=8,\n        frameon=True,\n        fancybox=False,\n        edgecolor=\"black\",\n        bbox_to_anchor=(0.5, 0.02),\n    )\n\n    # Save\n    filename = \"line_polarization_ratio_by_direction\"\n    title = self._get_title_with_phantom(\"Polarization Ratio vs Frequency by Direction\")\n    caption = (\n        \"Theta/phi polarization ratio as a function of frequency for each incident direction. \"\n        \"Ratio &gt; 1.0 indicates theta polarization gives higher SAR; ratio &lt; 1.0 indicates phi dominates. \"\n        \"The gray dashed line marks the equal polarization reference (ratio = 1.0). \"\n        \"Significant frequency-dependent variations indicate complex polarization sensitivity.\"\n    )\n    self._save_figure(fig, \"line\", filename, title=title, caption=caption, dpi=300)\n\n    logging.getLogger(\"progress\").info(\n        \"  - Generated polarization ratio line plot\",\n        extra={\"log_type\": \"info\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.outliers.OutliersPlotter","title":"goliat.analysis.plots.outliers.OutliersPlotter","text":"<pre><code>OutliersPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates outlier detection plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.outliers.OutliersPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.outliers.OutliersPlotter.identify_outliers","title":"identify_outliers","text":"<pre><code>identify_outliers(results_df: DataFrame, metrics: str | list[str], scenario_name: str | None = None, method: str = 'iqr', threshold: float = 1.5)\n</code></pre> <p>Identifies and visualizes outliers in SAR metrics.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with simulation results.</p> required <code>metrics</code> <code>str | list[str]</code> <p>Single metric column name or list of metric column names to check for outliers.</p> required <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> <code>method</code> <code>str</code> <p>Method for outlier detection ('iqr' for Interquartile Range, 'zscore' for Z-score).</p> <code>'iqr'</code> <code>threshold</code> <code>float</code> <p>Threshold multiplier for IQR method or Z-score threshold.</p> <code>1.5</code> <p>Returns:</p> Type Description <p>DataFrame containing outlier rows, or None if no outliers found.</p> Source code in <code>goliat/analysis/plots/outliers.py</code> <pre><code>def identify_outliers(\n    self,\n    results_df: pd.DataFrame,\n    metrics: str | list[str],\n    scenario_name: str | None = None,\n    method: str = \"iqr\",\n    threshold: float = 1.5,\n):\n    \"\"\"Identifies and visualizes outliers in SAR metrics.\n\n    Args:\n        results_df: DataFrame with simulation results.\n        metrics: Single metric column name or list of metric column names to check for outliers.\n        scenario_name: Optional scenario name for filtering.\n        method: Method for outlier detection ('iqr' for Interquartile Range, 'zscore' for Z-score).\n        threshold: Threshold multiplier for IQR method or Z-score threshold.\n\n    Returns:\n        DataFrame containing outlier rows, or None if no outliers found.\n    \"\"\"\n    plot_df = results_df.copy()\n\n    if scenario_name:\n        plot_df = plot_df[plot_df[\"scenario\"] == scenario_name].copy()\n\n    if plot_df.empty:\n        return pd.DataFrame()  # Return empty DataFrame instead of None\n\n    # Normalize metrics to list\n    if isinstance(metrics, str):\n        metrics = [metrics]\n\n    outlier_summary = []\n    all_outlier_dfs = []  # Collect all outlier DataFrames\n\n    for metric in metrics:\n        if metric not in plot_df.columns:\n            continue\n\n        metric_data = plot_df[metric].dropna()\n        if metric_data.empty:\n            continue\n\n        if method == \"iqr\":\n            Q1 = metric_data.quantile(0.25)\n            Q3 = metric_data.quantile(0.75)\n            IQR = Q3 - Q1\n            lower_bound = Q1 - threshold * IQR\n            upper_bound = Q3 + threshold * IQR\n            outliers = plot_df[(plot_df[metric] &lt; lower_bound) | (plot_df[metric] &gt; upper_bound)]\n        elif method == \"zscore\":\n            mean_val = metric_data.mean()\n            std_val = metric_data.std()\n            if std_val == 0:\n                continue\n            z_scores = np.abs((plot_df[metric] - mean_val) / std_val)\n            outliers = plot_df[z_scores &gt; threshold]\n        else:\n            continue\n\n        if not outliers.empty:\n            outlier_summary.append(\n                {\n                    \"metric\": metric,\n                    \"count\": len(outliers),\n                    \"outliers\": outliers,\n                }\n            )\n            all_outlier_dfs.append(outliers)\n\n    if not outlier_summary:\n        logging.getLogger(\"progress\").info(\n            f\"  - No outliers detected for metrics: {', '.join(metrics)}\",\n            extra={\"log_type\": \"info\"},\n        )\n        return pd.DataFrame()  # Return empty DataFrame instead of None\n\n    # Collect all outlier rows into a single DataFrame\n    if all_outlier_dfs:\n        all_outliers = pd.concat(all_outlier_dfs, ignore_index=True)\n        # Drop duplicates based on hashable columns only (avoid unhashable types like dicts)\n        # Get list of columns that are hashable (numeric, string, etc.)\n        hashable_cols = []\n        for col in all_outliers.columns:\n            try:\n                # Try to hash a sample value to check if column is hashable\n                sample_val = all_outliers[col].dropna().iloc[0] if not all_outliers[col].dropna().empty else None\n                if sample_val is not None:\n                    hash(sample_val)\n                    hashable_cols.append(col)\n            except (TypeError, IndexError):\n                # Column contains unhashable types, skip it\n                continue\n\n        # Drop duplicates using only hashable columns, or all columns if none are hashable\n        if hashable_cols:\n            try:\n                all_outliers = all_outliers.drop_duplicates(subset=hashable_cols)\n            except (TypeError, ValueError):\n                # If still fails, just return all outliers without deduplication\n                pass\n        # If no hashable columns, just return all outliers (no deduplication possible)\n    else:\n        all_outliers = pd.DataFrame()\n\n    # Create visualization\n    n_metrics = len(outlier_summary)\n    fig, axes = plt.subplots(n_metrics, 1, figsize=(3.5, 2.0 * n_metrics))  # IEEE single-column width\n    if n_metrics == 1:\n        axes = [axes]\n\n    for idx, summary in enumerate(outlier_summary):\n        ax = axes[idx]\n        metric = summary[\"metric\"]\n        outliers = summary[\"outliers\"]\n\n        # Boxplot with outliers highlighted\n        plot_data = plot_df[metric].dropna()\n        bp = ax.boxplot([plot_data], vert=True, patch_artist=True, showfliers=True)\n        bp[\"boxes\"][0].set_facecolor(\"lightblue\")\n        bp[\"boxes\"][0].set_alpha(0.7)\n\n        # Highlight outliers\n        outlier_values = outliers[metric].dropna()\n        if not outlier_values.empty:\n            ax.scatter([1] * len(outlier_values), outlier_values.values, color=\"red\", s=30, alpha=0.7, marker=\"x\", label=\"Outliers\")\n\n        ax.set_ylabel(f\"{METRIC_LABELS.get(metric, metric)} (mW kg$^{{-1}}$)\")\n        # Don't set title on plot - will be in caption file\n        ax.grid(True, alpha=0.3, axis=\"y\")\n        if not outlier_values.empty:\n            ax.legend()\n        # Set y-axis to start at 0 and go to max + 5%\n        y_max = ax.get_ylim()[1]\n        ax.set_ylim(0, y_max * 1.05)\n\n    plt.tight_layout()\n\n    filename_base = f\"outliers_{method}_{scenario_name or 'all'}\"\n    metrics_list = \", \".join(str(METRIC_LABELS.get(s[\"metric\"], s[\"metric\"])) for s in outlier_summary)\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The outlier detection plots show metrics {metrics_list} using {method} method for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario for {phantom_name_formatted}. Outliers are marked with red 'x' markers.\"\n    title_full = self._get_title_with_phantom(f\"outlier detection ({method} method)\")\n    filename = self._save_figure(fig, \"outliers\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    if not all_outliers.empty:\n        self._save_csv_data(all_outliers, \"outliers\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated outlier detection plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n\n    # Return DataFrame of all outliers\n    return all_outliers\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.penetration.PenetrationPlotter","title":"goliat.analysis.plots.penetration.PenetrationPlotter","text":"<pre><code>PenetrationPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates penetration depth plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.penetration.PenetrationPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.penetration.PenetrationPlotter.plot_penetration_depth_ratio","title":"plot_penetration_depth_ratio","text":"<pre><code>plot_penetration_depth_ratio(results_df: DataFrame, scenario_name: str | None = None, metric_type: str = 'psSAR10g')\n</code></pre> <p>Creates line plot showing SAR penetration depth ratio (Brain/Skin) vs frequency.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with psSAR10g_brain/psSAR10g_skin or SAR_brain/SAR_skin columns.</p> required <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> <code>metric_type</code> <code>str</code> <p>Type of SAR metric to use ('psSAR10g' or 'SAR').</p> <code>'psSAR10g'</code> Source code in <code>goliat/analysis/plots/penetration.py</code> <pre><code>def plot_penetration_depth_ratio(\n    self,\n    results_df: pd.DataFrame,\n    scenario_name: str | None = None,\n    metric_type: str = \"psSAR10g\",\n):\n    \"\"\"Creates line plot showing SAR penetration depth ratio (Brain/Skin) vs frequency.\n\n    Args:\n        results_df: DataFrame with psSAR10g_brain/psSAR10g_skin or SAR_brain/SAR_skin columns.\n        scenario_name: Optional scenario name for filtering.\n        metric_type: Type of SAR metric to use ('psSAR10g' or 'SAR').\n    \"\"\"\n    brain_col = f\"{metric_type}_brain\"\n    skin_col = f\"{metric_type}_skin\"\n    required_cols = [\"frequency_mhz\", brain_col, skin_col]\n    if not all(col in results_df.columns for col in required_cols):\n        logging.getLogger(\"progress\").warning(\n            f\"Missing columns for {metric_type} penetration depth plot: {brain_col}, {skin_col}.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    if scenario_name:\n        plot_df = results_df[results_df[\"scenario\"] == scenario_name].copy()\n    else:\n        plot_df = results_df.copy()\n\n    # Calculate ratio\n    plot_df = plot_df.copy()\n    plot_df[\"penetration_ratio\"] = plot_df[brain_col] / plot_df[skin_col]\n    plot_df = plot_df.dropna(subset=[\"penetration_ratio\"])\n    plot_df = plot_df[plot_df[\"penetration_ratio\"] &gt; 0]  # Remove invalid ratios\n\n    if plot_df.empty:\n        return\n\n    # Group by frequency\n    avg_ratio = plot_df.groupby(\"frequency_mhz\")[\"penetration_ratio\"].mean().reset_index()\n\n    fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n\n    linestyles = self._get_academic_linestyles(1)\n    markers = self._get_academic_markers(1)\n    colors = self._get_academic_colors(1)\n\n    ax.plot(\n        avg_ratio[\"frequency_mhz\"],\n        avg_ratio[\"penetration_ratio\"],\n        marker=markers[0],\n        linestyle=linestyles[0],\n        color=colors[0],\n        linewidth=2,\n        markersize=4,\n    )\n\n    ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n    ax.set_ylabel(f\"Ratio ({metric_type} Brain / {metric_type} Skin)\")\n    ax.set_yscale(\"log\")\n    # Rotate x-axis labels only for actual simulated frequencies\n    # Rotate frequency labels (always rotate when x-axis is Frequency)\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n    self._adjust_slanted_tick_labels(ax)\n    formatted_scenario = self._format_scenario_name(scenario_name) if scenario_name else None\n    if formatted_scenario:\n        base_title = f\"SAR penetration depth brain to skin {metric_type} ratio versus frequency for {formatted_scenario} scenario\"\n    else:\n        base_title = f\"SAR penetration depth brain to skin {metric_type} ratio versus frequency\"\n    title_full = self._get_title_with_phantom(base_title)\n    # Don't set title on plot - will be in caption file\n    ax.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n\n    plt.tight_layout()\n\n    filename_base = f\"penetration_ratio_{metric_type}_vs_frequency_{scenario_name or 'all'}\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The line plot shows the SAR penetration depth ratio (Brain/Skin) for {metric_type} as a function of frequency for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario for {phantom_name_formatted}. Higher ratios indicate deeper penetration into brain tissue relative to skin.\"\n    filename = self._save_figure(fig, \"penetration\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = avg_ratio[[\"frequency_mhz\", \"penetration_ratio\"]].copy()\n    self._save_csv_data(csv_data, \"penetration\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated penetration depth plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.power.PowerPlotter","title":"goliat.analysis.plots.power.PowerPlotter","text":"<pre><code>PowerPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates power balance plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.power.PowerPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.power.PowerPlotter.plot_power_efficiency_trends","title":"plot_power_efficiency_trends","text":"<pre><code>plot_power_efficiency_trends(results_df: DataFrame, scenario_name: str | None = None)\n</code></pre> <p>Creates line plot showing antenna efficiency and power component percentages across frequencies.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with power balance columns.</p> required <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> Source code in <code>goliat/analysis/plots/power.py</code> <pre><code>def plot_power_efficiency_trends(\n    self,\n    results_df: pd.DataFrame,\n    scenario_name: str | None = None,\n):\n    \"\"\"Creates line plot showing antenna efficiency and power component percentages across frequencies.\n\n    Args:\n        results_df: DataFrame with power balance columns.\n        scenario_name: Optional scenario name for filtering.\n    \"\"\"\n    if scenario_name:\n        plot_df = results_df[results_df[\"scenario\"] == scenario_name].copy()\n    else:\n        plot_df = results_df.copy()\n\n    required_cols = [\"frequency_mhz\", \"power_pin_W\", \"power_rad_W\", \"power_diel_loss_W\", \"power_sibc_loss_W\"]\n    missing_cols = [col for col in required_cols if col not in plot_df.columns]\n    if missing_cols:\n        logging.getLogger(\"progress\").warning(\n            f\"Missing columns for power efficiency plot: {missing_cols}\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Calculate efficiency and percentages\n    plot_df = plot_df.copy()\n    plot_df[\"efficiency\"] = (plot_df[\"power_rad_W\"] / plot_df[\"power_pin_W\"]) * 100\n    plot_df[\"diel_loss_pct\"] = (plot_df[\"power_diel_loss_W\"] / plot_df[\"power_pin_W\"]) * 100\n    plot_df[\"sibc_loss_pct\"] = (plot_df[\"power_sibc_loss_W\"] / plot_df[\"power_pin_W\"]) * 100\n    plot_df[\"rad_pct\"] = (plot_df[\"power_rad_W\"] / plot_df[\"power_pin_W\"]) * 100\n\n    # Group by frequency\n    freq_summary = (\n        plot_df.groupby(\"frequency_mhz\")\n        .agg(\n            {\n                \"efficiency\": \"mean\",\n                \"diel_loss_pct\": \"mean\",\n                \"sibc_loss_pct\": \"mean\",\n                \"rad_pct\": \"mean\",\n            }\n        )\n        .reset_index()\n    )\n\n    fig, axes = plt.subplots(2, 1, figsize=(3.5, 4.5))  # IEEE single-column width, taller for 2 subplots\n\n    # Top plot: Efficiency\n    ax1 = axes[0]\n    markers = self._get_academic_markers(1)\n    linestyles = self._get_academic_linestyles(1)\n    colors = self._get_academic_colors(1)\n    ax1.plot(\n        freq_summary[\"frequency_mhz\"],\n        freq_summary[\"efficiency\"],\n        marker=markers[0],\n        linestyle=linestyles[0],\n        linewidth=2,\n        markersize=4,\n        label=\"Antenna Efficiency\",\n        color=colors[0],\n    )\n    ax1.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n    ax1.set_ylabel(self._format_axis_label(\"Efficiency\", \"%\"))\n    ax1.set_title(\"Antenna efficiency vs frequency\")  # Subplot title - keep it\n    # Set explicit x-axis limits fitted to frequencies\n    freq_min = freq_summary[\"frequency_mhz\"].min()\n    freq_max = freq_summary[\"frequency_mhz\"].max()\n    freq_range = freq_max - freq_min\n    ax1.set_xlim(freq_min - freq_range * 0.05, freq_max + freq_range * 0.05)\n    # Rotate x-axis labels for real number line frequencies\n    plt.setp(ax1.get_xticklabels(), rotation=45, ha=\"right\")\n    self._adjust_slanted_tick_labels(ax1)\n    ax1.grid(True, alpha=0.3)\n    ax1.legend()\n    # Set y-axis to go up to 100%\n    ax1.set_ylim(0, 100)\n\n    # Bottom plot: Grouped bar chart for better visibility\n    ax2 = axes[1]\n    # Force x-axis to start at first frequency and end at last frequency\n    ax2.set_xlim(freq_min, freq_max)\n\n    # Check if SIBC loss is consistently very small (&lt; 2%)\n    sibc_max = freq_summary[\"sibc_loss_pct\"].max()\n    if sibc_max &lt; 2.0:\n        # Plot SIBC as a separate line on secondary y-axis for visibility\n        ax2_twin = ax2.twinx()\n        ax2.fill_between(\n            freq_summary[\"frequency_mhz\"], 0, freq_summary[\"diel_loss_pct\"], label=\"Dielectric Loss\", alpha=0.7, color=\"#00008B\"\n        )  # Dark blue\n        ax2.fill_between(\n            freq_summary[\"frequency_mhz\"],\n            freq_summary[\"diel_loss_pct\"],\n            100,\n            label=\"Radiated Power\",\n            alpha=0.7,\n            color=\"purple\",  # Purple instead of green\n        )\n        # Use distinct markers for SIBC line\n        markers = self._get_academic_markers(2)  # Get 2 to pick a different one if needed, or just use index 1\n        linestyles = self._get_academic_linestyles(2)\n        ax2_twin.plot(\n            freq_summary[\"frequency_mhz\"],\n            freq_summary[\"sibc_loss_pct\"],\n            marker=markers[1] if len(markers) &gt; 1 else \"s\",\n            linestyle=linestyles[1] if len(linestyles) &gt; 1 else \"--\",\n            label=\"SIBC Loss\",\n            color=\"orange\",\n            linewidth=2,\n            markersize=4,\n        )\n        ax2_twin.set_ylabel(\"SIBC Loss (%)\", color=\"orange\", fontsize=10)\n        ax2_twin.tick_params(axis=\"y\", labelcolor=\"orange\")\n        ax2_twin.set_ylim(0, max(sibc_max * 1.2, 0.5))\n        # Combine legends - move to top right\n        lines1, labels1 = ax2.get_legend_handles_labels()\n        lines2, labels2 = ax2_twin.get_legend_handles_labels()\n        ax2.legend(lines1 + lines2, labels1 + labels2, loc=\"upper right\")\n    else:\n        # Normal stacked area chart\n        ax2.fill_between(freq_summary[\"frequency_mhz\"], 0, freq_summary[\"diel_loss_pct\"], label=\"Dielectric Loss\", alpha=0.7)\n        ax2.fill_between(\n            freq_summary[\"frequency_mhz\"],\n            freq_summary[\"diel_loss_pct\"],\n            freq_summary[\"diel_loss_pct\"] + freq_summary[\"sibc_loss_pct\"],\n            label=\"SIBC Loss\",\n            alpha=0.7,\n        )\n        ax2.fill_between(\n            freq_summary[\"frequency_mhz\"],\n            freq_summary[\"diel_loss_pct\"] + freq_summary[\"sibc_loss_pct\"],\n            100,\n            label=\"Radiated Power\",\n            alpha=0.7,\n        )\n        ax2.legend(loc=\"upper right\")\n\n    ax2.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n    ax2.set_ylabel(self._format_axis_label(\"Percentage of input power\", \"%\"))\n    ax2.set_title(\"Power component breakdown vs frequency\")  # Subplot title - keep it\n    # Rotate x-axis labels for real number line frequencies\n    # Rotate x-axis labels only for actual simulated frequencies\n    # Rotate frequency labels (always rotate when x-axis is Frequency)\n    plt.setp(ax2.get_xticklabels(), rotation=45, ha=\"right\")\n    self._adjust_slanted_tick_labels(ax2)\n    ax2.set_ylim(0, 100)  # Already starts at 0, max is 100%\n    ax2.grid(True, alpha=0.3)\n\n    # Create title with phantom name\n    base_title = \"power efficiency trends\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n    # Don't set suptitle - will be in caption file\n    plt.tight_layout()\n\n    filename_base = f\"power_efficiency_{scenario_name or 'all'}\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The power efficiency analysis shows antenna efficiency and power component breakdown (dielectric loss, SIBC loss, radiated power) as a function of frequency for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario for {phantom_name_formatted}.\"\n    filename = self._save_figure(fig, \"power\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = pd.DataFrame(\n        {\n            \"frequency_mhz\": freq_summary[\"frequency_mhz\"],\n            \"efficiency\": freq_summary[\"efficiency\"],\n            \"dielectric_loss\": freq_summary.get(\"dielectric_loss\", np.nan),\n            \"sibc_loss\": freq_summary.get(\"sibc_loss\", np.nan),\n            \"radiated_power\": freq_summary.get(\"radiated_power\", np.nan),\n        }\n    )\n    self._save_csv_data(csv_data, \"power\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated power efficiency plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.power.PowerPlotter.plot_power_absorption_distribution","title":"plot_power_absorption_distribution","text":"<pre><code>plot_power_absorption_distribution(organ_results_df: DataFrame, scenario_name: str | None = None, frequency_mhz: int | None = None)\n</code></pre> <p>Creates pie chart or stacked bar chart showing how total power is distributed across tissue groups.</p> <p>Pie charts are kept as-is (not using scienceplots) as they work well with default matplotlib.</p> <p>Parameters:</p> Name Type Description Default <code>organ_results_df</code> <code>DataFrame</code> <p>DataFrame with tissue-level data including 'Total Loss' column.</p> required <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> <code>frequency_mhz</code> <code>int | None</code> <p>Optional frequency for filtering.</p> <code>None</code> Source code in <code>goliat/analysis/plots/power.py</code> <pre><code>def plot_power_absorption_distribution(\n    self,\n    organ_results_df: pd.DataFrame,\n    scenario_name: str | None = None,\n    frequency_mhz: int | None = None,\n):\n    \"\"\"Creates pie chart or stacked bar chart showing how total power is distributed across tissue groups.\n\n    Pie charts are kept as-is (not using scienceplots) as they work well with default matplotlib.\n\n    Args:\n        organ_results_df: DataFrame with tissue-level data including 'Total Loss' column.\n        scenario_name: Optional scenario name for filtering.\n        frequency_mhz: Optional frequency for filtering.\n    \"\"\"\n    if organ_results_df.empty or \"Total Loss\" not in organ_results_df.columns:\n        logging.getLogger(\"progress\").warning(\n            \"No 'Total Loss' data available for power absorption plot.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    plot_df = organ_results_df.copy()\n    # Filter out 'All Regions' - it's a whole-body aggregate and would double-count in pie charts\n    plot_df = self._filter_all_regions(plot_df, tissue_column=\"tissue\")\n\n    # Filter by frequency if provided\n    if frequency_mhz is not None:\n        plot_df = plot_df[plot_df[\"frequency_mhz\"] == frequency_mhz].copy()\n\n    # Aggregate by tissue group if available, otherwise by tissue\n    if \"tissue_group\" in plot_df.columns:\n        group_loss = plot_df.groupby(\"tissue_group\")[\"Total Loss\"].sum().reset_index()\n        group_loss = group_loss[group_loss[\"Total Loss\"] &gt; 0]\n    else:\n        # Use individual tissues\n        group_loss = plot_df.groupby(\"tissue\")[\"Total Loss\"].sum().reset_index()\n        group_loss = group_loss[group_loss[\"Total Loss\"] &gt; 0]\n        group_loss = group_loss.nlargest(10, \"Total Loss\")  # Top 10 tissues\n\n    if group_loss.empty:\n        return\n\n    # Vertical arrangement: 2 rows, 1 column, variable height\n    subplot_height = 2.5  # Height per subplot\n    total_height = 2 * subplot_height\n    fig, axes = plt.subplots(2, 1, figsize=(3.5, total_height))  # IEEE single-column width, vertical arrangement\n\n    # Pie chart - group tissues &lt;5% into \"Others\"\n    ax1 = axes[0]\n    group_loss_copy = group_loss.copy()\n    group_loss_copy = group_loss_copy.sort_values(\"Total Loss\", ascending=False)\n    total_loss_sum = group_loss_copy[\"Total Loss\"].sum()\n    threshold = total_loss_sum * 0.05  # 5% threshold\n\n    # Separate into main groups and others\n    main_groups = group_loss_copy[group_loss_copy[\"Total Loss\"] &gt;= threshold]\n    others_group = group_loss_copy[group_loss_copy[\"Total Loss\"] &lt; threshold]\n\n    # Combine others if any exist\n    if not others_group.empty and len(others_group) &gt; 0:\n        others_sum = others_group[\"Total Loss\"].sum()\n        others_row = pd.DataFrame({group_loss_copy.columns[0]: [\"Others\"], \"Total Loss\": [others_sum]})\n        pie_data = pd.concat([main_groups, others_row], ignore_index=True)\n    else:\n        pie_data = main_groups\n\n    # Generate colors - use Set3 colormap\n    n_colors = len(pie_data)\n    colors = plt.cm.Set3(np.linspace(0, 1, n_colors))\n\n    wedges, texts, autotexts = ax1.pie(\n        pie_data[\"Total Loss\"],\n        labels=pie_data.iloc[:, 0],\n        autopct=\"%1.1f%%\",\n        colors=colors,\n        startangle=90,\n    )\n    ax1.set_title(\"Power Absorption Distribution (Pie Chart)\")\n\n    # Stacked bar chart by frequency\n    ax2 = axes[1]\n    if frequency_mhz is None and \"frequency_mhz\" in plot_df.columns:\n        # Aggregate across frequencies\n        if \"tissue_group\" in plot_df.columns:\n            freq_group_loss = plot_df.groupby([\"frequency_mhz\", \"tissue_group\"])[\"Total Loss\"].sum().reset_index()\n            freq_group_loss = freq_group_loss.pivot(index=\"frequency_mhz\", columns=\"tissue_group\", values=\"Total Loss\").fillna(0)\n        else:\n            # Use top tissues\n            top_tissues = plot_df.groupby(\"tissue\")[\"Total Loss\"].sum().nlargest(5).index\n            plot_df_top = plot_df[plot_df[\"tissue\"].isin(top_tissues)]\n            freq_group_loss = plot_df_top.groupby([\"frequency_mhz\", \"tissue\"])[\"Total Loss\"].sum().reset_index()\n            freq_group_loss = freq_group_loss.pivot(index=\"frequency_mhz\", columns=\"tissue\", values=\"Total Loss\").fillna(0)\n\n        # Use same colors as pie chart - create color mapping\n        # Get column order from pie chart (main groups + Others if exists)\n        pie_cols = pie_data.iloc[:, 0].tolist()\n        color_map = dict(zip(pie_cols, colors[: len(pie_cols)]))\n\n        # Reorder freq_group_loss columns to match pie chart order\n        freq_cols = freq_group_loss.columns.tolist()\n        # Put pie chart columns first, then others\n        ordered_cols = [col for col in pie_cols if col in freq_cols] + [col for col in freq_cols if col not in pie_cols]\n        freq_group_loss_ordered = freq_group_loss[ordered_cols]\n\n        # Create color list matching column order\n        bar_colors = [color_map.get(col, plt.cm.Set3(0.5)) for col in ordered_cols]\n\n        freq_group_loss_ordered.plot(kind=\"bar\", stacked=True, ax=ax2, color=bar_colors)\n        ax2.set_xlabel(\"Frequency (MHz)\")\n        ax2.set_ylabel(\"Total Loss (W)\")\n        ax2.set_title(\"Power Absorption Distribution by Frequency (Stacked)\")\n        # Format legend labels to be human readable and place below subfigure\n        legend = ax2.get_legend()\n        if legend:\n            # Get current labels and format them\n            current_labels = [t.get_text() for t in legend.get_texts()]\n            formatted_labels = []\n            for label in current_labels:\n                # Format tissue group names\n                formatted_label = (\n                    self._format_organ_name(label) if hasattr(self, \"_format_organ_name\") else label.replace(\"_\", \" \").title()\n                )\n                formatted_labels.append(formatted_label)\n            # Remove old legend and create new one below\n            legend.remove()\n            legend_new = ax2.legend(\n                title=\"Tissue Group\",\n                labels=formatted_labels,\n                loc=\"upper center\",\n                bbox_to_anchor=(0.5, -0.25),\n                ncol=min(3, len(formatted_labels)),\n                fontsize=8,\n            )\n            legend_new.get_frame().set_linewidth(0.5)\n            legend_new.get_frame().set_edgecolor(\"black\")\n            # Adjust subplot to accommodate legend\n            fig.subplots_adjust(bottom=0.3)\n        else:\n            legend_new = ax2.legend(title=\"Tissue Group\", loc=\"upper center\", bbox_to_anchor=(0.5, -0.25))\n            legend_new.get_frame().set_linewidth(0.5)\n            legend_new.get_frame().set_edgecolor(\"black\")\n            fig.subplots_adjust(bottom=0.3)\n        # Rotate frequency labels (always rotate when x-axis is Frequency)\n        plt.setp(ax2.get_xticklabels(), rotation=45, ha=\"right\")\n        self._adjust_slanted_tick_labels(ax2)\n    else:\n        ax2.text(0.5, 0.5, \"Single frequency - use pie chart\", ha=\"center\", va=\"center\", transform=ax2.transAxes)\n        ax2.set_title(\"Power Absorption Distribution\")\n\n    base_title = \"power absorption distribution\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n    plt.tight_layout()\n\n    filename_base = f\"power_absorption_{scenario_name or 'all'}_{frequency_mhz or 'all'}MHz\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The power absorption distribution analysis shows pie chart of total power loss by tissue group and stacked bar chart by frequency for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario{f' at {frequency_mhz} MHz' if frequency_mhz else ''} for {phantom_name_formatted}.\"\n    filename = self._save_figure(fig, \"power\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = (\n        plot_df[[\"tissue_group\", \"Total Loss\", \"frequency_mhz\"]].copy()\n        if \"tissue_group\" in plot_df.columns\n        else plot_df[[\"tissue\", \"Total Loss\", \"frequency_mhz\"]].copy()\n    )\n    self._save_csv_data(csv_data, \"power\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated power absorption plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.power.PowerPlotter.plot_power_balance_overview","title":"plot_power_balance_overview","text":"<pre><code>plot_power_balance_overview(results_df: DataFrame)\n</code></pre> <p>Creates power balance overview heatmap with all components.</p> <p>Parameters:</p> Name Type Description Default <code>results_df</code> <code>DataFrame</code> <p>DataFrame with power balance columns.</p> required Source code in <code>goliat/analysis/plots/power.py</code> <pre><code>def plot_power_balance_overview(self, results_df: pd.DataFrame):\n    \"\"\"Creates power balance overview heatmap with all components.\n\n    Args:\n        results_df: DataFrame with power balance columns.\n    \"\"\"\n    power_df = self._prepare_power_data(results_df)\n    if power_df is None:\n        return\n\n    # Group by frequency and scenario\n    balance_summary = (\n        power_df.groupby([\"frequency_mhz\", \"scenario\"])\n        .agg(\n            {\n                \"power_balance_pct\": [\"mean\", \"std\", \"min\", \"max\"],\n                \"power_pin_W\": \"mean\",\n                \"power_rad_W\": \"mean\",\n                \"power_diel_loss_W\": \"mean\",\n                \"power_sibc_loss_W\": \"mean\",\n            }\n        )\n        .reset_index()\n    )\n\n    # Flatten column names\n    balance_summary.columns = [\"_\".join(col).strip(\"_\") if col[1] else col[0] for col in balance_summary.columns.values]\n\n    # Vertical arrangement: 3 rows, 1 column for heatmaps only\n    subplot_height = 2.5  # Height per subplot\n    total_height = 3 * subplot_height\n    fig, axes = plt.subplots(3, 1, figsize=(3.5, total_height))  # IEEE single-column width, vertical arrangement\n\n    # Balance percentage heatmap - round to one decimal, start at 0, red to green colormap\n    balance_pivot = balance_summary.pivot(index=\"scenario\", columns=\"frequency_mhz\", values=\"power_balance_pct_mean\")\n    sns.heatmap(balance_pivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=100, vmin=0, ax=axes[0], cbar_kws={\"label\": \"Balance (%)\"})\n    axes[0].set_title(\"Power Balance Percentage\")\n    axes[0].set_ylabel(\"Scenario\")\n    axes[0].tick_params(which=\"minor\", length=0)  # No minor ticks\n\n    # Input power heatmap - convert to mW, start at 0\n    pin_pivot = balance_summary.pivot(index=\"scenario\", columns=\"frequency_mhz\", values=\"power_pin_W_mean\")\n    pin_pivot_mW = pin_pivot * 1000  # Convert W to mW\n    sns.heatmap(pin_pivot_mW, annot=True, fmt=\".1f\", cmap=\"jet\", vmin=0, ax=axes[1], cbar_kws={\"label\": \"Power (mW)\"})\n    axes[1].set_title(\"Input Power\")\n    axes[1].set_ylabel(\"Scenario\")\n    axes[1].tick_params(which=\"minor\", length=0)  # No minor ticks\n\n    # Radiated power heatmap - convert to mW, start at 0\n    rad_pivot = balance_summary.pivot(index=\"scenario\", columns=\"frequency_mhz\", values=\"power_rad_W_mean\")\n    rad_pivot_mW = rad_pivot * 1000  # Convert W to mW\n    sns.heatmap(rad_pivot_mW, annot=True, fmt=\".1f\", cmap=\"jet\", vmin=0, ax=axes[2], cbar_kws={\"label\": \"Power (mW)\"})\n    axes[2].set_title(\"Radiated Power\")\n    axes[2].set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n    axes[2].set_ylabel(\"Scenario\")\n    axes[2].tick_params(which=\"minor\", length=0)  # No minor ticks\n\n    base_title = \"power balance overview\"\n    title_full = self._get_title_with_phantom(base_title)\n    # Don't set suptitle - will be in caption file\n    plt.tight_layout()\n\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The power balance overview shows heatmaps of power balance percentage, input power, and radiated power across scenarios and frequencies for {phantom_name_formatted}.\"\n    filename = self._save_figure(fig, \"power\", \"power_balance_overview\", title=title_full, caption=caption, dpi=300)\n\n    # Now create separate figure for Power Loss Breakdown\n    loss_diel_pivot = (\n        balance_summary.pivot(index=\"scenario\", columns=\"frequency_mhz\", values=\"power_diel_loss_W_mean\") * 1000\n    )  # Convert to mW\n    loss_sibc_pivot = (\n        balance_summary.pivot(index=\"scenario\", columns=\"frequency_mhz\", values=\"power_sibc_loss_W_mean\") * 1000\n    )  # Convert to mW\n\n    if not loss_diel_pivot.empty:\n        # Sum across frequencies for each scenario\n        loss_diel_sum = loss_diel_pivot.sum(axis=1)\n        loss_sibc_sum = loss_sibc_pivot.sum(axis=1)\n\n        # Create DataFrame for stacked bar chart\n        loss_combined = pd.DataFrame({\"Dielectric\": loss_diel_sum, \"SIBC\": loss_sibc_sum})\n\n        # Create separate figure for Power Loss Breakdown\n        fig_loss, ax_loss = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n        loss_combined.plot(kind=\"bar\", stacked=True, ax=ax_loss, color=[\"#00008B\", \"orange\"])  # Dark blue instead of blue\n        ax_loss.set_title(\"Power Loss Breakdown\")\n        ax_loss.set_xlabel(\"Scenario\")\n        ax_loss.set_ylabel(\"Power Loss (mW)\")\n        ax_loss.legend(title=\"Loss Type\", labels=[\"Dielectric\", \"SIBC\"])\n        ax_loss.set_ylim(bottom=0)  # Start at 0\n        plt.setp(ax_loss.get_xticklabels(), rotation=45, ha=\"right\")\n        self._adjust_slanted_tick_labels(ax_loss)\n\n        base_title_loss = \"power loss breakdown\"\n        title_full_loss = self._get_title_with_phantom(base_title_loss)\n        plt.tight_layout()\n\n        phantom_name_formatted_loss = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n        caption_loss = f\"The power loss breakdown shows stacked bar chart of dielectric and SIBC power losses summed across frequencies for each scenario for {phantom_name_formatted_loss}.\"\n        filename_loss = self._save_figure(\n            fig_loss, \"power\", \"power_loss_breakdown\", title=title_full_loss, caption=caption_loss, dpi=300\n        )\n        logging.getLogger(\"progress\").info(\n            \"  - Generated power loss breakdown\",\n            extra={\"log_type\": \"success\"},\n        )\n\n    # Save CSV data - save the power balance data\n    csv_data = power_df.copy() if \"power_df\" in locals() else pd.DataFrame()\n    if not csv_data.empty:\n        self._save_csv_data(csv_data, \"power\", \"power_balance_overview\")\n    logging.getLogger(\"progress\").info(\n        \"  - Generated power balance overview\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.ranking.RankingPlotter","title":"goliat.analysis.plots.ranking.RankingPlotter","text":"<pre><code>RankingPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates ranking plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.ranking.RankingPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.ranking.RankingPlotter.plot_top20_tissues_ranking","title":"plot_top20_tissues_ranking","text":"<pre><code>plot_top20_tissues_ranking(organ_results_df: DataFrame, metric: str = 'max_local_sar_mw_kg', scenario_name: str | None = None, frequency_mhz: int | None = None)\n</code></pre> <p>Creates horizontal bar chart showing top 20 tissues ranked by various metrics.</p> <p>Parameters:</p> Name Type Description Default <code>organ_results_df</code> <code>DataFrame</code> <p>DataFrame with tissue-level data.</p> required <code>metric</code> <code>str</code> <p>Metric to rank by (e.g., 'max_local_sar_mw_kg', 'mass_avg_sar_mw_kg', 'Total Loss').</p> <code>'max_local_sar_mw_kg'</code> <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> <code>frequency_mhz</code> <code>int | None</code> <p>Optional frequency for filtering.</p> <code>None</code> Source code in <code>goliat/analysis/plots/ranking.py</code> <pre><code>def plot_top20_tissues_ranking(\n    self,\n    organ_results_df: pd.DataFrame,\n    metric: str = \"max_local_sar_mw_kg\",\n    scenario_name: str | None = None,\n    frequency_mhz: int | None = None,\n):\n    \"\"\"Creates horizontal bar chart showing top 20 tissues ranked by various metrics.\n\n    Args:\n        organ_results_df: DataFrame with tissue-level data.\n        metric: Metric to rank by (e.g., 'max_local_sar_mw_kg', 'mass_avg_sar_mw_kg', 'Total Loss').\n        scenario_name: Optional scenario name for filtering.\n        frequency_mhz: Optional frequency for filtering.\n    \"\"\"\n    if organ_results_df.empty:\n        return\n\n    plot_df = organ_results_df.copy()\n    # Filter out 'All Regions' - it's a whole-body aggregate, not a real tissue\n    plot_df = self._filter_all_regions(plot_df, tissue_column=\"tissue\")\n\n    # Filter by frequency if provided\n    if frequency_mhz is not None:\n        plot_df = plot_df[plot_df[\"frequency_mhz\"] == frequency_mhz].copy()\n\n    if metric not in plot_df.columns:\n        logging.getLogger(\"progress\").warning(\n            f\"Metric '{metric}' not found in data.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Aggregate by tissue\n    if \"placement\" in plot_df.columns:\n        plot_df = (\n            plot_df.groupby(\"tissue\")\n            .agg(\n                {\n                    metric: \"mean\",\n                }\n            )\n            .reset_index()\n        )\n\n    # Get top 20\n    top20 = plot_df.nlargest(20, metric).sort_values(metric, ascending=True)\n\n    if top20.empty:\n        return\n\n    fig, ax = plt.subplots(figsize=(3.5, 4.0))  # IEEE single-column width, taller for ranking\n\n    # Auto-detect unit family based on max value\n    max_val_raw = top20[metric].max()\n    unit_multiplier = 1.0\n    unit_label = r\"mW kg$^{-1}$\"\n\n    if max_val_raw &lt; 1e-6:\n        unit_multiplier = 1e9\n        unit_label = r\"nW kg$^{-1}$\"\n    elif max_val_raw &lt; 1e-3:\n        unit_multiplier = 1e6\n        unit_label = r\"$\\mu$W kg$^{{-1}}$\"\n    elif max_val_raw &lt; 1.0:\n        unit_multiplier = 1e3\n        unit_label = r\"mW kg$^{-1}$\"\n    # else: keep as mW/kg (default)\n\n    # Scale values for display\n    top20_scaled = top20.copy()\n    top20_scaled[metric] = top20_scaled[metric] * unit_multiplier\n\n    # Detect outliers: if ratio between #1 and #2 &gt; 2.5, cap the display\n    outlier_threshold = 2.5\n    values_sorted = top20_scaled[metric].sort_values(ascending=False)\n    has_outlier = False\n    outlier_cap_value = None\n\n    if len(values_sorted) &gt;= 2:\n        first_val = values_sorted.iloc[0]\n        second_val = values_sorted.iloc[1]\n        if second_val &gt; 0 and first_val / second_val &gt; outlier_threshold:\n            has_outlier = True\n            # Cap at 1.5x the second value for display\n            outlier_cap_value = second_val * 1.5\n\n    # Color by tissue group using academic color palette\n    colors = self._get_academic_colors(len(top20_scaled))\n\n    # Clean and format tissue names (remove redundant phantom identifiers and format for display)\n    top20_clean = top20_scaled.copy()\n    top20_clean[\"tissue_clean\"] = top20_clean[\"tissue\"].apply(lambda x: self._format_organ_name(x))\n\n    # Create display values - cap outliers if needed\n    display_values = top20_clean[metric].copy()\n    outlier_mask = pd.Series([False] * len(display_values), index=display_values.index)\n\n    if has_outlier and outlier_cap_value is not None:\n        # Mark the outlier(s) - values that are significantly higher than the cap\n        outlier_mask = display_values &gt; outlier_cap_value\n        display_values = display_values.clip(upper=outlier_cap_value)\n\n    # Draw bars\n    bar_positions = range(len(top20_clean))\n    bars = ax.barh(bar_positions, display_values, color=colors, alpha=0.7, edgecolor=\"black\", linewidth=0.5)\n\n    # Add broken bar pattern for outliers\n    if has_outlier:\n        for i, (bar, is_outlier) in enumerate(zip(bars, outlier_mask.values)):\n            if is_outlier:\n                # Add diagonal lines to indicate broken/capped bar\n                bar_height = bar.get_height()\n                bar_y = bar.get_y()\n                bar_width = bar.get_width()\n\n                # Add break marks at the end of the bar\n                break_x = bar_width * 0.95\n                ax.plot([break_x, break_x], [bar_y + 0.1, bar_y + bar_height - 0.1], color=\"white\", linewidth=2, zorder=3)\n                ax.plot(\n                    [break_x - bar_width * 0.02, break_x + bar_width * 0.02],\n                    [bar_y + bar_height * 0.3, bar_y + bar_height * 0.7],\n                    color=\"white\",\n                    linewidth=2,\n                    zorder=3,\n                )\n                ax.plot(\n                    [break_x - bar_width * 0.02, break_x + bar_width * 0.02],\n                    [bar_y + bar_height * 0.7, bar_y + bar_height * 0.3],\n                    color=\"white\",\n                    linewidth=2,\n                    zorder=3,\n                )\n\n    ax.set_yticks(bar_positions)\n    ax.set_yticklabels(top20_clean[\"tissue_clean\"], fontsize=9)\n    ax.tick_params(axis=\"y\", which=\"major\", length=0)  # Remove y-axis tick marks\n    # Reduce top and bottom margins\n    ax.margins(y=0.01)  # Minimal top/bottom margins\n\n    # Format x-axis label properly\n    metric_display = metric.replace(\"_mw_kg\", \"\").replace(\"_\", \" \")\n    # Capitalize properly, preserving SAR and psSAR10g acronyms\n    metric_words = metric_display.split()\n    metric_formatted = []\n    for word in metric_words:\n        word_lower = word.lower()\n        # Check for psSAR10g in any capitalization variation and fix it\n        if \"pssar10g\" in word_lower:\n            # Replace any variation (pssar10g, Pssar10g, PSSAR10G, etc.) with psSAR10g\n            metric_formatted.append(\"psSAR10g\")\n        elif word.upper() == \"SAR\":\n            metric_formatted.append(\"SAR\")\n        else:\n            metric_formatted.append(word.capitalize())\n    metric_display = \" \".join(metric_formatted)\n    # Final safety check: replace any incorrect psSAR10g capitalization\n    metric_display = metric_display.replace(\"Pssar10g\", \"psSAR10g\").replace(\"PSSAR10g\", \"psSAR10g\").replace(\"Pssar\", \"psSAR\")\n    ax.set_xlabel(f\"{metric_display} ({unit_label})\")\n    ax.set_ylabel(\"Tissue\")\n\n    # Create title with phantom name\n    base_title = f\"top 20 tissues by {metric_display}\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n    # Don't set title on plot - will be in caption file\n    ax.grid(True, alpha=0.3, axis=\"x\")\n\n    # Set x-axis range - use capped value if outliers exist\n    if has_outlier and outlier_cap_value is not None:\n        ax.set_xlim(0, outlier_cap_value * 1.15)  # Extra space for label\n    else:\n        max_val = top20_clean[metric].max()\n        ax.set_xlim(0, max_val * 1.05)\n\n    # Add value labels on bars\n    # For the highest bar (last one in sorted order), put label IN the bar, others to the right\n    # Find the index position of the max value (it's the last bar since sorted ascending=True)\n    max_bar_idx = len(top20_clean) - 1\n\n    for i, (idx, row) in enumerate(top20_clean.iterrows()):\n        actual_value = row[metric]\n        display_value = display_values.loc[idx]\n        is_outlier_bar = outlier_mask.loc[idx] if has_outlier else False\n\n        if is_outlier_bar:\n            # Outlier bar: show actual value with asterisk indicator\n            # Position label left of break marks (which are at 0.95), use black for readability\n            label_text = f\"{actual_value:.3f}*\"\n            ax.text(display_value * 0.85, i, label_text, va=\"center\", ha=\"right\", fontsize=8, color=\"black\", weight=\"bold\")\n        elif i == max_bar_idx:  # Highest bar (last position) - only if not outlier\n            # Highest bar: label inside, right-aligned, black text\n            ax.text(actual_value * 0.95, i, f\"{actual_value:.3f}\", va=\"center\", ha=\"right\", fontsize=8, color=\"black\", weight=\"bold\")\n        else:\n            # Other bars: label to the right\n            ax.text(actual_value, i, f\" {actual_value:.3f}\", va=\"center\", fontsize=8)\n\n    plt.tight_layout()\n\n    metric_name = metric.replace(\"_mw_kg\", \"\").replace(\"_\", \"_\")\n    filename_base = f\"ranking_top20_{metric_name}_{scenario_name or 'all'}_{frequency_mhz or 'all'}MHz\"\n    # Use the properly formatted metric_display and unit_label for caption\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    outlier_note = (\n        \" Note: values marked with * are outliers that exceed the display scale; the actual value is shown.\" if has_outlier else \"\"\n    )\n    caption = f\"The horizontal bar chart ranks the top 20 tissues by {metric_display} ({unit_label}) for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario{f' at {frequency_mhz} MHz' if frequency_mhz else ''} for {phantom_name_formatted}.{outlier_note}\"\n    filename = self._save_figure(fig, \"ranking\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = top20_clean[[\"tissue_clean\", metric]].copy()\n    csv_data.columns = [\"tissue\", metric]\n    csv_data = csv_data.sort_values(metric, ascending=True)\n    self._save_csv_data(csv_data, \"ranking\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated ranking plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.spatial.SpatialPlotter","title":"goliat.analysis.plots.spatial.SpatialPlotter","text":"<pre><code>SpatialPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates spatial/3D plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.spatial.SpatialPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.spatial.SpatialPlotter.plot_peak_location_3d_interactive","title":"plot_peak_location_3d_interactive","text":"<pre><code>plot_peak_location_3d_interactive(peak_data: DataFrame, scenario_name: str | None = None, axis_limits: dict | None = None)\n</code></pre> <p>Creates an interactive 3D plot of peak SAR locations as wireframe boxes.</p> <p>Each box represents the spatial averaging cube (10g) centered at the peak location. Uses Plotly for interactive visualization (not affected by scienceplots).</p> <p>Parameters:</p> Name Type Description Default <code>peak_data</code> <code>DataFrame</code> <p>DataFrame with columns: ['PeakLocation', 'PeakCubeSideLength',       'PeakValue', 'placement', 'frequency_mhz', 'scenario']</p> required <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering and filename.</p> <code>None</code> <code>axis_limits</code> <code>dict | None</code> <p>Optional dict with 'x', 'y', 'z' keys containing (min, max) tuples.         If None, calculates from filtered data.</p> <code>None</code> Source code in <code>goliat/analysis/plots/spatial.py</code> <pre><code>def plot_peak_location_3d_interactive(\n    self,\n    peak_data: pd.DataFrame,\n    scenario_name: str | None = None,\n    axis_limits: dict | None = None,\n):\n    \"\"\"Creates an interactive 3D plot of peak SAR locations as wireframe boxes.\n\n    Each box represents the spatial averaging cube (10g) centered at the peak location.\n    Uses Plotly for interactive visualization (not affected by scienceplots).\n\n    Args:\n        peak_data: DataFrame with columns: ['PeakLocation', 'PeakCubeSideLength',\n                  'PeakValue', 'placement', 'frequency_mhz', 'scenario']\n        scenario_name: Optional scenario name for filtering and filename.\n        axis_limits: Optional dict with 'x', 'y', 'z' keys containing (min, max) tuples.\n                    If None, calculates from filtered data.\n    \"\"\"\n    try:\n        import plotly.graph_objects as go\n    except ImportError:\n        logging.getLogger(\"progress\").warning(\n            \"Plotly not available. Skipping 3D interactive plot. Install with: pip install plotly\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    if peak_data.empty:\n        logging.getLogger(\"progress\").warning(\n            \"No peak location data available for 3D plot.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    # Filter by scenario if provided\n    plot_data = peak_data.copy()\n    if scenario_name:\n        plot_data = plot_data[plot_data[\"scenario\"] == scenario_name].copy()\n\n    if plot_data.empty:\n        return\n\n    # Calculate axis limits if not provided\n    if axis_limits is None:\n        axis_limits = self._calculate_axis_limits(plot_data)\n\n    fig = go.Figure()\n    colorscale = \"jet\"\n\n    # Normalize PeakValue for color mapping\n    if \"PeakValue\" in plot_data.columns:\n        peak_values = plot_data[\"PeakValue\"].values\n        vmin, vmax = peak_values.min(), peak_values.max()\n    else:\n        vmin, vmax = 0, 1\n        peak_values = np.zeros(len(plot_data))\n\n    # Get unique scenarios for color coding\n    if \"scenario\" in plot_data.columns:\n        unique_scenarios = sorted(plot_data[\"scenario\"].unique())\n        scenario_colors = plt.cm.tab10(np.linspace(0, 1, len(unique_scenarios)))\n        scenario_color_map = {scenario: tuple(scenario_colors[i][:3]) for i, scenario in enumerate(unique_scenarios)}\n    else:\n        scenario_color_map = {}\n\n    for idx, row in plot_data.iterrows():\n        if pd.isna(row.get(\"PeakLocation\")) or pd.isna(row.get(\"PeakCubeSideLength\")):\n            continue\n\n        location = row[\"PeakLocation\"]\n        if isinstance(location, str):\n            try:\n                import ast\n\n                location = ast.literal_eval(location)\n            except Exception:\n                continue\n\n        if not isinstance(location, (list, tuple)) or len(location) != 3:\n            continue\n\n        x, y, z = location\n        side_length = float(row.get(\"PeakCubeSideLength\", 0.01))\n        peak_val = float(row.get(\"PeakValue\", 0))\n\n        # Convert to millimeters\n        x_mm, y_mm, z_mm = x * 1000, y * 1000, z * 1000\n        side_length_mm = side_length * 1000\n\n        # Create wireframe box vertices (in mm)\n        half = side_length_mm / 2\n        vertices = [\n            [x_mm - half, y_mm - half, z_mm - half],\n            [x_mm + half, y_mm - half, z_mm - half],\n            [x_mm + half, y_mm + half, z_mm - half],\n            [x_mm - half, y_mm + half, z_mm - half],\n            [x_mm - half, y_mm - half, z_mm + half],\n            [x_mm + half, y_mm - half, z_mm + half],\n            [x_mm + half, y_mm + half, z_mm + half],\n            [x_mm - half, y_mm + half, z_mm + half],\n        ]\n\n        # Define box edges\n        edges = [\n            [0, 1],\n            [1, 2],\n            [2, 3],\n            [3, 0],  # bottom face\n            [4, 5],\n            [5, 6],\n            [6, 7],\n            [7, 4],  # top face\n            [0, 4],\n            [1, 5],\n            [2, 6],\n            [3, 7],  # vertical edges\n        ]\n\n        scenario = row.get(\"scenario\", \"unknown\")\n        placement = row.get(\"placement\", \"unknown\")\n        freq = row.get(\"frequency_mhz\", \"unknown\")\n        label = f\"{scenario} | {placement} | {freq} MHz\"\n\n        # For aggregated plot: use scenario colors and show legend grouped by scenario\n        # For individual scenario plot: use peak value colors, no legend\n        if scenario_name is None and scenario in scenario_color_map:\n            box_color = scenario_color_map[scenario]\n            legend_name = scenario  # Group by scenario in aggregated plot\n            show_legend = True\n        else:\n            normalized_val = (peak_val - vmin) / (vmax - vmin) if vmax &gt; vmin else 0.5\n            box_color = plt.cm.get_cmap(colorscale)(normalized_val)[:3]\n            legend_name = label\n            show_legend = False\n\n        # Create a trace for this box (all edges together for legend)\n        edge_x, edge_y, edge_z = [], [], []\n        for edge in edges:\n            v0, v1 = vertices[edge[0]], vertices[edge[1]]\n            edge_x.extend([v0[0], v1[0], None])\n            edge_y.extend([v0[1], v1[1], None])\n            edge_z.extend([v0[2], v1[2], None])\n\n        fig.add_trace(\n            go.Scatter3d(\n                x=edge_x,\n                y=edge_y,\n                z=edge_z,\n                mode=\"lines\",\n                line=dict(color=f\"rgb({int(box_color[0] * 255)}, {int(box_color[1] * 255)}, {int(box_color[2] * 255)})\", width=3),\n                name=legend_name,\n                showlegend=show_legend,\n                legendgroup=scenario if scenario_name is None else None,\n                hovertemplate=f\"{label}&lt;br&gt;Peak SAR: {peak_val:.2f} mW/kg&lt;br&gt;Location: ({x_mm:.2f}, {y_mm:.2f}, {z_mm:.2f}) mm&lt;extra&gt;&lt;/extra&gt;\",\n            )\n        )\n\n    # Add colorbar for peak values (only if not using scenario colors)\n    if scenario_name is not None or not scenario_color_map:\n        fig.add_trace(\n            go.Scatter3d(\n                x=[None],\n                y=[None],\n                z=[None],\n                mode=\"markers\",\n                marker=dict(\n                    colorscale=colorscale,\n                    showscale=True,\n                    cmin=vmin,\n                    cmax=vmax,\n                    colorbar=dict(title=\"Peak SAR (mW/kg)\", len=0.5, y=0.5),\n                ),\n                showlegend=False,\n            )\n        )\n\n    base_title = \"3D peak SAR location visualization\"\n    title_with_phantom = self._get_title_with_phantom(base_title, scenario_name)\n    # Title will be in caption file, not on plot\n    fig.update_layout(\n        title=title_with_phantom,\n        scene=dict(\n            xaxis_title=\"X (mm)\",\n            yaxis_title=\"Y (mm)\",\n            zaxis_title=\"Z (mm)\",\n            xaxis=dict(range=axis_limits[\"x\"]),\n            yaxis=dict(range=axis_limits[\"y\"]),\n            zaxis=dict(range=axis_limits[\"z\"]),\n            aspectmode=\"cube\",\n        ),\n        width=1000,\n        height=800,\n    )\n\n    subdir = self._get_subdir(\"spatial\")\n    filename = f\"peak_location_3d_interactive_{scenario_name}.html\" if scenario_name else \"peak_location_3d_interactive_all.html\"\n    fig.write_html(os.path.join(subdir, filename))\n\n    # Create caption file for HTML plot\n    caption_filename = filename.replace(\".html\", \".txt\")\n    caption_path = os.path.join(subdir, caption_filename)\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The interactive 3D visualization shows peak SAR locations as wireframe boxes representing the spatial averaging cube (10g) centered at each peak location for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario for {phantom_name_formatted}.\"\n    with open(caption_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(f\"Title: {title_with_phantom}\\n\\n\")\n        f.write(f\"Caption: {caption}\\n\")\n\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated 3D interactive plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.spatial.SpatialPlotter.plot_peak_location_2d_projections","title":"plot_peak_location_2d_projections","text":"<pre><code>plot_peak_location_2d_projections(peak_data: DataFrame, scenario_name: str | None = None)\n</code></pre> <p>Creates 2D scatter plots showing peak locations projected onto XY, XZ, YZ planes.</p> <p>Parameters:</p> Name Type Description Default <code>peak_data</code> <code>DataFrame</code> <p>DataFrame with columns: ['PeakLocation', 'PeakValue', 'placement',       'frequency_mhz', 'scenario']</p> required <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering and filename.</p> <code>None</code> Source code in <code>goliat/analysis/plots/spatial.py</code> <pre><code>def plot_peak_location_2d_projections(\n    self,\n    peak_data: pd.DataFrame,\n    scenario_name: str | None = None,\n):\n    \"\"\"Creates 2D scatter plots showing peak locations projected onto XY, XZ, YZ planes.\n\n    Args:\n        peak_data: DataFrame with columns: ['PeakLocation', 'PeakValue', 'placement',\n                  'frequency_mhz', 'scenario']\n        scenario_name: Optional scenario name for filtering and filename.\n    \"\"\"\n    if peak_data.empty:\n        return\n\n    if scenario_name:\n        peak_data = peak_data[peak_data[\"scenario\"] == scenario_name].copy()\n\n    if peak_data.empty:\n        return\n\n    # Extract coordinates\n    locations = []\n    peak_values = []\n    for idx, row in peak_data.iterrows():\n        if pd.isna(row.get(\"PeakLocation\")):\n            continue\n        location = row[\"PeakLocation\"]\n        if isinstance(location, str):\n            try:\n                import ast\n\n                location = ast.literal_eval(location)\n            except Exception:\n                continue\n        if isinstance(location, (list, tuple)) and len(location) == 3:\n            locations.append(location)\n            peak_values.append(float(row.get(\"PeakValue\", 0)))\n\n    if not locations:\n        return\n\n    locations = np.array(locations)\n    peak_values = np.array(peak_values)\n\n    # Convert from meters to millimeters\n    locations_mm = locations * 1000\n\n    # Vertical arrangement: 3 rows, 1 column, variable height\n    subplot_height = 2.5  # Height per subplot\n    total_height = 3 * subplot_height\n    fig, axes = plt.subplots(3, 1, figsize=(3.5, total_height))  # IEEE single-column width, vertical arrangement\n\n    # Auto-detect unit family based on max peak value\n    max_val_raw = peak_values.max()\n    unit_multiplier = 1.0\n    unit_label = r\"mW kg$^{-1}$\"\n\n    if max_val_raw &lt; 1e-6:\n        unit_multiplier = 1e9\n        unit_label = r\"nW kg$^{-1}$\"\n    elif max_val_raw &lt; 1e-3:\n        unit_multiplier = 1e6\n        unit_label = r\"$\\mu$W kg$^{{-1}}$\"\n    elif max_val_raw &lt; 1.0:\n        unit_multiplier = 1e3\n        unit_label = r\"mW kg$^{-1}$\"\n\n    peak_values_scaled = peak_values * unit_multiplier\n    vmin = 0.0 * unit_multiplier  # Start colormap at 0\n    vmax = peak_values_scaled.max()\n\n    # Transverse-XY plane (subplot title - keep it)\n    scatter1 = axes[0].scatter(\n        locations_mm[:, 0], locations_mm[:, 1], c=peak_values_scaled, cmap=\"jet\", alpha=0.7, s=30, vmin=vmin, vmax=vmax\n    )\n    axes[0].set_xlabel(self._format_axis_label(\"X\", \"mm\"))\n    axes[0].set_ylabel(self._format_axis_label(\"Y\", \"mm\"))\n    axes[0].set_title(\"Transverse-XY plane\")\n    axes[0].grid(True, alpha=0.3)\n    cbar1 = plt.colorbar(scatter1, ax=axes[0])\n    cbar1.set_label(self._format_axis_label(\"Peak SAR\", unit_label))\n\n    # Sagittal-XZ plane (subplot title - keep it)\n    scatter2 = axes[1].scatter(\n        locations_mm[:, 0], locations_mm[:, 2], c=peak_values_scaled, cmap=\"jet\", alpha=0.7, s=30, vmin=vmin, vmax=vmax\n    )\n    axes[1].set_xlabel(self._format_axis_label(\"X\", \"mm\"))\n    axes[1].set_ylabel(self._format_axis_label(\"Z\", \"mm\"))\n    axes[1].set_title(\"Sagittal-XZ plane\")\n    axes[1].grid(True, alpha=0.3)\n    cbar2 = plt.colorbar(scatter2, ax=axes[1])\n    cbar2.set_label(self._format_axis_label(\"Peak SAR\", unit_label))\n\n    # Coronal-YZ plane (subplot title - keep it)\n    scatter3 = axes[2].scatter(\n        locations_mm[:, 1], locations_mm[:, 2], c=peak_values_scaled, cmap=\"jet\", alpha=0.7, s=30, vmin=vmin, vmax=vmax\n    )\n    axes[2].set_xlabel(self._format_axis_label(\"Y\", \"mm\"))\n    axes[2].set_ylabel(self._format_axis_label(\"Z\", \"mm\"))\n    axes[2].set_title(\"Coronal-YZ plane\")\n    axes[2].grid(True, alpha=0.3)\n    cbar3 = plt.colorbar(scatter3, ax=axes[2])\n    cbar3.set_label(self._format_axis_label(\"Peak SAR\", unit_label))\n\n    base_title = \"peak SAR location 2D projections\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n    # Don't set suptitle - will be in caption file\n\n    # Add sample size annotation - top-right, simple box, black border\n    n_samples = len(locations_mm)\n    fig.text(\n        0.95,\n        0.95,\n        f\"n = {n_samples}\",\n        fontsize=8,\n        transform=fig.transFigure,\n        verticalalignment=\"top\",\n        horizontalalignment=\"right\",\n        bbox=dict(boxstyle=\"square,pad=0.4\", facecolor=\"white\", edgecolor=\"black\", linewidth=0.5, alpha=1.0),\n    )\n    plt.tight_layout()\n\n    filename_base = f\"peak_location_2d_{scenario_name}\" if scenario_name else \"peak_location_2d\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The 2D projections show peak SAR locations onto Transverse-XY, Sagittal-XZ, and Coronal-YZ planes for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario for {phantom_name_formatted}. Each point represents a peak location, colored by peak SAR value.\"\n    filename = self._save_figure(fig, \"spatial\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = pd.DataFrame(\n        {\"x_mm\": locations_mm[:, 0], \"y_mm\": locations_mm[:, 1], \"z_mm\": locations_mm[:, 2], \"peak_sar_mw_kg\": peak_values}\n    )\n    self._save_csv_data(csv_data, \"spatial\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated 2D projection plots: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.tissue_analysis.TissueAnalysisPlotter","title":"goliat.analysis.plots.tissue_analysis.TissueAnalysisPlotter","text":"<pre><code>TissueAnalysisPlotter(plots_dir: str, phantom_name: str | None = None, plot_format: str = 'pdf')\n</code></pre> <p>               Bases: <code>BasePlotter</code></p> <p>Generates tissue analysis plots for SAR analysis.</p> Source code in <code>goliat/analysis/plots/base.py</code> <pre><code>def __init__(self, plots_dir: str, phantom_name: str | None = None, plot_format: str = \"pdf\"):\n    \"\"\"Initialize base plotter.\n\n    Args:\n        plots_dir: Directory where all plots will be saved.\n        phantom_name: Optional phantom model name for titles.\n        plot_format: Output format for plots ('pdf' or 'png'), default 'pdf'.\n    \"\"\"\n    self.plots_dir = plots_dir\n    self.phantom_name = phantom_name\n    self.plot_format = plot_format\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.tissue_analysis.TissueAnalysisPlotter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.analysis.plots.tissue_analysis.TissueAnalysisPlotter.plot_max_local_vs_pssar10g_scatter","title":"plot_max_local_vs_pssar10g_scatter","text":"<pre><code>plot_max_local_vs_pssar10g_scatter(organ_results_df: DataFrame, scenario_name: str | None = None, frequency_mhz: int | None = None)\n</code></pre> <p>Creates scatter plot showing relationship between Max Local SAR and psSAR10g.</p> <p>Parameters:</p> Name Type Description Default <code>organ_results_df</code> <code>DataFrame</code> <p>DataFrame with max_local_sar_mw_kg and psSAR10g columns.</p> required <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> <code>frequency_mhz</code> <code>int | None</code> <p>Optional frequency for filtering.</p> <code>None</code> Source code in <code>goliat/analysis/plots/tissue_analysis.py</code> <pre><code>def plot_max_local_vs_pssar10g_scatter(\n    self,\n    organ_results_df: pd.DataFrame,\n    scenario_name: str | None = None,\n    frequency_mhz: int | None = None,\n):\n    \"\"\"Creates scatter plot showing relationship between Max Local SAR and psSAR10g.\n\n    Args:\n        organ_results_df: DataFrame with max_local_sar_mw_kg and psSAR10g columns.\n        scenario_name: Optional scenario name for filtering.\n        frequency_mhz: Optional frequency for filtering.\n    \"\"\"\n    # Check for required columns, try alternative names\n    if \"max_local_sar_mw_kg\" not in organ_results_df.columns:\n        if \"Max. local SAR\" in organ_results_df.columns:\n            organ_results_df = organ_results_df.rename(columns={\"Max. local SAR\": \"max_local_sar_mw_kg\"})\n\n    if \"psSAR10g\" not in organ_results_df.columns:\n        if \"peak_sar_10g_mw_kg\" in organ_results_df.columns:\n            organ_results_df[\"psSAR10g\"] = organ_results_df[\"peak_sar_10g_mw_kg\"]\n        elif \"Peak Spatial-Average SAR[IEEE/IEC62704-1] (10g)\" in organ_results_df.columns:\n            organ_results_df[\"psSAR10g\"] = organ_results_df[\"Peak Spatial-Average SAR[IEEE/IEC62704-1] (10g)\"]\n\n    required_cols = [\"max_local_sar_mw_kg\", \"psSAR10g\"]\n    if not all(col in organ_results_df.columns for col in required_cols):\n        logging.getLogger(\"progress\").warning(\n            \"Missing columns for Max Local SAR vs psSAR10g scatter plot.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    plot_df = organ_results_df.copy()\n\n    if frequency_mhz is not None:\n        plot_df = plot_df[plot_df[\"frequency_mhz\"] == frequency_mhz].copy()\n\n    plot_df = plot_df.dropna(subset=required_cols)\n    plot_df = plot_df[(plot_df[\"max_local_sar_mw_kg\"] &gt; 0) &amp; (plot_df[\"psSAR10g\"] &gt; 0)]\n\n    if plot_df.empty:\n        return\n\n    # Filter out extreme outliers in Max Local SAR (using iterative ratio method)\n    # This removes points where the max value is &gt; 2x the average of the next 30 points\n    if len(plot_df) &gt;= 6:\n        iteration = 0\n        original_count = len(plot_df)\n\n        while len(plot_df) &gt;= 6:\n            iteration += 1\n            # Sort by Max Local SAR descending\n            plot_df = plot_df.sort_values(\"max_local_sar_mw_kg\", ascending=False)\n\n            # Get the top value and the next 30\n            top_row = plot_df.iloc[0]\n            top_val = top_row[\"max_local_sar_mw_kg\"]\n\n            next_n = plot_df.iloc[1:31]\n            avg_next_n = next_n[\"max_local_sar_mw_kg\"].mean()\n\n            if avg_next_n &lt;= 0:\n                break\n\n            ratio = top_val / avg_next_n\n\n            if ratio &gt; 2.0:\n                # Found an outlier - remove the top row\n                plot_df = plot_df.iloc[1:].copy()\n            else:\n                # Ratio is acceptable, stop checking\n                break\n\n        new_count = len(plot_df)\n        if new_count &lt; original_count:\n            logging.getLogger(\"progress\").info(\n                f\"  - Filtered {original_count - new_count} extreme outlier(s) using iterative ratio method (&gt;2.0x avg of next 30).\",\n                extra={\"log_type\": \"info\"},\n            )\n\n    if plot_df.empty:\n        return\n\n    # Check for outliers and dense clusters\n    max_x = plot_df[\"max_local_sar_mw_kg\"].max()\n    max_y = plot_df[\"psSAR10g\"].max()\n\n    # Identify dense region (95th percentile)\n    x_p95 = plot_df[\"max_local_sar_mw_kg\"].quantile(0.95)\n    y_p95 = plot_df[\"psSAR10g\"].quantile(0.95)\n\n    # Set minimum axis values to avoid overplotting at origin\n    x_min_val = plot_df[\"max_local_sar_mw_kg\"].quantile(0.01)\n\n    # Create main plot with inset for dense region\n    fig = plt.figure(figsize=(3.5, 3.0))  # IEEE single-column width\n    ax = fig.add_subplot(111)\n\n    # Color by frequency if available\n    if \"frequency_mhz\" in plot_df.columns and len(plot_df[\"frequency_mhz\"].unique()) &gt; 1:\n        scatter_plot = ax.scatter(\n            plot_df[\"max_local_sar_mw_kg\"],\n            plot_df[\"psSAR10g\"],\n            c=plot_df[\"frequency_mhz\"],\n            cmap=\"jet\",\n            alpha=0.6,\n            s=30,\n        )\n        # Create colorbar with proper positioning to avoid extra subplot\n        cbar = plt.colorbar(scatter_plot, ax=ax, pad=0.02)\n        cbar.set_label(\"Frequency (MHz)\")\n    else:\n        ax.scatter(plot_df[\"max_local_sar_mw_kg\"], plot_df[\"psSAR10g\"], alpha=0.6, s=30)\n\n    # Add diagonal reference line (y=x) - limit to reasonable range\n    max_val = max(x_p95, y_p95)\n    ax.plot([x_min_val, max_val], [x_min_val, max_val], \"r--\", linewidth=2, label=\"y=x (No Spatial Averaging)\")\n\n    # Set axis limits: start at 0 for SAR values, go to max + 5%\n    ax.set_xlim(0, max_x * 1.05)\n    ax.set_ylim(0, max_y * 1.05)\n\n    ax.set_xlabel(r\"Max Local SAR (mW kg$^{-1}$)\")\n    ax.set_ylabel(r\"psSAR10g (mW kg$^{-1}$)\")\n\n    # Create title with phantom name\n    base_title = \"max local SAR vs psSAR10g\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n    # Don't set title on plot - will be in caption file\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n\n    # Add inset for dense region if there's significant clustering\n    if x_p95 &lt; max_x * 0.5 or y_p95 &lt; max_y * 0.5:\n        ax_inset = inset_axes(ax, width=\"40%\", height=\"40%\", loc=\"upper right\", borderpad=2)\n\n        # Filter data for inset (include a bit more than p95)\n        inset_limit_x = x_p95 * 1.1\n        inset_limit_y = y_p95 * 1.1\n\n        inset_df = plot_df[(plot_df[\"max_local_sar_mw_kg\"] &lt;= inset_limit_x) &amp; (plot_df[\"psSAR10g\"] &lt;= inset_limit_y)]\n\n        if not inset_df.empty:\n            if \"frequency_mhz\" in inset_df.columns and len(inset_df[\"frequency_mhz\"].unique()) &gt; 1:\n                ax_inset.scatter(\n                    inset_df[\"max_local_sar_mw_kg\"],\n                    inset_df[\"psSAR10g\"],\n                    c=inset_df[\"frequency_mhz\"],\n                    cmap=\"jet\",\n                    alpha=0.6,\n                    s=20,\n                )\n            else:\n                ax_inset.scatter(inset_df[\"max_local_sar_mw_kg\"], inset_df[\"psSAR10g\"], alpha=0.6, s=20)\n\n        # Reference line in inset\n        min_val = 0\n        inset_max_ref = min(inset_limit_x, inset_limit_y)\n        ax_inset.plot([min_val, inset_max_ref], [min_val, inset_max_ref], \"r--\", linewidth=1, alpha=0.5)\n\n        # Set limits\n        ax_inset.set_xlim(0, inset_limit_x)\n        ax_inset.set_ylim(0, inset_limit_y)\n\n        # Ensure 0 is shown as a tick if possible, but rely mainly on limits\n        # Manual checking of tick labels can be fragile with tight layouts\n\n        ax_inset.set_xlabel(\"Max Local SAR\", fontsize=8)\n        ax_inset.set_ylabel(\"psSAR10g\", fontsize=8)\n        ax_inset.tick_params(labelsize=7)\n        ax_inset.grid(True, alpha=0.3)\n        ax_inset.set_title(\"Zoomed View\\n(95th percentile)\", fontsize=8)\n\n    plt.tight_layout()\n\n    filename_base = f\"scatter_MaxLocal_vs_psSAR10g_{scenario_name or 'all'}_{frequency_mhz or 'all'}MHz\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The scatter plot compares Max Local SAR and psSAR10g values for tissues in the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario{f' at {frequency_mhz} MHz' if frequency_mhz else ''} for {phantom_name_formatted}. The red dashed line represents y=x (no spatial averaging). Points are colored by frequency when multiple frequencies are present.\"\n    filename = self._save_figure(fig, \"tissue_analysis\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data - use actual columns that exist\n    csv_cols = [\"max_local_sar_mw_kg\", \"psSAR10g\"]\n    if \"frequency_mhz\" in plot_df.columns:\n        csv_cols.append(\"frequency_mhz\")\n    csv_data = plot_df[csv_cols].copy()\n    self._save_csv_data(csv_data, \"tissue_analysis\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated scatter plot: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.tissue_analysis.TissueAnalysisPlotter.plot_tissue_frequency_response","title":"plot_tissue_frequency_response","text":"<pre><code>plot_tissue_frequency_response(organ_results_df: DataFrame, tissue_name: str, scenario_name: str | None = None)\n</code></pre> <p>Creates line plot showing how a specific tissue responds across frequencies.</p> <p>Parameters:</p> Name Type Description Default <code>organ_results_df</code> <code>DataFrame</code> <p>DataFrame with tissue-level data.</p> required <code>tissue_name</code> <code>str</code> <p>Name of the tissue to plot.</p> required <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> Source code in <code>goliat/analysis/plots/tissue_analysis.py</code> <pre><code>def plot_tissue_frequency_response(\n    self,\n    organ_results_df: pd.DataFrame,\n    tissue_name: str,\n    scenario_name: str | None = None,\n):\n    \"\"\"Creates line plot showing how a specific tissue responds across frequencies.\n\n    Args:\n        organ_results_df: DataFrame with tissue-level data.\n        tissue_name: Name of the tissue to plot.\n        scenario_name: Optional scenario name for filtering.\n    \"\"\"\n    # Skip if trying to plot 'All Regions' - it's not a real tissue\n    if tissue_name == \"All Regions\":\n        return\n\n    plot_df = organ_results_df[organ_results_df[\"tissue\"] == tissue_name].copy()\n\n    if plot_df.empty:\n        return\n\n    if scenario_name:\n        plot_df = plot_df[plot_df[\"scenario\"] == scenario_name].copy()\n\n    if plot_df.empty:\n        return\n\n    # Aggregate by frequency\n    sar_cols = [\"min_local_sar_mw_kg\", \"mass_avg_sar_mw_kg\", \"max_local_sar_mw_kg\"]\n    available_cols = [col for col in sar_cols if col in plot_df.columns]\n\n    if not available_cols:\n        # Try alternative column names\n        if \"Min. local SAR\" in plot_df.columns:\n            plot_df[\"min_local_sar_mw_kg\"] = plot_df[\"Min. local SAR\"]\n            available_cols.append(\"min_local_sar_mw_kg\")\n        if \"Mass-Averaged SAR\" in plot_df.columns:\n            plot_df[\"mass_avg_sar_mw_kg\"] = plot_df[\"Mass-Averaged SAR\"]\n            available_cols.append(\"mass_avg_sar_mw_kg\")\n        if \"Max. local SAR\" in plot_df.columns:\n            plot_df[\"max_local_sar_mw_kg\"] = plot_df[\"Max. local SAR\"]\n            available_cols.append(\"max_local_sar_mw_kg\")\n\n    if not available_cols:\n        return\n\n    freq_summary = plot_df.groupby(\"frequency_mhz\")[available_cols].mean().reset_index()\n\n    fig, ax = plt.subplots(figsize=(3.5, 2.5))  # IEEE single-column width\n\n    colors = self._get_academic_colors(len(available_cols))\n    linestyles = self._get_academic_linestyles(len(available_cols))\n    markers = self._get_academic_markers(len(available_cols))\n\n    for idx, col in enumerate(available_cols):\n        # Format label properly: remove \"_mw_kg\", preserve SAR acronym\n        label_base = col.replace(\"_mw_kg\", \"\").replace(\"_\", \" \")\n        # Capitalize properly, preserving SAR acronym\n        label_words = label_base.split()\n        label_formatted = []\n        for word in label_words:\n            if word.upper() == \"SAR\":\n                label_formatted.append(\"SAR\")\n            else:\n                label_formatted.append(word.capitalize())\n        label = \" \".join(label_formatted)\n        ax.plot(\n            freq_summary[\"frequency_mhz\"],\n            freq_summary[col],\n            marker=markers[idx],\n            linestyle=linestyles[idx],\n            color=colors[idx],\n            label=label,\n            linewidth=2,\n            markersize=4,\n        )\n\n    ax.set_xlabel(self._format_axis_label(\"Frequency\", \"MHz\"))\n    ax.set_ylabel(self._format_axis_label(\"SAR\", r\"mW kg$^{-1}$\"))\n    # Rotate x-axis labels for real number line frequencies\n    # Rotate x-axis labels only for actual simulated frequencies\n    # Rotate frequency labels (always rotate when x-axis is Frequency)\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n    self._adjust_slanted_tick_labels(ax)\n\n    # Clean tissue name and create title with phantom name\n    tissue_clean = self._clean_tissue_name(tissue_name)\n    formatted_scenario = self._format_scenario_name(scenario_name) if scenario_name else None\n    if formatted_scenario:\n        base_title = f\"frequency response for {tissue_clean} in {formatted_scenario} scenario\"\n    else:\n        base_title = f\"frequency response for {tissue_clean}\"\n    title_full = self._get_title_with_phantom(base_title)\n    # Don't set title on plot - will be in caption file\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    # Set y-axis to start at 0 and go to max + 5%\n    y_max = ax.get_ylim()[1]\n    ax.set_ylim(0, y_max * 1.05)\n\n    plt.tight_layout()\n\n    safe_tissue_name = tissue_name.replace(\"/\", \"_\").replace(\" \", \"_\")\n    filename_base = f\"tissue_frequency_response_{safe_tissue_name}_{scenario_name or 'all'}\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The line plot shows the frequency response of SAR metrics (Min Local SAR, Mass-Averaged SAR, Max Local SAR) for {tissue_clean} in the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario for {phantom_name_formatted}.\"\n    filename = self._save_figure(fig, \"tissue_analysis\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = freq_summary.copy()\n    csv_data.index.name = \"frequency_mhz\"\n    self._save_csv_data(csv_data, \"tissue_analysis\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated tissue frequency response: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.analysis.plots.tissue_analysis.TissueAnalysisPlotter.plot_tissue_mass_volume_distribution","title":"plot_tissue_mass_volume_distribution","text":"<pre><code>plot_tissue_mass_volume_distribution(organ_results_df: DataFrame, scenario_name: str | None = None)\n</code></pre> <p>Creates histograms and scatter plot showing tissue mass and volume distributions.</p> <p>Parameters:</p> Name Type Description Default <code>organ_results_df</code> <code>DataFrame</code> <p>DataFrame with 'Total Mass' and 'Total Volume' columns.</p> required <code>scenario_name</code> <code>str | None</code> <p>Optional scenario name for filtering.</p> <code>None</code> Source code in <code>goliat/analysis/plots/tissue_analysis.py</code> <pre><code>def plot_tissue_mass_volume_distribution(\n    self,\n    organ_results_df: pd.DataFrame,\n    scenario_name: str | None = None,\n):\n    \"\"\"Creates histograms and scatter plot showing tissue mass and volume distributions.\n\n    Args:\n        organ_results_df: DataFrame with 'Total Mass' and 'Total Volume' columns.\n        scenario_name: Optional scenario name for filtering.\n    \"\"\"\n    required_cols = [\"Total Mass\", \"Total Volume\"]\n    if not all(col in organ_results_df.columns for col in required_cols):\n        logging.getLogger(\"progress\").warning(\n            \"Missing columns for mass/volume distribution plot.\",\n            extra={\"log_type\": \"warning\"},\n        )\n        return\n\n    plot_df = organ_results_df.copy()\n    # Filter out 'All Regions' - it's a whole-body aggregate, not a real tissue\n    plot_df = self._filter_all_regions(plot_df, tissue_column=\"tissue\")\n    plot_df = plot_df.dropna(subset=required_cols)\n    plot_df = plot_df[(plot_df[\"Total Mass\"] &gt; 0) &amp; (plot_df[\"Total Volume\"] &gt; 0)]\n\n    if plot_df.empty:\n        return\n\n    # Aggregate by tissue if multiple placements\n    if \"placement\" in plot_df.columns:\n        plot_df = (\n            plot_df.groupby(\"tissue\")\n            .agg(\n                {\n                    \"Total Mass\": \"mean\",\n                    \"Total Volume\": \"mean\",\n                }\n            )\n            .reset_index()\n        )\n\n    # Vertical arrangement: 3 rows, 1 column, variable height\n    subplot_height = 2.5  # Height per subplot\n    total_height = 3 * subplot_height\n    fig, axes = plt.subplots(3, 1, figsize=(3.5, total_height))  # IEEE single-column width, vertical arrangement\n\n    # Histogram of Total Mass - use log-spaced bins for constant bin size on log scale\n    mass_min = plot_df[\"Total Mass\"].min()\n    mass_max = plot_df[\"Total Mass\"].max()\n    # Create logarithmically spaced bins\n    mass_bins = np.logspace(np.log10(mass_min), np.log10(mass_max), 31)  # 31 edges = 30 bins\n    axes[0].hist(plot_df[\"Total Mass\"], bins=mass_bins, edgecolor=\"black\", alpha=0.7)\n    axes[0].set_xscale(\"log\")\n    axes[0].set_xlabel(\"Total Mass (kg)\")\n    axes[0].set_ylabel(\"Frequency\")\n    axes[0].set_title(\"Distribution of Total Mass\")  # Subplot title - keep it\n    axes[0].grid(True, alpha=0.3)\n\n    # Histogram of Total Volume - use log-spaced bins for constant bin size on log scale\n    vol_min = plot_df[\"Total Volume\"].min()\n    vol_max = plot_df[\"Total Volume\"].max()\n    # Create logarithmically spaced bins\n    vol_bins = np.logspace(np.log10(vol_min), np.log10(vol_max), 31)  # 31 edges = 30 bins\n    axes[1].hist(plot_df[\"Total Volume\"], bins=vol_bins, edgecolor=\"black\", alpha=0.7)\n    axes[1].set_xscale(\"log\")\n    axes[1].set_xlabel(\"Total Volume (m$^3$)\")\n    axes[1].set_ylabel(\"Frequency\")\n    axes[1].set_title(\"Distribution of Total Volume\")  # Subplot title - keep it\n    axes[1].grid(True, alpha=0.3)\n\n    # Scatter: Volume vs Mass\n    axes[2].scatter(plot_df[\"Total Volume\"], plot_df[\"Total Mass\"], alpha=0.6, s=30, edgecolors=\"black\", linewidth=0.5)\n    axes[2].set_xscale(\"log\")\n    axes[2].set_yscale(\"log\")\n    axes[2].set_xlabel(\"Total Volume (m$^3$)\")\n    axes[2].set_ylabel(\"Total Mass (kg)\")\n    axes[2].set_title(\"Volume vs Mass (Density Analysis)\")  # Subplot title - keep it\n\n    # Add reference line for water density (1000 kg m$^{-3}$)\n    vol_range = [plot_df[\"Total Volume\"].min(), plot_df[\"Total Volume\"].max()]\n    mass_water = [v * 1000 for v in vol_range]\n    axes[2].plot(vol_range, mass_water, \"r--\", linewidth=2, label=\"Water Density (1000 kg m$^{-3}$)\")\n    axes[2].legend()\n    axes[2].grid(True, alpha=0.3)\n\n    base_title = \"tissue mass/volume distribution\"\n    title_full = self._get_title_with_phantom(base_title, scenario_name)\n    # Don't set suptitle - will be in caption file\n    plt.tight_layout()\n\n    filename_base = f\"distribution_mass_volume_{scenario_name or 'all'}\"\n    phantom_name_formatted = self.phantom_name.capitalize() if self.phantom_name else \"the phantom\"\n    caption = f\"The distribution analysis shows histograms of tissue total mass and total volume (log scale), and a scatter plot of volume vs mass with water density reference line for the {self._format_scenario_name(scenario_name) if scenario_name else 'all scenarios'} scenario for {phantom_name_formatted}.\"\n    filename = self._save_figure(fig, \"tissue_analysis\", filename_base, title=title_full, caption=caption, dpi=300)\n\n    # Save CSV data\n    csv_data = plot_df[[\"tissue\", \"Total Mass\", \"Total Volume\"]].copy()\n    self._save_csv_data(csv_data, \"tissue_analysis\", filename_base)\n    logging.getLogger(\"progress\").info(\n        f\"  - Generated mass/volume distribution: {filename}\",\n        extra={\"log_type\": \"success\"},\n    )\n</code></pre>"},{"location":"reference/api_reference/#gui-components","title":"GUI Components","text":"<p>Graphical user interface for monitoring simulation progress.</p>"},{"location":"reference/api_reference/#analysis-gui","title":"Analysis Gui","text":""},{"location":"reference/api_reference/#goliat.gui.analysis_gui.SignalingLogHandler","title":"goliat.gui.analysis_gui.SignalingLogHandler","text":"<pre><code>SignalingLogHandler()\n</code></pre> <p>               Bases: <code>Handler</code>, <code>QObject</code></p> <p>Log handler that emits Qt signals for log records.</p> Source code in <code>goliat/gui/analysis_gui.py</code> <pre><code>def __init__(self):\n    \"\"\"Dual init for Handler and QObject.\"\"\"\n    logging.Handler.__init__(self)\n    QObject.__init__(self)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.analysis_gui.SignalingLogHandler-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.analysis_gui.SignalingLogHandler.emit","title":"emit","text":"<pre><code>emit(record)\n</code></pre> <p>Format record and emit as Qt signal.</p> Source code in <code>goliat/gui/analysis_gui.py</code> <pre><code>def emit(self, record):\n    \"\"\"Format record and emit as Qt signal.\"\"\"\n    try:\n        msg = self.format(record)\n        # Extract log_type for coloring (defaults to 'default')\n        log_type = getattr(record, \"log_type\", \"default\")\n        self.log_signal.emit(msg, record.levelname, log_type)\n    except Exception:\n        self.handleError(record)\n</code></pre>"},{"location":"reference/api_reference/#progress-gui","title":"Progress Gui","text":""},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI","title":"goliat.gui.progress_gui.ProgressGUI","text":"<pre><code>ProgressGUI(queue: Queue, stop_event: Event, process: Process, init_window_title: str = '', use_web: bool = True, auto_close: bool = False)\n</code></pre> <p>               Bases: <code>QWidget</code></p> <p>Main GUI window for monitoring simulation progress.</p> <p>Provides real-time progress tracking via progress bars, ETA estimation, and status logs. Runs in the main process and communicates with worker process through a multiprocessing queue.</p> <p>The GUI architecture: - Main window runs in main process, worker runs in separate process - Communication via multiprocessing.Queue for thread-safe message passing - QueueHandler polls queue every 100ms and updates UI - Multiple timers handle different update frequencies (queue, clock, graphs)</p> <p>Features: - Overall progress bar (weighted across all simulations) - Stage progress bar (current phase: setup/run/extract) - Real-time ETA calculation based on profiler estimates - Status log with color-coded messages - Timings table showing execution statistics - Pie charts showing phase/subtask breakdowns - Time series plots for progress and ETA trends - System tray integration for background operation</p> <p>Initializes data manager, status manager, UI builder, timers, and queue handler. Sets up Qt timers for periodic updates (queue polling, clock updates, graph refreshes).</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>Queue for receiving messages from worker process.</p> required <code>stop_event</code> <code>Event</code> <p>Event to signal termination to worker process.</p> required <code>process</code> <code>Process</code> <p>Worker process running the study.</p> required <code>init_window_title</code> <code>str</code> <p>Initial window title.</p> <code>''</code> <code>use_web</code> <code>bool</code> <p>Whether to enable web bridge for remote monitoring.</p> <code>True</code> <code>auto_close</code> <code>bool</code> <p>Whether to automatically close GUI on successful completion.</p> <code>False</code> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def __init__(\n    self,\n    queue: Queue,\n    stop_event: Event,\n    process: Process,\n    init_window_title: str = \"\",\n    use_web: bool = True,\n    auto_close: bool = False,\n) -&gt; None:\n    \"\"\"Sets up the GUI window and all components.\n\n    Initializes data manager, status manager, UI builder, timers, and\n    queue handler. Sets up Qt timers for periodic updates (queue polling,\n    clock updates, graph refreshes).\n\n    Args:\n        queue: Queue for receiving messages from worker process.\n        stop_event: Event to signal termination to worker process.\n        process: Worker process running the study.\n        init_window_title: Initial window title.\n        use_web: Whether to enable web bridge for remote monitoring.\n        auto_close: Whether to automatically close GUI on successful completion.\n    \"\"\"\n    super().__init__()\n    self.queue: Queue = queue\n    self.stop_event: Event = stop_event\n    self.process: Process = process\n    self.start_time: float = time.monotonic()\n    self.progress_logger: logging.Logger = logging.getLogger(\"progress\")\n    self.verbose_logger: logging.Logger = logging.getLogger(\"verbose\")\n    self.init_window_title: str = init_window_title\n    self.auto_close: bool = auto_close\n    self.DEBUG: bool = False\n    self.study_is_finished: bool = False\n    self.study_had_errors: bool = False\n    self.child_exit_code: int = 0  # Exit code from child process (42 = memory error)\n\n    self.total_simulations: int = 0\n    self.current_simulation_count: int = 0\n\n    # Initialize components\n    self._initialize_components()\n\n    # Auto-detect machine ID\n    self.machine_id = MachineIdDetector.detect(self.verbose_logger)\n    self.server_url = \"https://monitor.goliat.waves-ugent.be\"\n\n    # Build UI\n    UIBuilder.build(self, self.status_manager)\n\n    # Initialize managers\n    self.web_bridge_manager = WebBridgeManager(self, self.server_url, self.machine_id, use_web=use_web)\n    self.progress_manager = ProgressManager(self)\n    self.clock_manager = ClockManager(self)\n    self.utilization_manager = UtilizationManager(self)\n    self.graph_manager = GraphManager(self)\n\n    # Initialize web GUI bridge after UI is built (so we can set callback)\n    self.web_bridge_manager.initialize()\n\n    # Initialize animation and other components\n    self._initialize_animation()\n    self._initialize_managers()\n    self._setup_timers()\n    self._initialize_system_monitoring()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.update_overall_progress","title":"update_overall_progress","text":"<pre><code>update_overall_progress(current_step: float, total_steps: int) -&gt; None\n</code></pre> <p>Updates overall progress bar across all simulations.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_overall_progress(self, current_step: float, total_steps: int) -&gt; None:\n    \"\"\"Updates overall progress bar across all simulations.\"\"\"\n    self.progress_manager.update_overall(current_step, total_steps)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.update_stage_progress","title":"update_stage_progress","text":"<pre><code>update_stage_progress(stage_name: str, current_step: int, total_steps: int, sub_stage: str = '') -&gt; None\n</code></pre> <p>Updates stage-specific progress bar and label.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_stage_progress(self, stage_name: str, current_step: int, total_steps: int, sub_stage: str = \"\") -&gt; None:\n    \"\"\"Updates stage-specific progress bar and label.\"\"\"\n    self.progress_manager.update_stage(stage_name, current_step, total_steps, sub_stage)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.start_stage_animation","title":"start_stage_animation","text":"<pre><code>start_stage_animation(estimated_duration: float, end_step: int) -&gt; None\n</code></pre> <p>Starts smooth animated progress bar for a stage.</p> <p>Instead of jumping to discrete progress values, animates smoothly over the estimated duration. This provides visual feedback during long-running tasks where progress updates are infrequent.</p> <p>The animation uses linear interpolation between current value and target (always 100% = 1000). Updates every 50ms via Qt timer.</p> <p>Parameters:</p> Name Type Description Default <code>estimated_duration</code> <code>float</code> <p>Estimated task duration in seconds (from profiler).</p> required <code>end_step</code> <code>int</code> <p>Target step value (unused, always animates to 100%).</p> required Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def start_stage_animation(self, estimated_duration: float, end_step: int) -&gt; None:\n    \"\"\"Starts smooth animated progress bar for a stage.\n\n    Instead of jumping to discrete progress values, animates smoothly over\n    the estimated duration. This provides visual feedback during long-running\n    tasks where progress updates are infrequent.\n\n    The animation uses linear interpolation between current value and target\n    (always 100% = 1000). Updates every 50ms via Qt timer.\n\n    Args:\n        estimated_duration: Estimated task duration in seconds (from profiler).\n        end_step: Target step value (unused, always animates to 100%).\n    \"\"\"\n    if self.DEBUG:\n        self.update_status(f\"DEBUG: start_stage_animation received: duration={estimated_duration:.2f}s, end_step={end_step}\")\n    self.progress_animation.start(estimated_duration, end_step)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.end_stage_animation","title":"end_stage_animation","text":"<pre><code>end_stage_animation() -&gt; None\n</code></pre> <p>Stops stage progress bar animation.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def end_stage_animation(self) -&gt; None:\n    \"\"\"Stops stage progress bar animation.\"\"\"\n    self.progress_animation.stop()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.update_animation","title":"update_animation","text":"<pre><code>update_animation() -&gt; None\n</code></pre> <p>Updates progress bar animation frame and syncs overall progress.</p> <p>Called every 50ms by Qt timer when animation is active. Calculates current progress based on elapsed time and estimated duration, then updates stage progress bar. Also syncs overall progress bar using weighted progress calculation from profiler.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_animation(self) -&gt; None:\n    \"\"\"Updates progress bar animation frame and syncs overall progress.\n\n    Called every 50ms by Qt timer when animation is active. Calculates\n    current progress based on elapsed time and estimated duration, then\n    updates stage progress bar. Also syncs overall progress bar using\n    weighted progress calculation from profiler.\n    \"\"\"\n    self.progress_animation.update()\n\n    # Sync overall progress based on stage animation\n    if self.profiler and self.profiler.current_phase:\n        current_value = self.stage_progress_bar.value()\n        percent = (current_value / 1000) * 100\n        progress = self.profiler.get_weighted_progress(self.profiler.current_phase, percent / 100.0)\n        self.progress_manager.update_overall(progress, 100)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.update_simulation_details","title":"update_simulation_details","text":"<pre><code>update_simulation_details(sim_count: int, total_sims: int, details: str) -&gt; None\n</code></pre> <p>Updates simulation counter and details labels.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_simulation_details(self, sim_count: int, total_sims: int, details: str) -&gt; None:\n    \"\"\"Updates simulation counter and details labels.\"\"\"\n    self.progress_manager.update_simulation_details(sim_count, total_sims, details)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.update_status","title":"update_status","text":"<pre><code>update_status(message: str, log_type: str = 'default') -&gt; None\n</code></pre> <p>Appends message to status log with color formatting.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message text.</p> required <code>log_type</code> <code>str</code> <p>Log type for color coding.</p> <code>'default'</code> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_status(self, message: str, log_type: str = \"default\") -&gt; None:\n    \"\"\"Appends message to status log with color formatting.\n\n    Args:\n        message: Message text.\n        log_type: Log type for color coding.\n    \"\"\"\n    self.status_manager.record_log(log_type)\n    # Update error counter with current web status\n    web_connected = False\n    if (\n        hasattr(self, \"web_bridge_manager\")\n        and self.web_bridge_manager.web_bridge\n        and hasattr(self.web_bridge_manager.web_bridge, \"is_connected\")\n    ):\n        web_connected = self.web_bridge_manager.web_bridge.is_connected\n    self.error_counter_label.setText(self.status_manager.get_error_summary(web_connected=web_connected))\n    formatted_message = self.status_manager.format_message(message, log_type)\n    self.status_text.append(formatted_message)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.update_utilization","title":"update_utilization","text":"<pre><code>update_utilization() -&gt; None\n</code></pre> <p>Updates CPU, RAM, and GPU utilization displays.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_utilization(self) -&gt; None:\n    \"\"\"Updates CPU, RAM, and GPU utilization displays.\"\"\"\n    self.utilization_manager.update()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.update_utilization_plot","title":"update_utilization_plot","text":"<pre><code>update_utilization_plot() -&gt; None\n</code></pre> <p>Updates the system utilization plot with current values.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_utilization_plot(self) -&gt; None:\n    \"\"\"Updates the system utilization plot with current values.\"\"\"\n    self.utilization_manager.update_plot()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.update_clock","title":"update_clock","text":"<pre><code>update_clock() -&gt; None\n</code></pre> <p>Updates elapsed time, ETA labels, and window title.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_clock(self) -&gt; None:\n    \"\"\"Updates elapsed time, ETA labels, and window title.\"\"\"\n    self.clock_manager.update()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.update_graphs","title":"update_graphs","text":"<pre><code>update_graphs() -&gt; None\n</code></pre> <p>Updates time remaining and overall progress graphs.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def update_graphs(self) -&gt; None:\n    \"\"\"Updates time remaining and overall progress graphs.\"\"\"\n    self.graph_manager.update()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.hide_to_tray","title":"hide_to_tray","text":"<pre><code>hide_to_tray() -&gt; None\n</code></pre> <p>Hides main window and shows system tray icon.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def hide_to_tray(self) -&gt; None:\n    \"\"\"Hides main window and shows system tray icon.\"\"\"\n    self.hide()\n    self.tray_manager.show()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.show_from_tray","title":"show_from_tray","text":"<pre><code>show_from_tray() -&gt; None\n</code></pre> <p>Shows main window from system tray.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def show_from_tray(self) -&gt; None:\n    \"\"\"Shows main window from system tray.\"\"\"\n    self.show()\n    self.tray_manager.hide()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.stop_study","title":"stop_study","text":"<pre><code>stop_study() -&gt; None\n</code></pre> <p>Sends stop signal to worker process.</p> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def stop_study(self) -&gt; None:\n    \"\"\"Sends stop signal to worker process.\"\"\"\n    message = \"--- Sending stop signal to study process ---\"\n    self.progress_logger.info(message, extra={\"log_type\": \"warning\"})\n    self.verbose_logger.info(message, extra={\"log_type\": \"warning\"})\n    self.update_status(message, log_type=\"warning\")\n    self.stop_button.setEnabled(False)\n    self.tray_button.setEnabled(False)\n    self.stop_event.set()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.study_finished","title":"study_finished","text":"<pre><code>study_finished(error: bool = False, memory_error: bool = False) -&gt; None\n</code></pre> <p>Handles study completion, stopping timers and updating UI.</p> <p>Called when worker process signals completion. Stops all timers, updates final progress to 100%, sets stage label, and schedules window auto-close after 3 seconds (if no errors).</p> <p>For memory errors (exit code 42), the GUI auto-closes even with errors so the batch worker can retry the assignment.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>bool</code> <p>Whether study finished with errors (affects UI styling).</p> <code>False</code> <code>memory_error</code> <code>bool</code> <p>Whether this was a memory error (exit code 42).          Memory errors auto-close to allow batch retry.</p> <code>False</code> Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def study_finished(self, error: bool = False, memory_error: bool = False) -&gt; None:\n    \"\"\"Handles study completion, stopping timers and updating UI.\n\n    Called when worker process signals completion. Stops all timers,\n    updates final progress to 100%, sets stage label, and schedules\n    window auto-close after 3 seconds (if no errors).\n\n    For memory errors (exit code 42), the GUI auto-closes even with errors\n    so the batch worker can retry the assignment.\n\n    Args:\n        error: Whether study finished with errors (affects UI styling).\n        memory_error: Whether this was a memory error (exit code 42).\n                     Memory errors auto-close to allow batch retry.\n    \"\"\"\n    self.study_is_finished = True\n    self.study_had_errors = error\n    self.clock_timer.stop()\n    self.queue_timer.stop()\n    self.graph_timer.stop()\n    self.utilization_timer.stop()\n    self.utilization_plot_timer.stop()\n    self.progress_sync_timer.stop()\n    self.progress_animation.stop()\n    if not error:\n        self.update_status(\"--- Study Finished ---\", log_type=\"success\")\n        self.overall_progress_bar.setValue(self.overall_progress_bar.maximum())\n        self.stage_label.setText(\"Finished\")\n    elif memory_error:\n        self.update_status(\"--- Study Stopped: Memory Error (will retry) ---\", log_type=\"fatal\")\n        self.stage_label.setText(\"Memory Error\")\n    else:\n        self.update_status(\"--- Study Finished with Errors ---\", log_type=\"fatal\")\n        self.stage_label.setText(\"Error\")\n\n    self.stop_button.setEnabled(False)\n    self.tray_button.setEnabled(False)\n\n    # Send final status update to web before stopping bridge\n    self.web_bridge_manager.send_finished(error)\n\n    self.update_clock()  # Final title update\n\n    # Instead of auto-closing, show a message that user can close the window\n    if not error:\n        self.progress_logger.info(\"All done! You may close this window now.\", extra={\"log_type\": \"success\"})\n        self.update_status(\"\\n\u2713 All done! You may close this window now.\", log_type=\"success\")\n        # Auto-close if enabled (used by batch worker mode)\n        if self.auto_close:\n            self.progress_logger.info(\"Auto-closing GUI in 2 seconds...\", extra={\"log_type\": \"info\"})\n            from PySide6.QtCore import QTimer as _QTimer\n\n            _QTimer.singleShot(2000, self.close)\n    elif memory_error:\n        # Memory errors should ALWAYS auto-close so the process can be restarted to free GPU memory.\n        # This is required for both batch worker retry logic and persistent mode retry logic.\n        # Unlike normal errors, memory errors cannot be resolved without a full process restart.\n        self.progress_logger.info(\"Memory error detected. Auto-closing for retry...\", extra={\"log_type\": \"warning\"})\n        self.update_status(\"\\n\u26a0 Memory error detected. Auto-closing for retry...\", log_type=\"warning\")\n        from PySide6.QtCore import QTimer as _QTimer\n\n        _QTimer.singleShot(2000, self.close)\n    else:\n        self.progress_logger.info(\"Finished with errors. You may close this window now.\", extra={\"log_type\": \"warning\"})\n        self.update_status(\"\\n\u2713 Finished with errors. You may close this window now.\", log_type=\"warning\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.progress_gui.ProgressGUI.closeEvent","title":"closeEvent","text":"<pre><code>closeEvent(event: Any) -&gt; None\n</code></pre> <p>Handles window close event, ensuring worker process termination.</p> <p>Parameters:</p> Name Type Description Default <code>event</code> <code>Any</code> <p>Close event.</p> required Source code in <code>goliat/gui/progress_gui.py</code> <pre><code>def closeEvent(self, event: Any) -&gt; None:\n    \"\"\"Handles window close event, ensuring worker process termination.\n\n    Args:\n        event: Close event.\n    \"\"\"\n    if self.tray_manager.is_visible():\n        self.tray_manager.hide()\n\n    if self.process.is_alive():\n        self.progress_logger.info(\"Terminating study process...\", extra={\"log_type\": \"warning\"})\n        self.process.terminate()\n        self.process.join(timeout=5)\n\n    # Stop web bridge if enabled\n    self.web_bridge_manager.stop()\n\n    shutdown_loggers()\n    event.accept()\n</code></pre>"},{"location":"reference/api_reference/#queue-gui","title":"Queue Gui","text":""},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI","title":"goliat.gui.queue_gui.QueueGUI","text":"<pre><code>QueueGUI(queue: Queue, stop_event: Event, profiler: Profiler, progress_logger: Logger, verbose_logger: Logger)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Proxy for ProgressGUI that operates in a separate process.</p> <p>Mimics the ProgressGUI interface but routes all calls through a multiprocessing queue, enabling thread-safe communication between worker and GUI processes. All methods serialize their arguments and send them via queue for the GUI process to handle.</p> <p>Parameters:</p> Name Type Description Default <code>queue</code> <code>Queue</code> <p>Multiprocessing queue for IPC.</p> required <code>stop_event</code> <code>Event</code> <p>Event flagging user cancellation.</p> required <code>profiler</code> <code>Profiler</code> <p>Profiler for ETA calculations.</p> required <code>progress_logger</code> <code>Logger</code> <p>Logger for progress-level messages.</p> required <code>verbose_logger</code> <code>Logger</code> <p>Logger for detailed messages.</p> required Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def __init__(\n    self,\n    queue: Queue,\n    stop_event: Event,\n    profiler: \"Profiler\",\n    progress_logger: Logger,\n    verbose_logger: Logger,\n) -&gt; None:\n    \"\"\"Sets up the queue GUI proxy.\n\n    Args:\n        queue: Multiprocessing queue for IPC.\n        stop_event: Event flagging user cancellation.\n        profiler: Profiler for ETA calculations.\n        progress_logger: Logger for progress-level messages.\n        verbose_logger: Logger for detailed messages.\n    \"\"\"\n    self.queue: Queue = queue\n    self.stop_event: Event = stop_event\n    self.profiler: \"Profiler\" = profiler\n    self.progress_logger: Logger = progress_logger\n    self.verbose_logger: Logger = verbose_logger\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI.log","title":"log","text":"<pre><code>log(message: str, level: str = 'verbose', log_type: str = 'default') -&gt; None\n</code></pre> <p>Sends a log message to the GUI via queue.</p> <p>All messages are forwarded through the queue for terminal output (S4L 9.2 fix). Progress messages update the GUI status box; verbose messages only print to terminal.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Log message text.</p> required <code>level</code> <code>str</code> <p>Log level ('progress' or 'verbose').</p> <code>'verbose'</code> <code>log_type</code> <code>str</code> <p>Type for color coding in GUI.</p> <code>'default'</code> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def log(self, message: str, level: str = \"verbose\", log_type: str = \"default\") -&gt; None:\n    \"\"\"Sends a log message to the GUI via queue.\n\n    All messages are forwarded through the queue for terminal output (S4L 9.2 fix).\n    Progress messages update the GUI status box; verbose messages only print to terminal.\n\n    Args:\n        message: Log message text.\n        level: Log level ('progress' or 'verbose').\n        log_type: Type for color coding in GUI.\n    \"\"\"\n    import time\n\n    # Use monotonic time with a small increment to ensure unique timestamps\n    # even for messages sent in rapid succession\n    if not hasattr(self, \"_last_timestamp\"):\n        self._last_timestamp = 0.0\n    current_time = time.time()\n    # Ensure timestamp is always increasing, even if system clock jumps backward\n    if current_time &lt;= self._last_timestamp:\n        self._last_timestamp += 0.000001  # 1 microsecond increment\n    else:\n        self._last_timestamp = current_time\n\n    # Determine message type based on level\n    # 'status' messages update GUI status box AND print to terminal\n    # 'terminal_only' messages only print to terminal (for verbose logs)\n    msg_type = \"status\" if level == \"progress\" else \"terminal_only\"\n\n    self.queue.put(\n        {\n            \"type\": msg_type,\n            \"message\": message,\n            \"log_type\": log_type,\n            \"timestamp\": self._last_timestamp,\n        }\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI.update_simulation_details","title":"update_simulation_details","text":"<pre><code>update_simulation_details(sim_count: int, total_sims: int, details: str) -&gt; None\n</code></pre> <p>Sends current simulation case details to GUI.</p> <p>Parameters:</p> Name Type Description Default <code>sim_count</code> <code>int</code> <p>Current simulation number (1-indexed).</p> required <code>total_sims</code> <code>int</code> <p>Total simulations in study.</p> required <code>details</code> <code>str</code> <p>Human-readable description of current case.</p> required Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def update_simulation_details(self, sim_count: int, total_sims: int, details: str) -&gt; None:\n    \"\"\"Sends current simulation case details to GUI.\n\n    Args:\n        sim_count: Current simulation number (1-indexed).\n        total_sims: Total simulations in study.\n        details: Human-readable description of current case.\n    \"\"\"\n    self.queue.put(\n        {\n            \"type\": \"sim_details\",\n            \"count\": sim_count,\n            \"total\": total_sims,\n            \"details\": details,\n        }\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI.update_overall_progress","title":"update_overall_progress","text":"<pre><code>update_overall_progress(current_step: float, total_steps: int) -&gt; None\n</code></pre> <p>Updates overall study progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>current_step</code> <code>float</code> <p>Current step number or percentage (0-100).</p> required <code>total_steps</code> <code>int</code> <p>Total steps in study.</p> required Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def update_overall_progress(self, current_step: float, total_steps: int) -&gt; None:\n    \"\"\"Updates overall study progress bar.\n\n    Args:\n        current_step: Current step number or percentage (0-100).\n        total_steps: Total steps in study.\n    \"\"\"\n    self.queue.put({\"type\": \"overall_progress\", \"current\": current_step, \"total\": total_steps})\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI.update_stage_progress","title":"update_stage_progress","text":"<pre><code>update_stage_progress(stage_name: str, current_step: int, total_steps: int, sub_stage: str = '') -&gt; None\n</code></pre> <p>Updates progress for a specific stage (setup/run/extract).</p> <p>Parameters:</p> Name Type Description Default <code>stage_name</code> <code>str</code> <p>Stage name like 'Setup' or 'Running Simulation'.</p> required <code>current_step</code> <code>int</code> <p>Current step within stage.</p> required <code>total_steps</code> <code>int</code> <p>Total steps for stage.</p> required <code>sub_stage</code> <code>str</code> <p>Optional sub-stage description.</p> <code>''</code> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def update_stage_progress(self, stage_name: str, current_step: int, total_steps: int, sub_stage: str = \"\") -&gt; None:\n    \"\"\"Updates progress for a specific stage (setup/run/extract).\n\n    Args:\n        stage_name: Stage name like 'Setup' or 'Running Simulation'.\n        current_step: Current step within stage.\n        total_steps: Total steps for stage.\n        sub_stage: Optional sub-stage description.\n    \"\"\"\n    self.queue.put(\n        {\n            \"type\": \"stage_progress\",\n            \"name\": stage_name,\n            \"current\": current_step,\n            \"total\": total_steps,\n            \"sub_stage\": sub_stage,\n        }\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI.start_stage_animation","title":"start_stage_animation","text":"<pre><code>start_stage_animation(task_name: str, end_value: int) -&gt; None\n</code></pre> <p>Starts animated progress bar for a stage.</p> <p>Looks up time estimate from profiler and starts animation that progresses toward end_value over that duration.</p> <p>Parameters:</p> Name Type Description Default <code>task_name</code> <code>str</code> <p>Task name ('setup', 'run', 'extract', or subtask name).</p> required <code>end_value</code> <code>int</code> <p>Target progress value (typically 100).</p> required Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def start_stage_animation(self, task_name: str, end_value: int) -&gt; None:\n    \"\"\"Starts animated progress bar for a stage.\n\n    Looks up time estimate from profiler and starts animation that\n    progresses toward end_value over that duration.\n\n    Args:\n        task_name: Task name ('setup', 'run', 'extract', or subtask name).\n        end_value: Target progress value (typically 100).\n    \"\"\"\n    if task_name in [\"setup\", \"run\", \"extract\"]:\n        estimate = self.profiler.profiling_config.get(f\"avg_{task_name}_time\", 60)\n    else:\n        estimate = self.profiler.get_subtask_estimate(task_name)\n    self.queue.put({\"type\": \"start_animation\", \"estimate\": estimate, \"end_value\": end_value})\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI.end_stage_animation","title":"end_stage_animation","text":"<pre><code>end_stage_animation() -&gt; None\n</code></pre> <p>Stops the current animated progress bar.</p> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def end_stage_animation(self) -&gt; None:\n    \"\"\"Stops the current animated progress bar.\"\"\"\n    self.queue.put({\"type\": \"end_animation\"})\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI.update_profiler","title":"update_profiler","text":"<pre><code>update_profiler() -&gt; None\n</code></pre> <p>Sends profiler state to GUI for ETA display.</p> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def update_profiler(self) -&gt; None:\n    \"\"\"Sends profiler state to GUI for ETA display.\"\"\"\n    self.queue.put({\"type\": \"profiler_update\", \"profiler\": self.profiler})\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI.process_events","title":"process_events","text":"<pre><code>process_events() -&gt; None\n</code></pre> <p>No-op for interface compatibility with ProgressGUI.</p> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def process_events(self) -&gt; None:\n    \"\"\"No-op for interface compatibility with ProgressGUI.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.queue_gui.QueueGUI.is_stopped","title":"is_stopped","text":"<pre><code>is_stopped() -&gt; bool\n</code></pre> <p>Checks if user requested cancellation via GUI.</p> Source code in <code>goliat/gui/queue_gui.py</code> <pre><code>def is_stopped(self) -&gt; bool:\n    \"\"\"Checks if user requested cancellation via GUI.\"\"\"\n    return self.stop_event.is_set()\n</code></pre>"},{"location":"reference/api_reference/#components","title":"Components","text":""},{"location":"reference/api_reference/#goliat.gui.components.clock_manager.ClockManager","title":"goliat.gui.components.clock_manager.ClockManager","text":"<pre><code>ClockManager(gui: ProgressGUI)\n</code></pre> <p>Manages elapsed time, ETA, and window title updates.</p> <p>Parameters:</p> Name Type Description Default <code>gui</code> <code>ProgressGUI</code> <p>ProgressGUI instance.</p> required Source code in <code>goliat/gui/components/clock_manager.py</code> <pre><code>def __init__(self, gui: \"ProgressGUI\") -&gt; None:\n    \"\"\"Store GUI reference for timer updates.\n\n    Args:\n        gui: ProgressGUI instance.\n    \"\"\"\n    self.gui = gui\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.clock_manager.ClockManager-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.clock_manager.ClockManager.update","title":"update","text":"<pre><code>update() -&gt; None\n</code></pre> <p>Updates elapsed time, ETA labels, and window title.</p> <p>Called every second by Qt timer. Calculates elapsed time from start, gets ETA from profiler (if available), and updates window title with current status and progress percentage.</p> <p>The window title shows: [progress%] GOLIAT | Sim X/Y | Status where Status is 'Booting...', 'Running...', or 'Finished'.</p> Source code in <code>goliat/gui/components/clock_manager.py</code> <pre><code>def update(self) -&gt; None:\n    \"\"\"Updates elapsed time, ETA labels, and window title.\n\n    Called every second by Qt timer. Calculates elapsed time from start,\n    gets ETA from profiler (if available), and updates window title with\n    current status and progress percentage.\n\n    The window title shows: [progress%] GOLIAT | Sim X/Y | Status\n    where Status is 'Booting...', 'Running...', or 'Finished'.\n    \"\"\"\n    elapsed_sec = time.monotonic() - self.gui.start_time\n    self.gui.elapsed_label.setText(f\"Elapsed: {format_time(elapsed_sec)}\")\n\n    eta_sec: Optional[float] = None\n    if self.gui.profiler and self.gui.profiler.current_phase:\n        current_stage_progress_ratio = self.gui.stage_progress_bar.value() / 1000.0\n        eta_sec = self.gui.profiler.get_time_remaining(current_stage_progress=current_stage_progress_ratio)\n\n        if eta_sec is not None:\n            time_remaining_str = format_time(eta_sec)\n            self.gui.eta_label.setText(f\"Time Remaining: {time_remaining_str}\")\n        else:\n            self.gui.eta_label.setText(\"Time Remaining: N/A\")\n    else:\n        self.gui.eta_label.setText(\"Time Remaining: N/A\")\n\n    # Update window title with status\n    progress_percent = max(0, self.gui.overall_progress_bar.value() / 100.0)\n    title = self.gui.init_window_title\n    if title:\n        title += \" | \"\n    title += f\"[{progress_percent:.2f}%] GOLIAT\"\n    if self.gui.total_simulations &gt; 0:\n        title += f\" | Sim {self.gui.current_simulation_count}/{self.gui.total_simulations}\"\n\n    # Determine status based on actual activity\n    if self.gui.study_is_finished:\n        status = \"Finished\" if not self.gui.study_had_errors else \"Finished with Errors\"\n    elif progress_percent &gt; 0 or self.gui.current_simulation_count &gt; 0:\n        status = \"Running...\"\n    else:\n        status = \"Booting...\"\n\n    title += f\" | {status}\"\n    self.gui.setWindowTitle(title)\n\n    # Update web connection status indicator periodically\n    if hasattr(self.gui, \"web_bridge_manager\") and self.gui.web_bridge_manager and self.gui.web_bridge_manager.web_bridge:\n        if hasattr(self.gui.web_bridge_manager.web_bridge, \"is_connected\"):\n            if hasattr(self.gui, \"error_counter_label\") and hasattr(self.gui, \"status_manager\"):\n                self.gui._update_web_status(self.gui.web_bridge_manager.web_bridge.is_connected)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.data_manager.DataManager","title":"goliat.gui.components.data_manager.DataManager","text":"<pre><code>DataManager(data_dir: str, verbose_logger: Logger)\n</code></pre> <p>Manages CSV data files for time remaining and overall progress tracking.</p> <p>Writes timestamped data points to CSV files for plotting and analysis. Automatically cleans up old files (keeps last 50) to prevent disk bloat. Creates unique session files using timestamp and process hash.</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str</code> <p>Directory where data files will be stored.</p> required <code>verbose_logger</code> <code>Logger</code> <p>Logger for verbose messages.</p> required Source code in <code>goliat/gui/components/data_manager.py</code> <pre><code>def __init__(self, data_dir: str, verbose_logger: Logger) -&gt; None:\n    \"\"\"Create session-specific CSV files for progress tracking.\n\n    Args:\n        data_dir: Directory where data files will be stored.\n        verbose_logger: Logger for verbose messages.\n    \"\"\"\n    self.data_dir: str = data_dir\n    self.verbose_logger: Logger = verbose_logger\n    self.session_hash: str = hashlib.md5(f\"{time.time()}_{os.getpid()}\".encode()).hexdigest()[:8]\n    session_timestamp = datetime.now().strftime(\"%d-%m_%H-%M-%S\")\n\n    # Cleanup old CSV files before creating new ones\n    self._cleanup_old_data_files()\n\n    self.time_remaining_file: str = os.path.join(self.data_dir, f\"time_remaining_{session_timestamp}_{self.session_hash}.csv\")\n    self.overall_progress_file: str = os.path.join(self.data_dir, f\"overall_progress_{session_timestamp}_{self.session_hash}.csv\")\n    self.system_utilization_file: str = os.path.join(self.data_dir, f\"system_utilization_{session_timestamp}_{self.session_hash}.csv\")\n\n    # Initialize data files\n    self._initialize_files()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.data_manager.DataManager-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.data_manager.DataManager.write_time_remaining","title":"write_time_remaining","text":"<pre><code>write_time_remaining(hours_remaining: float) -&gt; None\n</code></pre> <p>Appends a time remaining data point to CSV.</p> <p>Writes timestamp and hours remaining to session-specific CSV file. Used for plotting ETA trends over time.</p> <p>Parameters:</p> Name Type Description Default <code>hours_remaining</code> <code>float</code> <p>Estimated hours remaining as float.</p> required Source code in <code>goliat/gui/components/data_manager.py</code> <pre><code>def write_time_remaining(self, hours_remaining: float) -&gt; None:\n    \"\"\"Appends a time remaining data point to CSV.\n\n    Writes timestamp and hours remaining to session-specific CSV file.\n    Used for plotting ETA trends over time.\n\n    Args:\n        hours_remaining: Estimated hours remaining as float.\n    \"\"\"\n    self._write_csv_row(self.time_remaining_file, hours_remaining, \"time remaining\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.data_manager.DataManager.write_overall_progress","title":"write_overall_progress","text":"<pre><code>write_overall_progress(progress_percent: float) -&gt; None\n</code></pre> <p>Appends an overall progress data point to CSV.</p> <p>Writes timestamp and progress percentage to session-specific CSV file. Used for plotting progress trends over time.</p> <p>Parameters:</p> Name Type Description Default <code>progress_percent</code> <code>float</code> <p>Overall progress percentage (0-100).</p> required Source code in <code>goliat/gui/components/data_manager.py</code> <pre><code>def write_overall_progress(self, progress_percent: float) -&gt; None:\n    \"\"\"Appends an overall progress data point to CSV.\n\n    Writes timestamp and progress percentage to session-specific CSV file.\n    Used for plotting progress trends over time.\n\n    Args:\n        progress_percent: Overall progress percentage (0-100).\n    \"\"\"\n    self._write_csv_row(self.overall_progress_file, progress_percent, \"overall progress\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.data_manager.DataManager.write_system_utilization","title":"write_system_utilization","text":"<pre><code>write_system_utilization(cpu_percent: float, ram_percent: float, gpu_percent: Optional[float] = None, gpu_vram_percent: Optional[float] = None, disk_read_mbps: Optional[float] = None, disk_write_mbps: Optional[float] = None) -&gt; None\n</code></pre> <p>Appends a system utilization data point to CSV.</p> <p>Writes timestamp and CPU, RAM, GPU utilization, GPU VRAM, and disk I/O throughput to session-specific CSV file. Used for plotting utilization trends over time.</p> <p>Parameters:</p> Name Type Description Default <code>cpu_percent</code> <code>float</code> <p>CPU utilization percentage (0-100).</p> required <code>ram_percent</code> <code>float</code> <p>RAM utilization percentage (0-100).</p> required <code>gpu_percent</code> <code>Optional[float]</code> <p>GPU utilization percentage (0-100), or None if unavailable.</p> <code>None</code> <code>gpu_vram_percent</code> <code>Optional[float]</code> <p>GPU VRAM utilization percentage (0-100), or None if unavailable.</p> <code>None</code> <code>disk_read_mbps</code> <code>Optional[float]</code> <p>Disk read throughput in MB/s, or None if unavailable.</p> <code>None</code> <code>disk_write_mbps</code> <code>Optional[float]</code> <p>Disk write throughput in MB/s, or None if unavailable.</p> <code>None</code> Source code in <code>goliat/gui/components/data_manager.py</code> <pre><code>def write_system_utilization(\n    self,\n    cpu_percent: float,\n    ram_percent: float,\n    gpu_percent: Optional[float] = None,\n    gpu_vram_percent: Optional[float] = None,\n    disk_read_mbps: Optional[float] = None,\n    disk_write_mbps: Optional[float] = None,\n) -&gt; None:\n    \"\"\"Appends a system utilization data point to CSV.\n\n    Writes timestamp and CPU, RAM, GPU utilization, GPU VRAM, and disk I/O\n    throughput to session-specific CSV file. Used for plotting utilization trends over time.\n\n    Args:\n        cpu_percent: CPU utilization percentage (0-100).\n        ram_percent: RAM utilization percentage (0-100).\n        gpu_percent: GPU utilization percentage (0-100), or None if unavailable.\n        gpu_vram_percent: GPU VRAM utilization percentage (0-100), or None if unavailable.\n        disk_read_mbps: Disk read throughput in MB/s, or None if unavailable.\n        disk_write_mbps: Disk write throughput in MB/s, or None if unavailable.\n    \"\"\"\n    try:\n        current_time = get_ntp_utc_time()  # Use NTP time (bypasses system clock issues)\n        with open(self.system_utilization_file, \"a\", newline=\"\") as f:\n            writer = csv.writer(f)\n            writer.writerow(\n                [\n                    current_time.isoformat(),\n                    cpu_percent,\n                    ram_percent,\n                    gpu_percent if gpu_percent is not None else \"\",\n                    gpu_vram_percent if gpu_vram_percent is not None else \"\",\n                    f\"{disk_read_mbps:.2f}\" if disk_read_mbps is not None else \"\",\n                    f\"{disk_write_mbps:.2f}\" if disk_write_mbps is not None else \"\",\n                ]\n            )\n    except Exception as e:\n        self.verbose_logger.error(f\"Failed to write system utilization data: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.graph_manager.GraphManager","title":"goliat.gui.components.graph_manager.GraphManager","text":"<pre><code>GraphManager(gui: ProgressGUI)\n</code></pre> <p>Manages time remaining and overall progress graph updates.</p> <p>Parameters:</p> Name Type Description Default <code>gui</code> <code>ProgressGUI</code> <p>ProgressGUI instance.</p> required Source code in <code>goliat/gui/components/graph_manager.py</code> <pre><code>def __init__(self, gui: \"ProgressGUI\") -&gt; None:\n    \"\"\"Initializes graph manager.\n\n    Args:\n        gui: ProgressGUI instance.\n    \"\"\"\n    self.gui = gui\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.graph_manager.GraphManager-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.graph_manager.GraphManager.update","title":"update","text":"<pre><code>update() -&gt; None\n</code></pre> <p>Updates time remaining, overall progress, and system utilization graphs (called every 5 seconds).</p> <p>Gets current ETA and progress values, writes them to CSV files (via DataManager), and adds data points to matplotlib plots. The plots show trends over time, helping users see if ETA is converging or progress is steady.</p> <p>This runs less frequently than clock updates (5s vs 1s) because plotting is more expensive and the trends don't need millisecond precision.</p> Source code in <code>goliat/gui/components/graph_manager.py</code> <pre><code>def update(self) -&gt; None:\n    \"\"\"Updates time remaining, overall progress, and system utilization graphs (called every 5 seconds).\n\n    Gets current ETA and progress values, writes them to CSV files (via\n    DataManager), and adds data points to matplotlib plots. The plots\n    show trends over time, helping users see if ETA is converging or\n    progress is steady.\n\n    This runs less frequently than clock updates (5s vs 1s) because\n    plotting is more expensive and the trends don't need millisecond\n    precision.\n    \"\"\"\n    # Get current ETA\n    eta_sec: Optional[float] = None\n    if self.gui.profiler and self.gui.profiler.current_phase:\n        current_stage_progress_ratio = self.gui.stage_progress_bar.value() / 1000.0\n        eta_sec = self.gui.profiler.get_time_remaining(current_stage_progress=current_stage_progress_ratio)\n\n    # Get current progress\n    progress_percent = max(0, self.gui.overall_progress_bar.value() / 100.0)\n\n    # Update time remaining data\n    if eta_sec is not None:\n        current_time = get_ntp_utc_time()  # Use NTP time (bypasses system clock issues)\n        hours_remaining = eta_sec / 3600.0\n        self.gui.data_manager.write_time_remaining(hours_remaining)\n        self.gui.time_remaining_plot.add_data_point(current_time, hours_remaining)\n\n    # Update overall progress data\n    current_time = get_ntp_utc_time()  # Use NTP time (bypasses system clock issues)\n    self.gui.data_manager.write_overall_progress(progress_percent)\n    self.gui.overall_progress_plot.add_data_point(current_time, progress_percent)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.machine_id_detector.MachineIdDetector","title":"goliat.gui.components.machine_id_detector.MachineIdDetector","text":"<p>Detects machine ID (public IP or local IP) for web monitoring.</p> <p>Tries external service first with retries, then falls back to local IP. Matches the logic in run_worker.py to ensure consistency.</p>"},{"location":"reference/api_reference/#goliat.gui.components.machine_id_detector.MachineIdDetector-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.machine_id_detector.MachineIdDetector.detect","title":"detect  <code>staticmethod</code>","text":"<pre><code>detect(verbose_logger: Logger) -&gt; Optional[str]\n</code></pre> <p>Auto-detects machine ID (public IP or local IP).</p> <p>Parameters:</p> Name Type Description Default <code>verbose_logger</code> <code>Logger</code> <p>Logger for verbose messages.</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Machine ID string, or None if detection failed.</p> Source code in <code>goliat/gui/components/machine_id_detector.py</code> <pre><code>@staticmethod\ndef detect(verbose_logger: Logger) -&gt; Optional[str]:\n    \"\"\"Auto-detects machine ID (public IP or local IP).\n\n    Args:\n        verbose_logger: Logger for verbose messages.\n\n    Returns:\n        Machine ID string, or None if detection failed.\n    \"\"\"\n    try:\n        import requests\n\n        # Try external service first with retries (matches run_worker.py)\n        public_ip = None\n        for attempt in range(3):  # Try up to 3 times\n            try:\n                response = requests.get(\"https://api.ipify.org\", timeout=10)\n                if response.status_code == 200:\n                    public_ip = response.text.strip()\n                    if public_ip:\n                        break\n            except Exception:\n                if attempt &lt; 2:  # Not the last attempt\n                    continue\n                # Last attempt failed, will fall through to local IP\n\n        if public_ip:\n            verbose_logger.info(f\"Auto-detected public IP: {public_ip}\")\n            return public_ip\n        else:\n            # Fallback to local IP\n            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            s.connect((\"8.8.8.8\", 80))\n            local_ip = s.getsockname()[0]\n            s.close()\n            verbose_logger.info(f\"Auto-detected local IP: {local_ip}\")\n            return local_ip\n    except Exception as e:\n        verbose_logger.warning(f\"Could not auto-detect machine ID: {e}\")\n        return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.progress_animation.ProgressAnimation","title":"goliat.gui.components.progress_animation.ProgressAnimation","text":"<pre><code>ProgressAnimation(progress_bar: QProgressBar, timer: QTimer, debug: bool = False)\n</code></pre> <p>Manages smooth progress bar animations based on estimated durations.</p> <p>Provides linear interpolation animation for progress bars when explicit progress updates aren't available. Animates from current value to target (100%) over estimated duration, giving visual feedback during long tasks.</p> <p>Updates every 50ms via Qt timer, calculating progress ratio from elapsed time and duration. Stops automatically when target is reached or stopped explicitly.</p> <p>Parameters:</p> Name Type Description Default <code>progress_bar</code> <code>QProgressBar</code> <p>Progress bar widget to animate (0-1000 range).</p> required <code>timer</code> <code>QTimer</code> <p>QTimer instance for animation updates (50ms interval).</p> required <code>debug</code> <code>bool</code> <p>Enable debug logging (currently unused).</p> <code>False</code> Source code in <code>goliat/gui/components/progress_animation.py</code> <pre><code>def __init__(self, progress_bar: \"QProgressBar\", timer: \"QTimer\", debug: bool = False) -&gt; None:\n    \"\"\"Sets up the animation handler.\n\n    Args:\n        progress_bar: Progress bar widget to animate (0-1000 range).\n        timer: QTimer instance for animation updates (50ms interval).\n        debug: Enable debug logging (currently unused).\n    \"\"\"\n    from PySide6.QtWidgets import QProgressBar as _QProgressBar\n    from PySide6.QtCore import QTimer as _QTimer\n\n    self.progress_bar: _QProgressBar = progress_bar\n    self.timer: _QTimer = timer\n    self.debug: bool = debug\n    self.active: bool = False\n    self.start_time: float = 0.0\n    self.duration: float = 0.0\n    self.start_value: int = 0\n    self.end_value: int = 0\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.progress_animation.ProgressAnimation-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.progress_animation.ProgressAnimation.start","title":"start","text":"<pre><code>start(estimated_duration: float, end_step: int) -&gt; None\n</code></pre> <p>Starts smooth animation for progress bar.</p> <p>Begins linear interpolation from current value to 100% over estimated duration. If already at 100%, skips animation. Starts Qt timer if not already active.</p> <p>Parameters:</p> Name Type Description Default <code>estimated_duration</code> <code>float</code> <p>Estimated task duration in seconds (from profiler).</p> required <code>end_step</code> <code>int</code> <p>Target step value (unused, always animates to 100%).</p> required Source code in <code>goliat/gui/components/progress_animation.py</code> <pre><code>def start(self, estimated_duration: float, end_step: int) -&gt; None:\n    \"\"\"Starts smooth animation for progress bar.\n\n    Begins linear interpolation from current value to 100% over estimated\n    duration. If already at 100%, skips animation. Starts Qt timer if\n    not already active.\n\n    Args:\n        estimated_duration: Estimated task duration in seconds (from profiler).\n        end_step: Target step value (unused, always animates to 100%).\n    \"\"\"\n    if self.debug:\n        self._log(f\"start_animation received: duration={estimated_duration:.2f}s, end_step={end_step}\")\n\n    self.start_time = time.monotonic()\n    self.duration = estimated_duration\n    self.start_value = self.progress_bar.value()\n    self.end_value = 1000  # Progress bar range is 0-1000\n\n    if self.start_value &gt;= self.end_value:\n        if self.debug:\n            self._log(\"Animation skipped, start_value &gt;= end_value.\")\n        return\n\n    self.active = True\n    if not self.timer.isActive():\n        self.timer.start(50)\n    if self.debug:\n        self._log(\"Animation started.\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.progress_animation.ProgressAnimation.stop","title":"stop","text":"<pre><code>stop() -&gt; None\n</code></pre> <p>Stops the progress bar animation.</p> Source code in <code>goliat/gui/components/progress_animation.py</code> <pre><code>def stop(self) -&gt; None:\n    \"\"\"Stops the progress bar animation.\"\"\"\n    if self.active and self.debug:\n        self._log(\"end_animation called.\")\n    self.active = False\n    if self.timer.isActive():\n        self.timer.stop()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.progress_animation.ProgressAnimation.update","title":"update","text":"<pre><code>update() -&gt; None\n</code></pre> <p>Updates progress bar animation frame by frame.</p> <p>Calculates current progress ratio based on elapsed time and duration, then interpolates between start and end values. Updates progress bar value and format string. Called every 50ms by Qt timer when active.</p> Source code in <code>goliat/gui/components/progress_animation.py</code> <pre><code>def update(self) -&gt; None:\n    \"\"\"Updates progress bar animation frame by frame.\n\n    Calculates current progress ratio based on elapsed time and duration,\n    then interpolates between start and end values. Updates progress bar\n    value and format string. Called every 50ms by Qt timer when active.\n    \"\"\"\n    if not self.active:\n        return\n\n    elapsed = time.monotonic() - self.start_time\n\n    if self.duration &gt; 0:\n        progress_ratio = min(elapsed / self.duration, 1.0)\n    else:\n        progress_ratio = 1.0\n\n    value_range = self.end_value - self.start_value\n    current_value = self.start_value + int(value_range * progress_ratio)\n    current_value = min(current_value, self.end_value)\n\n    self.progress_bar.setValue(current_value)\n    percent = (current_value / 1000) * 100\n    self.progress_bar.setFormat(f\"{percent:.0f}%\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.progress_manager.ProgressManager","title":"goliat.gui.components.progress_manager.ProgressManager","text":"<pre><code>ProgressManager(gui: ProgressGUI)\n</code></pre> <p>Manages progress bar updates for overall and stage progress.</p> <p>Parameters:</p> Name Type Description Default <code>gui</code> <code>ProgressGUI</code> <p>ProgressGUI instance.</p> required Source code in <code>goliat/gui/components/progress_manager.py</code> <pre><code>def __init__(self, gui: \"ProgressGUI\") -&gt; None:\n    \"\"\"Initializes progress manager.\n\n    Args:\n        gui: ProgressGUI instance.\n    \"\"\"\n    self.gui = gui\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.progress_manager.ProgressManager-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.progress_manager.ProgressManager.update_overall","title":"update_overall","text":"<pre><code>update_overall(current_step: float, total_steps: int) -&gt; None\n</code></pre> <p>Updates overall progress bar across all simulations.</p> <p>The progress bar uses a 0-10000 range internally (for finer granularity), but displays as percentage. Overall progress accounts for completed simulations plus progress within current simulation.</p> <p>Parameters:</p> Name Type Description Default <code>current_step</code> <code>float</code> <p>Current step number (0-100 range) or percentage (0-100).</p> required <code>total_steps</code> <code>int</code> <p>Total number of steps (typically 100).</p> required Source code in <code>goliat/gui/components/progress_manager.py</code> <pre><code>def update_overall(self, current_step: float, total_steps: int) -&gt; None:\n    \"\"\"Updates overall progress bar across all simulations.\n\n    The progress bar uses a 0-10000 range internally (for finer granularity),\n    but displays as percentage. Overall progress accounts for completed\n    simulations plus progress within current simulation.\n\n    Args:\n        current_step: Current step number (0-100 range) or percentage (0-100).\n        total_steps: Total number of steps (typically 100).\n    \"\"\"\n    if self.gui.DEBUG:\n        self.gui.update_status(f\"DEBUG: update_overall_progress received: current={current_step}, total={total_steps}\")\n    if total_steps &gt; 0:\n        progress_percent = (current_step / total_steps) * 100\n        self.gui.overall_progress_bar.setValue(int(progress_percent * 100))\n        self.gui.overall_progress_bar.setFormat(f\"{progress_percent:.2f}%\")\n        if self.gui.DEBUG:\n            self.gui.update_status(f\"DEBUG: Overall progress set to: {progress_percent:.2f}%\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.progress_manager.ProgressManager.update_stage","title":"update_stage","text":"<pre><code>update_stage(stage_name: str, current_step: int, total_steps: int, sub_stage: str = '') -&gt; None\n</code></pre> <p>Updates stage-specific progress bar and label.</p> <p>Shows progress within current phase (setup/run/extract). Stops any active animation when explicit progress is set. Uses 0-1000 range internally for finer granularity.</p> <p>Parameters:</p> Name Type Description Default <code>stage_name</code> <code>str</code> <p>Name of current stage (e.g., 'Setup', 'Running Simulation').</p> required <code>current_step</code> <code>int</code> <p>Current step within stage.</p> required <code>total_steps</code> <code>int</code> <p>Total steps for the stage.</p> required <code>sub_stage</code> <code>str</code> <p>Optional sub-stage description (currently unused).</p> <code>''</code> Source code in <code>goliat/gui/components/progress_manager.py</code> <pre><code>def update_stage(self, stage_name: str, current_step: int, total_steps: int, sub_stage: str = \"\") -&gt; None:\n    \"\"\"Updates stage-specific progress bar and label.\n\n    Shows progress within current phase (setup/run/extract). Stops any\n    active animation when explicit progress is set. Uses 0-1000 range\n    internally for finer granularity.\n\n    Args:\n        stage_name: Name of current stage (e.g., 'Setup', 'Running Simulation').\n        current_step: Current step within stage.\n        total_steps: Total steps for the stage.\n        sub_stage: Optional sub-stage description (currently unused).\n    \"\"\"\n    if self.gui.DEBUG:\n        self.gui.update_status(\n            f\"DEBUG: update_stage_progress received: name='{stage_name}', current={current_step}, total={total_steps}, sub_stage='{sub_stage}'\"\n        )\n\n    self.gui.stage_label.setText(f\"Current Stage: {stage_name}\")\n    self.gui.total_steps_for_stage = total_steps\n    self.gui.progress_animation.stop()\n\n    progress_percent = (current_step / total_steps) if total_steps &gt; 0 else 0\n    final_value = int(progress_percent * 1000)\n\n    self.gui.stage_progress_bar.setValue(final_value)\n    self.gui.stage_progress_bar.setFormat(f\"{progress_percent * 100:.0f}%\")\n    if self.gui.DEBUG:\n        self.gui.update_status(f\"DEBUG: Stage '{stage_name}' progress set to: {progress_percent * 100:.0f}%\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.progress_manager.ProgressManager.update_simulation_details","title":"update_simulation_details","text":"<pre><code>update_simulation_details(sim_count: int, total_sims: int, details: str) -&gt; None\n</code></pre> <p>Updates simulation counter and details labels.</p> <p>Parameters:</p> Name Type Description Default <code>sim_count</code> <code>int</code> <p>Current simulation number.</p> required <code>total_sims</code> <code>int</code> <p>Total number of simulations.</p> required <code>details</code> <code>str</code> <p>Description of current simulation case.</p> required Source code in <code>goliat/gui/components/progress_manager.py</code> <pre><code>def update_simulation_details(self, sim_count: int, total_sims: int, details: str) -&gt; None:\n    \"\"\"Updates simulation counter and details labels.\n\n    Args:\n        sim_count: Current simulation number.\n        total_sims: Total number of simulations.\n        details: Description of current simulation case.\n    \"\"\"\n    self.gui.current_simulation_count = sim_count\n    self.gui.total_simulations = total_sims\n    self.gui.sim_counter_label.setText(f\"Simulation: {sim_count} / {total_sims}\")\n    self.gui.sim_details_label.setText(f\"Current Case: {details}\")\n\n    # Send simulation details to web dashboard\n    if hasattr(self.gui, \"web_bridge_manager\") and self.gui.web_bridge_manager is not None:\n        if self.gui.web_bridge_manager.web_bridge is not None:\n            self.gui.web_bridge_manager.web_bridge.enqueue(\n                {\"type\": \"simulation_details\", \"simulation_count\": sim_count, \"total_simulations\": total_sims, \"current_case\": details}\n            )\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.queue_handler.QueueHandler","title":"goliat.gui.components.queue_handler.QueueHandler","text":"<pre><code>QueueHandler(gui_instance: ProgressGUI)\n</code></pre> <p>Handles processing of messages from the worker process queue.</p> <p>Polls the multiprocessing queue and dispatches messages to the matching GUI update methods. This decouples message handling from queue polling, making the code cleaner and easier to test.</p> <p>Message types: - 'status': Log message with color coding - 'overall_progress': Update overall progress bar - 'stage_progress': Update stage progress bar - 'start_animation': Start animated progress bar - 'end_animation': Stop animation - 'profiler_update': Update profiler state and refresh timing displays - 'sim_details': Update simulation counter and details - 'finished': Study completed successfully - 'fatal_error': Study failed with fatal error</p> <p>Parameters:</p> Name Type Description Default <code>gui_instance</code> <code>ProgressGUI</code> <p>ProgressGUI instance to update with messages.</p> required Source code in <code>goliat/gui/components/queue_handler.py</code> <pre><code>def __init__(self, gui_instance: \"ProgressGUI\") -&gt; None:\n    \"\"\"Wire up message handlers to GUI instance.\n\n    Args:\n        gui_instance: ProgressGUI instance to update with messages.\n    \"\"\"\n    self.gui: \"ProgressGUI\" = gui_instance\n    self._MESSAGE_HANDLERS = {\n        \"status\": self._handle_status,\n        \"terminal_only\": self._handle_terminal_only,  # Verbose logs - terminal only, no GUI update\n        \"print\": self._handle_print,  # stdout/stderr from child process\n        \"overall_progress\": self._handle_overall_progress,\n        \"stage_progress\": self._handle_stage_progress,\n        \"start_animation\": self._handle_start_animation,\n        \"end_animation\": self._handle_end_animation,\n        \"profiler_update\": self._handle_profiler_update,\n        \"sim_details\": self._handle_sim_details,\n        \"finished\": self._handle_finished,\n        \"fatal_error\": self._handle_fatal_error,\n        \"memory_error\": self._handle_memory_error,\n    }\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.queue_handler.QueueHandler-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.queue_handler.QueueHandler.process_queue","title":"process_queue","text":"<pre><code>process_queue() -&gt; None\n</code></pre> <p>Processes messages from worker process queue and updates UI.</p> <p>Polls queue non-blockingly and processes all available messages in one call. Routes each message type to its handler method. Catches and logs exceptions to prevent one bad message from crashing GUI.</p> <p>This method is called every 100ms by Qt timer to keep UI responsive.</p> <p>After processing each message for the GUI, forwards a copy to WebGUIBridge if it exists (for web dashboard monitoring).</p> Source code in <code>goliat/gui/components/queue_handler.py</code> <pre><code>def process_queue(self) -&gt; None:\n    \"\"\"Processes messages from worker process queue and updates UI.\n\n    Polls queue non-blockingly and processes all available messages in one\n    call. Routes each message type to its handler method.\n    Catches and logs exceptions to prevent one bad message from crashing GUI.\n\n    This method is called every 100ms by Qt timer to keep UI responsive.\n\n    After processing each message for the GUI, forwards a copy to WebGUIBridge\n    if it exists (for web dashboard monitoring).\n    \"\"\"\n    while not self.gui.queue.empty():\n        try:\n            msg: Dict[str, Any] = self.gui.queue.get_nowait()\n            msg_type: Optional[str] = msg.get(\"type\")\n\n            # Dispatch message to its handler\n            if msg_type:\n                handler = self._MESSAGE_HANDLERS.get(msg_type)\n                if handler:\n                    handler(msg)\n\n            # Forward message to web bridge if enabled\n            if hasattr(self.gui, \"web_bridge_manager\") and self.gui.web_bridge_manager.web_bridge is not None:\n                try:\n                    # Sanitize profiler_update messages before forwarding\n                    if msg_type == \"profiler_update\" and \"profiler\" in msg:\n                        profiler = msg.get(\"profiler\")\n                        # Extract only serializable data from profiler\n                        # Calculate eta_seconds using get_time_remaining() method\n                        eta_seconds = None\n                        if profiler and hasattr(profiler, \"get_time_remaining\"):\n                            try:\n                                # Get current stage progress ratio from GUI if available\n                                current_stage_progress = 0.0\n                                if hasattr(self.gui, \"stage_progress_bar\"):\n                                    stage_value = self.gui.stage_progress_bar.value()\n                                    stage_max = self.gui.stage_progress_bar.maximum()\n                                    if stage_max &gt; 0:\n                                        current_stage_progress = stage_value / stage_max\n                                # Call get_time_remaining() to get ETA in seconds\n                                eta_seconds = profiler.get_time_remaining(current_stage_progress=current_stage_progress)\n                            except Exception as e:\n                                # If calculation fails, log but don't crash\n                                if hasattr(self.gui, \"verbose_logger\"):\n                                    self.gui.verbose_logger.debug(f\"Failed to calculate ETA: {e}\")\n                        sanitized_msg = {\n                            \"type\": \"profiler_update\",\n                            \"eta_seconds\": eta_seconds,\n                        }\n                        self.gui.web_bridge_manager.web_bridge.enqueue(sanitized_msg)\n                    else:\n                        self.gui.web_bridge_manager.web_bridge.enqueue(msg)\n                except Exception as e:\n                    # Don't let web bridge errors crash the GUI\n                    self.gui.verbose_logger.warning(f\"Failed to forward message to web bridge: {e}\")\n\n        except Empty:\n            break\n        except Exception as e:\n            self.gui.verbose_logger.error(f\"Error processing GUI queue: {e}\\n{traceback.format_exc()}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.screenshot_capture.ScreenshotCapture","title":"goliat.gui.components.screenshot_capture.ScreenshotCapture","text":"<pre><code>ScreenshotCapture(gui: ProgressGUI)\n</code></pre> <p>Captures screenshots of GUI tabs for web monitoring.</p> <p>Parameters:</p> Name Type Description Default <code>gui</code> <code>ProgressGUI</code> <p>ProgressGUI instance with tabs to capture.</p> required Source code in <code>goliat/gui/components/screenshot_capture.py</code> <pre><code>def __init__(self, gui: \"ProgressGUI\") -&gt; None:\n    \"\"\"Initialize screenshot capture component.\n\n    Args:\n        gui: ProgressGUI instance with tabs to capture.\n    \"\"\"\n    self.gui = gui\n    self.verbose_logger = logging.getLogger(\"screenshot_capture\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.screenshot_capture.ScreenshotCapture-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.screenshot_capture.ScreenshotCapture.capture_all_tabs","title":"capture_all_tabs","text":"<pre><code>capture_all_tabs() -&gt; Dict[str, bytes]\n</code></pre> <p>Capture all GUI tabs as JPEG bytes.</p> <p>Captures each tab widget individually without switching tabs, so it doesn't interfere with the user's current view.</p> <p>Returns:</p> Type Description <code>Dict[str, bytes]</code> <p>Dictionary mapping tab names to JPEG bytes.</p> <code>Dict[str, bytes]</code> <p>Empty dict if capture fails or PySide6 not available.</p> Source code in <code>goliat/gui/components/screenshot_capture.py</code> <pre><code>def capture_all_tabs(self) -&gt; Dict[str, bytes]:\n    \"\"\"Capture all GUI tabs as JPEG bytes.\n\n    Captures each tab widget individually without switching tabs,\n    so it doesn't interfere with the user's current view.\n\n    Returns:\n        Dictionary mapping tab names to JPEG bytes.\n        Empty dict if capture fails or PySide6 not available.\n    \"\"\"\n    if QBuffer is None or QWidget is None or QPixmap is None:\n        return {}\n\n    screenshots: Dict[str, bytes] = {}\n\n    try:\n        if not hasattr(self.gui, \"tabs\"):\n            self.verbose_logger.warning(\"GUI has no tabs attribute\")\n            return {}\n\n        tabs = self.gui.tabs\n        tab_count = tabs.count()\n\n        for i in range(tab_count):\n            try:\n                tab_widget = tabs.widget(i)\n                tab_name = tabs.tabText(i)\n\n                if tab_widget is None:\n                    self.verbose_logger.warning(f\"Tab {i} ({tab_name}) has no widget\")\n                    continue\n\n                # Skip the main \"Progress\" tab - its data is already sent via other mechanisms\n                if tab_name == \"Progress\":\n                    continue\n\n                # Get the size of the tab widget's parent (QTabWidget) to know the proper size\n                # Non-visible tabs might have zero size, so we use parent size as reference\n                parent_size = tabs.size()\n                widget_width = tab_widget.width() if tab_widget.width() &gt; 0 else parent_size.width()\n                widget_height = tab_widget.height() if tab_widget.height() &gt; 0 else parent_size.height()\n\n                # Fallback to reasonable defaults if sizes are still zero\n                if widget_width == 0:\n                    widget_width = 800\n                if widget_height == 0:\n                    widget_height = 600\n\n                # Process events to ensure all widgets are painted\n                if QApplication is not None:\n                    QApplication.processEvents()\n\n                pixmap = QPixmap(widget_width, widget_height)\n                pixmap.fill()\n                tab_widget.render(pixmap)\n\n                # Process events after rendering\n                if QApplication is not None:\n                    QApplication.processEvents()\n\n                if pixmap.isNull():\n                    self.verbose_logger.warning(f\"Failed to grab pixmap for tab {tab_name}\")\n                    continue\n\n                # Verify pixmap has content (not just empty/white)\n                if pixmap.width() == 0 or pixmap.height() == 0:\n                    self.verbose_logger.warning(f\"Pixmap for tab {tab_name} has zero size\")\n                    continue\n\n                # Convert to JPEG bytes\n                jpeg_bytes = self._compress_to_jpeg(pixmap)\n\n                if jpeg_bytes:\n                    screenshots[tab_name] = jpeg_bytes\n                    self.verbose_logger.debug(f\"Captured screenshot for tab '{tab_name}' ({len(jpeg_bytes)} bytes)\")\n\n            except Exception as e:\n                # Log error but continue capturing other tabs\n                self.verbose_logger.warning(f\"Failed to capture tab {i}: {e}\", exc_info=True)\n                continue\n\n    except Exception as e:\n        self.verbose_logger.error(f\"Failed to capture screenshots: {e}\", exc_info=True)\n\n    return screenshots\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.status_manager.StatusManager","title":"goliat.gui.components.status_manager.StatusManager","text":"<pre><code>StatusManager()\n</code></pre> <p>Manages status colors, counting, and message formatting for GUI.</p> <p>Handles color mapping for different log types (info, warning, error, etc.), counts warnings and errors for display in error summary, and formats messages with HTML color styling for the QTextEdit widget.</p> <p>Note: Uses white for 'progress' messages in GUI (unlike terminal colors) because all messages shown here are progress updates. This improves readability in the dark-themed GUI.</p> Source code in <code>goliat/gui/components/status_manager.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initializes status manager with default counters and color map.\"\"\"\n    self.warning_count: int = 0\n    self.error_count: int = 0\n\n    # Color mapping - NOTE: Intentionally using white for \"progress\" in GUI\n    # since all messages shown here are progress updates. This deviates from\n    # the terminal color scheme defined in goliat/colors.py for better readability.\n    self.color_map: dict[str, str] = {\n        \"default\": \"#f0f0f0\",  # WHITE\n        \"progress\": \"#f0f0f0\",  # WHITE (GUI-specific override)\n        \"info\": \"#17a2b8\",  # CYAN\n        \"verbose\": \"#007acc\",  # BLUE\n        \"warning\": \"#ffc107\",  # YELLOW\n        \"error\": \"#dc3545\",  # RED\n        \"fatal\": \"#d63384\",  # MAGENTA\n        \"success\": \"#5cb85c\",  # BRIGHT GREEN\n        \"header\": \"#e83e8c\",  # BRIGHT MAGENTA\n        \"highlight\": \"#ffd700\",  # BRIGHT YELLOW\n        \"caller\": \"#6c757d\",  # DIM (gray)\n    }\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.status_manager.StatusManager-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.status_manager.StatusManager.get_color","title":"get_color","text":"<pre><code>get_color(log_type: str) -&gt; str\n</code></pre> <p>Gets HTML color code for a log type.</p> <p>Parameters:</p> Name Type Description Default <code>log_type</code> <code>str</code> <p>Type of log message.</p> required <p>Returns:</p> Type Description <code>str</code> <p>HTML color code (hex).</p> Source code in <code>goliat/gui/components/status_manager.py</code> <pre><code>def get_color(self, log_type: str) -&gt; str:\n    \"\"\"Gets HTML color code for a log type.\n\n    Args:\n        log_type: Type of log message.\n\n    Returns:\n        HTML color code (hex).\n    \"\"\"\n    return self.color_map.get(log_type, \"#f0f0f0\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.status_manager.StatusManager.format_message","title":"format_message","text":"<pre><code>format_message(message: str, log_type: str = 'default') -&gt; str\n</code></pre> <p>Formats message with HTML color styling.</p> <p>Strips any ANSI escape codes (from terminal formatters), preserves leading spaces by converting them to \u00a0 entities, then wraps message in a  tag with the matching color. <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Message text to format.</p> required <code>log_type</code> <code>str</code> <p>Log type for color selection.</p> <code>'default'</code> <p>Returns:</p> Type Description <code>str</code> <p>HTML-formatted message string ready for QTextEdit.</p> Source code in <code>goliat/gui/components/status_manager.py</code> <pre><code>def format_message(self, message: str, log_type: str = \"default\") -&gt; str:\n    \"\"\"Formats message with HTML color styling.\n\n    Strips any ANSI escape codes (from terminal formatters), preserves\n    leading spaces by converting them to &amp;nbsp; entities, then wraps\n    message in a &lt;span&gt; tag with the matching color.\n\n    Args:\n        message: Message text to format.\n        log_type: Log type for color selection.\n\n    Returns:\n        HTML-formatted message string ready for QTextEdit.\n    \"\"\"\n    import re\n\n    # Strip ANSI escape codes (e.g., \\x1b[35m, \\x1b[0m)\n    ansi_pattern = re.compile(r\"\\x1b\\[[0-9;]*m\")\n    clean_message = ansi_pattern.sub(\"\", message)\n\n    # Preserve leading spaces by converting them to &amp;nbsp;\n    preserved_message = clean_message.replace(\" \", \"&amp;nbsp;\")\n    color = self.get_color(log_type)\n    return f'&lt;span style=\"color:{color};\"&gt;{preserved_message}&lt;/span&gt;'\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.status_manager.StatusManager.record_log","title":"record_log","text":"<pre><code>record_log(log_type: str) -&gt; None\n</code></pre> <p>Records log entry and updates warning/error counters.</p> <p>Parameters:</p> Name Type Description Default <code>log_type</code> <code>str</code> <p>Type of log message.</p> required Source code in <code>goliat/gui/components/status_manager.py</code> <pre><code>def record_log(self, log_type: str) -&gt; None:\n    \"\"\"Records log entry and updates warning/error counters.\n\n    Args:\n        log_type: Type of log message.\n    \"\"\"\n    if log_type == \"warning\":\n        self.warning_count += 1\n    elif log_type in [\"error\", \"fatal\"]:\n        self.error_count += 1\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.status_manager.StatusManager.get_error_summary","title":"get_error_summary","text":"<pre><code>get_error_summary(web_connected: bool = False) -&gt; str\n</code></pre> <p>Gets formatted summary of warnings and errors with optional web status.</p> <p>Parameters:</p> Name Type Description Default <code>web_connected</code> <code>bool</code> <p>Whether web dashboard is connected (optional).</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted string with emoji indicators and counts.</p> Source code in <code>goliat/gui/components/status_manager.py</code> <pre><code>def get_error_summary(self, web_connected: bool = False) -&gt; str:\n    \"\"\"Gets formatted summary of warnings and errors with optional web status.\n\n    Args:\n        web_connected: Whether web dashboard is connected (optional).\n\n    Returns:\n        Formatted string with emoji indicators and counts.\n    \"\"\"\n    web_status = \"\ud83d\udfe2\" if web_connected else \"\ud83d\udd34\"\n    return f\"\u26a0\ufe0f Warnings: {self.warning_count} | \u274c Errors: {self.error_count} | {web_status} Web\"\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor","title":"goliat.gui.components.system_monitor.SystemMonitor","text":"<p>Monitors system resource utilization (CPU, RAM, GPU).</p> <p>Provides methods to get current CPU usage percentage, RAM usage in GB, and GPU utilization percentage (via nvidia-smi). Gracefully handles missing dependencies (psutil) and unavailable GPU.</p>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.get_cpu_utilization","title":"get_cpu_utilization  <code>staticmethod</code>","text":"<pre><code>get_cpu_utilization() -&gt; float\n</code></pre> <p>Gets current CPU utilization percentage.</p> <p>Uses non-blocking approach by calling cpu_percent() without interval, which returns utilization since last call. For accurate measurement, ensure this is called at consistent intervals (e.g., every 1 second).</p> <p>Returns:</p> Type Description <code>float</code> <p>CPU usage percentage (0-100), or 0.0 if psutil unavailable.</p> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef get_cpu_utilization() -&gt; float:\n    \"\"\"Gets current CPU utilization percentage.\n\n    Uses non-blocking approach by calling cpu_percent() without interval,\n    which returns utilization since last call. For accurate measurement,\n    ensure this is called at consistent intervals (e.g., every 1 second).\n\n    Returns:\n        CPU usage percentage (0-100), or 0.0 if psutil unavailable.\n    \"\"\"\n    if not PSUTIL_AVAILABLE:\n        return 0.0\n    try:\n        # Non-blocking call - returns utilization since last call\n        # psutil is guaranteed to be available here due to PSUTIL_AVAILABLE check\n        cpu_percent = psutil.cpu_percent(interval=None)  # type: ignore[possibly-unbound]\n        # Clamp to valid range (psutil can sometimes return slightly negative or &gt;100)\n        return max(0.0, min(100.0, cpu_percent))\n    except Exception:\n        return 0.0\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.get_ram_utilization","title":"get_ram_utilization  <code>staticmethod</code>","text":"<pre><code>get_ram_utilization() -&gt; Tuple[float, float]\n</code></pre> <p>Gets current RAM usage and total RAM.</p> <p>Returns:</p> Type Description <code>Tuple[float, float]</code> <p>Tuple of (used_GB, total_GB), or (0.0, 0.0) if psutil unavailable.</p> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef get_ram_utilization() -&gt; Tuple[float, float]:\n    \"\"\"Gets current RAM usage and total RAM.\n\n    Returns:\n        Tuple of (used_GB, total_GB), or (0.0, 0.0) if psutil unavailable.\n    \"\"\"\n    if not PSUTIL_AVAILABLE:\n        return (0.0, 0.0)\n    try:\n        # psutil is guaranteed to be available here due to PSUTIL_AVAILABLE check\n        memory = psutil.virtual_memory()  # type: ignore[possibly-unbound]\n        used_gb = memory.used / (1024**3)\n        total_gb = memory.total / (1024**3)\n        return (used_gb, total_gb)\n    except Exception:\n        return (0.0, 0.0)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.get_ram_utilization_detailed","title":"get_ram_utilization_detailed  <code>staticmethod</code>","text":"<pre><code>get_ram_utilization_detailed() -&gt; Tuple[float, float, float]\n</code></pre> <p>Gets RAM utilization with and without cacheable memory.</p> <p>Returns:</p> Type Description <code>float</code> <p>Tuple of (percent_with_cache, percent_without_cache, total_GB), or (0.0, 0.0, 0.0) if psutil unavailable.</p> <code>float</code> <ul> <li>percent_with_cache: (used / total) * 100 (includes cacheable memory)</li> </ul> <code>float</code> <ul> <li>percent_without_cache: ((total - available) / total) * 100 (excludes cacheable memory)</li> </ul> <code>Tuple[float, float, float]</code> <ul> <li>total_GB: Total RAM in GB</li> </ul> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef get_ram_utilization_detailed() -&gt; Tuple[float, float, float]:\n    \"\"\"Gets RAM utilization with and without cacheable memory.\n\n    Returns:\n        Tuple of (percent_with_cache, percent_without_cache, total_GB), or (0.0, 0.0, 0.0) if psutil unavailable.\n        - percent_with_cache: (used / total) * 100 (includes cacheable memory)\n        - percent_without_cache: ((total - available) / total) * 100 (excludes cacheable memory)\n        - total_GB: Total RAM in GB\n    \"\"\"\n    if not PSUTIL_AVAILABLE:\n        return (0.0, 0.0, 0.0)\n    try:\n        # psutil is guaranteed to be available here due to PSUTIL_AVAILABLE check\n        memory = psutil.virtual_memory()  # type: ignore[possibly-unbound]\n        total_gb = memory.total / (1024**3)\n\n        # With cache: used / total\n        percent_with_cache = memory.percent\n\n        # Without cache: (total - available) / total\n        # This excludes cacheable memory that can be freed\n        percent_without_cache = ((memory.total - memory.available) / memory.total) * 100\n\n        return (percent_with_cache, percent_without_cache, total_gb)\n    except Exception:\n        return (0.0, 0.0, 0.0)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.get_gpu_vram_utilization","title":"get_gpu_vram_utilization  <code>staticmethod</code>","text":"<pre><code>get_gpu_vram_utilization() -&gt; Optional[Tuple[float, float]]\n</code></pre> <p>Gets current GPU VRAM usage and total VRAM.</p> <p>Returns:</p> Type Description <code>Optional[Tuple[float, float]]</code> <p>Tuple of (used_GB, total_GB), or None if nvidia-smi unavailable.</p> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef get_gpu_vram_utilization() -&gt; Optional[Tuple[float, float]]:\n    \"\"\"Gets current GPU VRAM usage and total VRAM.\n\n    Returns:\n        Tuple of (used_GB, total_GB), or None if nvidia-smi unavailable.\n    \"\"\"\n    try:\n        result = subprocess.run(\n            [\"nvidia-smi\", \"--query-gpu=memory.used,memory.total\", \"--format=csv,noheader,nounits\"],\n            capture_output=True,\n            text=True,\n            timeout=2,\n            check=False,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # Get first GPU's memory usage\n            memory_str = result.stdout.strip().split(\"\\n\")[0].strip()\n            parts = memory_str.split(\", \")\n            if len(parts) == 2:\n                used_mb = float(parts[0].strip())\n                total_mb = float(parts[1].strip())\n                used_gb = used_mb / 1024.0\n                total_gb = total_mb / 1024.0\n                return (used_gb, total_gb)\n        return None\n    except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError, ValueError, IndexError):\n        return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.get_gpu_utilization","title":"get_gpu_utilization  <code>staticmethod</code>","text":"<pre><code>get_gpu_utilization() -&gt; Optional[float]\n</code></pre> <p>Gets current GPU utilization percentage via nvidia-smi.</p> <p>Returns:</p> Type Description <code>Optional[float]</code> <p>GPU usage percentage (0-100), or None if nvidia-smi unavailable.</p> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef get_gpu_utilization() -&gt; Optional[float]:\n    \"\"\"Gets current GPU utilization percentage via nvidia-smi.\n\n    Returns:\n        GPU usage percentage (0-100), or None if nvidia-smi unavailable.\n    \"\"\"\n    try:\n        result = subprocess.run(\n            [\"nvidia-smi\", \"--query-gpu=utilization.gpu\", \"--format=csv,noheader,nounits\"],\n            capture_output=True,\n            text=True,\n            timeout=2,\n            check=False,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # Get first GPU's utilization\n            utilization_str = result.stdout.strip().split(\"\\n\")[0].strip()\n            return float(utilization_str)\n        return None\n    except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError, ValueError):\n        return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.get_gpu_name","title":"get_gpu_name  <code>staticmethod</code>","text":"<pre><code>get_gpu_name() -&gt; Optional[str]\n</code></pre> <p>Gets GPU name via nvidia-smi.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>GPU name (e.g., \"RTX 4090\"), or None if nvidia-smi unavailable.</p> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef get_gpu_name() -&gt; Optional[str]:\n    \"\"\"Gets GPU name via nvidia-smi.\n\n    Returns:\n        GPU name (e.g., \"RTX 4090\"), or None if nvidia-smi unavailable.\n    \"\"\"\n    try:\n        result = subprocess.run(\n            [\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"],\n            capture_output=True,\n            text=True,\n            timeout=2,\n            check=False,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # Get first GPU's name and clean it up\n            gpu_name = result.stdout.strip().split(\"\\n\")[0].strip()\n            # Remove common prefixes like \"NVIDIA \" and clean up\n            gpu_name = gpu_name.replace(\"NVIDIA \", \"\").strip()\n            return gpu_name\n        return None\n    except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):\n        return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.get_cpu_cores","title":"get_cpu_cores  <code>staticmethod</code>","text":"<pre><code>get_cpu_cores() -&gt; int\n</code></pre> <p>Gets number of CPU cores.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of CPU cores, or 0 if psutil unavailable.</p> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef get_cpu_cores() -&gt; int:\n    \"\"\"Gets number of CPU cores.\n\n    Returns:\n        Number of CPU cores, or 0 if psutil unavailable.\n    \"\"\"\n    if not PSUTIL_AVAILABLE:\n        return 0\n    try:\n        return psutil.cpu_count(logical=True) or 0  # type: ignore[possibly-unbound]\n    except Exception:\n        return 0\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.get_total_ram_gb","title":"get_total_ram_gb  <code>staticmethod</code>","text":"<pre><code>get_total_ram_gb() -&gt; float\n</code></pre> <p>Gets total RAM in GB.</p> <p>Returns:</p> Type Description <code>float</code> <p>Total RAM in GB, or 0.0 if psutil unavailable.</p> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef get_total_ram_gb() -&gt; float:\n    \"\"\"Gets total RAM in GB.\n\n    Returns:\n        Total RAM in GB, or 0.0 if psutil unavailable.\n    \"\"\"\n    if not PSUTIL_AVAILABLE:\n        return 0.0\n    try:\n        memory = psutil.virtual_memory()  # type: ignore[possibly-unbound]\n        return memory.total / (1024**3)\n    except Exception:\n        return 0.0\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.get_disk_io_throughput","title":"get_disk_io_throughput  <code>staticmethod</code>","text":"<pre><code>get_disk_io_throughput() -&gt; Optional[Tuple[float, float]]\n</code></pre> <p>Gets current disk I/O throughput in MB/s.</p> <p>Calculates read and write speeds by comparing current I/O counters with values from the previous call. First call returns None as there's no baseline for comparison.</p> <p>Returns:</p> Type Description <code>Optional[Tuple[float, float]]</code> <p>Tuple of (read_MB_per_sec, write_MB_per_sec), or None if unavailable.</p> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef get_disk_io_throughput() -&gt; Optional[Tuple[float, float]]:\n    \"\"\"Gets current disk I/O throughput in MB/s.\n\n    Calculates read and write speeds by comparing current I/O counters\n    with values from the previous call. First call returns None as there's\n    no baseline for comparison.\n\n    Returns:\n        Tuple of (read_MB_per_sec, write_MB_per_sec), or None if unavailable.\n    \"\"\"\n    if not PSUTIL_AVAILABLE:\n        return None\n    try:\n        import time\n\n        current_time = time.time()\n        # psutil is guaranteed to be available here due to PSUTIL_AVAILABLE check\n        io_counters = psutil.disk_io_counters()  # type: ignore[possibly-unbound]\n        if io_counters is None:\n            return None\n\n        current_read = io_counters.read_bytes\n        current_write = io_counters.write_bytes\n\n        if SystemMonitor._last_disk_io is None:\n            # First call - store baseline and return None\n            SystemMonitor._last_disk_io = (current_read, current_write, current_time)\n            return None\n\n        last_read, last_write, last_time = SystemMonitor._last_disk_io\n        time_delta = current_time - last_time\n\n        if time_delta &lt;= 0:\n            return None\n\n        # Calculate throughput in MB/s\n        read_speed = (current_read - last_read) / (1024 * 1024) / time_delta\n        write_speed = (current_write - last_write) / (1024 * 1024) / time_delta\n\n        # Update stored values for next call\n        SystemMonitor._last_disk_io = (current_read, current_write, current_time)\n\n        # Clamp to non-negative (counters can wrap on some systems)\n        return (max(0.0, read_speed), max(0.0, write_speed))\n    except Exception:\n        return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.is_gpu_available","title":"is_gpu_available  <code>staticmethod</code>","text":"<pre><code>is_gpu_available() -&gt; bool\n</code></pre> <p>Checks if GPU is available via nvidia-smi.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if nvidia-smi is available and returns successfully, False otherwise.</p> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef is_gpu_available() -&gt; bool:\n    \"\"\"Checks if GPU is available via nvidia-smi.\n\n    Returns:\n        True if nvidia-smi is available and returns successfully, False otherwise.\n    \"\"\"\n    return SystemMonitor.get_gpu_utilization() is not None\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.system_monitor.SystemMonitor.get_page_faults_per_second","title":"get_page_faults_per_second  <code>staticmethod</code>","text":"<pre><code>get_page_faults_per_second() -&gt; Optional[float]\n</code></pre> <p>Gets current hard page faults per second.</p> <p>Hard page faults (major faults) occur when the system needs to read data from disk because it's not in RAM. High rates indicate memory pressure and can significantly impact performance.</p> <p>Calculates the rate by comparing current page fault count with the previous call. First call returns None as there's no baseline.</p> <p>Returns:</p> Type Description <code>Optional[float]</code> <p>Page faults per second, or None if unavailable.</p> Source code in <code>goliat/gui/components/system_monitor.py</code> <pre><code>@staticmethod\ndef get_page_faults_per_second() -&gt; Optional[float]:\n    \"\"\"Gets current hard page faults per second.\n\n    Hard page faults (major faults) occur when the system needs to read data\n    from disk because it's not in RAM. High rates indicate memory pressure\n    and can significantly impact performance.\n\n    Calculates the rate by comparing current page fault count with the\n    previous call. First call returns None as there's no baseline.\n\n    Returns:\n        Page faults per second, or None if unavailable.\n    \"\"\"\n    if not PSUTIL_AVAILABLE:\n        return None\n    try:\n        import time\n\n        current_time = time.time()\n        # psutil is guaranteed to be available here due to PSUTIL_AVAILABLE check\n        swap_info = psutil.swap_memory()  # type: ignore[possibly-unbound]\n\n        # On Windows, swap_memory().sin and .sout track page-ins and page-outs\n        # We use sin (swap in) as it represents data being read from disk to RAM\n        # which is the hard fault scenario\n        # Note: On Linux, we could also use /proc/vmstat for more detailed stats\n        current_faults = swap_info.sin  # Bytes swapped in from disk\n\n        if SystemMonitor._last_page_faults is None:\n            # First call - store baseline and return None\n            SystemMonitor._last_page_faults = (current_faults, current_time)\n            return None\n\n        last_faults, last_time = SystemMonitor._last_page_faults\n        time_delta = current_time - last_time\n\n        if time_delta &lt;= 0:\n            return None\n\n        # Calculate faults per second (convert bytes to pages, assuming 4KB pages)\n        page_size = 4096  # Standard page size in bytes\n        faults_delta = current_faults - last_faults\n        pages_swapped = faults_delta / page_size\n        faults_per_second = pages_swapped / time_delta\n\n        # Update stored values for next call\n        SystemMonitor._last_page_faults = (current_faults, current_time)\n\n        # Clamp to non-negative (counters can wrap on some systems)\n        return max(0.0, faults_per_second)\n    except Exception:\n        return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.timings_table.TimingsTable","title":"goliat.gui.components.timings_table.TimingsTable","text":"<pre><code>TimingsTable(table_widget: QTableWidget)\n</code></pre> <p>Manages timings table displaying profiling statistics.</p> <p>Shows execution time statistics (mean, median, min, max, percentiles) for all phases and subtasks. Filters out fake aggregated entries and organizes data by phase for easy inspection. Updates automatically when profiler state changes via queue messages.</p> <p>Parameters:</p> Name Type Description Default <code>table_widget</code> <code>QTableWidget</code> <p>QTableWidget instance to populate with timing data.</p> required Source code in <code>goliat/gui/components/timings_table.py</code> <pre><code>def __init__(self, table_widget: QTableWidget) -&gt; None:\n    \"\"\"Sets up the timings table widget.\n\n    Args:\n        table_widget: QTableWidget instance to populate with timing data.\n    \"\"\"\n    self.table: QTableWidget = table_widget\n    self._setup_table()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.timings_table.TimingsTable-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.timings_table.TimingsTable.update","title":"update","text":"<pre><code>update(profiler: Profiler) -&gt; None\n</code></pre> <p>Populates table with timing statistics from profiler.</p> <p>Collects all phase and subtask timing data, computes statistics (mean, median, percentiles), and displays in table. Filters out fake aggregated entries that shouldn't be shown.</p> <p>Statistics computed: - Mean, median, min, max - 10<sup>th</sup>, 25<sup>th</sup>, 75<sup>th</sup>, 90<sup>th</sup> percentiles</p> <p>Parameters:</p> Name Type Description Default <code>profiler</code> <code>Profiler</code> <p>Profiler instance containing timing data.</p> required Source code in <code>goliat/gui/components/timings_table.py</code> <pre><code>def update(self, profiler: \"Profiler\") -&gt; None:\n    \"\"\"Populates table with timing statistics from profiler.\n\n    Collects all phase and subtask timing data, computes statistics\n    (mean, median, percentiles), and displays in table. Filters out\n    fake aggregated entries that shouldn't be shown.\n\n    Statistics computed:\n    - Mean, median, min, max\n    - 10th, 25th, 75th, 90th percentiles\n\n    Args:\n        profiler: Profiler instance containing timing data.\n    \"\"\"\n    if not profiler:\n        return\n\n    self.table.setRowCount(0)\n\n    # Collect all tasks with their raw timing data\n    all_tasks: Dict[str, Dict[str, Any]] = {}\n    for phase in [\"setup\", \"run\", \"extract\"]:\n        avg_time = profiler.profiling_config.get(f\"avg_{phase}_time\")\n        if avg_time is not None:\n            raw_times = profiler.subtask_times.get(phase, [])\n            all_tasks[f\"{phase}_total\"] = {\n                \"phase\": phase,\n                \"subtask\": \"---\",\n                \"raw_times\": raw_times if raw_times else [avg_time],\n            }\n\n    # Filter out fake aggregated entries that shouldn't be displayed\n    fake_entries = [\"setup_simulation\", \"run_simulation_total\", \"extract_results_total\"]\n\n    for key, value in profiler.profiling_config.items():\n        if key.startswith(\"avg_\") and \"_time\" not in key:\n            task_name = key.replace(\"avg_\", \"\")\n\n            # Skip fake aggregated entries\n            if task_name in fake_entries:\n                continue\n\n            parts = task_name.split(\"_\", 1)\n            phase = parts[0]\n            subtask_name = parts[1] if len(parts) &gt; 1 else phase\n            raw_times = profiler.subtask_times.get(task_name, [])\n            all_tasks[key] = {\n                \"phase\": phase,\n                \"subtask\": subtask_name,\n                \"raw_times\": raw_times if raw_times else [value],\n            }\n\n    # Populate table with statistics\n    for task_info in all_tasks.values():\n        row_position = self.table.rowCount()\n        self.table.insertRow(row_position)\n\n        times: List[float] = task_info.get(\"raw_times\", [])\n        if times:\n            times_array = np.array(times)\n            mean_val = float(np.mean(times_array))\n            median_val = float(np.median(times_array))\n            min_val = float(np.min(times_array))\n            max_val = float(np.max(times_array))\n            p10 = float(np.percentile(times_array, 10))\n            p25 = float(np.percentile(times_array, 25))\n            p75 = float(np.percentile(times_array, 75))\n            p90 = float(np.percentile(times_array, 90))\n        else:\n            mean_val = median_val = min_val = max_val = p10 = p25 = p75 = p90 = 0.0\n\n        # Create items and set text color to ensure visibility in both light and dark modes\n        light_text_color = QColor(\"#f0f0f0\")\n        items = [\n            QTableWidgetItem(task_info.get(\"phase\", \"N/A\")),\n            QTableWidgetItem(task_info.get(\"subtask\", \"---\")),\n            QTableWidgetItem(f\"{mean_val:.2f}\"),\n            QTableWidgetItem(f\"{median_val:.2f}\"),\n            QTableWidgetItem(f\"{min_val:.2f}\"),\n            QTableWidgetItem(f\"{max_val:.2f}\"),\n            QTableWidgetItem(f\"{p10:.2f}\"),\n            QTableWidgetItem(f\"{p25:.2f}\"),\n            QTableWidgetItem(f\"{p75:.2f}\"),\n            QTableWidgetItem(f\"{p90:.2f}\"),\n        ]\n        for item in items:\n            item.setForeground(light_text_color)\n\n        self.table.setItem(row_position, 0, items[0])\n        self.table.setItem(row_position, 1, items[1])\n        self.table.setItem(row_position, 2, items[2])\n        self.table.setItem(row_position, 3, items[3])\n        self.table.setItem(row_position, 4, items[4])\n        self.table.setItem(row_position, 5, items[5])\n        self.table.setItem(row_position, 6, items[6])\n        self.table.setItem(row_position, 7, items[7])\n        self.table.setItem(row_position, 8, items[8])\n        self.table.setItem(row_position, 9, items[9])\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.tray_manager.TrayManager","title":"goliat.gui.components.tray_manager.TrayManager","text":"<pre><code>TrayManager(parent_widget: QWidget, show_callback: Callable[[], None], close_callback: Callable[[], None])\n</code></pre> <p>Manages system tray icon and menu.</p> <p>Handles system tray integration for background operation. Shows tray icon with favicon, provides context menu (Show/Exit), and handles click events to restore window. Allows users to minimize GUI to tray and continue monitoring via icon.</p> <p>Parameters:</p> Name Type Description Default <code>parent_widget</code> <code>QWidget</code> <p>Parent widget (ProgressGUI window).</p> required <code>show_callback</code> <code>Callable[[], None]</code> <p>Function to call when restoring window.</p> required <code>close_callback</code> <code>Callable[[], None]</code> <p>Function to call when exiting application.</p> required Source code in <code>goliat/gui/components/tray_manager.py</code> <pre><code>def __init__(self, parent_widget: QWidget, show_callback: Callable[[], None], close_callback: Callable[[], None]) -&gt; None:\n    \"\"\"Sets up tray icon with menu.\n\n    Args:\n        parent_widget: Parent widget (ProgressGUI window).\n        show_callback: Function to call when restoring window.\n        close_callback: Function to call when exiting application.\n    \"\"\"\n    self.parent: QWidget = parent_widget\n    self.tray_icon: QSystemTrayIcon = QSystemTrayIcon(parent_widget)\n\n    # Set icon\n    icon_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), \"assets\", \"favicon.svg\")\n    if os.path.exists(icon_path):\n        self.tray_icon.setIcon(QIcon(icon_path))\n    else:\n        style = parent_widget.style()\n        icon = style.standardIcon(style.StandardPixmap.SP_ComputerIcon)\n        self.tray_icon.setIcon(icon)\n    self.tray_icon.setToolTip(\"Simulation is running...\")\n\n    # Create menu\n    tray_menu = QMenu(parent_widget)\n    show_action = QAction(\"Show\", parent_widget)\n    show_action.triggered.connect(show_callback)\n    tray_menu.addAction(show_action)\n\n    exit_action = QAction(\"Exit\", parent_widget)\n    exit_action.triggered.connect(close_callback)\n    tray_menu.addAction(exit_action)\n\n    self.tray_icon.setContextMenu(tray_menu)\n    self.tray_icon.activated.connect(lambda reason: self._tray_icon_activated(reason, show_callback))\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.tray_manager.TrayManager-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.tray_manager.TrayManager.show","title":"show","text":"<pre><code>show() -&gt; None\n</code></pre> <p>Shows the tray icon.</p> Source code in <code>goliat/gui/components/tray_manager.py</code> <pre><code>def show(self) -&gt; None:\n    \"\"\"Shows the tray icon.\"\"\"\n    self.tray_icon.show()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.tray_manager.TrayManager.hide","title":"hide","text":"<pre><code>hide() -&gt; None\n</code></pre> <p>Hides the tray icon.</p> Source code in <code>goliat/gui/components/tray_manager.py</code> <pre><code>def hide(self) -&gt; None:\n    \"\"\"Hides the tray icon.\"\"\"\n    self.tray_icon.hide()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.tray_manager.TrayManager.is_visible","title":"is_visible","text":"<pre><code>is_visible() -&gt; bool\n</code></pre> <p>Checks if tray icon is visible.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if visible, False otherwise.</p> Source code in <code>goliat/gui/components/tray_manager.py</code> <pre><code>def is_visible(self) -&gt; bool:\n    \"\"\"Checks if tray icon is visible.\n\n    Returns:\n        True if visible, False otherwise.\n    \"\"\"\n    return self.tray_icon.isVisible()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.ui_builder.UIBuilder","title":"goliat.gui.components.ui_builder.UIBuilder","text":"<p>Builds UI components for ProgressGUI.</p> <p>Provides static methods to construct the complete GUI layout, including tabs, progress bars, plots, tables, and buttons. Handles styling via Qt stylesheets for dark theme appearance.</p>"},{"location":"reference/api_reference/#goliat.gui.components.ui_builder.UIBuilder-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.ui_builder.UIBuilder.get_icon_path","title":"get_icon_path  <code>staticmethod</code>","text":"<pre><code>get_icon_path() -&gt; str\n</code></pre> <p>Gets path to window icon.</p> <p>Returns:</p> Type Description <code>str</code> <p>Absolute path to favicon.svg.</p> Source code in <code>goliat/gui/components/ui_builder.py</code> <pre><code>@staticmethod\ndef get_icon_path() -&gt; str:\n    \"\"\"Gets path to window icon.\n\n    Returns:\n        Absolute path to favicon.svg.\n    \"\"\"\n    return os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), \"assets\", \"favicon.svg\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.ui_builder.UIBuilder.build","title":"build  <code>staticmethod</code>","text":"<pre><code>build(gui_instance: ProgressGUI, status_manager: StatusManager) -&gt; None\n</code></pre> <p>Builds complete UI for the GUI instance.</p> <p>Sets up window properties, applies stylesheet, creates tabs (Progress, Timings, Piecharts, Time Remaining, Overall Progress), and adds control buttons. Attaches components to gui_instance for later access.</p> <p>Parameters:</p> Name Type Description Default <code>gui_instance</code> <code>ProgressGUI</code> <p>ProgressGUI instance to build UI for.</p> required <code>status_manager</code> <code>StatusManager</code> <p>StatusManager instance for error summary display.</p> required Source code in <code>goliat/gui/components/ui_builder.py</code> <pre><code>@staticmethod\ndef build(gui_instance: \"ProgressGUI\", status_manager: \"StatusManager\") -&gt; None:\n    \"\"\"Builds complete UI for the GUI instance.\n\n    Sets up window properties, applies stylesheet, creates tabs (Progress,\n    Timings, Piecharts, Time Remaining, Overall Progress), and adds\n    control buttons. Attaches components to gui_instance for later access.\n\n    Args:\n        gui_instance: ProgressGUI instance to build UI for.\n        status_manager: StatusManager instance for error summary display.\n    \"\"\"\n    gui_instance.setWindowTitle(gui_instance.init_window_title)\n    gui_instance.resize(800, 900)\n\n    # Set window icon\n    icon_path = UIBuilder.get_icon_path()\n    if os.path.exists(icon_path):\n        gui_instance.setWindowIcon(QIcon(icon_path))\n\n    gui_instance.setStyleSheet(UIBuilder.STYLESHEET)\n\n    main_layout = QVBoxLayout(gui_instance)\n    gui_instance.tabs = QTabWidget()\n    main_layout.addWidget(gui_instance.tabs)\n\n    # Build tabs\n    UIBuilder._build_progress_tab(gui_instance, status_manager)\n    UIBuilder._build_timings_tab(gui_instance)\n    UIBuilder._build_piecharts_tab(gui_instance)\n    UIBuilder._build_time_remaining_tab(gui_instance)\n    UIBuilder._build_overall_progress_tab(gui_instance)\n    UIBuilder._build_system_utilization_tab(gui_instance)\n    UIBuilder._build_disk_io_tab(gui_instance)\n\n    # Build buttons\n    UIBuilder._build_buttons(gui_instance, main_layout)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.utilization_manager.UtilizationManager","title":"goliat.gui.components.utilization_manager.UtilizationManager","text":"<pre><code>UtilizationManager(gui: ProgressGUI)\n</code></pre> <p>Manages CPU, RAM, and GPU utilization displays.</p> <p>Parameters:</p> Name Type Description Default <code>gui</code> <code>ProgressGUI</code> <p>ProgressGUI instance.</p> required Source code in <code>goliat/gui/components/utilization_manager.py</code> <pre><code>def __init__(self, gui: \"ProgressGUI\") -&gt; None:\n    \"\"\"Initializes utilization manager.\n\n    Args:\n        gui: ProgressGUI instance.\n    \"\"\"\n    self.gui = gui\n    # Initialize last values to avoid issues before first update\n    self._last_cpu_percent: float = 0.0\n    self._last_ram_percent: float = 0.0\n    self._last_gpu_percent: Optional[float] = None\n    self._last_gpu_vram_percent: Optional[float] = None\n    self._last_disk_read_mbps: Optional[float] = None\n    self._last_disk_write_mbps: Optional[float] = None\n    self._last_page_faults_per_sec: Optional[float] = None\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.utilization_manager.UtilizationManager-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.utilization_manager.UtilizationManager.update","title":"update","text":"<pre><code>update() -&gt; None\n</code></pre> <p>Updates CPU, RAM, and GPU utilization displays.</p> <p>Called every second by Qt timer. Gets current utilization values from SystemMonitor and updates the progress bars and labels.</p> Source code in <code>goliat/gui/components/utilization_manager.py</code> <pre><code>def update(self) -&gt; None:\n    \"\"\"Updates CPU, RAM, and GPU utilization displays.\n\n    Called every second by Qt timer. Gets current utilization values\n    from SystemMonitor and updates the progress bars and labels.\n    \"\"\"\n    # Update CPU utilization\n    cpu_percent = SystemMonitor.get_cpu_utilization()\n    self.gui.cpu_bar.setValue(int(cpu_percent))\n    self.gui.cpu_bar.setFormat(f\"{cpu_percent:.0f}%\")\n\n    # Update RAM utilization\n    ram_percent_with_cache, _, total_gb = SystemMonitor.get_ram_utilization_detailed()\n    used_gb, _ = SystemMonitor.get_ram_utilization()\n\n    if total_gb &gt; 0:\n        ram_percent = ram_percent_with_cache\n        self.gui.ram_bar.setValue(int(ram_percent))\n        self.gui.ram_bar.setFormat(f\"{used_gb:.1f}/{total_gb:.1f} GB\")\n    else:\n        ram_percent = 0.0\n        self.gui.ram_bar.setValue(0)\n        self.gui.ram_bar.setFormat(\"N/A\")\n\n    # Update GPU utilization\n    # Always try to get GPU data, not just when gpu_available is True\n    # This allows recovery after temporary failures\n    gpu_percent: Optional[float] = None\n    gpu_percent = SystemMonitor.get_gpu_utilization()\n    if gpu_percent is not None:\n        self.gui.gpu_bar.setValue(int(gpu_percent))\n        self.gui.gpu_bar.setFormat(f\"{gpu_percent:.0f}%\")\n        self.gui.gpu_available = True  # Reset to True if we get data\n    else:\n        self.gui.gpu_bar.setValue(0)\n        self.gui.gpu_bar.setFormat(\"N/A\")\n        # Don't set gpu_available to False here - allow recovery\n\n    # Store current values for plot update (updated less frequently via graph_manager)\n    self._last_cpu_percent = cpu_percent\n    self._last_ram_percent = ram_percent\n    self._last_gpu_percent = gpu_percent\n\n    # Get GPU VRAM utilization for plot (not shown in main tab)\n    # Always try to get VRAM data, not just when gpu_available is True\n    # This allows recovery after temporary failures\n    vram_info = SystemMonitor.get_gpu_vram_utilization()\n    if vram_info is not None:\n        used_vram_gb, total_vram_gb = vram_info\n        if total_vram_gb &gt; 0:\n            self._last_gpu_vram_percent = (used_vram_gb / total_vram_gb) * 100\n            self.gui.gpu_available = True  # Reset to True if we get VRAM data\n        else:\n            self._last_gpu_vram_percent = None\n    else:\n        self._last_gpu_vram_percent = None\n\n    # Get disk I/O throughput for plot (not shown in main tab)\n    disk_io = SystemMonitor.get_disk_io_throughput()\n    if disk_io is not None:\n        self._last_disk_read_mbps, self._last_disk_write_mbps = disk_io\n    else:\n        self._last_disk_read_mbps = None\n        self._last_disk_write_mbps = None\n\n    # Get page faults per second for plot (indicates memory pressure)\n    self._last_page_faults_per_sec = SystemMonitor.get_page_faults_per_second()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.utilization_manager.UtilizationManager.update_plot","title":"update_plot","text":"<pre><code>update_plot() -&gt; None\n</code></pre> <p>Updates the system utilization plot with current values.</p> <p>Called less frequently (every 2 seconds) to avoid excessive plot updates. Writes to CSV and adds data point to plot.</p> Source code in <code>goliat/gui/components/utilization_manager.py</code> <pre><code>def update_plot(self) -&gt; None:\n    \"\"\"Updates the system utilization plot with current values.\n\n    Called less frequently (every 2 seconds) to avoid excessive plot updates.\n    Writes to CSV and adds data point to plot.\n    \"\"\"\n    current_time = get_ntp_utc_time()  # Use NTP time (bypasses system clock issues)\n\n    # Write to CSV (includes RAM, GPU VRAM, and disk I/O)\n    try:\n        self.gui.data_manager.write_system_utilization(\n            self._last_cpu_percent,\n            self._last_ram_percent,\n            self._last_gpu_percent,\n            self._last_gpu_vram_percent,\n            self._last_disk_read_mbps,\n            self._last_disk_write_mbps,\n        )\n    except Exception as e:\n        self.gui.verbose_logger.error(f\"[UtilizationPlot] CSV write failed: {e}\")\n\n    # Add to system utilization plot (CPU, RAM, GPU, VRAM)\n    if hasattr(self.gui, \"system_utilization_plot\"):\n        # Get system info for legend\n        from goliat.gui.components.system_monitor import SystemMonitor\n\n        cpu_cores = SystemMonitor.get_cpu_cores()\n        total_ram_gb = SystemMonitor.get_total_ram_gb()\n        gpu_name = SystemMonitor.get_gpu_name()\n\n        # Get GPU VRAM total for legend\n        # Always try to get VRAM info, not just when gpu_available is True\n        total_gpu_vram_gb = 0.0\n        vram_info = SystemMonitor.get_gpu_vram_utilization()\n        if vram_info is not None:\n            _, total_gpu_vram_gb = vram_info\n\n        try:\n            self.gui.system_utilization_plot.add_data_point(\n                timestamp=current_time,\n                cpu_percent=self._last_cpu_percent,\n                ram_percent=self._last_ram_percent,\n                gpu_percent=self._last_gpu_percent,\n                gpu_vram_percent=self._last_gpu_vram_percent,\n                cpu_cores=cpu_cores,\n                total_ram_gb=total_ram_gb,\n                gpu_name=gpu_name,\n                total_gpu_vram_gb=total_gpu_vram_gb,\n            )\n        except Exception as e:\n            self.gui.verbose_logger.error(f\"[UtilizationPlot] Failed to add plot data point: {e}\")\n    else:\n        self.gui.verbose_logger.warning(\"[UtilizationPlot] system_utilization_plot attribute not found on GUI\")\n\n    # Add to disk I/O plot (includes page faults on secondary axis)\n    if hasattr(self.gui, \"disk_io_plot\"):\n        try:\n            self.gui.disk_io_plot.add_data_point(\n                timestamp=current_time,\n                disk_read_mbps=self._last_disk_read_mbps,\n                disk_write_mbps=self._last_disk_write_mbps,\n                page_faults_per_sec=self._last_page_faults_per_sec,\n            )\n        except Exception as e:\n            self.gui.verbose_logger.error(f\"[DiskIOPlot] Failed to add plot data point: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.web_bridge_manager.WebBridgeManager","title":"goliat.gui.components.web_bridge_manager.WebBridgeManager","text":"<pre><code>WebBridgeManager(gui: ProgressGUI, server_url: str, machine_id: Optional[str], use_web: bool = True)\n</code></pre> <p>Manages web GUI bridge initialization and status updates.</p> <p>Handles connection to web dashboard, collects system info, and manages bridge lifecycle. Keeps web bridge code exactly as is per requirements.</p> <p>Parameters:</p> Name Type Description Default <code>gui</code> <code>ProgressGUI</code> <p>ProgressGUI instance.</p> required <code>server_url</code> <code>str</code> <p>Web dashboard server URL.</p> required <code>machine_id</code> <code>Optional[str]</code> <p>Machine ID for identification.</p> required <code>use_web</code> <code>bool</code> <p>Whether to enable web bridge (default: True).</p> <code>True</code> Source code in <code>goliat/gui/components/web_bridge_manager.py</code> <pre><code>def __init__(self, gui: \"ProgressGUI\", server_url: str, machine_id: Optional[str], use_web: bool = True) -&gt; None:\n    \"\"\"Initializes web bridge manager.\n\n    Args:\n        gui: ProgressGUI instance.\n        server_url: Web dashboard server URL.\n        machine_id: Machine ID for identification.\n        use_web: Whether to enable web bridge (default: True).\n    \"\"\"\n    self.gui = gui\n    self.server_url = server_url\n    self.machine_id = machine_id\n    self.use_web = use_web\n    self.web_bridge: Optional[Any] = None\n    self.screenshot_timer: Optional[Any] = None\n    self.screenshot_capture: Optional[Any] = None\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.web_bridge_manager.WebBridgeManager-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.web_bridge_manager.WebBridgeManager.initialize","title":"initialize","text":"<pre><code>initialize() -&gt; None\n</code></pre> <p>Initializes web GUI bridge for remote monitoring.</p> <p>Sets up connection to web dashboard, collects system info, and starts the bridge. Errors are caught so GUI can continue without web monitoring.</p> Source code in <code>goliat/gui/components/web_bridge_manager.py</code> <pre><code>def initialize(self) -&gt; None:\n    \"\"\"Initializes web GUI bridge for remote monitoring.\n\n    Sets up connection to web dashboard, collects system info, and starts\n    the bridge. Errors are caught so GUI can continue without web monitoring.\n    \"\"\"\n    if not self.use_web:\n        # Web bridge disabled via config\n        if hasattr(self.gui, \"error_counter_label\") and hasattr(self.gui, \"status_manager\"):\n            self.gui._update_web_status(False)\n        return\n\n    if self.machine_id:\n        try:\n            from goliat.utils.gui_bridge import WebGUIBridge\n            from goliat.gui.components.system_monitor import SystemMonitor\n\n            self.web_bridge = WebGUIBridge(self.server_url, self.machine_id)\n\n            # Collect system info\n            gpu_name = SystemMonitor.get_gpu_name()\n            cpu_cores = SystemMonitor.get_cpu_cores()\n            total_ram_gb = SystemMonitor.get_total_ram_gb()\n            hostname = socket.gethostname()\n\n            system_info = {\"gpuName\": gpu_name or \"N/A\", \"cpuCores\": cpu_cores, \"totalRamGB\": total_ram_gb, \"hostname\": hostname}\n            self.web_bridge.set_system_info(system_info)\n\n            # Set callback to update GUI indicator BEFORE starting\n            self.web_bridge.set_connection_callback(self.gui._update_web_status)\n            # start() already sends initial heartbeat, no need to send again\n            self.web_bridge.start()\n\n            # Initialize screenshot capture\n            self._initialize_screenshot_capture()\n\n            self.gui.verbose_logger.info(f\"Web GUI bridge enabled: {self.server_url}, machine_id={self.machine_id}\")\n            self.gui.verbose_logger.info(\n                f\"System info: GPU={gpu_name or 'N/A'}, CPU={cpu_cores} cores, RAM={total_ram_gb:.1f} GB, Hostname={hostname}\"\n            )\n        except Exception as e:\n            self.gui.verbose_logger.warning(f\"Failed to initialize web GUI bridge: {e}. Continuing without web monitoring.\")\n            if hasattr(self.gui, \"error_counter_label\") and hasattr(self.gui, \"status_manager\"):\n                self.gui._update_web_status(False)\n    else:\n        if hasattr(self.gui, \"error_counter_label\") and hasattr(self.gui, \"status_manager\"):\n            self.gui._update_web_status(False)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.web_bridge_manager.WebBridgeManager.sync_progress","title":"sync_progress","text":"<pre><code>sync_progress() -&gt; None\n</code></pre> <p>Periodically sync actual GUI progress bar values to web dashboard.</p> <p>Sends the current progress bar values to the web bridge so the dashboard always shows the actual progress, even if progress messages aren't sent.</p> Source code in <code>goliat/gui/components/web_bridge_manager.py</code> <pre><code>def sync_progress(self) -&gt; None:\n    \"\"\"Periodically sync actual GUI progress bar values to web dashboard.\n\n    Sends the current progress bar values to the web bridge so the dashboard\n    always shows the actual progress, even if progress messages aren't sent.\n    \"\"\"\n    if self.web_bridge is None:\n        return\n\n    try:\n        # Get actual progress bar values\n        overall_value = self.gui.overall_progress_bar.value()\n        overall_max = self.gui.overall_progress_bar.maximum()\n        overall_progress = (overall_value / overall_max * 100) if overall_max &gt; 0 else 0\n\n        stage_value = self.gui.stage_progress_bar.value()\n        stage_max = self.gui.stage_progress_bar.maximum()\n        stage_progress = (stage_value / stage_max * 100) if stage_max &gt; 0 else 0\n\n        # Send overall progress\n        if overall_progress &gt; 0:\n            self.web_bridge.enqueue({\"type\": \"overall_progress\", \"current\": overall_progress, \"total\": 100})\n\n        # Send stage progress if we have a stage name\n        if stage_progress &gt; 0 and hasattr(self.gui, \"stage_label\"):\n            stage_name = self.gui.stage_label.text().replace(\"Current Stage: \", \"\")\n            if stage_name and stage_name != \"Current Stage:\":\n                self.web_bridge.enqueue({\"type\": \"stage_progress\", \"name\": stage_name, \"current\": stage_progress, \"total\": 100})\n    except Exception as e:\n        # Don't let progress sync errors break the GUI\n        if hasattr(self.gui, \"verbose_logger\"):\n            self.gui.verbose_logger.debug(f\"Failed to sync progress to web: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.web_bridge_manager.WebBridgeManager.stop","title":"stop","text":"<pre><code>stop() -&gt; None\n</code></pre> <p>Stops the web bridge and screenshot capture.</p> Source code in <code>goliat/gui/components/web_bridge_manager.py</code> <pre><code>def stop(self) -&gt; None:\n    \"\"\"Stops the web bridge and screenshot capture.\"\"\"\n    # Stop screenshot timer\n    if self.screenshot_timer is not None:\n        try:\n            self.screenshot_timer.stop()\n        except Exception as e:\n            if hasattr(self.gui, \"verbose_logger\"):\n                self.gui.verbose_logger.warning(f\"Error stopping screenshot timer: {e}\")\n\n    # Stop web bridge\n    if self.web_bridge is not None:\n        try:\n            self.web_bridge.stop()\n        except Exception as e:\n            if hasattr(self.gui, \"verbose_logger\"):\n                self.gui.verbose_logger.warning(f\"Error stopping web bridge: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.web_bridge_manager.WebBridgeManager.send_finished","title":"send_finished","text":"<pre><code>send_finished(error: bool = False) -&gt; None\n</code></pre> <p>Sends final status update to web before stopping bridge.</p> <p>Sends multiple 100% progress updates with delays to ensure the cloud receives them even if it's lagging behind. This prevents tasks from appearing stuck at 99% on the web interface.</p> <p>Parameters:</p> Name Type Description Default <code>error</code> <code>bool</code> <p>Whether study finished with errors.</p> <code>False</code> Source code in <code>goliat/gui/components/web_bridge_manager.py</code> <pre><code>def send_finished(self, error: bool = False) -&gt; None:\n    \"\"\"Sends final status update to web before stopping bridge.\n\n    Sends multiple 100% progress updates with delays to ensure the cloud\n    receives them even if it's lagging behind. This prevents tasks from\n    appearing stuck at 99% on the web interface.\n\n    Args:\n        error: Whether study finished with errors.\n    \"\"\"\n    # Stop screenshot timer first to prevent new screenshots from being queued\n    if self.screenshot_timer is not None:\n        try:\n            self.screenshot_timer.stop()\n        except Exception as e:\n            if hasattr(self.gui, \"verbose_logger\"):\n                self.gui.verbose_logger.warning(f\"Error stopping screenshot timer: {e}\")\n\n    if self.web_bridge is not None:\n        try:\n            import time\n\n            # Check if bridge is still running before sending messages\n            if not self.web_bridge.running:\n                # Bridge already stopped, just ensure screenshot timer is stopped\n                return\n\n            # Send multiple 100% progress updates with delays to ensure cloud receives them\n            # Cloud is often lagging behind, so we send updates multiple times\n            for i in range(5):  # Send 5 times to ensure at least one gets through\n                # Check if bridge is still running before each enqueue\n                if not self.web_bridge.running:\n                    break\n                self.web_bridge.enqueue({\"type\": \"overall_progress\", \"current\": 100, \"total\": 100})\n                # Also send stage progress at 100% if we have a stage name\n                if hasattr(self.gui, \"stage_label\"):\n                    stage_name = self.gui.stage_label.text().replace(\"Current Stage: \", \"\")\n                    if stage_name and stage_name != \"Current Stage:\":\n                        self.web_bridge.enqueue({\"type\": \"stage_progress\", \"name\": stage_name, \"current\": 100, \"total\": 100})\n                if i &lt; 4:  # Don't sleep after the last iteration\n                    time.sleep(0.5)  # 500ms delay between updates\n\n            # Send finished message only if bridge is still running\n            if self.web_bridge.running:\n                self.web_bridge.enqueue(\n                    {\"type\": \"finished\", \"message\": \"Study finished successfully\" if not error else \"Study finished with errors\"}\n                )\n\n                # Wait longer for final messages to send (cloud might be processing previous updates)\n                time.sleep(3)  # Increased from 1s to 3s to give cloud more time\n\n            # Stop the bridge (safe to call even if already stopped)\n            self.web_bridge.stop()\n        except Exception as e:\n            if hasattr(self.gui, \"verbose_logger\"):\n                self.gui.verbose_logger.warning(f\"Error stopping web bridge: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#components-plots","title":"Components / Plots","text":""},{"location":"reference/api_reference/#goliat.gui.components.plots._matplotlib_imports","title":"goliat.gui.components.plots._matplotlib_imports","text":"<p>Matplotlib imports with fallback handling for plotting components.</p>"},{"location":"reference/api_reference/#goliat.gui.components.plots.overall_progress_plot.OverallProgressPlot","title":"goliat.gui.components.plots.overall_progress_plot.OverallProgressPlot","text":"<pre><code>OverallProgressPlot()\n</code></pre> <p>Manages overall progress plot with real-time updates.</p> <p>Creates a matplotlib line plot showing progress percentage trends over time. Updates dynamically as new data points arrive. Uses green color scheme to distinguish from time remaining plot. Y-axis fixed at 0-100%.</p> Source code in <code>goliat/gui/components/plots/overall_progress_plot.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Sets up matplotlib figure and axes with dark theme.\"\"\"\n    if Figure is None or FigureCanvas is None:\n        raise ImportError(\"matplotlib is required for plotting\")\n    from matplotlib.figure import Figure as _Figure\n    from matplotlib.backends.backend_qtagg import FigureCanvasQTAgg as _FigureCanvas\n    from matplotlib.axes import Axes as _Axes\n\n    self.figure: _Figure = _Figure(figsize=(10, 6), facecolor=\"#2b2b2b\")\n    self.canvas: _FigureCanvas = _FigureCanvas(self.figure)\n    self.ax: _Axes = self.figure.add_subplot(111)\n    self.data: List[Tuple[datetime, float]] = []\n    self.max_progress_seen: float = 0.0\n    self._setup()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.overall_progress_plot.OverallProgressPlot-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.plots.overall_progress_plot.OverallProgressPlot.add_data_point","title":"add_data_point","text":"<pre><code>add_data_point(timestamp: datetime, progress_percent: float) -&gt; None\n</code></pre> <p>Adds data point and refreshes plot.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>datetime</code> <p>Timestamp for the data point.</p> required <code>progress_percent</code> <code>float</code> <p>Progress percentage as float.</p> required Source code in <code>goliat/gui/components/plots/overall_progress_plot.py</code> <pre><code>def add_data_point(self, timestamp: datetime, progress_percent: float) -&gt; None:\n    \"\"\"Adds data point and refreshes plot.\n\n    Args:\n        timestamp: Timestamp for the data point.\n        progress_percent: Progress percentage as float.\n    \"\"\"\n    if progress_percent &gt; self.max_progress_seen:\n        self.max_progress_seen = progress_percent\n    # Convert timestamp to UTC+1\n    utc_plus_one_timestamp = convert_to_utc_plus_one(timestamp)\n\n    # Validate timestamp: reject if it's anomalously far from the last timestamp\n    # This prevents spikes from corrupted timestamps (e.g., from NTP cache issues)\n    if self.data and not validate_timestamp(utc_plus_one_timestamp, self.data[-1][0]):\n        # Skip this data point - timestamp is anomalous\n        return\n\n    self.data.append((utc_plus_one_timestamp, progress_percent))\n    self._refresh()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.pie_charts_manager.PieChartsManager","title":"goliat.gui.components.plots.pie_charts_manager.PieChartsManager","text":"<pre><code>PieChartsManager()\n</code></pre> <p>Manages four pie charts displaying timing breakdowns by phase and subtask.</p> <p>Shows visual breakdown of execution time: - Top-left: Phase weights (setup/run/extract relative durations) - Top-right: Setup subtasks breakdown - Bottom-left: Run subtasks breakdown - Bottom-right: Extract subtasks breakdown</p> <p>Updates automatically when profiler state changes. Filters out fake aggregated entries. Uses color palette for visual distinction.</p> Source code in <code>goliat/gui/components/plots/pie_charts_manager.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Sets up matplotlib figure with 2x2 subplot grid.\"\"\"\n    if Figure is None or FigureCanvas is None:\n        raise ImportError(\"matplotlib is required for plotting\")\n    from matplotlib.figure import Figure as _Figure\n    from matplotlib.backends.backend_qtagg import FigureCanvasQTAgg as _FigureCanvas\n    from matplotlib.axes import Axes as _Axes\n\n    self.figure: _Figure = _Figure(figsize=(12, 10), facecolor=\"#2b2b2b\")\n    self.canvas: _FigureCanvas = _FigureCanvas(self.figure)\n    self.axes: List[_Axes] = [\n        self.figure.add_subplot(221),  # Top-left: Phase weights\n        self.figure.add_subplot(222),  # Top-right: Setup subtasks\n        self.figure.add_subplot(223),  # Bottom-left: Run subtasks\n        self.figure.add_subplot(224),  # Bottom-right: Extract subtasks\n    ]\n    self._setup()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.pie_charts_manager.PieChartsManager-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.plots.pie_charts_manager.PieChartsManager.update","title":"update","text":"<pre><code>update(profiler: Profiler) -&gt; None\n</code></pre> <p>Updates pie charts with timing data from profiler.</p> <p>Collects phase weights and subtask timing data, filters out fake aggregated entries, and renders pie charts with percentages. Charts show relative time spent in each phase/subtask, helping identify bottlenecks.</p> <p>Parameters:</p> Name Type Description Default <code>profiler</code> <code>Profiler</code> <p>Profiler instance containing timing data.</p> required Source code in <code>goliat/gui/components/plots/pie_charts_manager.py</code> <pre><code>def update(self, profiler: \"Profiler\") -&gt; None:\n    \"\"\"Updates pie charts with timing data from profiler.\n\n    Collects phase weights and subtask timing data, filters out fake\n    aggregated entries, and renders pie charts with percentages. Charts\n    show relative time spent in each phase/subtask, helping identify\n    bottlenecks.\n\n    Args:\n        profiler: Profiler instance containing timing data.\n    \"\"\"\n    if not profiler:\n        return\n\n    colors = [\"#ff6b6b\", \"#4ecdc4\", \"#45b7d1\", \"#f9ca24\", \"#6c5ce7\", \"#00b894\", \"#fdcb6e\", \"#e17055\"]\n\n    # Chart 0 (Top-left): Phase Weights\n    ax0 = self.axes[0]\n    ax0.clear()\n    ax0.set_facecolor(\"#2b2b2b\")\n\n    # Get phase weights/times\n    phase_weights: Dict[str, float] = {}\n    for phase in [\"setup\", \"run\", \"extract\"]:\n        avg_time = profiler.profiling_config.get(f\"avg_{phase}_time\")\n        if avg_time is not None:\n            phase_weights[phase.capitalize()] = avg_time\n\n    if phase_weights:\n        labels = list(phase_weights.keys())\n        sizes = list(phase_weights.values())\n\n        # Group small slices into \"Others\"\n        labels, sizes = self._group_small_slices(labels, sizes, threshold_percent=3.0)\n\n        pie_result = ax0.pie(\n            sizes,\n            labels=labels,\n            autopct=\"%1.1f%%\",\n            startangle=90,\n            colors=[\"#ff6b6b\", \"#4ecdc4\", \"#45b7d1\"],\n            textprops={\"color\": \"#f0f0f0\", \"fontsize\": 10},\n        )\n\n        autotexts = pie_result[2] if len(pie_result) &gt; 2 else []\n        for autotext in autotexts:\n            autotext.set_color(\"#2b2b2b\")\n            autotext.set_fontweight(\"bold\")\n            autotext.set_fontsize(9)\n\n        ax0.set_title(\"Phase Weights\", fontsize=12, color=\"#f0f0f0\", pad=10)\n    else:\n        ax0.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\", fontsize=12, color=\"#f0f0f0\", transform=ax0.transAxes)\n        ax0.set_title(\"Phase Weights\", fontsize=12, color=\"#f0f0f0\", pad=10)\n        # Hide axes when showing \"No data\"\n        ax0.set_xticks([])\n        ax0.set_yticks([])\n        ax0.spines[\"top\"].set_visible(False)\n        ax0.spines[\"right\"].set_visible(False)\n        ax0.spines[\"bottom\"].set_visible(False)\n        ax0.spines[\"left\"].set_visible(False)\n\n    # Charts 1-3: Subtasks for each phase\n    phases = [\"setup\", \"run\", \"extract\"]\n    phase_titles = [\"Setup Subtasks\", \"Run Subtasks\", \"Extract Subtasks\"]\n\n    for i, (phase, title) in enumerate(zip(phases, phase_titles), start=1):\n        ax = self.axes[i]\n        ax.clear()\n        ax.set_facecolor(\"#2b2b2b\")\n\n        # Collect subtask data for this phase\n        # Filter out fake aggregated entries\n        fake_entries = [\"simulation\", \"simulation_total\", \"results_total\"]\n\n        subtask_data: Dict[str, float] = {}\n        for key, value in profiler.profiling_config.items():\n            if key.startswith(f\"avg_{phase}_\") and key != f\"avg_{phase}_time\":\n                # Extract the subtask name (everything after \"avg_{phase}_\")\n                subtask_key = key.replace(f\"avg_{phase}_\", \"\")\n\n                # Skip fake aggregated entries\n                if subtask_key in fake_entries:\n                    continue\n\n                task_name = self._format_task_label(subtask_key)\n                subtask_data[task_name] = value\n\n        if subtask_data:\n            labels = list(subtask_data.keys())\n            sizes = list(subtask_data.values())\n\n            # Group small slices into \"Others\"\n            labels, sizes = self._group_small_slices(labels, sizes, threshold_percent=3.0)\n\n            # Create pie chart\n            pie_result = ax.pie(\n                sizes,\n                labels=labels,\n                autopct=\"%1.1f%%\",\n                startangle=90,\n                colors=colors[: len(labels)],\n                textprops={\"color\": \"#f0f0f0\", \"fontsize\": 9},\n            )\n\n            # Unpack result safely\n            autotexts = pie_result[2] if len(pie_result) &gt; 2 else []\n\n            # Enhance text visibility\n            for autotext in autotexts:\n                autotext.set_color(\"#2b2b2b\")\n                autotext.set_fontweight(\"bold\")\n                autotext.set_fontsize(8)\n\n            ax.set_title(title, fontsize=12, color=\"#f0f0f0\", pad=10)\n        else:\n            ax.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\", fontsize=12, color=\"#f0f0f0\", transform=ax.transAxes)\n            ax.set_title(title, fontsize=12, color=\"#f0f0f0\", pad=10)\n            # Hide axes when showing \"No data\"\n            ax.set_xticks([])\n            ax.set_yticks([])\n            ax.spines[\"top\"].set_visible(False)\n            ax.spines[\"right\"].set_visible(False)\n            ax.spines[\"bottom\"].set_visible(False)\n            ax.spines[\"left\"].set_visible(False)\n\n    self.figure.tight_layout()\n    self.canvas.draw()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.system_utilization_plot.SystemUtilizationPlot","title":"goliat.gui.components.plots.system_utilization_plot.SystemUtilizationPlot","text":"<pre><code>SystemUtilizationPlot()\n</code></pre> <p>Manages system utilization plot with real-time updates.</p> <p>Creates a matplotlib line plot showing CPU, RAM, GPU utilization, and GPU VRAM utilization percentages over time. Updates dynamically as new data points arrive.</p> <p>Y-axis: Utilization (0-105%) for CPU, RAM, GPU, VRAM</p> <p>GPU lines only shown if GPU is available.</p> Source code in <code>goliat/gui/components/plots/system_utilization_plot.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Sets up matplotlib figure and axes with dark theme.\"\"\"\n    if Figure is None or FigureCanvas is None:\n        raise ImportError(\"matplotlib is required for plotting\")\n    from matplotlib.figure import Figure as _Figure\n    from matplotlib.backends.backend_qtagg import FigureCanvasQTAgg as _FigureCanvas\n    from matplotlib.axes import Axes as _Axes\n\n    self.figure: _Figure = _Figure(figsize=(10, 6), facecolor=\"#2b2b2b\")\n    self.canvas: _FigureCanvas = _FigureCanvas(self.figure)\n    self.ax: _Axes = self.figure.add_subplot(111)\n\n    self.cpu_data: List[Tuple[datetime, float]] = []\n    self.ram_data: List[Tuple[datetime, float]] = []\n    self.gpu_data: List[Tuple[datetime, Optional[float]]] = []\n    self.gpu_vram_data: List[Tuple[datetime, Optional[float]]] = []\n    self.gpu_available: bool = False\n\n    # System info for legend (will be populated when first data point is added)\n    self.cpu_cores: int = 0\n    self.total_ram_gb: float = 0.0\n    self.gpu_name: Optional[str] = None\n    self.total_gpu_vram_gb: float = 0.0\n\n    self._setup()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.system_utilization_plot.SystemUtilizationPlot-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.plots.system_utilization_plot.SystemUtilizationPlot.add_data_point","title":"add_data_point","text":"<pre><code>add_data_point(timestamp: datetime, cpu_percent: float, ram_percent: float, gpu_percent: Optional[float] = None, gpu_vram_percent: Optional[float] = None, cpu_cores: int = 0, total_ram_gb: float = 0.0, gpu_name: Optional[str] = None, total_gpu_vram_gb: float = 0.0) -&gt; None\n</code></pre> <p>Adds data point and refreshes plot.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>datetime</code> <p>Timestamp for the data point.</p> required <code>cpu_percent</code> <code>float</code> <p>CPU utilization percentage (0-100).</p> required <code>ram_percent</code> <code>float</code> <p>RAM utilization percentage (0-100).</p> required <code>gpu_percent</code> <code>Optional[float]</code> <p>GPU utilization percentage (0-100), or None if unavailable.</p> <code>None</code> <code>gpu_vram_percent</code> <code>Optional[float]</code> <p>GPU VRAM utilization percentage (0-100), or None if unavailable.</p> <code>None</code> <code>cpu_cores</code> <code>int</code> <p>Number of CPU cores (for legend).</p> <code>0</code> <code>total_ram_gb</code> <code>float</code> <p>Total RAM in GB (for legend).</p> <code>0.0</code> <code>gpu_name</code> <code>Optional[str]</code> <p>GPU model name (for legend).</p> <code>None</code> <code>total_gpu_vram_gb</code> <code>float</code> <p>Total GPU VRAM in GB (for legend).</p> <code>0.0</code> Source code in <code>goliat/gui/components/plots/system_utilization_plot.py</code> <pre><code>def add_data_point(\n    self,\n    timestamp: datetime,\n    cpu_percent: float,\n    ram_percent: float,\n    gpu_percent: Optional[float] = None,\n    gpu_vram_percent: Optional[float] = None,\n    cpu_cores: int = 0,\n    total_ram_gb: float = 0.0,\n    gpu_name: Optional[str] = None,\n    total_gpu_vram_gb: float = 0.0,\n) -&gt; None:\n    \"\"\"Adds data point and refreshes plot.\n\n    Args:\n        timestamp: Timestamp for the data point.\n        cpu_percent: CPU utilization percentage (0-100).\n        ram_percent: RAM utilization percentage (0-100).\n        gpu_percent: GPU utilization percentage (0-100), or None if unavailable.\n        gpu_vram_percent: GPU VRAM utilization percentage (0-100), or None if unavailable.\n        cpu_cores: Number of CPU cores (for legend).\n        total_ram_gb: Total RAM in GB (for legend).\n        gpu_name: GPU model name (for legend).\n        total_gpu_vram_gb: Total GPU VRAM in GB (for legend).\n    \"\"\"\n    # Store system info on first data point\n    if len(self.cpu_data) == 0:\n        self.cpu_cores = cpu_cores\n        self.total_ram_gb = total_ram_gb\n        self.gpu_name = gpu_name\n        self.total_gpu_vram_gb = total_gpu_vram_gb\n\n    # Convert timestamp to UTC+1\n    utc_plus_one_timestamp = convert_to_utc_plus_one(timestamp)\n\n    # Validate timestamp: reject if it's anomalously far from the last timestamp\n    # This prevents spikes from corrupted timestamps (e.g., from NTP cache issues)\n    if self.cpu_data and not validate_timestamp(utc_plus_one_timestamp, self.cpu_data[-1][0]):\n        # Skip this data point - timestamp is anomalous\n        return\n\n    self.cpu_data.append((utc_plus_one_timestamp, cpu_percent))\n    self.ram_data.append((utc_plus_one_timestamp, ram_percent))\n\n    self.gpu_data.append((utc_plus_one_timestamp, gpu_percent))\n    if gpu_percent is not None:\n        self.gpu_available = True\n\n    self.gpu_vram_data.append((utc_plus_one_timestamp, gpu_vram_percent))\n    if gpu_vram_percent is not None:\n        self.gpu_available = True\n\n    self._refresh()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.time_remaining_plot.TimeRemainingPlot","title":"goliat.gui.components.plots.time_remaining_plot.TimeRemainingPlot","text":"<pre><code>TimeRemainingPlot()\n</code></pre> <p>Manages time remaining plot with real-time updates.</p> <p>Creates a matplotlib line plot showing ETA trends over time. Updates dynamically as new data points arrive, maintaining dark theme styling consistent with GUI. Tracks maximum time seen to set Y-axis limits.</p> Source code in <code>goliat/gui/components/plots/time_remaining_plot.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Sets up matplotlib figure and axes with dark theme.\"\"\"\n    if Figure is None or FigureCanvas is None:\n        raise ImportError(\"matplotlib is required for plotting\")\n    from matplotlib.figure import Figure as _Figure\n    from matplotlib.backends.backend_qtagg import FigureCanvasQTAgg as _FigureCanvas\n    from matplotlib.axes import Axes as _Axes\n\n    self.figure: _Figure = _Figure(figsize=(10, 6), facecolor=\"#2b2b2b\")\n    self.canvas: _FigureCanvas = _FigureCanvas(self.figure)\n    self.ax: _Axes = self.figure.add_subplot(111)\n    self.data: List[Tuple[datetime, float]] = []\n    self.max_time_remaining_seen: float = 0.0\n    self._setup()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.time_remaining_plot.TimeRemainingPlot-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.plots.time_remaining_plot.TimeRemainingPlot.add_data_point","title":"add_data_point","text":"<pre><code>add_data_point(timestamp: datetime, hours_remaining: float) -&gt; None\n</code></pre> <p>Adds data point and refreshes plot.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>datetime</code> <p>Timestamp for the data point.</p> required <code>hours_remaining</code> <code>float</code> <p>Hours remaining as float.</p> required Source code in <code>goliat/gui/components/plots/time_remaining_plot.py</code> <pre><code>def add_data_point(self, timestamp: datetime, hours_remaining: float) -&gt; None:\n    \"\"\"Adds data point and refreshes plot.\n\n    Args:\n        timestamp: Timestamp for the data point.\n        hours_remaining: Hours remaining as float.\n    \"\"\"\n    if hours_remaining &gt; self.max_time_remaining_seen:\n        self.max_time_remaining_seen = hours_remaining\n    # Convert timestamp to UTC+1\n    utc_plus_one_timestamp = convert_to_utc_plus_one(timestamp)\n\n    # Validate timestamp: reject if it's anomalously far from the last timestamp\n    # This prevents spikes from corrupted timestamps (e.g., from NTP cache issues)\n    if self.data and not validate_timestamp(utc_plus_one_timestamp, self.data[-1][0]):\n        # Skip this data point - timestamp is anomalous\n        return\n\n    self.data.append((utc_plus_one_timestamp, hours_remaining))\n    self._refresh()\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.utils","title":"goliat.gui.components.plots.utils","text":"<p>Common utilities for plotting components.</p>"},{"location":"reference/api_reference/#goliat.gui.components.plots.utils-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.gui.components.plots.utils.get_ntp_utc_time","title":"get_ntp_utc_time","text":"<pre><code>get_ntp_utc_time() -&gt; datetime\n</code></pre> <p>Get current UTC time from NTP server (bypasses system clock).</p> <p>Uses NTP to get accurate time independent of system clock issues. Caches the result for 30 seconds to minimize performance impact. Falls back to system time if NTP query fails.</p> <p>Returns:</p> Type Description <code>datetime</code> <p>Current UTC time as timezone-aware datetime.</p> Source code in <code>goliat/gui/components/plots/utils.py</code> <pre><code>def get_ntp_utc_time() -&gt; datetime:\n    \"\"\"Get current UTC time from NTP server (bypasses system clock).\n\n    Uses NTP to get accurate time independent of system clock issues.\n    Caches the result for 30 seconds to minimize performance impact.\n    Falls back to system time if NTP query fails.\n\n    Returns:\n        Current UTC time as timezone-aware datetime.\n    \"\"\"\n    global _ntp_cache\n\n    # Check cache first\n    current_system_time = time.time()\n    if _ntp_cache is not None:\n        cached_time, cache_timestamp = _ntp_cache\n        elapsed = current_system_time - cache_timestamp\n\n        # If cache is still valid and elapsed time is reasonable\n        if 0 &lt;= elapsed &lt; _NTP_CACHE_DURATION:\n            # Return cached time adjusted by elapsed time since cache\n            return cached_time + timedelta(seconds=elapsed)\n        elif elapsed &lt; 0 or elapsed &gt; _NTP_CACHE_DURATION * 2:\n            # System clock jumped backwards or way forward - invalidate cache\n            # This prevents anomalous timestamps from corrupted cache adjustments\n            _ntp_cache = None\n\n    # Query NTP\n    try:\n        ntp_query = bytearray(48)\n        ntp_query[0] = 0x1B  # NTP version 3, client mode\n\n        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n        s.settimeout(2.0)  # 2 second timeout\n        s.sendto(ntp_query, (\"pool.ntp.org\", 123))\n        data, _ = s.recvfrom(48)\n        s.close()\n\n        # Extract timestamp from NTP response (bytes 40-44)\n        ntp_timestamp = struct.unpack(\"!I\", data[40:44])[0] - 2208988800  # Convert from NTP epoch to Unix epoch\n        utc_time = datetime.fromtimestamp(ntp_timestamp, tz=timezone.utc)\n\n        # Cache the result\n        _ntp_cache = (utc_time, current_system_time)\n        return utc_time\n    except Exception:\n        # Fallback to system time if NTP fails (but log a warning)\n        # In production, you might want to log this\n        fallback_time = datetime.now(timezone.utc)\n        # Still cache it to avoid repeated failures\n        _ntp_cache = (fallback_time, current_system_time)\n        return fallback_time\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.utils.convert_to_utc_plus_one","title":"convert_to_utc_plus_one","text":"<pre><code>convert_to_utc_plus_one(timestamp: datetime) -&gt; datetime\n</code></pre> <p>Convert a datetime to UTC+1 timezone.</p> <p>Handles both naive (assumed UTC) and timezone-aware datetimes. Works reliably across VMs worldwide by always normalizing to UTC first.</p> <p>Parameters:</p> Name Type Description Default <code>timestamp</code> <code>datetime</code> <p>Datetime to convert (can be naive or timezone-aware).       If naive, assumes it's already in UTC (recommended usage).</p> required <p>Returns:</p> Type Description <code>datetime</code> <p>Datetime in UTC+1 timezone (timezone-aware).</p> Source code in <code>goliat/gui/components/plots/utils.py</code> <pre><code>def convert_to_utc_plus_one(timestamp: datetime) -&gt; datetime:\n    \"\"\"Convert a datetime to UTC+1 timezone.\n\n    Handles both naive (assumed UTC) and timezone-aware datetimes.\n    Works reliably across VMs worldwide by always normalizing to UTC first.\n\n    Args:\n        timestamp: Datetime to convert (can be naive or timezone-aware).\n                  If naive, assumes it's already in UTC (recommended usage).\n\n    Returns:\n        Datetime in UTC+1 timezone (timezone-aware).\n    \"\"\"\n    utc_plus_one_tz = timezone(timedelta(hours=1))\n\n    # If timestamp is naive, assume it's UTC (most reliable for VMs worldwide)\n    if timestamp.tzinfo is None:\n        # Treat naive datetime as UTC\n        utc_timestamp = timestamp.replace(tzinfo=timezone.utc)\n    else:\n        # Convert timezone-aware datetime to UTC first\n        utc_timestamp = timestamp.astimezone(timezone.utc)\n\n    # Convert UTC to UTC+1\n    return utc_timestamp.astimezone(utc_plus_one_tz)\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.utils.validate_timestamp","title":"validate_timestamp","text":"<pre><code>validate_timestamp(new_timestamp: datetime, last_timestamp: datetime, max_seconds_diff: float = 300.0) -&gt; bool\n</code></pre> <p>Validate that a new timestamp is within reasonable range of the last timestamp.</p> <p>Prevents anomalous timestamps from causing plot artifacts (vertical spikes, overlapping lines).</p> <p>Parameters:</p> Name Type Description Default <code>new_timestamp</code> <code>datetime</code> <p>The new timestamp to validate.</p> required <code>last_timestamp</code> <code>datetime</code> <p>The previous timestamp to compare against.</p> required <code>max_seconds_diff</code> <code>float</code> <p>Maximum allowed difference in seconds (default 5 minutes).</p> <code>300.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if timestamp is valid (within range), False if anomalous.</p> Source code in <code>goliat/gui/components/plots/utils.py</code> <pre><code>def validate_timestamp(new_timestamp: datetime, last_timestamp: datetime, max_seconds_diff: float = 300.0) -&gt; bool:\n    \"\"\"Validate that a new timestamp is within reasonable range of the last timestamp.\n\n    Prevents anomalous timestamps from causing plot artifacts (vertical spikes, overlapping lines).\n\n    Args:\n        new_timestamp: The new timestamp to validate.\n        last_timestamp: The previous timestamp to compare against.\n        max_seconds_diff: Maximum allowed difference in seconds (default 5 minutes).\n\n    Returns:\n        True if timestamp is valid (within range), False if anomalous.\n    \"\"\"\n    time_diff = abs((new_timestamp - last_timestamp).total_seconds())\n    return time_diff &lt;= max_seconds_diff\n</code></pre>"},{"location":"reference/api_reference/#goliat.gui.components.plots.utils.clean_plot_data","title":"clean_plot_data","text":"<pre><code>clean_plot_data(data: List[Tuple[datetime, float]], max_seconds_diff: float = 300.0) -&gt; List[Tuple[datetime, float]]\n</code></pre> <p>Clean plot data by sorting, deduplicating, and filtering anomalies.</p> <p>Processes timestamped data to ensure it's ready for plotting: 1. Sorts by timestamp (chronological order) 2. Removes duplicate timestamps (keeps most recent value) 3. Filters out anomalous timestamps (too far from previous point)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>List[Tuple[datetime, float]]</code> <p>List of (timestamp, value) tuples to clean.</p> required <code>max_seconds_diff</code> <code>float</code> <p>Maximum allowed time difference between consecutive points (default 5 minutes).</p> <code>300.0</code> <p>Returns:</p> Type Description <code>List[Tuple[datetime, float]]</code> <p>Cleaned list of (timestamp, value) tuples, sorted chronologically.</p> Source code in <code>goliat/gui/components/plots/utils.py</code> <pre><code>def clean_plot_data(data: List[Tuple[datetime, float]], max_seconds_diff: float = 300.0) -&gt; List[Tuple[datetime, float]]:\n    \"\"\"Clean plot data by sorting, deduplicating, and filtering anomalies.\n\n    Processes timestamped data to ensure it's ready for plotting:\n    1. Sorts by timestamp (chronological order)\n    2. Removes duplicate timestamps (keeps most recent value)\n    3. Filters out anomalous timestamps (too far from previous point)\n\n    Args:\n        data: List of (timestamp, value) tuples to clean.\n        max_seconds_diff: Maximum allowed time difference between consecutive points (default 5 minutes).\n\n    Returns:\n        Cleaned list of (timestamp, value) tuples, sorted chronologically.\n    \"\"\"\n    if not data:\n        return data\n\n    # Sort by timestamp\n    sorted_data = sorted(data, key=lambda x: x[0])\n\n    # Remove duplicate timestamps (keep last occurrence)\n    seen: dict[datetime, float] = {}\n    for timestamp, value in sorted_data:\n        seen[timestamp] = value\n    deduplicated = [(t, v) for t, v in sorted(seen.items(), key=lambda x: x[0])]\n\n    # Filter out anomalous timestamps\n    filtered = [deduplicated[0]]  # Always keep first point\n    for i in range(1, len(deduplicated)):\n        prev_time = filtered[-1][0]\n        curr_time = deduplicated[i][0]\n        time_diff = abs((curr_time - prev_time).total_seconds())\n        # Keep point if it's within allowed range\n        if time_diff &lt;= max_seconds_diff:\n            filtered.append(deduplicated[i])\n\n    return filtered\n</code></pre>"},{"location":"reference/api_reference/#ai-assistant","title":"AI Assistant","text":"<p>AI-powered assistant for error diagnosis and code assistance.</p>"},{"location":"reference/api_reference/#assistant","title":"Assistant","text":""},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant","title":"goliat.ai.assistant.GOLIATAssistant","text":"<pre><code>GOLIATAssistant(backend: BackendType = 'openai', base_dir: Optional[str] = None, config: Optional[AIConfig] = None)\n</code></pre> <p>AI Assistant for GOLIAT with codebase understanding.</p> <p>Uses a simple but effective RAG approach: 1. Embed all code/docs into a local vector store 2. On query, find relevant chunks via semantic search 3. Send retrieved context + query to LLM (model chosen by complexity)</p> <p>Model Selection: - Simple questions \u2192 gpt-5-mini (fast, \\(0.25/\\)2.00 per 1M tokens) - Complex/debugging \u2192 gpt-5 (smart, \\(1.25/\\)10.00 per 1M tokens)</p> Example usage <p>assistant = GOLIATAssistant()</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>BackendType</code> <p>Which backend to use (\"openai\" uses OpenAI embeddings + GPT)</p> <code>'openai'</code> <code>base_dir</code> <code>Optional[str]</code> <p>Base directory of GOLIAT project. Auto-detected if None.</p> <code>None</code> <code>config</code> <code>Optional[AIConfig]</code> <p>Configuration instance. Uses default if None.</p> <code>None</code> Source code in <code>goliat/ai/assistant.py</code> <pre><code>def __init__(\n    self,\n    backend: BackendType = \"openai\",\n    base_dir: Optional[str] = None,\n    config: Optional[AIConfig] = None,\n):\n    \"\"\"Initialize the GOLIAT assistant.\n\n    Args:\n        backend: Which backend to use (\"openai\" uses OpenAI embeddings + GPT)\n        base_dir: Base directory of GOLIAT project. Auto-detected if None.\n        config: Configuration instance. Uses default if None.\n    \"\"\"\n    self.config = config or get_default_config()\n    self.config.backend = backend  # Override backend from config\n    self.base_dir = base_dir or self._find_base_dir()\n\n    # Initialize OpenAI client\n    self.client = self._init_openai()\n\n    # Initialize components\n    self.cost_tracker = CostTracker(self.config, self.base_dir)\n    self.indexer = EmbeddingIndexer(self.config, self.base_dir, self.client)\n    self.query_processor = QueryProcessor(self.config, self.client)\n    self.chat_handler = ChatHandler(self.config, self.indexer, self.query_processor, self.cost_tracker, self.client)\n\n    # Build or load the index\n    self.indexer.ensure_index()\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant--one-shot-question","title":"One-shot question","text":"<p>answer = assistant.ask(\"How does tissue grouping work?\")</p>"},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant--interactive-chat","title":"Interactive chat","text":"<p>assistant.chat()</p>"},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant--debug-an-error","title":"Debug an error","text":"<p>diagnosis = assistant.debug(error_message, log_context)</p>"},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant.get_cost_summary","title":"get_cost_summary","text":"<pre><code>get_cost_summary() -&gt; dict\n</code></pre> <p>Get cost summary for current session.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with total_cost, call_count, breakdown, and pricing info.</p> Source code in <code>goliat/ai/assistant.py</code> <pre><code>def get_cost_summary(self) -&gt; dict:\n    \"\"\"Get cost summary for current session.\n\n    Returns:\n        Dictionary with total_cost, call_count, breakdown, and pricing info.\n    \"\"\"\n    return self.cost_tracker.get_summary()\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant.ask","title":"ask","text":"<pre><code>ask(question: str, context: str = '', force_complex: Optional[bool] = None) -&gt; str\n</code></pre> <p>Ask a one-shot question about GOLIAT.</p> <p>Auto-selects model based on complexity: - Simple questions \u2192 gpt-5-mini (fast, cheap) - Complex questions \u2192 gpt-5 (smart, thorough)</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>The question to ask.</p> required <code>context</code> <code>str</code> <p>Optional additional context (e.g., error logs).</p> <code>''</code> <code>force_complex</code> <code>Optional[bool]</code> <p>None (auto-select), False (force simple), True (force complex)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The assistant's response.</p> Source code in <code>goliat/ai/assistant.py</code> <pre><code>    def ask(self, question: str, context: str = \"\", force_complex: Optional[bool] = None) -&gt; str:\n        \"\"\"Ask a one-shot question about GOLIAT.\n\n        Auto-selects model based on complexity:\n        - Simple questions \u2192 gpt-5-mini (fast, cheap)\n        - Complex questions \u2192 gpt-5 (smart, thorough)\n\n        Args:\n            question: The question to ask.\n            context: Optional additional context (e.g., error logs).\n            force_complex: None (auto-select), False (force simple), True (force complex)\n\n        Returns:\n            The assistant's response.\n        \"\"\"\n        self.indexer.ensure_index()\n\n        # Select model based on query complexity (single call to avoid duplicate classification)\n        model, complexity = self.query_processor.select_model_with_complexity(question, force_complex=force_complex)\n\n        # Search for relevant chunks (cost tracking handled inside)\n        relevant_chunks = self.indexer.search(question, cost_tracker=self.cost_tracker)\n\n        # Build context from retrieved chunks\n        retrieved_context = \"\\n\\n---\\n\\n\".join(chunk[\"content\"] for chunk in relevant_chunks)\n\n        # Build the prompt\n        user_message = f\"\"\"Based on the following code/documentation from the GOLIAT codebase:\n\n{retrieved_context}\n\n{f\"Additional context provided by user: {context}\" if context else \"\"}\n\nQuestion: {question}\n\nPlease provide a helpful, accurate answer based on the GOLIAT codebase.\"\"\"\n\n        # Build API call kwargs\n        create_kwargs = {\n            \"model\": model,\n            \"messages\": [{\"role\": \"system\", \"content\": self.config.system_prompt}, {\"role\": \"user\", \"content\": user_message}],\n        }\n        # Use max_completion_tokens for GPT-5, max_tokens for older models\n        if model.startswith(\"gpt-5\"):\n            create_kwargs[\"max_completion_tokens\"] = self.config.llm.max_output_tokens\n            # GPT-5 only supports default temperature (1), don't set it\n        else:\n            create_kwargs[\"max_tokens\"] = self.config.llm.max_output_tokens\n            # Set temperature for older models\n            temperature = self.config.llm.temperature_complex if complexity == \"complex\" else self.config.llm.temperature_simple\n            create_kwargs[\"temperature\"] = temperature\n\n        # Make API call\n        response = self.client.chat.completions.create(**create_kwargs)\n\n        # Track cost\n        if hasattr(response, \"usage\"):\n            usage = {\n                \"prompt_tokens\": response.usage.prompt_tokens,\n                \"completion_tokens\": response.usage.completion_tokens,\n                \"total_tokens\": response.usage.total_tokens,\n            }\n            cost = self.cost_tracker.calculate_cost(model, usage)\n            self.cost_tracker.track_call(\n                {\n                    \"type\": \"chat\",\n                    \"model\": model,\n                    \"complexity\": complexity,\n                    \"input_tokens\": usage[\"prompt_tokens\"],\n                    \"output_tokens\": usage[\"completion_tokens\"],\n                    \"total_tokens\": usage[\"total_tokens\"],\n                    \"cost\": cost,\n                }\n            )\n\n        content = response.choices[0].message.content\n        if not content or not content.strip():\n            return \"The AI model returned an empty response. This may indicate an API issue or the query was too complex.\"\n        return content\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant.chat","title":"chat","text":"<pre><code>chat() -&gt; None\n</code></pre> <p>Start an interactive chat session.</p> Source code in <code>goliat/ai/assistant.py</code> <pre><code>def chat(self) -&gt; None:\n    \"\"\"Start an interactive chat session.\"\"\"\n    self.chat_handler.start_chat()\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant.debug","title":"debug","text":"<pre><code>debug(error_message: str, log_context: str = '', config_snippet: str = '', model_selection: str = 'auto') -&gt; str\n</code></pre> <p>Debug an error with AI assistance.</p> <p>Parameters:</p> Name Type Description Default <code>error_message</code> <code>str</code> <p>The error message or exception.</p> required <code>log_context</code> <code>str</code> <p>Recent log output, shell context, or other debugging context.</p> <code>''</code> <code>config_snippet</code> <code>str</code> <p>Relevant config if applicable.</p> <code>''</code> <code>model_selection</code> <code>str</code> <p>Model selection mode - \"simple\", \"complex\", or \"auto\" (default).</p> <code>'auto'</code> <p>Returns:</p> Type Description <code>str</code> <p>Diagnosis and suggested fixes.</p> Source code in <code>goliat/ai/assistant.py</code> <pre><code>    def debug(self, error_message: str, log_context: str = \"\", config_snippet: str = \"\", model_selection: str = \"auto\") -&gt; str:\n        \"\"\"Debug an error with AI assistance.\n\n        Args:\n            error_message: The error message or exception.\n            log_context: Recent log output, shell context, or other debugging context.\n            config_snippet: Relevant config if applicable.\n            model_selection: Model selection mode - \"simple\", \"complex\", or \"auto\" (default).\n\n        Returns:\n            Diagnosis and suggested fixes.\n        \"\"\"\n        context_parts = []\n\n        if log_context:\n            context_parts.append(log_context)\n\n        if config_snippet:\n            context_parts.append(f\"Config:\\n```json\\n{config_snippet}\\n```\")\n\n        question = f\"\"\"I encountered this error while running GOLIAT:\n\n```\n{error_message}\n```\n\nPlease diagnose the issue and suggest specific fixes. Reference relevant code files if helpful.\nIf shell context is provided, use it to understand what commands were run and what might have gone wrong.\"\"\"\n\n        # Determine force_complex based on model_selection\n        if model_selection == \"simple\":\n            force_complex = False\n        elif model_selection == \"complex\":\n            force_complex = True\n        else:  # \"auto\"\n            force_complex = None  # Let ask() decide based on query complexity\n\n        return self.ask(question, \"\\n\\n\".join(context_parts), force_complex=force_complex)\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant.recommend","title":"recommend","text":"<pre><code>recommend(log_output: str) -&gt; Optional[str]\n</code></pre> <p>Analyze logs and provide recommendations if issues are detected.</p> <p>Parameters:</p> Name Type Description Default <code>log_output</code> <code>str</code> <p>Recent log output to analyze.</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Recommendations if issues detected, None otherwise.</p> Source code in <code>goliat/ai/assistant.py</code> <pre><code>    def recommend(self, log_output: str) -&gt; Optional[str]:\n        \"\"\"Analyze logs and provide recommendations if issues are detected.\n\n        Args:\n            log_output: Recent log output to analyze.\n\n        Returns:\n            Recommendations if issues detected, None otherwise.\n        \"\"\"\n        warning_keywords = [\"WARNING\", \"ERROR\", \"FATAL\", \"retry\", \"failed\", \"timeout\"]\n        has_issues = any(kw.lower() in log_output.lower() for kw in warning_keywords)\n\n        if not has_issues:\n            return None\n\n        question = f\"\"\"Analyze these GOLIAT logs and identify any issues that need attention:\n\n```\n{log_output[-self.config.error_advisor.max_log_chars :]}\n```\n\nIf there are concerning patterns (errors, excessive retries, warnings), explain what's wrong and how to fix it.\nIf the logs look normal, just say \"Logs look healthy.\"\nBe concise.\"\"\"\n\n        # Use complex model for log analysis\n        return self.ask(question, force_complex=True)\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.assistant.GOLIATAssistant.reindex","title":"reindex","text":"<pre><code>reindex() -&gt; None\n</code></pre> <p>Force reindex of the codebase.</p> Source code in <code>goliat/ai/assistant.py</code> <pre><code>def reindex(self) -&gt; None:\n    \"\"\"Force reindex of the codebase.\"\"\"\n    self.indexer.clear_cache()\n    print(f\"Rebuilding index with {self.config.models.embedding}...\")\n    self.indexer.ensure_index()\n</code></pre>"},{"location":"reference/api_reference/#chat-handler","title":"Chat Handler","text":""},{"location":"reference/api_reference/#goliat.ai.chat_handler.ChatHandler","title":"goliat.ai.chat_handler.ChatHandler","text":"<pre><code>ChatHandler(config: AIConfig, indexer: EmbeddingIndexer, query_processor: QueryProcessor, cost_tracker: CostTracker, client)\n</code></pre> <p>Handles interactive chat sessions.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AIConfig</code> <p>AI configuration</p> required <code>indexer</code> <code>EmbeddingIndexer</code> <p>Embedding indexer instance</p> required <code>query_processor</code> <code>QueryProcessor</code> <p>Query processor instance</p> required <code>cost_tracker</code> <code>CostTracker</code> <p>Cost tracker instance</p> required <code>client</code> <p>OpenAI client instance</p> required Source code in <code>goliat/ai/chat_handler.py</code> <pre><code>def __init__(\n    self,\n    config: AIConfig,\n    indexer: EmbeddingIndexer,\n    query_processor: QueryProcessor,\n    cost_tracker: CostTracker,\n    client,\n):\n    \"\"\"Initialize the chat handler.\n\n    Args:\n        config: AI configuration\n        indexer: Embedding indexer instance\n        query_processor: Query processor instance\n        cost_tracker: Cost tracker instance\n        client: OpenAI client instance\n    \"\"\"\n    self.config = config\n    self.indexer = indexer\n    self.query_processor = query_processor\n    self.cost_tracker = cost_tracker\n    self.client = client\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.chat_handler.ChatHandler-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.ai.chat_handler.ChatHandler.start_chat","title":"start_chat","text":"<pre><code>start_chat() -&gt; None\n</code></pre> <p>Start an interactive chat session.</p> Source code in <code>goliat/ai/chat_handler.py</code> <pre><code>def start_chat(self) -&gt; None:\n    \"\"\"Start an interactive chat session.\"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"GOLIAT AI Assistant - Interactive Chat\")\n    print(\"=\" * 60)\n    print(\"Model selection: simple queries \u2192 gpt-5-mini, complex \u2192 gpt-5\")\n    print(\"Ask anything about GOLIAT. Type 'exit' or 'quit' to end.\\n\")\n\n    conversation_history = []\n\n    while True:\n        try:\n            user_input = input(\"You: \").strip()\n        except (KeyboardInterrupt, EOFError):\n            print(\"\\nGoodbye!\")\n            break\n\n        if not user_input:\n            continue\n\n        if user_input.lower() in (\"exit\", \"quit\", \"q\"):\n            print(\"Goodbye!\")\n            break\n\n        if user_input.lower() == \"cost\":\n            self._show_cost_summary()\n            continue\n\n        # Select model and show which one is being used (single call to avoid duplicate classification)\n        model, complexity = self.query_processor.select_model_with_complexity(user_input)\n        print(f\"\\n[{complexity} query \u2192 {model}]\")\n        print(\"Assistant: \", end=\"\", flush=True)\n\n        # For chat, include conversation history\n        self.indexer.ensure_index()\n        relevant_chunks = self.indexer.search(user_input, cost_tracker=self.cost_tracker)\n        retrieved_context = \"\\n\\n---\\n\\n\".join(chunk[\"content\"] for chunk in relevant_chunks)\n\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": self.config.system_prompt + f\"\\n\\nRelevant code context:\\n{retrieved_context}\",\n            }\n        ]\n        messages.extend(conversation_history[-self.config.processing.chat_history_messages :])\n        messages.append({\"role\": \"user\", \"content\": user_input})\n\n        # Build API call kwargs\n        create_kwargs = self._build_chat_kwargs(model, complexity, messages)\n\n        response = self.client.chat.completions.create(**create_kwargs)\n\n        # Track cost\n        cost = 0.0\n        if hasattr(response, \"usage\") and response.usage:\n            usage = {\n                \"prompt_tokens\": response.usage.prompt_tokens,\n                \"completion_tokens\": response.usage.completion_tokens,\n                \"total_tokens\": response.usage.total_tokens,\n            }\n            cost = self.cost_tracker.calculate_cost(model, usage)\n            self.cost_tracker.track_call(\n                {\n                    \"type\": \"chat\",\n                    \"model\": model,\n                    \"complexity\": complexity,\n                    \"input_tokens\": usage[\"prompt_tokens\"],\n                    \"output_tokens\": usage[\"completion_tokens\"],\n                    \"total_tokens\": usage[\"total_tokens\"],\n                    \"cost\": cost,\n                }\n            )\n\n        answer = response.choices[0].message.content\n        print(answer)\n\n        # Show cost\n        if cost &gt; 0:\n            print(f\"\\n[Cost: ${cost:.6f} | Total: ${self.cost_tracker._total_cost:.6f}]\")\n\n        print()\n\n        # Update history\n        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n        conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n</code></pre>"},{"location":"reference/api_reference/#config","title":"Config","text":""},{"location":"reference/api_reference/#goliat.ai.config.ModelConfig","title":"goliat.ai.config.ModelConfig  <code>dataclass</code>","text":"<pre><code>ModelConfig(simple: str = 'gpt-5-mini', complex: str = 'gpt-5', embedding: str = 'text-embedding-3-large')\n</code></pre> <p>Configuration for AI models.</p>"},{"location":"reference/api_reference/#cost-tracker","title":"Cost Tracker","text":""},{"location":"reference/api_reference/#goliat.ai.cost_tracker.CostTracker","title":"goliat.ai.cost_tracker.CostTracker","text":"<pre><code>CostTracker(config: AIConfig, base_dir: str)\n</code></pre> <p>Tracks API costs and calculates pricing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AIConfig</code> <p>AI configuration</p> required <code>base_dir</code> <code>str</code> <p>Base directory of GOLIAT project</p> required Source code in <code>goliat/ai/cost_tracker.py</code> <pre><code>def __init__(self, config: AIConfig, base_dir: str):\n    \"\"\"Initialize the cost tracker.\n\n    Args:\n        config: AI configuration\n        base_dir: Base directory of GOLIAT project\n    \"\"\"\n    self.config = config\n    self.base_dir = base_dir\n    self._session_costs = []  # Track costs per call\n    self._total_cost = 0.0\n    self.pricing = self._load_pricing_config()\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.cost_tracker.CostTracker-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.ai.cost_tracker.CostTracker.calculate_cost","title":"calculate_cost","text":"<pre><code>calculate_cost(model: str, usage: dict) -&gt; float\n</code></pre> <p>Calculate cost from token usage using configured pricing.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Model name (e.g., \"gpt-5-mini\", \"text-embedding-3-large\")</p> required <code>usage</code> <code>dict</code> <p>Usage dict with prompt_tokens, completion_tokens, total_tokens</p> required <p>Returns:</p> Type Description <code>float</code> <p>Cost in USD</p> Source code in <code>goliat/ai/cost_tracker.py</code> <pre><code>def calculate_cost(self, model: str, usage: dict) -&gt; float:\n    \"\"\"Calculate cost from token usage using configured pricing.\n\n    Args:\n        model: Model name (e.g., \"gpt-5-mini\", \"text-embedding-3-large\")\n        usage: Usage dict with prompt_tokens, completion_tokens, total_tokens\n\n    Returns:\n        Cost in USD\n    \"\"\"\n    if model not in self.pricing:\n        return 0.0\n\n    cost = 0.0\n    pricing = self.pricing[model]\n\n    if \"input\" in pricing:\n        input_tokens = usage.get(\"prompt_tokens\", 0)\n        cost += (input_tokens / 1_000_000) * pricing[\"input\"]\n\n    if \"output\" in pricing:\n        output_tokens = usage.get(\"completion_tokens\", 0)\n        cost += (output_tokens / 1_000_000) * pricing[\"output\"]\n\n    return cost\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.cost_tracker.CostTracker.track_call","title":"track_call","text":"<pre><code>track_call(call_info: dict) -&gt; None\n</code></pre> <p>Track an API call and its cost.</p> <p>Parameters:</p> Name Type Description Default <code>call_info</code> <code>dict</code> <p>Dictionary with call details including 'cost'</p> required Source code in <code>goliat/ai/cost_tracker.py</code> <pre><code>def track_call(self, call_info: dict) -&gt; None:\n    \"\"\"Track an API call and its cost.\n\n    Args:\n        call_info: Dictionary with call details including 'cost'\n    \"\"\"\n    cost = call_info.get(\"cost\", 0.0)\n    self._total_cost += cost\n    self._session_costs.append(call_info)\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.cost_tracker.CostTracker.get_summary","title":"get_summary","text":"<pre><code>get_summary() -&gt; dict\n</code></pre> <p>Get cost summary for current session.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with total_cost, call_count, breakdown, and pricing info.</p> Source code in <code>goliat/ai/cost_tracker.py</code> <pre><code>def get_summary(self) -&gt; dict:\n    \"\"\"Get cost summary for current session.\n\n    Returns:\n        Dictionary with total_cost, call_count, breakdown, and pricing info.\n    \"\"\"\n    return {\n        \"total_cost\": self._total_cost,\n        \"call_count\": len(self._session_costs),\n        \"breakdown\": self._session_costs.copy(),\n        \"pricing_config\": self.pricing.copy(),\n    }\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.cost_tracker.CostTracker.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset cost tracking for a new session.</p> Source code in <code>goliat/ai/cost_tracker.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"Reset cost tracking for a new session.\"\"\"\n    self._session_costs = []\n    self._total_cost = 0.0\n</code></pre>"},{"location":"reference/api_reference/#embedding-indexer","title":"Embedding Indexer","text":""},{"location":"reference/api_reference/#goliat.ai.embedding_indexer.EmbeddingIndexer","title":"goliat.ai.embedding_indexer.EmbeddingIndexer","text":"<pre><code>EmbeddingIndexer(config: AIConfig, base_dir: str, client)\n</code></pre> <p>Handles codebase indexing, chunking, and embedding storage.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AIConfig</code> <p>AI configuration</p> required <code>base_dir</code> <code>str</code> <p>Base directory of GOLIAT project</p> required <code>client</code> <p>OpenAI client instance</p> required Source code in <code>goliat/ai/embedding_indexer.py</code> <pre><code>def __init__(self, config: AIConfig, base_dir: str, client):\n    \"\"\"Initialize the indexer.\n\n    Args:\n        config: AI configuration\n        base_dir: Base directory of GOLIAT project\n        client: OpenAI client instance\n    \"\"\"\n    self.config = config\n    self.base_dir = base_dir\n    self.client = client\n    self._embeddings_cache: dict = {}\n    self._index_ready = False\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.embedding_indexer.EmbeddingIndexer-attributes","title":"Attributes","text":""},{"location":"reference/api_reference/#goliat.ai.embedding_indexer.EmbeddingIndexer.is_ready","title":"is_ready  <code>property</code>","text":"<pre><code>is_ready: bool\n</code></pre> <p>Check if index is ready.</p>"},{"location":"reference/api_reference/#goliat.ai.embedding_indexer.EmbeddingIndexer-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.ai.embedding_indexer.EmbeddingIndexer.ensure_index","title":"ensure_index","text":"<pre><code>ensure_index() -&gt; None\n</code></pre> <p>Ensure the embedding index is ready.</p> Source code in <code>goliat/ai/embedding_indexer.py</code> <pre><code>def ensure_index(self) -&gt; None:\n    \"\"\"Ensure the embedding index is ready.\"\"\"\n    if self._index_ready:\n        return\n\n    cache_path = os.path.join(self.base_dir, self.config.indexing.cache_file)\n    current_hash = self._compute_codebase_hash()\n\n    # Check if cached index exists and can be loaded\n    if os.path.exists(cache_path):\n        try:\n            with open(cache_path, encoding=\"utf-8\") as f:\n                cache = json.load(f)\n\n            cached_hash = cache.get(\"index_hash\")\n            cached_model = cache.get(\"embedding_model\", \"text-embedding-3-small\")\n            has_embeddings = \"embeddings\" in cache and len(cache.get(\"embeddings\", {})) &gt; 0\n\n            # Check if we need to rebuild due to model change\n            if cached_model != self.config.models.embedding:\n                print(f\"[INFO] Embedding model changed ({cached_model} \u2192 {self.config.models.embedding}), rebuilding index...\")\n            elif has_embeddings:\n                # Use cache even if hash mismatches\n                self._embeddings_cache = cache[\"embeddings\"]\n                if cached_hash != current_hash:\n                    print(\"[WARNING] Using cached index, but codebase has changed.\")\n                    print(\"         Run 'goliat ask --reindex' to rebuild with latest code.\")\n                print(f\"[INFO] Loaded cached index ({len(self._embeddings_cache)} chunks, model: {cached_model})\")\n                self._index_ready = True\n                return\n            else:\n                print(\"Cache has no embeddings, rebuilding index...\")\n        except json.JSONDecodeError:\n            print(\"Cache file corrupted (JSON error), rebuilding index...\")\n        except Exception as e:\n            print(f\"Error loading cache ({type(e).__name__}), rebuilding index...\")\n\n    # Build new index\n    print(f\"Building codebase index with {self.config.models.embedding}...\")\n    self._build_index()\n\n    # Save cache\n    os.makedirs(os.path.dirname(cache_path), exist_ok=True)\n    with open(cache_path, \"w\") as f:\n        json.dump(\n            {\"index_hash\": current_hash, \"embedding_model\": self.config.models.embedding, \"embeddings\": self._embeddings_cache}, f\n        )\n\n    print(f\"[INFO] Index ready ({len(self._embeddings_cache)} chunks)\")\n    self._index_ready = True\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.embedding_indexer.EmbeddingIndexer.search","title":"search","text":"<pre><code>search(query: str, top_k: Optional[int] = None, cost_tracker=None) -&gt; list[dict]\n</code></pre> <p>Search for relevant chunks using embedding similarity.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Search query</p> required <code>top_k</code> <code>Optional[int]</code> <p>Number of chunks to return (default: config.rag.top_k_chunks)</p> <code>None</code> <code>cost_tracker</code> <p>Optional cost tracker to record embedding costs</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of relevant chunks sorted by similarity</p> Source code in <code>goliat/ai/embedding_indexer.py</code> <pre><code>def search(self, query: str, top_k: Optional[int] = None, cost_tracker=None) -&gt; list[dict]:\n    \"\"\"Search for relevant chunks using embedding similarity.\n\n    Args:\n        query: Search query\n        top_k: Number of chunks to return (default: config.rag.top_k_chunks)\n        cost_tracker: Optional cost tracker to record embedding costs\n\n    Returns:\n        List of relevant chunks sorted by similarity\n    \"\"\"\n    if top_k is None:\n        top_k = self.config.rag.top_k_chunks\n    response = self.client.embeddings.create(model=self.config.models.embedding, input=[query])\n\n    # Track embedding cost if tracker provided\n    if cost_tracker and hasattr(response, \"usage\"):\n        usage = {\"prompt_tokens\": response.usage.prompt_tokens, \"total_tokens\": response.usage.total_tokens}\n        cost = cost_tracker.calculate_cost(self.config.models.embedding, usage)\n        cost_tracker.track_call(\n            {\"type\": \"embedding\", \"model\": self.config.models.embedding, \"tokens\": usage[\"total_tokens\"], \"cost\": cost}\n        )\n\n    query_embedding = response.data[0].embedding\n\n    # Compute similarities\n    import math\n\n    def cosine_similarity(a, b):\n        \"\"\"Dot product divided by product of magnitudes.\"\"\"\n        dot = sum(x * y for x, y in zip(a, b))\n        norm_a = math.sqrt(sum(x * x for x in a))\n        norm_b = math.sqrt(sum(x * x for x in b))\n        return dot / (norm_a * norm_b) if norm_a and norm_b else 0\n\n    scored = []\n    for chunk_id, chunk_data in self._embeddings_cache.items():\n        score = cosine_similarity(query_embedding, chunk_data[\"embedding\"])\n        scored.append((score, chunk_data))\n\n    scored.sort(key=lambda x: x[0], reverse=True)\n    return [item[1] for item in scored[:top_k]]\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.embedding_indexer.EmbeddingIndexer.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache() -&gt; None\n</code></pre> <p>Clear the index cache and force rebuild.</p> Source code in <code>goliat/ai/embedding_indexer.py</code> <pre><code>def clear_cache(self) -&gt; None:\n    \"\"\"Clear the index cache and force rebuild.\"\"\"\n    cache_path = os.path.join(self.base_dir, self.config.indexing.cache_file)\n\n    if os.path.exists(cache_path):\n        os.remove(cache_path)\n        print(\"\u2713 Cleared existing cache.\")\n\n    self._embeddings_cache = {}\n    self._index_ready = False\n</code></pre>"},{"location":"reference/api_reference/#error-advisor","title":"Error Advisor","text":""},{"location":"reference/api_reference/#goliat.ai.error_advisor.Recommendation","title":"goliat.ai.error_advisor.Recommendation  <code>dataclass</code>","text":"<pre><code>Recommendation(severity: SeverityType, message: str, suggested_fix: str, related_files: list[str])\n</code></pre> <p>A recommendation from the AI advisor.</p>"},{"location":"reference/api_reference/#query-processor","title":"Query Processor","text":""},{"location":"reference/api_reference/#goliat.ai.query_processor.QueryProcessor","title":"goliat.ai.query_processor.QueryProcessor","text":"<pre><code>QueryProcessor(config: AIConfig, client=None)\n</code></pre> <p>Handles query classification and model selection.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AIConfig</code> <p>AI configuration</p> required <code>client</code> <p>OpenAI client instance (required for AI-based classification)</p> <code>None</code> Source code in <code>goliat/ai/query_processor.py</code> <pre><code>def __init__(self, config: AIConfig, client=None):\n    \"\"\"Initialize the query processor.\n\n    Args:\n        config: AI configuration\n        client: OpenAI client instance (required for AI-based classification)\n    \"\"\"\n    self.config = config\n    self.client = client\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.query_processor.QueryProcessor-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.ai.query_processor.QueryProcessor.classify_complexity","title":"classify_complexity","text":"<pre><code>classify_complexity(query: str) -&gt; ComplexityType\n</code></pre> <p>Classify a query as simple or complex to select the right model.</p> <p>Uses AI model to intelligently classify queries: - Simple queries \u2192 gpt-5-mini (fast, cheap) - Complex queries \u2192 gpt-5 (smart, thorough)</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The user's question or request</p> required <p>Returns:</p> Type Description <code>ComplexityType</code> <p>\"simple\" or \"complex\"</p> Source code in <code>goliat/ai/query_processor.py</code> <pre><code>    def classify_complexity(self, query: str) -&gt; ComplexityType:\n        \"\"\"Classify a query as simple or complex to select the right model.\n\n        Uses AI model to intelligently classify queries:\n        - Simple queries \u2192 gpt-5-mini (fast, cheap)\n        - Complex queries \u2192 gpt-5 (smart, thorough)\n\n        Args:\n            query: The user's question or request\n\n        Returns:\n            \"simple\" or \"complex\"\n        \"\"\"\n        if not self.client:\n            # Fallback to simple if no client available\n            return \"simple\"\n\n        # Use AI to classify the query\n        classification_prompt = f\"\"\"Classify the following query as either \"simple\" or \"complex\".\n\nA simple query is a straightforward question that can be answered quickly with basic information, like:\n- \"What is X?\"\n- \"Where is Y?\"\n- \"List Z\"\n- Quick lookups or definitions\n\nA complex query requires deeper reasoning, analysis, or multi-step problem solving, like:\n- Debugging errors or issues\n- Explaining how something works\n- Code implementation or refactoring\n- Architecture or design questions\n- Multi-step problem solving\n\nQuery: {query}\n\nRespond with only one word: \"simple\" or \"complex\".\"\"\"\n\n        try:\n            response = self.client.chat.completions.create(\n                model=self.config.models.simple,  # Use simple model for classification to keep costs low\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are a query classifier. Respond with only 'simple' or 'complex'.\"},\n                    {\"role\": \"user\", \"content\": classification_prompt},\n                ],\n                max_tokens=10,\n                temperature=0.0,  # Deterministic classification\n            )\n\n            result = response.choices[0].message.content.strip().lower()\n            if \"complex\" in result:\n                return \"complex\"\n            else:\n                return \"simple\"\n        except Exception:\n            # Fallback to simple on any error\n            return \"simple\"\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.query_processor.QueryProcessor.select_model","title":"select_model","text":"<pre><code>select_model(query: str, force_complex: Optional[bool] = None) -&gt; str\n</code></pre> <p>Select model based on query complexity.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The user's question</p> required <code>force_complex</code> <code>Optional[bool]</code> <p>None (auto-select), False (force simple), True (force complex)</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Model name to use</p> Source code in <code>goliat/ai/query_processor.py</code> <pre><code>def select_model(self, query: str, force_complex: Optional[bool] = None) -&gt; str:\n    \"\"\"Select model based on query complexity.\n\n    Args:\n        query: The user's question\n        force_complex: None (auto-select), False (force simple), True (force complex)\n\n    Returns:\n        Model name to use\n    \"\"\"\n    model, _ = self.select_model_with_complexity(query, force_complex)\n    return model\n</code></pre>"},{"location":"reference/api_reference/#goliat.ai.query_processor.QueryProcessor.select_model_with_complexity","title":"select_model_with_complexity","text":"<pre><code>select_model_with_complexity(query: str, force_complex: Optional[bool] = None) -&gt; tuple[str, ComplexityType]\n</code></pre> <p>Select model and return both model name and complexity.</p> <p>This avoids duplicate classification calls when both values are needed.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The user's question</p> required <code>force_complex</code> <code>Optional[bool]</code> <p>None (auto-select), False (force simple), True (force complex)</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[str, ComplexityType]</code> <p>Tuple of (model_name, complexity_type)</p> Source code in <code>goliat/ai/query_processor.py</code> <pre><code>def select_model_with_complexity(self, query: str, force_complex: Optional[bool] = None) -&gt; tuple[str, ComplexityType]:\n    \"\"\"Select model and return both model name and complexity.\n\n    This avoids duplicate classification calls when both values are needed.\n\n    Args:\n        query: The user's question\n        force_complex: None (auto-select), False (force simple), True (force complex)\n\n    Returns:\n        Tuple of (model_name, complexity_type)\n    \"\"\"\n    if force_complex is True:\n        return self.config.models.complex, \"complex\"\n    elif force_complex is False:\n        return self.config.models.simple, \"simple\"\n\n    # Auto-select based on query complexity\n    complexity = self.classify_complexity(query)\n\n    if complexity == \"simple\":\n        return self.config.models.simple, complexity\n    else:\n        return self.config.models.complex, complexity\n</code></pre>"},{"location":"reference/api_reference/#types","title":"Types","text":""},{"location":"reference/api_reference/#goliat.ai.types","title":"goliat.ai.types","text":"<p>Type definitions for GOLIAT AI module.</p>"},{"location":"reference/api_reference/#osparc-batch-processing","title":"oSPARC Batch Processing","text":"<p>Batch processing and worker management for oSPARC cloud execution.</p>"},{"location":"reference/api_reference/#cleanup","title":"Cleanup","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.cleanup","title":"goliat.osparc_batch.cleanup","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.cleanup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.cleanup.clear_log_directory","title":"clear_log_directory","text":"<pre><code>clear_log_directory(base_dir: str) -&gt; None\n</code></pre> <p>Deletes all files in the osparc_submission_logs directory.</p> Source code in <code>goliat/osparc_batch/cleanup.py</code> <pre><code>def clear_log_directory(base_dir: str) -&gt; None:\n    \"\"\"Deletes all files in the osparc_submission_logs directory.\"\"\"\n    log_dir = Path(base_dir) / \"logs\" / \"osparc_submission_logs\"\n    if log_dir.exists():\n        main_logger.info(f\"--- Clearing log directory: {log_dir} ---\")\n        for item in log_dir.iterdir():\n            if item.is_file():\n                try:\n                    item.unlink()\n                except OSError as e:\n                    main_logger.error(f\"Error deleting file {item}: {e}\")\n            elif item.is_dir():\n                try:\n                    shutil.rmtree(item)\n                except OSError as e:\n                    main_logger.error(f\"Error deleting directory {item}: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.cleanup.clear_temp_download_directory","title":"clear_temp_download_directory","text":"<pre><code>clear_temp_download_directory(base_dir: str) -&gt; None\n</code></pre> <p>Deletes the temporary download directory.</p> Source code in <code>goliat/osparc_batch/cleanup.py</code> <pre><code>def clear_temp_download_directory(base_dir: str) -&gt; None:\n    \"\"\"Deletes the temporary download directory.\"\"\"\n    temp_dir = Path(base_dir) / \"tmp_download\"\n    if temp_dir.exists():\n        main_logger.info(f\"--- Clearing temporary download directory: {temp_dir} ---\")\n        try:\n            shutil.rmtree(temp_dir)\n        except OSError as e:\n            main_logger.error(f\"Error deleting directory {temp_dir}: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#file-finder","title":"File Finder","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.file_finder","title":"goliat.osparc_batch.file_finder","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.file_finder-classes","title":"Classes","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.file_finder-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.file_finder.find_input_files","title":"find_input_files","text":"<pre><code>find_input_files(config: Config) -&gt; list[Path]\n</code></pre> <p>Finds solver input files (.h5) and cleans up older files.</p> <p>Supports both far-field and near-field study types.</p> Source code in <code>goliat/osparc_batch/file_finder.py</code> <pre><code>def find_input_files(config: \"Config\") -&gt; list[Path]:\n    \"\"\"Finds solver input files (.h5) and cleans up older files.\n\n    Supports both far-field and near-field study types.\n    \"\"\"\n    main_logger.info(f\"{colorama.Fore.MAGENTA}--- Searching for input files based on configuration ---\")\n    results_base_dir = Path(config.base_dir) / \"results\"\n    study_type = config[\"study_type\"]\n    phantoms = config[\"phantoms\"] or []\n\n    # Get frequencies based on study type\n    if study_type == \"far_field\":\n        frequencies = config[\"frequencies_mhz\"] or []\n        if not frequencies:\n            raise ValueError(\"Far-field config must specify 'frequencies_mhz'.\")\n    elif study_type == \"near_field\":\n        # Near-field uses antenna_config keys as frequencies\n        antenna_config = config[\"antenna_config\"] or {}\n        if not antenna_config:\n            raise ValueError(\"Near-field config must specify 'antenna_config'.\")\n        frequencies = [int(freq_str) for freq_str in antenna_config.keys()]\n    else:\n        raise ValueError(f\"Unknown study_type: {study_type}\")\n\n    if not all([study_type, phantoms]):\n        raise ValueError(\"Config must specify 'study_type' and 'phantoms'.\")\n\n    all_input_files: list[Path] = []\n    if phantoms:\n        for phantom in phantoms:\n            for freq in frequencies:\n                if study_type == \"far_field\":\n                    all_input_files.extend(_find_far_field_input_files(config, results_base_dir, phantom, freq))\n                elif study_type == \"near_field\":\n                    all_input_files.extend(_find_near_field_input_files(config, results_base_dir, phantom, freq))\n\n    if not all_input_files:\n        main_logger.error(f\"{colorama.Fore.RED}ERROR: Could not find any input files to process.\")\n        sys.exit(1)\n\n    main_logger.info(f\"{colorama.Fore.GREEN}--- Found a total of {len(all_input_files)} input files to process. ---\")\n    return all_input_files\n</code></pre>"},{"location":"reference/api_reference/#gui","title":"Gui","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.gui.BatchGUI","title":"goliat.osparc_batch.gui.BatchGUI","text":"<pre><code>BatchGUI()\n</code></pre> <p>               Bases: <code>QWidget</code></p> <p>A simple GUI for the oSPARC batch run.</p> Source code in <code>goliat/osparc_batch/gui.py</code> <pre><code>def __init__(self):\n    \"\"\"Create window and wire up button signals.\"\"\"\n    super().__init__()\n    self.init_ui()\n\n    logger.info(\"Initializing BatchGUI UI.\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.gui.BatchGUI-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.gui.BatchGUI.init_ui","title":"init_ui","text":"<pre><code>init_ui()\n</code></pre> <p>Initializes the user interface components.</p> Source code in <code>goliat/osparc_batch/gui.py</code> <pre><code>def init_ui(self):\n    \"\"\"Initializes the user interface components.\"\"\"\n    self.setWindowTitle(\"oSPARC Batch Runner\")\n    layout = QVBoxLayout()\n\n    self.button_layout = QHBoxLayout()\n    self.progress_button = QPushButton(\"Print Progress\")\n    self.progress_button.clicked.connect(self.print_progress_requested.emit)\n\n    self.force_stop_button = QPushButton(\"Force Stop\")\n    self.force_stop_button.clicked.connect(self.force_stop_run)\n\n    self.stop_and_cancel_button = QPushButton(\"Stop and Cancel Jobs\")\n    self.stop_and_cancel_button.clicked.connect(self.stop_and_cancel_jobs)\n\n    self.tray_button = QPushButton(\"Move to Tray\")\n    self.tray_button.clicked.connect(self.hide_to_tray)\n\n    self.button_layout.addWidget(self.progress_button)\n    self.button_layout.addWidget(self.force_stop_button)\n    self.button_layout.addWidget(self.stop_and_cancel_button)\n    self.button_layout.addWidget(self.tray_button)\n    layout.addLayout(self.button_layout)\n\n    self.setLayout(layout)\n\n    self.tray_icon = QSystemTrayIcon(self)\n    style = self.style()\n    icon = style.standardIcon(style.StandardPixmap.SP_ComputerIcon)\n    self.tray_icon.setIcon(icon)\n    self.tray_icon.setToolTip(\"oSPARC batch run is in progress...\")\n\n    tray_menu = QMenu(self)\n    show_action = QAction(\"Show\", self)\n    show_action.triggered.connect(self.show_from_tray)\n    tray_menu.addAction(show_action)\n\n    exit_action = QAction(\"Exit\", self)\n    exit_action.triggered.connect(self.close)\n    tray_menu.addAction(exit_action)\n\n    self.tray_icon.setContextMenu(tray_menu)\n    self.tray_icon.activated.connect(self.tray_icon_activated)\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.gui.BatchGUI.force_stop_run","title":"force_stop_run","text":"<pre><code>force_stop_run()\n</code></pre> <p>Stops the main batch process immediately.</p> Source code in <code>goliat/osparc_batch/gui.py</code> <pre><code>def force_stop_run(self):\n    \"\"\"Stops the main batch process immediately.\"\"\"\n    logger.info(\"Force stop button clicked.\")\n    self.force_stop_button.setEnabled(False)\n    self.stop_and_cancel_button.setEnabled(False)\n    self.stop_run_requested.emit()\n    QApplication.instance().quit()  # type: ignore\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.gui.BatchGUI.stop_and_cancel_jobs","title":"stop_and_cancel_jobs","text":"<pre><code>stop_and_cancel_jobs()\n</code></pre> <p>Stops the main batch process and cancels all running jobs.</p> Source code in <code>goliat/osparc_batch/gui.py</code> <pre><code>def stop_and_cancel_jobs(self):\n    \"\"\"Stops the main batch process and cancels all running jobs.\"\"\"\n    logger.info(\"Stop and cancel jobs button clicked.\")\n    self.force_stop_button.setEnabled(False)\n    self.stop_and_cancel_button.setEnabled(False)\n    self.cancel_jobs_requested.emit()\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.gui.BatchGUI.hide_to_tray","title":"hide_to_tray","text":"<pre><code>hide_to_tray()\n</code></pre> <p>Hides the main window and shows the tray icon.</p> Source code in <code>goliat/osparc_batch/gui.py</code> <pre><code>def hide_to_tray(self):\n    \"\"\"Hides the main window and shows the tray icon.\"\"\"\n    logger.info(\"Hiding window to system tray.\")\n    self.hide()\n    self.tray_icon.show()\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.gui.BatchGUI.show_from_tray","title":"show_from_tray","text":"<pre><code>show_from_tray()\n</code></pre> <p>Shows the main window and hides the tray icon.</p> Source code in <code>goliat/osparc_batch/gui.py</code> <pre><code>def show_from_tray(self):\n    \"\"\"Shows the main window and hides the tray icon.\"\"\"\n    logger.info(\"Showing window from system tray.\")\n    self.show()\n    self.tray_icon.hide()\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.gui.BatchGUI.tray_icon_activated","title":"tray_icon_activated","text":"<pre><code>tray_icon_activated(reason)\n</code></pre> <p>Handles tray icon activation.</p> Source code in <code>goliat/osparc_batch/gui.py</code> <pre><code>def tray_icon_activated(self, reason):\n    \"\"\"Handles tray icon activation.\"\"\"\n    if reason == QSystemTrayIcon.ActivationReason.Trigger:\n        logger.debug(\"Tray icon clicked, showing window.\")\n        self.show_from_tray()\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.gui.BatchGUI.closeEvent","title":"closeEvent","text":"<pre><code>closeEvent(event)\n</code></pre> <p>Handles the window close event.</p> Source code in <code>goliat/osparc_batch/gui.py</code> <pre><code>def closeEvent(self, event):\n    \"\"\"Handles the window close event.\"\"\"\n    logger.info(\"Window close event triggered.\")\n    self.force_stop_run()\n    event.accept()\n</code></pre>"},{"location":"reference/api_reference/#logging-utils","title":"Logging Utils","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.logging_utils","title":"goliat.osparc_batch.logging_utils","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.logging_utils-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.logging_utils.setup_console_logging","title":"setup_console_logging","text":"<pre><code>setup_console_logging() -&gt; logging.Logger\n</code></pre> <p>Sets up a basic console logger with color.</p> Source code in <code>goliat/osparc_batch/logging_utils.py</code> <pre><code>def setup_console_logging() -&gt; logging.Logger:\n    \"\"\"Sets up a basic console logger with color.\"\"\"\n    init_colorama()\n    logger = logging.getLogger(\"osparc_batch\")\n    logger.setLevel(logging.INFO)\n    handler = logging.StreamHandler()\n    handler.setFormatter(logging.Formatter(\"%(message)s\"))\n    logger.addHandler(handler)\n    return logger\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.logging_utils.setup_job_logging","title":"setup_job_logging","text":"<pre><code>setup_job_logging(base_dir: str, job_id: str) -&gt; logging.Logger\n</code></pre> <p>Sets up a unique log file for each job in a specific subdirectory.</p> Source code in <code>goliat/osparc_batch/logging_utils.py</code> <pre><code>def setup_job_logging(base_dir: str, job_id: str) -&gt; logging.Logger:\n    \"\"\"Sets up a unique log file for each job in a specific subdirectory.\"\"\"\n    from pathlib import Path\n\n    log_dir = Path(base_dir) / \"logs\" / \"osparc_submission_logs\"\n    log_dir.mkdir(parents=True, exist_ok=True)\n    log_file_path = log_dir / f\"job_{job_id}.log\"\n\n    job_logger = logging.getLogger(f\"job_{job_id}\")\n    job_logger.setLevel(logging.INFO)\n    job_logger.propagate = False\n\n    if job_logger.hasHandlers():\n        job_logger.handlers.clear()\n\n    file_handler = logging.FileHandler(log_file_path, mode=\"w\")\n    file_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n    job_logger.addHandler(file_handler)\n\n    return job_logger\n</code></pre>"},{"location":"reference/api_reference/#main-logic","title":"Main Logic","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.main_logic","title":"goliat.osparc_batch.main_logic","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.main_logic-classes","title":"Classes","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.main_logic-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.main_logic.main_process_logic","title":"main_process_logic","text":"<pre><code>main_process_logic(worker: Worker)\n</code></pre> <p>The main logic of the batch run, executed in a QThread.</p> Source code in <code>goliat/osparc_batch/main_logic.py</code> <pre><code>def main_process_logic(worker: \"Worker\"):\n    \"\"\"The main logic of the batch run, executed in a QThread.\"\"\"\n    import osparc as osparc_module\n\n    try:\n        base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../..\"))\n        worker.client_cfg = get_osparc_client_config(worker.config, osparc_module)  # type: ignore\n\n        solver_key = \"simcore/services/comp/isolve-gpu\"\n        solver_version = \"2.2.212\"\n\n        main_logger.info(f\"{colorama.Fore.MAGENTA}--- Submitting Jobs to oSPARC in Parallel ---\")\n        worker.running_jobs = {}\n        with ProcessPoolExecutor(max_workers=min(len(worker.input_files), 61) or 1) as executor:\n            future_to_file = {\n                executor.submit(\n                    _submit_job_in_process,\n                    fp,\n                    worker.client_cfg,  # type: ignore\n                    solver_key,\n                    solver_version,\n                ): fp\n                for fp in worker.input_files\n            }\n            for future in as_completed(future_to_file):\n                file_path = future_to_file[future]\n                try:\n                    result = future.result()\n                    if result:\n                        job, solver = result\n                        worker.running_jobs[file_path] = (job, solver)\n                        if job.id:\n                            setup_job_logging(base_dir, job.id)\n                            job_logger = logging.getLogger(f\"job_{job.id}\")\n                            job_logger.info(f\"Job {job.id} submitted for input file {file_path.name} at path {file_path}.\")\n                except Exception as exc:\n                    main_logger.error(f\"ERROR: Submitting job for {file_path.name} generated an exception: {exc}\\n{traceback.format_exc()}\")\n\n        if not worker.running_jobs:\n            main_logger.error(\"ERROR: No jobs were successfully submitted. Exiting.\")\n            worker.finished.emit()\n            return\n\n        main_logger.info(f\"{colorama.Fore.MAGENTA}--- Polling for Job Completion and Downloading Results ---\")\n        worker.job_statuses = {job.id: (\"PENDING\", time.time()) for _, (job, _) in worker.running_jobs.items()}\n        worker.file_to_job_id = {fp: j.id for fp, (j, s) in worker.running_jobs.items()}\n        worker.downloaded_jobs = set()\n\n        worker.timer.start(5000)\n\n    except Exception as e:\n        main_logger.error(f\"\\nCRITICAL ERROR in main process: {e}\\n{traceback.format_exc()}\")\n        worker.finished.emit()\n</code></pre>"},{"location":"reference/api_reference/#osparc-client","title":"Osparc Client","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.osparc_client","title":"goliat.osparc_batch.osparc_client","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.osparc_client-classes","title":"Classes","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.osparc_client-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.osparc_client.get_osparc_client_config","title":"get_osparc_client_config","text":"<pre><code>get_osparc_client_config(config: Config, osparc_module) -&gt; osparc.Configuration\n</code></pre> <p>Initializes and returns the oSPARC client configuration.</p> Source code in <code>goliat/osparc_batch/osparc_client.py</code> <pre><code>def get_osparc_client_config(config: \"Config\", osparc_module) -&gt; \"osparc.Configuration\":\n    \"\"\"Initializes and returns the oSPARC client configuration.\"\"\"\n    creds = config.get_osparc_credentials()\n    if not all(k in creds for k in [\"api_key\", \"api_secret\", \"api_server\"]):\n        raise ValueError(\"Missing oSPARC credentials in configuration.\")\n\n    temp_dir = Path(config.base_dir) / \"tmp_download\"\n    temp_dir.mkdir(exist_ok=True)\n\n    client_config = osparc_module.Configuration(\n        host=creds[\"api_server\"],\n        username=creds[\"api_key\"],\n        password=creds[\"api_secret\"],\n    )\n    client_config.temp_folder_path = str(temp_dir)\n    return client_config\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.osparc_client.submit_job","title":"submit_job","text":"<pre><code>submit_job(input_file_path: Path, client_cfg: Configuration, solver_key: str, solver_version: str, osparc_module) -&gt; tuple[osparc.Job, osparc.Solver]\n</code></pre> <p>Submits a single job to oSPARC and returns the job and solver objects.</p> Source code in <code>goliat/osparc_batch/osparc_client.py</code> <pre><code>def submit_job(\n    input_file_path: Path,\n    client_cfg: \"osparc.Configuration\",\n    solver_key: str,\n    solver_version: str,\n    osparc_module,\n) -&gt; tuple[\"osparc.Job\", \"osparc.Solver\"]:\n    \"\"\"Submits a single job to oSPARC and returns the job and solver objects.\"\"\"\n    with osparc_module.ApiClient(client_cfg) as api_client:\n        files_api = osparc_module.FilesApi(api_client)\n        solvers_api = osparc_module.SolversApi(api_client)\n\n        input_file_osparc = files_api.upload_file(file=str(input_file_path))\n        solver = solvers_api.get_solver_release(solver_key, solver_version)\n\n        job = solvers_api.create_job(\n            solver.id,\n            solver.version,\n            job_inputs=osparc_module.JobInputs({\"input_1\": input_file_osparc}),\n        )\n\n        if not job.id:\n            raise RuntimeError(\"oSPARC API did not return a job ID after creation.\")\n\n        solvers_api.start_job(solver.id, solver.version, job.id)\n        return job, solver\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.osparc_client.download_and_process_results","title":"download_and_process_results","text":"<pre><code>download_and_process_results(job: Job, solver: Solver, client_cfg: Configuration, input_file_path: Path, osparc_module, status_callback=None)\n</code></pre> <p>Downloads and processes the results for a single job.</p> Source code in <code>goliat/osparc_batch/osparc_client.py</code> <pre><code>def download_and_process_results(\n    job: \"osparc.Job\",\n    solver: \"osparc.Solver\",\n    client_cfg: \"osparc.Configuration\",\n    input_file_path: Path,\n    osparc_module,\n    status_callback=None,\n):\n    \"\"\"Downloads and processes the results for a single job.\"\"\"\n    job_logger = logging.getLogger(f\"job_{job.id}\")\n    try:\n        with osparc_module.ApiClient(client_cfg) as api_client:\n            files_api = osparc_module.FilesApi(api_client)\n            solvers_api = osparc_module.SolversApi(api_client)\n\n            job_logger.info(f\"--- Downloading results for job {job.id} ---\")\n            if status_callback:\n                status_callback.emit(job.id, \"DOWNLOADING\")\n            outputs = solvers_api.get_job_outputs(solver.id, solver.version, job.id)\n\n            output_dir = input_file_path.parent\n\n            for output_name, result_file in outputs.results.items():\n                job_logger.info(f\"Downloading {output_name} for job {job.id}...\")\n\n                download_path = files_api.download_file(file_id=result_file.id)\n\n                if result_file.filename.endswith(\".zip\"):\n                    job_logger.info(f\"Extracting {result_file.filename} to {output_dir}\")\n                    with zipfile.ZipFile(download_path, \"r\") as zip_ref:\n                        zip_ref.extractall(output_dir)\n\n                        # --- Enhanced Log File Handling ---\n                        uuid = input_file_path.stem.replace(\"_Input\", \"\")\n                        extracted_files = zip_ref.namelist()\n\n                        for filename in extracted_files:\n                            if filename.endswith(\".log\"):\n                                extracted_path = output_dir / filename\n                                if \"input.log\" in filename:\n                                    new_name = f\"iSolve-output-{uuid}.log\"\n                                else:\n                                    new_name = f\"{uuid}_AxLog.log\"\n\n                                final_log_path = output_dir / new_name\n                                shutil.move(extracted_path, final_log_path)\n                                job_logger.info(f\"Renamed and moved log file to {final_log_path}\")\n\n                    os.remove(download_path)\n                else:\n                    if \"output.h5\" in result_file.filename:\n                        output_filename = input_file_path.stem.replace(\"_Input\", \"_Output\") + \".h5\"\n                    else:\n                        output_filename = result_file.filename\n\n                    final_path = output_dir / output_filename\n                    shutil.move(download_path, final_path)\n                    job_logger.info(f\"Saved {output_name} to {final_path}\")\n\n                if status_callback:\n                    status_callback.emit(job.id, \"COMPLETED\")\n\n    except Exception as e:\n        job_logger.error(f\"Could not retrieve results for job {job.id}: {e}\\n{traceback.format_exc()}\")\n        if status_callback:\n            status_callback.emit(job.id, \"FAILED\")\n</code></pre>"},{"location":"reference/api_reference/#progress","title":"Progress","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.progress","title":"goliat.osparc_batch.progress","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.progress-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.progress.get_progress_report","title":"get_progress_report","text":"<pre><code>get_progress_report(input_files: list[Path], job_statuses: dict, file_to_job_id: dict) -&gt; str\n</code></pre> <p>Generates a status summary and a colored file tree string.</p> Source code in <code>goliat/osparc_batch/progress.py</code> <pre><code>def get_progress_report(input_files: list[Path], job_statuses: dict, file_to_job_id: dict) -&gt; str:\n    \"\"\"Generates a status summary and a colored file tree string.\"\"\"\n    report_lines = []\n\n    status_counts = defaultdict(int)\n    for status_tuple in job_statuses.values():\n        status_str = status_tuple if isinstance(status_tuple, tuple) else status_tuple\n        state = status_str.split(\" \")  # type: ignore\n        status_counts[state] += 1\n    summary = \" | \".join(f\"{state}: {count}\" for state, count in sorted(status_counts.items()))\n    report_lines.append(f\"\\n{colorama.Fore.BLUE}--- Progress Summary ---\\n{summary}\\n{colorama.Style.RESET_ALL}\")\n\n    tree = {}\n    if not input_files:\n        return \"\\n\".join(report_lines)\n\n    # --- Optimized Path Handling ---\n    try:\n        first_path_parts = input_files.parts  # type: ignore\n        results_index = first_path_parts.index(\"results\")\n        base_path = Path(*first_path_parts[: results_index + 1])\n    except (ValueError, IndexError):\n        # Fallback for safety, though not expected with the current structure\n        common_path_str = os.path.commonpath([str(p.parent) for p in input_files])\n        base_path = Path(common_path_str)\n\n    for file_path in input_files:\n        try:\n            relative_path = file_path.relative_to(base_path)\n            parts = list(relative_path.parts)\n            if not parts:\n                continue\n\n            current_level = tree\n            for part in parts[:-1]:\n                current_level = current_level.setdefault(part, {})\n\n            filename = parts[-1]\n            current_level[filename] = file_to_job_id.get(file_path)\n\n        except (IndexError, ValueError) as e:\n            report_lines.append(f\"{colorama.Fore.RED}Could not process path {file_path}: {e}{colorama.Style.RESET_ALL}\")\n\n    def build_tree_recursive(node, prefix=\"\"):\n        \"\"\"Walk nested dict and append tree lines to report_lines.\"\"\"\n\n        def sort_key(item):\n            \"\"\"Sort numeric prefixes first, then alphabetically.\"\"\"\n            match = re.match(r\"(\\d+)\", item)\n            if match:\n                return (1, int(match.group(1)))\n            return (0, item)\n\n        items = sorted(node.keys(), key=sort_key)\n        for i, item in enumerate(items):\n            is_last = i == len(items) - 1\n            connector = \"\u2514\u2500\u2500 \" if is_last else \"\u251c\u2500\u2500 \"\n\n            if isinstance(node[item], dict):\n                report_lines.append(f\"{prefix}{connector}{colorama.Fore.WHITE}{item}\")\n                new_prefix = prefix + (\"    \" if is_last else \"\u2502   \")\n                build_tree_recursive(node[item], new_prefix)\n            else:\n                job_id = node[item]\n                status_tuple = job_statuses.get(job_id, (\"UNKNOWN\", time.time()))\n                status_str, start_time = status_tuple if isinstance(status_tuple, tuple) else (status_tuple, time.time())\n\n                elapsed_time = time.time() - start_time\n                timer_str = f\" ({elapsed_time:.0f}s)\"\n\n                status = status_str.split(\" \")\n                color = STATUS_COLORS.get(status, colorama.Fore.WHITE)\n                colored_text = f\"{color}{item} (oSPARC Job: {job_id}, Status: {status_str}{timer_str}){colorama.Style.RESET_ALL}\"\n                report_lines.append(f\"{prefix}{connector}{colored_text}\")\n\n    report_lines.append(f\"{colorama.Fore.BLUE}--- File Status Tree ---{colorama.Style.RESET_ALL}\")\n    build_tree_recursive(tree)\n    report_lines.append(f\"{colorama.Fore.BLUE}------------------------{colorama.Style.RESET_ALL}\\n\")\n\n    return \"\\n\".join(report_lines)\n</code></pre>"},{"location":"reference/api_reference/#runner","title":"Runner","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.runner","title":"goliat.osparc_batch.runner","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.runner-classes","title":"Classes","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.runner-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.runner.main","title":"main","text":"<pre><code>main(config_path: str) -&gt; None\n</code></pre> <p>Main entry point: sets up and starts the GUI and the main logic process.</p> Source code in <code>goliat/osparc_batch/runner.py</code> <pre><code>def main(config_path: str) -&gt; None:\n    \"\"\"Main entry point: sets up and starts the GUI and the main logic process.\"\"\"\n    from PySide6.QtWidgets import QApplication\n\n    from goliat.config import Config\n\n    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../..\"))\n    clear_log_directory(base_dir)\n\n    config = Config(base_dir, config_path)\n    input_files = find_input_files(config)\n\n    app = QApplication.instance() or QApplication(sys.argv)\n\n    thread = QThread()\n    worker = Worker(\n        config_path=config_path,\n        logger=main_logger,\n        get_osparc_client_config_func=get_osparc_client_config,\n        download_and_process_results_func=download_and_process_results,\n        get_progress_report_func=get_progress_report,\n        main_process_logic_func=main_process_logic,\n    )\n    worker.config = config  # type: ignore\n    worker.input_files = input_files\n    worker.moveToThread(thread)\n\n    gui = BatchGUI()\n\n    # Connect signals and slots\n    thread.started.connect(worker.run)\n    worker.finished.connect(thread.quit)\n    worker.finished.connect(worker.deleteLater)\n    thread.finished.connect(thread.deleteLater)\n\n    worker.progress.connect(main_logger.info)\n    gui.print_progress_requested.connect(worker.request_progress_report)\n    gui.stop_run_requested.connect(worker.stop)\n    gui.cancel_jobs_requested.connect(worker.cancel_jobs)\n\n    worker.finished.connect(app.quit)\n\n    thread.start()\n    gui.show()\n    app.exec()\n\n    if thread.isRunning():\n        thread.quit()\n        thread.wait()\n\n    clear_temp_download_directory(base_dir)\n</code></pre>"},{"location":"reference/api_reference/#worker","title":"Worker","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.worker.Worker","title":"goliat.osparc_batch.worker.Worker","text":"<pre><code>Worker(config_path: str, logger: Logger, get_osparc_client_config_func: Callable[..., Any], download_and_process_results_func: Callable[..., Any], get_progress_report_func: Callable[..., str], main_process_logic_func: Callable[..., Any])\n</code></pre> <p>               Bases: <code>QObject</code></p> <p>Worker thread for oSPARC batch logic, polling, and downloads.</p> Source code in <code>goliat/osparc_batch/worker.py</code> <pre><code>def __init__(\n    self,\n    config_path: str,\n    logger: logging.Logger,\n    get_osparc_client_config_func: Callable[..., Any],\n    download_and_process_results_func: Callable[..., Any],\n    get_progress_report_func: Callable[..., str],\n    main_process_logic_func: Callable[..., Any],\n):\n    \"\"\"Store config path and inject dependencies for batch logic.\"\"\"\n    super().__init__()\n    # Inputs / injected dependencies\n    self.config_path = config_path\n    self.logger = logger\n    self.get_osparc_client_config = get_osparc_client_config_func\n    self.download_and_process_results = download_and_process_results_func\n    self.get_progress_report = get_progress_report_func\n    self.main_process_logic = main_process_logic_func\n\n    # Runtime state\n    self.config = None\n    self.stop_requested = False\n    self.input_files = []\n    self.job_statuses = {}\n    self.file_to_job_id = {}\n    self.running_jobs = {}\n    self.downloaded_jobs = set()\n    self.jobs_being_downloaded = set()\n    self.file_retries = {}  # Correct: Associate retries with the file path\n    self.client_cfg = None\n\n    # Executors and timers\n    self.download_executor = ThreadPoolExecutor(max_workers=4)\n    self.timer = QTimer(self)\n    self.timer.timeout.connect(self._check_jobs_status)\n    self.status_update_requested.connect(self._update_job_status)\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.worker.Worker-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.osparc_batch.worker.Worker.run","title":"run","text":"<pre><code>run()\n</code></pre> <p>Starts the long-running task.</p> Source code in <code>goliat/osparc_batch/worker.py</code> <pre><code>def run(self):\n    \"\"\"Starts the long-running task.\"\"\"\n    self.main_process_logic(self)\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.worker.Worker.request_progress_report","title":"request_progress_report","text":"<pre><code>request_progress_report()\n</code></pre> <p>Handles the request for a progress report.</p> Source code in <code>goliat/osparc_batch/worker.py</code> <pre><code>@Slot()\ndef request_progress_report(self):\n    \"\"\"Handles the request for a progress report.\"\"\"\n    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n    self.logger.info(f\"--- Progress report requested by user at {timestamp} ---\")\n    if not self.input_files:\n        self.logger.info(\"No input files found yet. The process may still be initializing.\")\n        return\n    report = self.get_progress_report(self.input_files, self.job_statuses, self.file_to_job_id)\n    self.logger.info(report)\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.worker.Worker.stop","title":"stop","text":"<pre><code>stop()\n</code></pre> <p>Requests the worker to stop.</p> Source code in <code>goliat/osparc_batch/worker.py</code> <pre><code>@Slot()\ndef stop(self):\n    \"\"\"Requests the worker to stop.\"\"\"\n    self.logger.info(\"--- Stop requested by user ---\")\n    self.stop_requested = True\n    if self.timer.isActive():\n        self.timer.stop()\n    # The cancel_futures parameter is available in Python 3.9+\n    # For older versions, this will still shut down cleanly.\n    self.download_executor.shutdown(wait=False, cancel_futures=True)\n    self.finished.emit()\n    if self.thread():\n        self.thread().quit()\n        self.thread().wait()\n</code></pre>"},{"location":"reference/api_reference/#goliat.osparc_batch.worker.Worker.cancel_jobs","title":"cancel_jobs","text":"<pre><code>cancel_jobs()\n</code></pre> <p>Cancels all running jobs and then stops the worker.</p> Source code in <code>goliat/osparc_batch/worker.py</code> <pre><code>@Slot()\ndef cancel_jobs(self):\n    \"\"\"Cancels all running jobs and then stops the worker.\"\"\"\n    self.logger.info(\"--- Cancellation of all jobs requested by user ---\")\n    self.stop_requested = True\n    if self.timer.isActive():\n        self.timer.stop()\n\n    # Run the cancel_all_jobs function\n    try:\n        import os\n        from goliat.utils.scripts.cancel_all_jobs import cancel_all_jobs\n\n        config_path = self.config_path\n        max_jobs = len(self.running_jobs)\n\n        # Determine base_dir from config_path\n        if os.path.isabs(config_path):\n            base_dir = os.path.dirname(os.path.dirname(config_path)) if \"configs\" in config_path else os.path.dirname(config_path)\n        else:\n            base_dir = os.getcwd()\n\n        self.logger.info(f\"Running cancellation for {max_jobs} jobs...\")\n        cancel_all_jobs(config_path, max_jobs, base_dir=base_dir)\n        self.logger.info(\"--- Job cancellation finished ---\")\n    except Exception as e:\n        self.logger.error(f\"An unexpected error occurred during job cancellation: {e}\")\n    finally:\n        self.download_executor.shutdown(wait=False, cancel_futures=True)\n        self.finished.emit()\n        if self.thread():\n            self.thread().quit()\n            self.thread().wait()\n</code></pre>"},{"location":"reference/api_reference/#dispersion","title":"Dispersion","text":"<p>Material dispersion fitting and caching.</p>"},{"location":"reference/api_reference/#fitter","title":"Fitter","text":""},{"location":"reference/api_reference/#goliat.dispersion.fitter.PoleFit","title":"goliat.dispersion.fitter.PoleFit  <code>dataclass</code>","text":"<pre><code>PoleFit(delta_eps: float, tau_s: float, damping_hz: float)\n</code></pre> <p>Parameters for a dispersion pole.</p>"},{"location":"reference/api_reference/#material-cache","title":"Material Cache","text":""},{"location":"reference/api_reference/#goliat.dispersion.material_cache","title":"goliat.dispersion.material_cache","text":"<p>Material property provider for multisine dispersion fitting.</p> <p>Computes material properties (eps_r, sigma) at any frequency using the Gabriel 4-Cole-Cole model from IT'IS V5.0 database.</p> <p>Supports two modes: 1. Direct DB lookup (preferred) - queries IT'IS V5.0 database 2. JSON cache fallback - uses precomputed cache file</p>"},{"location":"reference/api_reference/#goliat.dispersion.material_cache-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.dispersion.material_cache.get_material_properties","title":"get_material_properties","text":"<pre><code>get_material_properties(tissue_name: str, frequencies_mhz: list[int], use_db: bool = True) -&gt; list[dict]\n</code></pre> <p>Get material properties for a tissue at specified frequencies.</p> <p>Uses IT'IS V5.0 database with Cole-Cole calculation (preferred), with fallback to JSON cache if DB unavailable.</p> <p>Parameters:</p> Name Type Description Default <code>tissue_name</code> <code>str</code> <p>Name of tissue (IT'IS database name)</p> required <code>frequencies_mhz</code> <code>list[int]</code> <p>List of frequencies in MHz</p> required <code>use_db</code> <code>bool</code> <p>If True, try DB first; if False, use cache only</p> <code>True</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of dicts with {'eps_r': float, 'sigma': float} for each frequency</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If tissue not found</p> <code>ValueError</code> <p>If frequency not available (cache mode only)</p> Source code in <code>goliat/dispersion/material_cache.py</code> <pre><code>def get_material_properties(\n    tissue_name: str,\n    frequencies_mhz: list[int],\n    use_db: bool = True,\n) -&gt; list[dict]:\n    \"\"\"\n    Get material properties for a tissue at specified frequencies.\n\n    Uses IT'IS V5.0 database with Cole-Cole calculation (preferred),\n    with fallback to JSON cache if DB unavailable.\n\n    Args:\n        tissue_name: Name of tissue (IT'IS database name)\n        frequencies_mhz: List of frequencies in MHz\n        use_db: If True, try DB first; if False, use cache only\n\n    Returns:\n        List of dicts with {'eps_r': float, 'sigma': float} for each frequency\n\n    Raises:\n        KeyError: If tissue not found\n        ValueError: If frequency not available (cache mode only)\n    \"\"\"\n    if use_db:\n        try:\n            return _get_from_db(tissue_name, frequencies_mhz)\n        except FileNotFoundError:\n            logger.warning(\n                \"IT'IS database not found, falling back to JSON cache. \"\n                \"For full frequency support, run: git lfs pull --include='data/itis_v5.db' \"\n                \"or 'goliat init'\"\n            )\n            return _get_from_cache(tissue_name, frequencies_mhz)\n    else:\n        return _get_from_cache(tissue_name, frequencies_mhz)\n</code></pre>"},{"location":"reference/api_reference/#goliat.dispersion.material_cache.load_material_cache","title":"load_material_cache","text":"<pre><code>load_material_cache(cache_path: Optional[Path] = None) -&gt; dict\n</code></pre> <p>Load material property cache from JSON file.</p> <p>Kept for backward compatibility. Prefer get_material_properties() for new code.</p> Source code in <code>goliat/dispersion/material_cache.py</code> <pre><code>def load_material_cache(cache_path: Optional[Path] = None) -&gt; dict:\n    \"\"\"\n    Load material property cache from JSON file.\n\n    Kept for backward compatibility. Prefer get_material_properties() for new code.\n    \"\"\"\n    return _load_json_cache(cache_path)\n</code></pre>"},{"location":"reference/api_reference/#goliat.dispersion.material_cache.clear_cache","title":"clear_cache","text":"<pre><code>clear_cache() -&gt; None\n</code></pre> <p>Clear all in-memory caches to force reload on next access.</p> Source code in <code>goliat/dispersion/material_cache.py</code> <pre><code>def clear_cache() -&gt; None:\n    \"\"\"Clear all in-memory caches to force reload on next access.\"\"\"\n    global _db_gabriel_params, _json_cache\n    _db_gabriel_params = None\n    _json_cache = None\n</code></pre>"},{"location":"reference/api_reference/#goliat.dispersion.material_cache.get_available_tissues","title":"get_available_tissues","text":"<pre><code>get_available_tissues(use_db: bool = True) -&gt; list[str]\n</code></pre> <p>Get list of all available tissue names.</p> Source code in <code>goliat/dispersion/material_cache.py</code> <pre><code>def get_available_tissues(use_db: bool = True) -&gt; list[str]:\n    \"\"\"Get list of all available tissue names.\"\"\"\n    if use_db:\n        try:\n            params = _load_db_params()\n            return list(params.keys())\n        except FileNotFoundError:\n            pass\n\n    cache = _load_json_cache()\n    return list(cache.get(\"tissues\", {}).keys())\n</code></pre>"},{"location":"reference/api_reference/#goliat.dispersion.material_cache.get_cole_cole_params","title":"get_cole_cole_params","text":"<pre><code>get_cole_cole_params(tissue_name: str) -&gt; tuple\n</code></pre> <p>Get raw Cole-Cole parameters for a tissue.</p> <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple of (ef, poles, sigma_ionic) where poles is list of (delta, tau_s, alpha)</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If tissue not found</p> Source code in <code>goliat/dispersion/material_cache.py</code> <pre><code>def get_cole_cole_params(tissue_name: str) -&gt; tuple:\n    \"\"\"\n    Get raw Cole-Cole parameters for a tissue.\n\n    Returns:\n        Tuple of (ef, poles, sigma_ionic) where poles is list of (delta, tau_s, alpha)\n\n    Raises:\n        KeyError: If tissue not found\n    \"\"\"\n    params = _load_db_params()\n\n    if tissue_name not in params:\n        raise KeyError(f\"Tissue '{tissue_name}' not found in database\")\n\n    return params[tissue_name]\n</code></pre>"},{"location":"reference/api_reference/#utilities","title":"Utilities","text":"<p>Utility functions and helper modules.</p>"},{"location":"reference/api_reference/#bashrc","title":"Bashrc","text":""},{"location":"reference/api_reference/#goliat.utils.bashrc","title":"goliat.utils.bashrc","text":"<p>Bashrc configuration management.</p> <p>This module handles creating and updating .bashrc files for Sim4Life Python PATH configuration.</p>"},{"location":"reference/api_reference/#goliat.utils.bashrc-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.bashrc.sync_bashrc_to_home","title":"sync_bashrc_to_home","text":"<pre><code>sync_bashrc_to_home(base_dir)\n</code></pre> <p>Sync project .bashrc to home directory if preference is enabled.</p> Source code in <code>goliat/utils/bashrc.py</code> <pre><code>def sync_bashrc_to_home(base_dir):\n    \"\"\"Sync project .bashrc to home directory if preference is enabled.\"\"\"\n    project_bashrc = os.path.join(base_dir, \".bashrc\")\n    home_bashrc = os.path.join(os.path.expanduser(\"~\"), \".bashrc\")\n\n    if not os.path.exists(project_bashrc):\n        return\n\n    try:\n        with open(project_bashrc, \"r\", encoding=\"utf-8\") as f:\n            bashrc_content = f.read()\n\n        # Read existing home .bashrc\n        existing_content = \"\"\n        if os.path.exists(home_bashrc):\n            with open(home_bashrc, \"r\", encoding=\"utf-8\") as f:\n                existing_content = f.read()\n\n        # Remove old GOLIAT entries if they exist\n        lines = existing_content.split(\"\\n\")\n        new_lines = []\n        in_goliat_section = False\n        for line in lines:\n            if \"# GOLIAT: Sim4Life Python PATH\" in line:\n                in_goliat_section = True\n                continue\n            if in_goliat_section and (line.startswith(\"export PATH\") and \"Sim4Life\" in line):\n                continue\n            # Preserve AX_USE_UNSUPPORTED_CARDS even if it's in GOLIAT section\n            if in_goliat_section and \"AX_USE_UNSUPPORTED_CARDS\" in line:\n                new_lines.append(line)\n                continue\n            # Preserve PYTHONIOENCODING even if it's in GOLIAT section\n            if in_goliat_section and \"PYTHONIOENCODING\" in line:\n                new_lines.append(line)\n                continue\n            if in_goliat_section and line.strip() == \"\" and new_lines and new_lines[-1].strip() == \"\":\n                in_goliat_section = False\n                continue\n            if not in_goliat_section:\n                new_lines.append(line)\n\n        # Remove trailing empty lines\n        while new_lines and new_lines[-1].strip() == \"\":\n            new_lines.pop()\n\n        # Append new content\n        new_content = \"\\n\".join(new_lines)\n        if new_content and not new_content.endswith(\"\\n\"):\n            new_content += \"\\n\"\n        new_content += \"\\n# GOLIAT: Sim4Life Python PATH (auto-synced)\\n\"\n        new_content += bashrc_content\n\n        with open(home_bashrc, \"w\", encoding=\"utf-8\") as f:\n            f.write(new_content)\n\n        # Ensure ~/.bash_profile sources ~/.bashrc (Git Bash/MINGW64 compatibility)\n        _ensure_bash_profile_sources_bashrc()\n\n        logging.info(\"Synced .bashrc to ~/.bashrc (preference enabled)\")\n    except Exception as e:\n        logging.warning(f\"Could not sync .bashrc to home directory: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.bashrc.update_bashrc","title":"update_bashrc","text":"<pre><code>update_bashrc(selected_python_path, base_dir=None)\n</code></pre> <p>Creates/updates a project-local .bashrc with PATH entries for Sim4Life Python.</p> <p>This creates a .bashrc in the project directory (non-intrusive). If base_dir is provided and user preference is set, also syncs to ~/.bashrc.</p> <p>Preserves existing content that is not Sim4Life PATH related, including AX_USE_UNSUPPORTED_CARDS and other custom environment variables.</p> Source code in <code>goliat/utils/bashrc.py</code> <pre><code>def update_bashrc(selected_python_path, base_dir=None):\n    \"\"\"Creates/updates a project-local .bashrc with PATH entries for Sim4Life Python.\n\n    This creates a .bashrc in the project directory (non-intrusive).\n    If base_dir is provided and user preference is set, also syncs to ~/.bashrc.\n\n    Preserves existing content that is not Sim4Life PATH related, including\n    AX_USE_UNSUPPORTED_CARDS and other custom environment variables.\n    \"\"\"\n    bashrc_path = os.path.join(os.getcwd(), \".bashrc\")\n    _, python_line, scripts_line = _to_bash_path(selected_python_path)\n    preserved_lines, preserved_vars, has_ax_unsupported, has_pythonioencoding = _parse_existing_bashrc(bashrc_path)\n    new_lines = _build_bashrc_lines(python_line, scripts_line, preserved_lines, preserved_vars, has_ax_unsupported, has_pythonioencoding)\n\n    with open(bashrc_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(new_lines))\n        if new_lines:\n            f.write(\"\\n\")\n\n    logging.info(\"'.bashrc' has been updated. Please restart your shell or run 'source .bashrc'.\")\n\n    if base_dir:\n        prefs = get_user_preferences(base_dir)\n        if prefs.get(\"sync_bashrc_to_home\", False):\n            sync_bashrc_to_home(base_dir)\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.bashrc.prompt_copy_bashrc_to_home","title":"prompt_copy_bashrc_to_home","text":"<pre><code>prompt_copy_bashrc_to_home(base_dir)\n</code></pre> <p>Prompts user if they want to copy project .bashrc to their home directory. This makes Sim4Life Python available automatically in all new bash sessions.</p> Source code in <code>goliat/utils/bashrc.py</code> <pre><code>def prompt_copy_bashrc_to_home(base_dir):\n    \"\"\"\n    Prompts user if they want to copy project .bashrc to their home directory.\n    This makes Sim4Life Python available automatically in all new bash sessions.\n    \"\"\"\n    project_bashrc = os.path.join(base_dir, \".bashrc\")\n    home_bashrc = os.path.join(os.path.expanduser(\"~\"), \".bashrc\")\n\n    # Only prompt if project .bashrc exists\n    if not os.path.exists(project_bashrc):\n        return\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"Optional: Make Sim4Life Python available automatically\")\n    print(\"=\" * 80)\n    print(\"GOLIAT has created a .bashrc file in the project directory.\")\n    print(\"This file adds Sim4Life Python to your PATH.\")\n    print()\n    print(\"OPTION 1 (Recommended for beginners):\")\n    print(\"  Copy this configuration to your home directory (~/.bashrc)\")\n    print(\"  PRO: Sim4Life Python will be available automatically in ALL new bash windows\")\n    print(\"  PRO: You won't need to remember to run 'source .bashrc' each time\")\n    print(\"  CON: This modifies your global bash configuration\")\n    print()\n    print(\"OPTION 2 (Default):\")\n    print(\"  Keep using the project-local .bashrc file\")\n    print(\"  PRO: Non-intrusive - doesn't modify your global bash config\")\n    print(\"  CON: You must run 'source .bashrc' each time you open a new bash terminal\")\n    print(\"       (or navigate to the project directory and source it)\")\n    print()\n\n    response = input(\"Copy .bashrc to your home directory? [y/N]: \").strip().lower()\n\n    if response in [\"y\", \"yes\"]:\n        # Read project .bashrc content\n        try:\n            with open(project_bashrc, \"r\", encoding=\"utf-8\") as f:\n                bashrc_content = f.read()\n        except Exception as e:\n            logging.warning(f\"Could not read project .bashrc: {e}\")\n            return\n\n        # Check if content already exists in home .bashrc\n        existing_content = \"\"\n        if os.path.exists(home_bashrc):\n            try:\n                with open(home_bashrc, \"r\", encoding=\"utf-8\") as f:\n                    existing_content = f.read()\n            except Exception as e:\n                logging.warning(f\"Could not read existing ~/.bashrc: {e}\")\n\n        # Check if Sim4Life paths are already present\n        if \"Sim4Life\" in existing_content or any(\n            line.strip() in existing_content for line in bashrc_content.split(\"\\n\") if line.strip() and not line.strip().startswith(\"#\")\n        ):\n            print(\"\\nNote: Sim4Life Python paths already found in ~/.bashrc\")\n            overwrite = input(\"  Do you want to update them? [y/N]: \").strip().lower()\n            if overwrite not in [\"y\", \"yes\"]:\n                print(\"  Skipped. Using existing ~/.bashrc configuration.\")\n                return\n\n        # Append to home .bashrc (or create if doesn't exist)\n        try:\n            with open(home_bashrc, \"a\", encoding=\"utf-8\") as f:\n                f.write(\"\\n# GOLIAT: Sim4Life Python PATH (added automatically)\\n\")\n                f.write(bashrc_content)\n                f.write(\"\\n\")\n\n            print(\"\\nDone! Copied .bashrc configuration to ~/.bashrc\")\n            print(\"  New bash windows will automatically have Sim4Life Python in PATH.\")\n            print(\"  You can remove these lines from ~/.bashrc anytime if needed.\")\n            print(\"  This preference will be remembered - future .bashrc updates will sync automatically.\")\n\n            # Save preference\n            prefs = get_user_preferences(base_dir)\n            prefs[\"sync_bashrc_to_home\"] = True\n            save_user_preferences(base_dir, prefs)\n        except Exception as e:\n            logging.error(f\"Failed to write to ~/.bashrc: {e}\")\n            print(f\"\\nError: Could not write to ~/.bashrc: {e}\")\n            print(\"  You can manually copy the content from .bashrc to ~/.bashrc if desired.\")\n    else:\n        print(\"\\nOK, keeping project-local .bashrc\")\n        print(\"  Remember to run 'source .bashrc' when opening new bash terminals,\")\n        print(\"  or navigate to the project directory first.\")\n        print(\"  You can manually copy .bashrc to ~/.bashrc later if desired.\")\n        print(\"  You can edit data/.goliat_preferences.json to enable auto-sync later.\")\n\n        # Save preference as False\n        prefs = get_user_preferences(base_dir)\n        prefs[\"sync_bashrc_to_home\"] = False\n        save_user_preferences(base_dir, prefs)\n</code></pre>"},{"location":"reference/api_reference/#config-setup","title":"Config Setup","text":""},{"location":"reference/api_reference/#goliat.utils.config_setup","title":"goliat.utils.config_setup","text":"<p>Config file setup utilities.</p>"},{"location":"reference/api_reference/#goliat.utils.config_setup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.config_setup.setup_configs","title":"setup_configs","text":"<pre><code>setup_configs(base_dir: Optional[str] = None, overwrite: bool = False) -&gt; None\n</code></pre> <p>Copy default config files from package to base_dir/configs/.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>Optional[str]</code> <p>Base directory where configs should be copied (defaults to current working directory).</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>If True, overwrite existing files without prompting.</p> <code>False</code> Source code in <code>goliat/utils/config_setup.py</code> <pre><code>def setup_configs(base_dir: Optional[str] = None, overwrite: bool = False) -&gt; None:\n    \"\"\"Copy default config files from package to base_dir/configs/.\n\n    Args:\n        base_dir: Base directory where configs should be copied (defaults to current working directory).\n        overwrite: If True, overwrite existing files without prompting.\n    \"\"\"\n    if base_dir is None:\n        base_dir = os.getcwd()\n\n    # Get default configs from package\n    try:\n        from importlib.resources import files\n\n        defaults_traversable = files(\"goliat\") / \"config\" / \"defaults\"\n        if not defaults_traversable.is_dir():\n            raise FileNotFoundError(\"Package defaults directory not found\")\n        # Convert Traversable to Path for easier manipulation\n        defaults_dir = Path(str(defaults_traversable))\n    except (ImportError, ModuleNotFoundError, FileNotFoundError):\n        # Fallback: try to find in repo structure (for editable installs)\n        script_dir = Path(__file__).parent.parent.parent\n        defaults_dir = script_dir / \"config\" / \"defaults\"\n        if not defaults_dir.exists():\n            logging.warning(\"Could not find default config files. Skipping config setup.\")\n            return\n\n    # Target directory\n    configs_dir = Path(base_dir) / \"configs\"\n    configs_dir.mkdir(exist_ok=True)\n\n    # Copy each config file (exclude material_name_mapping.json - it goes to data/)\n    copied_count = 0\n    skipped_count = 0\n\n    for config_file in defaults_dir.glob(\"*.json\"):\n        # Skip material_name_mapping.json - it's copied separately to data/\n        if config_file.name == \"material_name_mapping.json\":\n            continue\n        target_file = configs_dir / config_file.name\n\n        # Check if file exists\n        if target_file.exists() and not overwrite:\n            # Silently skip existing files (don't prompt - this is called during normal operation)\n            skipped_count += 1\n            continue\n\n        # Copy file\n        try:\n            shutil.copy2(str(config_file), str(target_file))\n            logging.info(f\"  Done: Copied {config_file.name}\")\n            copied_count += 1\n        except Exception as e:\n            logging.error(f\"  Failed to copy {config_file.name}: {e}\")\n\n    if copied_count &gt; 0:\n        logging.info(f\"\\nDone: Config files initialized in {configs_dir}\")\n        if skipped_count &gt; 0:\n            logging.info(f\"  ({skipped_count} file(s) skipped - already exist)\")\n\n    # Copy material_name_mapping.json to data/ directory\n    try:\n        material_mapping_source = defaults_dir / \"material_name_mapping.json\"\n        if material_mapping_source.exists():\n            data_dir = Path(base_dir) / \"data\"\n            data_dir.mkdir(exist_ok=True)\n            material_mapping_target = data_dir / \"material_name_mapping.json\"\n\n            if material_mapping_target.exists() and not overwrite:\n                # Silently skip existing files (don't prompt)\n                logging.info(\"  Skipping material_name_mapping.json (already exists)\")\n            else:\n                shutil.copy2(str(material_mapping_source), str(material_mapping_target))\n                logging.info(\"  Done: Copied material_name_mapping.json to data/\")\n    except Exception as e:\n        logging.warning(f\"Could not copy material_name_mapping.json: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#core_1","title":"Core","text":""},{"location":"reference/api_reference/#goliat.utils.core.StudyCancelledError","title":"goliat.utils.core.StudyCancelledError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when the user cancels a study via the GUI.</p>"},{"location":"reference/api_reference/#data","title":"Data","text":""},{"location":"reference/api_reference/#goliat.utils.data","title":"goliat.utils.data","text":"<p>Data downloader for GOLIAT project.</p> <p>Downloads phantoms and antenna data from Google Drive using gdown.</p>"},{"location":"reference/api_reference/#goliat.utils.data-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.data.setup_console_logging","title":"setup_console_logging","text":"<pre><code>setup_console_logging()\n</code></pre> <p>Sets up a basic console logger with color.</p> Source code in <code>goliat/utils/data.py</code> <pre><code>def setup_console_logging():\n    \"\"\"Sets up a basic console logger with color.\"\"\"\n    init_colorama()\n    logger = logging.getLogger(\"script_logger\")\n    logger.setLevel(logging.INFO)\n    handler = logging.StreamHandler()\n    handler.setFormatter(logging.Formatter(\"%(message)s\"))\n    logger.addHandler(handler)\n    return logger\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.data.download_and_extract_data","title":"download_and_extract_data","text":"<pre><code>download_and_extract_data(base_dir, logger, aws=False)\n</code></pre> <p>Downloads folder from Google Drive.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <p>Root directory of the project</p> required <code>logger</code> <p>Logger instance for output</p> required <code>aws</code> <p>If True, downloads AWS-specific phantom file</p> <code>False</code> Source code in <code>goliat/utils/data.py</code> <pre><code>def download_and_extract_data(base_dir, logger, aws=False):\n    \"\"\"\n    Downloads folder from Google Drive.\n\n    Args:\n        base_dir: Root directory of the project\n        logger: Logger instance for output\n        aws: If True, downloads AWS-specific phantom file\n    \"\"\"\n    config_path = os.path.join(base_dir, \"configs/base_config.json\")\n    with open(config_path, \"r\") as f:\n        config = json.load(f)\n\n    data_dir = os.path.join(base_dir, config[\"data_setup\"][\"data_dir\"])\n    if not os.path.exists(data_dir):\n        os.makedirs(data_dir)\n\n    if aws:\n        gdrive_url = config[\"data_setup\"][\"gdrive_url_aws\"]\n        phantoms_dir = os.path.join(data_dir, \"phantoms\")\n        if not os.path.exists(phantoms_dir):\n            os.makedirs(phantoms_dir)\n        output_path = os.path.join(phantoms_dir, \"duke_posable.sab\")\n        logger.info(f\"{colorama.Fore.CYAN}Downloading data from {gdrive_url} into {output_path}...\")\n\n        try:\n            gdown.download(gdrive_url, output=output_path, quiet=False)\n        except Exception as e:\n            logger.warning(f\"{colorama.Fore.YELLOW}gdown failed: {e}\")\n            logger.info(f\"{colorama.Fore.CYAN}Attempting download with wget...\")\n            wget_url = _convert_gdrive_url_for_wget(gdrive_url)\n            if wget_url:\n                try:\n                    subprocess.run([\"wget\", \"--no-check-certificate\", \"-O\", output_path, wget_url], check=True)\n                    logger.info(f\"{colorama.Fore.GREEN}Download completed with wget.\")\n                except (subprocess.CalledProcessError, FileNotFoundError) as wget_error:\n                    logger.error(f\"{colorama.Fore.RED}wget also failed: {wget_error}\")\n                    raise\n            else:\n                logger.error(f\"{colorama.Fore.RED}Cannot convert URL for wget. Both download methods failed.\")\n                raise\n    else:\n        gdrive_url = config[\"data_setup\"][\"gdrive_url\"]\n        logger.info(f\"{colorama.Fore.CYAN}Downloading data from {gdrive_url} into {data_dir}...\")\n\n        try:\n            gdown.download_folder(gdrive_url, output=data_dir, quiet=False)\n        except Exception as e:\n            logger.warning(f\"{colorama.Fore.YELLOW}gdown failed: {e}\")\n            logger.warning(f\"{colorama.Fore.YELLOW}Note: wget does not support folder downloads from Google Drive.\")\n            logger.error(f\"{colorama.Fore.RED}Folder download failed. Please try again later or use gdown with cookies.\")\n            raise\n\n    logger.info(f\"{colorama.Fore.GREEN}Data download complete.\")\n</code></pre>"},{"location":"reference/api_reference/#data-prep","title":"Data Prep","text":""},{"location":"reference/api_reference/#goliat.utils.data_prep","title":"goliat.utils.data_prep","text":"<p>Data preparation utilities.</p> <p>This module handles downloading and preparing data files needed for studies.</p>"},{"location":"reference/api_reference/#goliat.utils.data_prep-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.data_prep.prepare_data","title":"prepare_data","text":"<pre><code>prepare_data(base_dir)\n</code></pre> <p>Ensures all necessary data is downloaded and prepared.</p> <p>This function is idempotent - it checks what exists and only performs missing steps. This allows repair of incomplete setups.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <p>Base directory of the project (where data/ directory is located).</p> required Source code in <code>goliat/utils/data_prep.py</code> <pre><code>def prepare_data(base_dir):\n    \"\"\"\n    Ensures all necessary data is downloaded and prepared.\n\n    This function is idempotent - it checks what exists and only performs\n    missing steps. This allows repair of incomplete setups.\n\n    Args:\n        base_dir: Base directory of the project (where data/ directory is located).\n    \"\"\"\n    from .data import download_and_extract_data\n\n    data_dir = os.path.join(base_dir, \"data\")\n\n    # Check and download phantoms if needed\n    phantoms_dir = os.path.join(data_dir, \"phantoms\")\n    phantom_files = []\n    if os.path.exists(phantoms_dir):\n        try:\n            phantom_files = [f for f in os.listdir(phantoms_dir) if f.endswith(\".sab\")]\n        except (PermissionError, OSError) as e:\n            logging.warning(f\"Could not read phantoms directory: {e}. Will attempt to download.\")\n            phantom_files = []\n\n    if not os.path.exists(phantoms_dir) or len(phantom_files) &lt; 4:\n        logging.info(\"Phantoms directory is missing or incomplete. Downloading phantoms...\")\n        download_and_extract_data(base_dir, logging.getLogger(), aws=False)  # Always download standard phantoms\n    else:\n        logging.info(f\"Phantoms already exist ({len(phantom_files)} files found). Skipping download.\")\n\n    # If on AWS, download the extra phantom file\n    if \"aws\" in platform.release():\n        logging.info(\"AWS environment detected. Downloading additional phantom...\")\n        download_and_extract_data(base_dir, logging.getLogger(), aws=True)\n\n    # Check and prepare antennas if needed\n    centered_dir = os.path.join(data_dir, \"antennas\", \"centered\")\n    antenna_files = []\n    if os.path.exists(centered_dir):\n        try:\n            antenna_files = [f for f in os.listdir(centered_dir) if f.endswith(\".sab\")]\n        except (PermissionError, OSError) as e:\n            logging.warning(f\"Could not read antennas directory: {e}. Will attempt to prepare.\")\n            antenna_files = []\n\n    if not os.path.exists(centered_dir) or len(antenna_files) == 0:\n        logging.info(\"Centered antenna directory is missing or empty. Preparing antennas...\")\n        from .scripts.prepare_antennas import main as prepare_antennas_main\n\n        prepare_antennas_main(base_dir)\n    else:\n        logging.info(f\"Centered antennas already exist ({len(antenna_files)} files found). Skipping preparation.\")\n</code></pre>"},{"location":"reference/api_reference/#gui-bridge","title":"Gui Bridge","text":""},{"location":"reference/api_reference/#goliat.utils.gui_bridge.WebGUIBridge","title":"goliat.utils.gui_bridge.WebGUIBridge","text":"<pre><code>WebGUIBridge(server_url: str, machine_id: str, throttle_hz: float = 10.0)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Bridges GUI messages to web monitoring dashboard.</p> <p>Receives messages via enqueue() and forwards them to the dashboard API. Uses an internal queue to decouple from the multiprocessing queue. Throttles messages to prevent overwhelming the API.</p> <p>Parameters:</p> Name Type Description Default <code>server_url</code> <code>str</code> <p>Base URL of the monitoring dashboard (e.g., https://goliat-monitoring.vercel.app)</p> required <code>machine_id</code> <code>str</code> <p>Unique identifier for this machine (typically IP address)</p> required <code>throttle_hz</code> <code>float</code> <p>Maximum message rate in Hz (default: 10 messages/second)</p> <code>10.0</code> Source code in <code>goliat/utils/gui_bridge.py</code> <pre><code>def __init__(self, server_url: str, machine_id: str, throttle_hz: float = 10.0):\n    \"\"\"Initialize the web GUI bridge.\n\n    Args:\n        server_url: Base URL of the monitoring dashboard (e.g., https://goliat-monitoring.vercel.app)\n        machine_id: Unique identifier for this machine (typically IP address)\n        throttle_hz: Maximum message rate in Hz (default: 10 messages/second)\n    \"\"\"\n    self.server_url = server_url.rstrip(\"/\")\n    self.machine_id = machine_id\n    self.throttle_interval = 1.0 / throttle_hz\n    self.internal_queue: Queue = Queue()\n    self.running = False\n    self.thread: Optional[threading.Thread] = None\n    # Use the main loggers so messages appear in log files\n    self.verbose_logger = logging.getLogger(\"verbose\")\n    self.progress_logger = logging.getLogger(\"progress\")\n    self.is_connected = False\n    self.last_heartbeat_success = False\n    self.connection_callback: Optional[Callable[[bool], None]] = None\n    self._system_info: Optional[Dict[str, Any]] = None\n    self.log_executor: Optional[ThreadPoolExecutor] = None\n    self.request_executor: Optional[ThreadPoolExecutor] = None\n\n    # Sequence number for ordering batches when sent in parallel\n    self._sequence_lock = threading.Lock()\n    self._sequence_counter = 0\n\n    # HTTP client for API calls\n    self.http_client = HTTPClient(self.server_url, self.machine_id, self.verbose_logger)\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.gui_bridge.WebGUIBridge-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.gui_bridge.WebGUIBridge.enqueue","title":"enqueue","text":"<pre><code>enqueue(message: Dict[str, Any]) -&gt; None\n</code></pre> <p>Enqueue a message to be forwarded to the dashboard.</p> <p>This method is called by QueueHandler after processing messages for the GUI. Messages are stored in an internal queue and forwarded asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Dict[str, Any]</code> <p>GUI message dictionary with 'type' and other fields</p> required Source code in <code>goliat/utils/gui_bridge.py</code> <pre><code>def enqueue(self, message: Dict[str, Any]) -&gt; None:\n    \"\"\"Enqueue a message to be forwarded to the dashboard.\n\n    This method is called by QueueHandler after processing messages for the GUI.\n    Messages are stored in an internal queue and forwarded asynchronously.\n\n    Args:\n        message: GUI message dictionary with 'type' and other fields\n    \"\"\"\n    if not self.running:\n        self._log(f\"WebGUIBridge not running, dropping message: {message.get('type', 'unknown')}\", level=\"verbose\", log_type=\"warning\")\n        return\n\n    try:\n        self.internal_queue.put_nowait(message)\n    except Exception as e:\n        self._log(f\"Failed to enqueue message: {e}\", level=\"verbose\", log_type=\"warning\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.gui_bridge.WebGUIBridge.start","title":"start","text":"<pre><code>start() -&gt; None\n</code></pre> <p>Start the forwarding thread and send initial heartbeat.</p> Source code in <code>goliat/utils/gui_bridge.py</code> <pre><code>def start(self) -&gt; None:\n    \"\"\"Start the forwarding thread and send initial heartbeat.\"\"\"\n    if self.running:\n        return\n\n    self.running = True\n    # Start thread pools for async HTTP requests\n    # log_executor: Multiple threads for parallel batch sending (order maintained via sequence numbers)\n    self.log_executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix=\"web_bridge_log\")\n    # request_executor: Multiple threads for independent requests like screenshots and heartbeats\n    self.request_executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix=\"web_bridge_req\")\n\n    self.thread = threading.Thread(target=self._forward_loop, daemon=True)\n    self.thread.start()\n    self._log(f\"WebGUIBridge started: {self.server_url}, machine_id={self.machine_id}\", level=\"verbose\")\n\n    # Send initial heartbeat to register worker\n    # Wait a bit for it to complete and call callback with initial status\n    self._send_heartbeat_async(self._system_info)\n    # Also trigger callback with current status (even if unchanged) so GUI gets initial state\n    if self.connection_callback:\n        self.connection_callback(self.is_connected)\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.gui_bridge.WebGUIBridge.set_system_info","title":"set_system_info","text":"<pre><code>set_system_info(system_info: Dict[str, Any]) -&gt; None\n</code></pre> <p>Set system information to be sent with heartbeats.</p> <p>Parameters:</p> Name Type Description Default <code>system_info</code> <code>Dict[str, Any]</code> <p>Dict with gpuName, cpuCores, totalRamGB, hostname</p> required Source code in <code>goliat/utils/gui_bridge.py</code> <pre><code>def set_system_info(self, system_info: Dict[str, Any]) -&gt; None:\n    \"\"\"Set system information to be sent with heartbeats.\n\n    Args:\n        system_info: Dict with gpuName, cpuCores, totalRamGB, hostname\n    \"\"\"\n    self._system_info = system_info\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.gui_bridge.WebGUIBridge.send_heartbeat_with_system_info","title":"send_heartbeat_with_system_info","text":"<pre><code>send_heartbeat_with_system_info(system_info: Dict[str, Any]) -&gt; None\n</code></pre> <p>Send a heartbeat with system information.</p> <p>Parameters:</p> Name Type Description Default <code>system_info</code> <code>Dict[str, Any]</code> <p>Dict with gpuName, cpuCores, totalRamGB, hostname</p> required Source code in <code>goliat/utils/gui_bridge.py</code> <pre><code>def send_heartbeat_with_system_info(self, system_info: Dict[str, Any]) -&gt; None:\n    \"\"\"Send a heartbeat with system information.\n\n    Args:\n        system_info: Dict with gpuName, cpuCores, totalRamGB, hostname\n    \"\"\"\n    self._send_heartbeat(system_info)\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.gui_bridge.WebGUIBridge.stop","title":"stop","text":"<pre><code>stop() -&gt; None\n</code></pre> <p>Stop the forwarding thread and flush any pending batches.</p> Source code in <code>goliat/utils/gui_bridge.py</code> <pre><code>def stop(self) -&gt; None:\n    \"\"\"Stop the forwarding thread and flush any pending batches.\"\"\"\n    self.running = False\n\n    # Flush any remaining messages in the queue before stopping\n    # Give the thread a moment to process remaining messages\n    if self.thread:\n        self.thread.join(timeout=2.0)\n\n    # Flush any remaining messages from internal queue\n    remaining = []\n    try:\n        while True:\n            msg = self.internal_queue.get_nowait()\n            remaining.append(msg)\n    except Exception:\n        pass\n\n    # Don't try to flush remaining messages - just cancel pending requests\n    # This prevents hanging on shutdown when network is slow\n    if remaining:\n        self._log(f\"Dropping {len(remaining)} remaining messages on stop (shutdown)\", level=\"verbose\")\n\n    # Cancel pending futures and shutdown immediately - don't wait for slow requests\n    if hasattr(self, \"log_executor\") and self.log_executor:\n        self.log_executor.shutdown(wait=False, cancel_futures=True)\n    if hasattr(self, \"request_executor\") and self.request_executor:\n        self.request_executor.shutdown(wait=False, cancel_futures=True)\n\n    self._log(\"WebGUIBridge stopped\", level=\"verbose\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.gui_bridge.WebGUIBridge.set_connection_callback","title":"set_connection_callback","text":"<pre><code>set_connection_callback(callback: Callable[[bool], None]) -&gt; None\n</code></pre> <p>Set a callback function to be called when connection status changes.</p> <p>Parameters:</p> Name Type Description Default <code>callback</code> <code>Callable[[bool], None]</code> <p>Function that takes a boolean (True=connected, False=disconnected)</p> required Source code in <code>goliat/utils/gui_bridge.py</code> <pre><code>def set_connection_callback(self, callback: Callable[[bool], None]) -&gt; None:\n    \"\"\"Set a callback function to be called when connection status changes.\n\n    Args:\n        callback: Function that takes a boolean (True=connected, False=disconnected)\n    \"\"\"\n    self.connection_callback = callback\n</code></pre>"},{"location":"reference/api_reference/#h5-slicer","title":"H5 Slicer","text":""},{"location":"reference/api_reference/#goliat.utils.h5_slicer.H5Slicer","title":"goliat.utils.h5_slicer.H5Slicer","text":"<pre><code>H5Slicer(src: File, dst: File, mesh_slices: Dict[str, Tuple[slice, slice, slice, int, int, int]])\n</code></pre> <p>Handles slicing of H5 datasets with proper mesh/bounds handling.</p> <p>Extracts the dataset copying logic from slice_h5_output into a class with dedicated methods for each dataset type.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>File</code> <p>Source H5 file (read mode).</p> required <code>dst</code> <code>File</code> <p>Destination H5 file (write mode).</p> required <code>mesh_slices</code> <code>Dict[str, Tuple[slice, slice, slice, int, int, int]]</code> <p>Dict mapping mesh paths to (sx, sy, sz, NX, NY, NZ).</p> required Source code in <code>goliat/utils/h5_slicer.py</code> <pre><code>def __init__(\n    self,\n    src: h5py.File,\n    dst: h5py.File,\n    mesh_slices: Dict[str, Tuple[slice, slice, slice, int, int, int]],\n):\n    \"\"\"Initialize the slicer with source, destination, and mesh slice info.\n\n    Args:\n        src: Source H5 file (read mode).\n        dst: Destination H5 file (write mode).\n        mesh_slices: Dict mapping mesh paths to (sx, sy, sz, NX, NY, NZ).\n    \"\"\"\n    self.src = src\n    self.dst = dst\n    self.mesh_slices = mesh_slices\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.h5_slicer.H5Slicer-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.h5_slicer.H5Slicer.find_best_mesh","title":"find_best_mesh","text":"<pre><code>find_best_mesh(data_shape: Tuple[int, ...]) -&gt; Optional[str]\n</code></pre> <p>Finds the mesh that matches a dataset's shape.</p> <p>Looks for a mesh where data_shape[0:3] matches either N or N-1 of the axis lengths (for Yee grid staggering).</p> <p>Parameters:</p> Name Type Description Default <code>data_shape</code> <code>Tuple[int, ...]</code> <p>Shape of the dataset (Nx, Ny, Nz, ...).</p> required <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Path to the matching mesh, or None if no match found.</p> Source code in <code>goliat/utils/h5_slicer.py</code> <pre><code>def find_best_mesh(self, data_shape: Tuple[int, ...]) -&gt; Optional[str]:\n    \"\"\"Finds the mesh that matches a dataset's shape.\n\n    Looks for a mesh where data_shape[0:3] matches either N or N-1\n    of the axis lengths (for Yee grid staggering).\n\n    Args:\n        data_shape: Shape of the dataset (Nx, Ny, Nz, ...).\n\n    Returns:\n        Path to the matching mesh, or None if no match found.\n    \"\"\"\n    for m_path, (sx, sy, sz, NX, NY, NZ) in self.mesh_slices.items():\n        match = True\n        for i, dim in enumerate(data_shape[:3]):\n            ax_len = [NX, NY, NZ][i]\n            if dim != ax_len and dim != ax_len - 1:\n                match = False\n                break\n        if match:\n            return m_path\n    return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.h5_slicer.H5Slicer.copy_group","title":"copy_group","text":"<pre><code>copy_group(name: str, obj: Group) -&gt; None\n</code></pre> <p>Copies a group and its attributes to the destination.</p> Source code in <code>goliat/utils/h5_slicer.py</code> <pre><code>def copy_group(self, name: str, obj: h5py.Group) -&gt; None:\n    \"\"\"Copies a group and its attributes to the destination.\"\"\"\n    if name in self.dst:\n        return  # Already created\n    dst_obj = self.dst.create_group(name)\n    for key, val in obj.attrs.items():\n        dst_obj.attrs[key] = val\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.h5_slicer.H5Slicer.copy_dataset","title":"copy_dataset","text":"<pre><code>copy_dataset(name: str, obj: Dataset) -&gt; None\n</code></pre> <p>Copies a dataset, slicing it based on its type (axis, 3D field, etc).</p> Source code in <code>goliat/utils/h5_slicer.py</code> <pre><code>def copy_dataset(self, name: str, obj: h5py.Dataset) -&gt; None:\n    \"\"\"Copies a dataset, slicing it based on its type (axis, 3D field, etc).\"\"\"\n    # Try axis dataset first\n    dst_dataset = self._handle_axis_dataset(name, obj)\n\n    # Try 3D dataset slicing\n    if dst_dataset is None:\n        dst_dataset = self._handle_3d_dataset(name, obj)\n\n    # Handle bounding box\n    if dst_dataset is None and name.endswith(\"bounding_box\"):\n        dst_dataset = self._handle_bounding_box(name, obj)\n\n    # Fallback: copy verbatim\n    if dst_dataset is None:\n        dst_dataset = self._copy_dataset_verbatim(name, obj)\n\n    # Copy attributes\n    for key, val in obj.attrs.items():\n        dst_dataset.attrs[key] = val\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.h5_slicer.H5Slicer.visit_item","title":"visit_item","text":"<pre><code>visit_item(name: str, obj) -&gt; None\n</code></pre> <p>Visitor callback for h5py.visititems.</p> Source code in <code>goliat/utils/h5_slicer.py</code> <pre><code>def visit_item(self, name: str, obj) -&gt; None:\n    \"\"\"Visitor callback for h5py.visititems.\"\"\"\n    if isinstance(obj, h5py.Group):\n        self.copy_group(name, obj)\n    elif isinstance(obj, h5py.Dataset):\n        self.copy_dataset(name, obj)\n</code></pre>"},{"location":"reference/api_reference/#http-client","title":"Http Client","text":""},{"location":"reference/api_reference/#goliat.utils.http_client.HTTPClient","title":"goliat.utils.http_client.HTTPClient","text":"<pre><code>HTTPClient(server_url: str, machine_id: str, logger: Logger)\n</code></pre> <p>               Bases: <code>LoggingMixin</code></p> <p>Handles HTTP requests to the monitoring dashboard API.</p> <p>Parameters:</p> Name Type Description Default <code>server_url</code> <code>str</code> <p>Base URL of the monitoring dashboard.</p> required <code>machine_id</code> <code>str</code> <p>Machine identifier.</p> required <code>logger</code> <code>Logger</code> <p>Logger instance (used for verbose_logger).</p> required Source code in <code>goliat/utils/http_client.py</code> <pre><code>def __init__(self, server_url: str, machine_id: str, logger: logging.Logger) -&gt; None:\n    \"\"\"Initialize HTTP client.\n\n    Args:\n        server_url: Base URL of the monitoring dashboard.\n        machine_id: Machine identifier.\n        logger: Logger instance (used for verbose_logger).\n    \"\"\"\n    self.server_url = server_url.rstrip(\"/\")\n    self.machine_id = machine_id\n    self.verbose_logger = logger\n    self.progress_logger = logger\n    self.gui = None\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.http_client.HTTPClient-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.http_client.HTTPClient.post_gui_update","title":"post_gui_update","text":"<pre><code>post_gui_update(message: Dict[str, Any], timeout: float = 10.0) -&gt; bool\n</code></pre> <p>Send a GUI update message to the API.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Dict[str, Any]</code> <p>Message dictionary to send (will be wrapped in payload).</p> required <code>timeout</code> <code>float</code> <p>Request timeout in seconds (default: 10.0).</p> <code>10.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise.</p> Source code in <code>goliat/utils/http_client.py</code> <pre><code>def post_gui_update(self, message: Dict[str, Any], timeout: float = 10.0) -&gt; bool:\n    \"\"\"Send a GUI update message to the API.\n\n    Args:\n        message: Message dictionary to send (will be wrapped in payload).\n        timeout: Request timeout in seconds (default: 10.0).\n\n    Returns:\n        True if successful, False otherwise.\n    \"\"\"\n    if not REQUESTS_AVAILABLE or requests is None:\n        return False\n\n    message_type = message.get(\"type\", \"unknown\")\n\n    try:\n        payload = {\n            \"machineId\": self.machine_id,\n            \"message\": message,\n            \"timestamp\": time.time(),\n        }\n\n        response = requests.post(  # type: ignore[attr-defined]\n            f\"{self.server_url}/api/gui-update\",\n            json=payload,\n            timeout=timeout,\n        )\n\n        if response.status_code == 200:\n            return True\n        else:\n            self._log(\n                f\"GUI update ({message_type}) returned status {response.status_code}: {response.text[:100]}\",\n                level=\"verbose\",\n                log_type=\"warning\",\n            )\n            return False\n\n    except Exception as e:\n        self._handle_exception(e, message_type, timeout=timeout)\n        return False\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.http_client.HTTPClient.post_heartbeat","title":"post_heartbeat","text":"<pre><code>post_heartbeat(system_info: Optional[Dict[str, Any]] = None, timeout: float = 10.0) -&gt; bool\n</code></pre> <p>Send a heartbeat to the API.</p> <p>Parameters:</p> Name Type Description Default <code>system_info</code> <code>Optional[Dict[str, Any]]</code> <p>Optional system information dictionary.</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Request timeout in seconds (default: 10.0).</p> <code>10.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise.</p> Source code in <code>goliat/utils/http_client.py</code> <pre><code>def post_heartbeat(self, system_info: Optional[Dict[str, Any]] = None, timeout: float = 10.0) -&gt; bool:\n    \"\"\"Send a heartbeat to the API.\n\n    Args:\n        system_info: Optional system information dictionary.\n        timeout: Request timeout in seconds (default: 10.0).\n\n    Returns:\n        True if successful, False otherwise.\n    \"\"\"\n    if not REQUESTS_AVAILABLE or requests is None:\n        return False\n\n    try:\n        payload = {\"machineId\": self.machine_id}\n        if system_info:\n            payload.update(system_info)\n\n        response = requests.post(\n            f\"{self.server_url}/api/heartbeat\",\n            json=payload,\n            timeout=timeout,\n        )\n\n        return response.status_code == 200\n\n    except Exception as e:\n        self._handle_exception(e, \"heartbeat\", timeout=timeout)\n        return False\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.http_client.HTTPClient.post_gui_screenshots","title":"post_gui_screenshots","text":"<pre><code>post_gui_screenshots(screenshots: Dict[str, bytes]) -&gt; bool\n</code></pre> <p>Send GUI screenshots to the API.</p> <p>Sends screenshots as multipart/form-data for efficient binary transfer. Each tab screenshot is sent as a separate file field.</p> <p>Parameters:</p> Name Type Description Default <code>screenshots</code> <code>Dict[str, bytes]</code> <p>Dictionary mapping tab names to JPEG bytes.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if successful, False otherwise.</p> Source code in <code>goliat/utils/http_client.py</code> <pre><code>def post_gui_screenshots(self, screenshots: Dict[str, bytes]) -&gt; bool:\n    \"\"\"Send GUI screenshots to the API.\n\n    Sends screenshots as multipart/form-data for efficient binary transfer.\n    Each tab screenshot is sent as a separate file field.\n\n    Args:\n        screenshots: Dictionary mapping tab names to JPEG bytes.\n\n    Returns:\n        True if successful, False otherwise.\n    \"\"\"\n    if not REQUESTS_AVAILABLE or requests is None:\n        return False\n\n    if not screenshots:\n        return False\n\n    try:\n        # Prepare multipart form data\n        files = []\n        for tab_name, jpeg_bytes in screenshots.items():\n            # Sanitize tab name for form field name (replace spaces with underscores)\n            field_name = tab_name.replace(\" \", \"_\")\n            files.append((field_name, (f\"{field_name}.jpg\", jpeg_bytes, \"image/jpeg\")))\n\n        # Add machineId as form field\n        data = {\"machineId\": self.machine_id}\n\n        # Send with longer timeout for large payloads (up to 2MB for 6 tabs)\n        response = requests.post(  # type: ignore[attr-defined]\n            f\"{self.server_url}/api/gui-screenshots\",\n            data=data,\n            files=files,\n            timeout=30,  # Longer timeout for large payloads\n        )\n\n        if response.status_code == 200:\n            return True\n        else:\n            self._log(\n                f\"GUI screenshots returned status {response.status_code}: {response.text[:100]}\",\n                level=\"verbose\",\n                log_type=\"warning\",\n            )\n            return False\n\n    except Exception as e:\n        self._handle_exception(e, \"gui_screenshots\", timeout=30)\n        return False\n</code></pre>"},{"location":"reference/api_reference/#mesh-slicer","title":"Mesh Slicer","text":""},{"location":"reference/api_reference/#goliat.utils.mesh_slicer","title":"goliat.utils.mesh_slicer","text":"<p>Mesh slicing utilities for SAPD extraction.</p> <p>Provides functions to slice 3D mesh entities to a bounding box around a center point. Used by both SapdExtractor and AutoInducedProcessor to reduce SAPD computation time.</p>"},{"location":"reference/api_reference/#goliat.utils.mesh_slicer-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.mesh_slicer.slice_entity_to_box","title":"slice_entity_to_box","text":"<pre><code>slice_entity_to_box(entity, center_mm: list[float], side_len_mm: float, model_module, xcoremodeling_module, logger: Logger | None = None) -&gt; tuple\n</code></pre> <p>Slices a mesh entity to a bounding box around a center point.</p> <p>Uses 6 PlanarCut operations to create a box-shaped region of the mesh. This is more robust than CSG operations for complex anatomical meshes.</p> <p>Parameters:</p> Name Type Description Default <code>entity</code> <p>The mesh entity to slice (will be modified in-place if slicing succeeds).</p> required <code>center_mm</code> <code>list[float]</code> <p>Center point in mm [x, y, z].</p> required <code>side_len_mm</code> <code>float</code> <p>Side length of the bounding box in mm.</p> required <code>model_module</code> <p>The s4l_v1.model module (for Vec3).</p> required <code>xcoremodeling_module</code> <p>The XCoreModeling module (for PlanarCut, mesh repair).</p> required <code>logger</code> <code>Logger | None</code> <p>Optional logger for debug output.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple of (sliced_entity, success_bool). If slicing fails, returns original entity.</p> Source code in <code>goliat/utils/mesh_slicer.py</code> <pre><code>def slice_entity_to_box(\n    entity,\n    center_mm: list[float],\n    side_len_mm: float,\n    model_module,\n    xcoremodeling_module,\n    logger: logging.Logger | None = None,\n) -&gt; tuple:\n    \"\"\"Slices a mesh entity to a bounding box around a center point.\n\n    Uses 6 PlanarCut operations to create a box-shaped region of the mesh.\n    This is more robust than CSG operations for complex anatomical meshes.\n\n    Args:\n        entity: The mesh entity to slice (will be modified in-place if slicing succeeds).\n        center_mm: Center point in mm [x, y, z].\n        side_len_mm: Side length of the bounding box in mm.\n        model_module: The s4l_v1.model module (for Vec3).\n        xcoremodeling_module: The XCoreModeling module (for PlanarCut, mesh repair).\n        logger: Optional logger for debug output.\n\n    Returns:\n        Tuple of (sliced_entity, success_bool). If slicing fails, returns original entity.\n    \"\"\"\n    if center_mm is None or side_len_mm is None:\n        return entity, False\n\n    try:\n        half_side = side_len_mm / 2.0\n\n        # Use 6 PlanarCut operations to cut mesh to a box\n        # PlanarCut keeps the volume in the half-space along the plane normal\n\n        # Cut -X side: keep everything with x &gt; center_x - half_side\n        entity = xcoremodeling_module.PlanarCut(\n            entity,\n            model_module.Vec3(center_mm[0] - half_side, center_mm[1], center_mm[2]),\n            model_module.Vec3(1, 0, 0),\n        )\n\n        # Cut +X side: keep everything with x &lt; center_x + half_side\n        entity = xcoremodeling_module.PlanarCut(\n            entity,\n            model_module.Vec3(center_mm[0] + half_side, center_mm[1], center_mm[2]),\n            model_module.Vec3(-1, 0, 0),\n        )\n\n        # Cut -Y side\n        entity = xcoremodeling_module.PlanarCut(\n            entity,\n            model_module.Vec3(center_mm[0], center_mm[1] - half_side, center_mm[2]),\n            model_module.Vec3(0, 1, 0),\n        )\n\n        # Cut +Y side\n        entity = xcoremodeling_module.PlanarCut(\n            entity,\n            model_module.Vec3(center_mm[0], center_mm[1] + half_side, center_mm[2]),\n            model_module.Vec3(0, -1, 0),\n        )\n\n        # Cut -Z side\n        entity = xcoremodeling_module.PlanarCut(\n            entity,\n            model_module.Vec3(center_mm[0], center_mm[1], center_mm[2] - half_side),\n            model_module.Vec3(0, 0, 1),\n        )\n\n        # Cut +Z side\n        entity = xcoremodeling_module.PlanarCut(\n            entity,\n            model_module.Vec3(center_mm[0], center_mm[1], center_mm[2] + half_side),\n            model_module.Vec3(0, 0, -1),\n        )\n\n        # Clean up the mesh after planar cuts\n        _cleanup_mesh(entity, xcoremodeling_module, logger)\n\n        return entity, True\n\n    except Exception as e:\n        if logger:\n            logger.warning(f\"Mesh slicing failed: {e}. Using unsliced entity.\")\n        return entity, False\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.mesh_slicer.voxel_idx_to_mm","title":"voxel_idx_to_mm","text":"<pre><code>voxel_idx_to_mm(voxel_idx: list[int], grid_axes: tuple) -&gt; list[float]\n</code></pre> <p>Converts voxel indices to mm coordinates using grid axes.</p> <p>Parameters:</p> Name Type Description Default <code>voxel_idx</code> <code>list[int]</code> <p>Voxel indices [i, j, k].</p> required <code>grid_axes</code> <code>tuple</code> <p>Tuple of (x_axis, y_axis, z_axis) arrays in mm.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Center coordinates in mm [x, y, z].</p> Source code in <code>goliat/utils/mesh_slicer.py</code> <pre><code>def voxel_idx_to_mm(voxel_idx: list[int], grid_axes: tuple) -&gt; list[float]:\n    \"\"\"Converts voxel indices to mm coordinates using grid axes.\n\n    Args:\n        voxel_idx: Voxel indices [i, j, k].\n        grid_axes: Tuple of (x_axis, y_axis, z_axis) arrays in mm.\n\n    Returns:\n        Center coordinates in mm [x, y, z].\n    \"\"\"\n    x_axis, y_axis, z_axis = grid_axes\n    ix, iy, iz = voxel_idx\n    return [\n        float(x_axis[min(ix, len(x_axis) - 1)]),\n        float(y_axis[min(iy, len(y_axis) - 1)]),\n        float(z_axis[min(iz, len(z_axis) - 1)]),\n    ]\n</code></pre>"},{"location":"reference/api_reference/#message-sanitizer","title":"Message Sanitizer","text":""},{"location":"reference/api_reference/#goliat.utils.message_sanitizer.MessageSanitizer","title":"goliat.utils.message_sanitizer.MessageSanitizer","text":"<p>Removes non-serializable objects from messages.</p>"},{"location":"reference/api_reference/#goliat.utils.message_sanitizer.MessageSanitizer-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.message_sanitizer.MessageSanitizer.sanitize","title":"sanitize  <code>staticmethod</code>","text":"<pre><code>sanitize(message: Dict[str, Any]) -&gt; Dict[str, Any]\n</code></pre> <p>Remove non-serializable objects from message.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>Dict[str, Any]</code> <p>GUI message dictionary that may contain non-serializable objects</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Sanitized message dictionary with only JSON-serializable values</p> Source code in <code>goliat/utils/message_sanitizer.py</code> <pre><code>@staticmethod\ndef sanitize(message: Dict[str, Any]) -&gt; Dict[str, Any]:\n    \"\"\"Remove non-serializable objects from message.\n\n    Args:\n        message: GUI message dictionary that may contain non-serializable objects\n\n    Returns:\n        Sanitized message dictionary with only JSON-serializable values\n    \"\"\"\n    sanitized = {}\n    for key, value in message.items():\n        if isinstance(value, (str, int, float, bool, type(None))):\n            sanitized[key] = value\n        elif isinstance(value, (list, tuple)):\n            sanitized[key] = [\n                MessageSanitizer.sanitize(item) if isinstance(item, dict) else item\n                for item in value\n                if isinstance(item, (str, int, float, bool, type(None), dict))\n            ]\n        elif isinstance(value, dict):\n            sanitized[key] = MessageSanitizer.sanitize(value)\n        # Skip other non-serializable types\n    return sanitized\n</code></pre>"},{"location":"reference/api_reference/#package","title":"Package","text":""},{"location":"reference/api_reference/#goliat.utils.package","title":"goliat.utils.package","text":"<p>Package installation and repository checks.</p> <p>This module provides functions for checking if the GOLIAT package is installed and verifying the repository structure.</p>"},{"location":"reference/api_reference/#goliat.utils.package-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.package.check_package_installed","title":"check_package_installed","text":"<pre><code>check_package_installed()\n</code></pre> <p>Check if goliat is installed as a package (editable or regular).</p> Source code in <code>goliat/utils/package.py</code> <pre><code>def check_package_installed():\n    \"\"\"Check if goliat is installed as a package (editable or regular).\"\"\"\n    try:\n        # Check if goliat module can be imported\n        spec = importlib.util.find_spec(\"goliat\")\n        if spec is None:\n            return False\n        # Check if goliat is installed via pip by checking pip list\n        try:\n            result = subprocess.run([sys.executable, \"-m\", \"pip\", \"list\", \"--format=json\"], capture_output=True, text=True, check=True)\n\n            installed_packages = json.loads(result.stdout)\n            # Check if goliat is in the pip list\n            return any(pkg[\"name\"].lower() == \"goliat\" for pkg in installed_packages)\n        except (subprocess.CalledProcessError, json.JSONDecodeError):\n            # Fallback: check if .egg-info exists in project root\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../..\"))\n            egg_info_dir = os.path.join(base_dir, \"goliat.egg-info\")\n            return os.path.exists(egg_info_dir)\n    except ImportError:\n        return False\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.package.check_repo_root","title":"check_repo_root","text":"<pre><code>check_repo_root()\n</code></pre> <p>Checks if the script is running from the root of the repository. It does this by checking for the existence of 'configs/' and 'goliat/' directories.</p> Source code in <code>goliat/utils/package.py</code> <pre><code>def check_repo_root():\n    \"\"\"\n    Checks if the script is running from the root of the repository.\n    It does this by checking for the existence of 'configs/' and 'goliat/' directories.\n    \"\"\"\n    is_root = os.path.isdir(\"configs\") and os.path.isdir(\"goliat\")\n    if not is_root:\n        logging.error(\"This script must be run from the root directory of the GOLIAT repository.\")\n        sys.exit(1)\n</code></pre>"},{"location":"reference/api_reference/#preferences","title":"Preferences","text":""},{"location":"reference/api_reference/#goliat.utils.preferences","title":"goliat.utils.preferences","text":"<p>User preferences management.</p> <p>This module handles loading and saving user preferences for GOLIAT setup.</p> <p>Preferences are stored in data/.goliat_preferences.json and include: - sync_bashrc_to_home: Whether to auto-sync .bashrc to ~/.bashrc - sim4life_python_path: Path to the selected Sim4Life Python directory</p>"},{"location":"reference/api_reference/#goliat.utils.preferences-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.preferences.get_user_preferences","title":"get_user_preferences","text":"<pre><code>get_user_preferences(base_dir)\n</code></pre> <p>Load user preferences from data/.goliat_preferences.json</p> Source code in <code>goliat/utils/preferences.py</code> <pre><code>def get_user_preferences(base_dir):\n    \"\"\"Load user preferences from data/.goliat_preferences.json\"\"\"\n    prefs_file = os.path.join(base_dir, \"data\", \".goliat_preferences.json\")\n    if os.path.exists(prefs_file):\n        try:\n            with open(prefs_file, \"r\", encoding=\"utf-8\") as f:\n                return json.load(f)\n        except Exception:\n            pass\n    return {}\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.preferences.save_user_preferences","title":"save_user_preferences","text":"<pre><code>save_user_preferences(base_dir, preferences)\n</code></pre> <p>Save user preferences to data/.goliat_preferences.json</p> Source code in <code>goliat/utils/preferences.py</code> <pre><code>def save_user_preferences(base_dir, preferences):\n    \"\"\"Save user preferences to data/.goliat_preferences.json\"\"\"\n    prefs_file = os.path.join(base_dir, \"data\", \".goliat_preferences.json\")\n    data_dir = os.path.dirname(prefs_file)\n    os.makedirs(data_dir, exist_ok=True)\n    try:\n        with open(prefs_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump(preferences, f, indent=2)\n    except Exception as e:\n        logging.warning(f\"Could not save preferences: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.preferences.get_sim4life_python_path","title":"get_sim4life_python_path","text":"<pre><code>get_sim4life_python_path(base_dir)\n</code></pre> <p>Get the stored Sim4Life Python path from preferences.</p> <p>Returns:</p> Type Description <p>str or None: The stored path, or None if not set.</p> Source code in <code>goliat/utils/preferences.py</code> <pre><code>def get_sim4life_python_path(base_dir):\n    \"\"\"Get the stored Sim4Life Python path from preferences.\n\n    Returns:\n        str or None: The stored path, or None if not set.\n    \"\"\"\n    prefs = get_user_preferences(base_dir)\n    return prefs.get(\"sim4life_python_path\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.preferences.set_sim4life_python_path","title":"set_sim4life_python_path","text":"<pre><code>set_sim4life_python_path(base_dir, python_path)\n</code></pre> <p>Store the selected Sim4Life Python path in preferences.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <p>Project base directory.</p> required <code>python_path</code> <p>Path to Sim4Life Python directory.</p> required Source code in <code>goliat/utils/preferences.py</code> <pre><code>def set_sim4life_python_path(base_dir, python_path):\n    \"\"\"Store the selected Sim4Life Python path in preferences.\n\n    Args:\n        base_dir: Project base directory.\n        python_path: Path to Sim4Life Python directory.\n    \"\"\"\n    prefs = get_user_preferences(base_dir)\n    prefs[\"sim4life_python_path\"] = python_path\n    save_user_preferences(base_dir, prefs)\n    logging.info(f\"Saved Sim4Life Python path preference: {python_path}\")\n</code></pre>"},{"location":"reference/api_reference/#python-interpreter","title":"Python Interpreter","text":""},{"location":"reference/api_reference/#goliat.utils.python_interpreter","title":"goliat.utils.python_interpreter","text":"<p>Sim4Life Python interpreter detection and management.</p> <p>This module provides functions for finding and checking Sim4Life Python interpreters.</p> <p>Supported versions: - 8.2.x: Original supported version - 9.2.x: Added in 2026</p> <p>NOT supported: - 9.0.x: Internal/beta release</p>"},{"location":"reference/api_reference/#goliat.utils.python_interpreter-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.python_interpreter.find_sim4life_python_executables","title":"find_sim4life_python_executables","text":"<pre><code>find_sim4life_python_executables()\n</code></pre> <p>Scans all drives for Sim4Life Python directories (versions 8.2 and 9.2). Windows-only function - should not be called on Linux/AWS.</p> <p>Returns paths sorted by preference (9.2 before 8.2), excluding unsupported versions like 9.0.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>Sorted list of paths to Sim4Life Python directories.</p> Source code in <code>goliat/utils/python_interpreter.py</code> <pre><code>def find_sim4life_python_executables():\n    \"\"\"\n    Scans all drives for Sim4Life Python directories (versions 8.2 and 9.2).\n    Windows-only function - should not be called on Linux/AWS.\n\n    Returns paths sorted by preference (9.2 before 8.2), excluding unsupported\n    versions like 9.0.\n\n    Returns:\n        list: Sorted list of paths to Sim4Life Python directories.\n    \"\"\"\n    if sys.platform != \"win32\":\n        return []\n\n    drives = [f\"{d}:\\\\\" for d in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" if os.path.exists(f\"{d}:\\\\\")]\n    found_python_dirs = []\n\n    for drive in drives:\n        # Support both 8.x and 9.x versions\n        for version_pattern in [\"Sim4Life_8.*\", \"Sim4Life_9.*\"]:\n            pattern = os.path.join(drive, \"Program Files\", version_pattern, \"Python\")\n            found_python_dirs.extend(m for m in glob.glob(pattern) if os.path.isdir(m))\n\n    # Sort by preference (9.2 first) and filter out unsupported versions (9.0)\n    return sort_versions_by_preference(found_python_dirs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.python_interpreter.find_sim4life_root","title":"find_sim4life_root","text":"<pre><code>find_sim4life_root()\n</code></pre> <p>Finds the Sim4Life installation root directory.</p> <p>Works for both direct Sim4Life Python usage and venvs created with Sim4Life Python using --system-site-packages.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>Path to Sim4Life root directory (e.g., C:\\Program Files\\Sim4Life_9.2.0.12345)</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If Sim4Life installation cannot be found</p> Source code in <code>goliat/utils/python_interpreter.py</code> <pre><code>def find_sim4life_root():\n    \"\"\"\n    Finds the Sim4Life installation root directory.\n\n    Works for both direct Sim4Life Python usage and venvs created with\n    Sim4Life Python using --system-site-packages.\n\n    Returns:\n        str: Path to Sim4Life root directory (e.g., C:\\\\Program Files\\\\Sim4Life_9.2.0.12345)\n\n    Raises:\n        FileNotFoundError: If Sim4Life installation cannot be found\n    \"\"\"\n    # Method 1: If sys.executable is directly Sim4Life Python, go up two directories\n    if \"Sim4Life\" in sys.executable:\n        s4l_root = os.path.dirname(os.path.dirname(sys.executable))\n        if _verify_s4l_root(s4l_root):\n            return s4l_root\n\n    # Method 2: If in a venv, check sys.base_prefix (points to original Python that created venv)\n    if hasattr(sys, \"base_prefix\") and sys.base_prefix != sys.prefix:\n        base_prefix = os.path.normpath(sys.base_prefix)\n        if \"Sim4Life\" in base_prefix:\n            # Try parent directory if base_prefix is Python directory, otherwise try both\n            candidates = (\n                [os.path.dirname(base_prefix)] if os.path.basename(base_prefix) == \"Python\" else [base_prefix, os.path.dirname(base_prefix)]\n            )\n            for s4l_root in candidates:\n                if _verify_s4l_root(s4l_root):\n                    return s4l_root\n\n    raise FileNotFoundError(\"Could not find Sim4Life installation root directory. Please ensure Sim4Life is installed and accessible.\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.python_interpreter.check_python_interpreter","title":"check_python_interpreter","text":"<pre><code>check_python_interpreter(base_dir=None)\n</code></pre> <p>Checks if the correct Sim4Life Python interpreter is being used. If not, it prompts the user to select a valid one and updates .bashrc.</p> <p>Supports Sim4Life 8.2 and 9.2. Version 9.0 is explicitly not supported.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <p>Optional base directory of the project. If provided, will check       user preferences for auto-syncing .bashrc to home directory.</p> <code>None</code> Source code in <code>goliat/utils/python_interpreter.py</code> <pre><code>def check_python_interpreter(base_dir=None):\n    \"\"\"\n    Checks if the correct Sim4Life Python interpreter is being used.\n    If not, it prompts the user to select a valid one and updates .bashrc.\n\n    Supports Sim4Life 8.2 and 9.2. Version 9.0 is explicitly not supported.\n\n    Args:\n        base_dir: Optional base directory of the project. If provided, will check\n                  user preferences for auto-syncing .bashrc to home directory.\n    \"\"\"\n    # Bypass check if running in the Sim4Life cloud environment\n    if \"aws\" in platform.release():\n        logging.info(\"AWS environment detected, bypassing Sim4Life interpreter check.\")\n        return\n\n    viable_pythons = find_sim4life_python_executables()\n\n    # Check if s4l_v1 is available without importing it (avoids triggering S4L initialization/license check)\n    # This handles venvs created with Sim4Life Python using --system-site-packages\n    import importlib.util\n\n    s4l_v1_available = importlib.util.find_spec(\"s4l_v1\") is not None\n\n    if \"Sim4Life\" in sys.executable:\n        sys_executable_dir = os.path.normpath(os.path.dirname(sys.executable))\n        viable_dirs = [os.path.normpath(p) for p in viable_pythons]\n\n        # Check if current interpreter is in the list of viable (supported) interpreters\n        if sys_executable_dir in viable_dirs:\n            detected_version = get_version_display_string()\n            if is_sim4life_92_or_later():\n                logging.info(f\"Sim4Life {detected_version} detected (9.2+ mode enabled).\")\n            else:\n                logging.info(f\"Sim4Life {detected_version} detected.\")\n            return\n\n        # Current interpreter is Sim4Life but not in viable list (e.g., 9.0.x)\n        detected_version = get_sim4life_version()\n        if detected_version and not is_version_supported(detected_version):\n            logging.warning(f\"You are using Sim4Life {get_version_display_string()}, which is not officially supported.\")\n            logging.warning(\"GOLIAT supports Sim4Life versions 8.2 and 9.2. Version 9.0 is not supported.\")\n        else:\n            logging.warning(f\"You are using an unsupported Sim4Life Python interpreter: {sys.executable}\")\n            logging.warning(\"GOLIAT supports Sim4Life versions 8.2 and 9.2.\")\n\n    elif s4l_v1_available:\n        # Running in a venv with system-site-packages\n        detected_version = get_version_display_string()\n        if is_sim4life_92_or_later():\n            logging.info(f\"Sim4Life {detected_version} packages detected via venv (9.2+ mode enabled).\")\n        else:\n            logging.info(f\"Sim4Life {detected_version} packages detected (venv with system-site-packages).\")\n        return\n    else:\n        logging.warning(\"You are not using a Sim4Life Python interpreter.\")\n\n    if not viable_pythons:\n        logging.warning(\"No supported Sim4Life Python executables (v8.2 or v9.2) found on this system.\")\n        logging.warning(\"Continuing with current interpreter - some features may not work as expected.\")\n        return\n\n    # Show helpful header\n    print(\"\\n\" + \"=\" * 70)\n    print(\"GOLIAT - Sim4Life Version Selection\")\n    print(\"=\" * 70)\n    print(\"\\nGOLIAT needs to use a Sim4Life Python interpreter.\")\n    print(\"The following supported versions were found on your system:\\n\")\n\n    for i, p in enumerate(viable_pythons):\n        # Extract version from path for cleaner display\n        import re\n\n        match = re.search(r\"Sim4Life[_-](\\d+\\.\\d+\\.\\d+)\", p)\n        version_str = match.group(1) if match else \"unknown\"\n        recommended = \" (recommended)\" if i == 0 else \"\"\n        print(f\"  [{i + 1}] Sim4Life {version_str}{recommended}\")\n        print(f\"      Path: {p}\")\n\n    print(\"\\n\" + \"-\" * 70)\n    print(\"TIP: Version 9.2 is recommended for new projects.\")\n    print(\"     You can change this later by running: goliat config set-version\")\n    print(\"-\" * 70)\n\n    try:\n        choice = input(\"\\nSelect a version (e.g., '1'), or press Enter for recommended: \")\n\n        if not choice:\n            # Default to first (recommended) option\n            selected_index = 0\n            print(f\"\\nUsing recommended version: {viable_pythons[0]}\")\n        else:\n            selected_index = int(choice) - 1\n            if not 0 &lt;= selected_index &lt; len(viable_pythons):\n                raise ValueError\n\n        selected_python = viable_pythons[selected_index]\n\n        # Save to preferences\n        from .preferences import set_sim4life_python_path\n\n        set_sim4life_python_path(base_dir, selected_python)\n\n        # Update bashrc\n        update_bashrc(selected_python, base_dir=base_dir)\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"SUCCESS! Your Sim4Life version has been configured.\")\n        print(\"=\" * 70)\n        print(f\"\\nSelected: {selected_python}\")\n        print(\"\\nNext steps:\")\n        print(\"  1. Open a new terminal window\")\n        print(\"     (If you haven't synced .bashrc to home, run: source .bashrc)\")\n        print(\"  2. Reinstall GOLIAT for the new Python:\")\n        print(\"     pip install goliat          # or\")\n        print(\"     pip install -e .            # for editable install\")\n        print(\"  3. Run your GOLIAT command\")\n        print(\"\\nTo change versions later, run: goliat config set-version\")\n        print(\"=\" * 70)\n        sys.exit(0)\n\n    except (ValueError, IndexError):\n        print(\"\\nInvalid selection. Please enter a number from the list.\")\n        print(\"You can run GOLIAT again to retry.\")\n        sys.exit(1)\n</code></pre>"},{"location":"reference/api_reference/#setup","title":"Setup","text":""},{"location":"reference/api_reference/#goliat.utils.setup","title":"goliat.utils.setup","text":"<p>Setup utilities for initializing the GOLIAT environment.</p> <p>This module provides the main initial_setup function that orchestrates all setup procedures. Individual setup functions are split into separate modules for better organization.</p>"},{"location":"reference/api_reference/#goliat.utils.setup-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.setup.update_bashrc","title":"update_bashrc","text":"<pre><code>update_bashrc(selected_python_path, base_dir=None)\n</code></pre> <p>Creates/updates a project-local .bashrc with PATH entries for Sim4Life Python.</p> <p>This creates a .bashrc in the project directory (non-intrusive). If base_dir is provided and user preference is set, also syncs to ~/.bashrc.</p> <p>Preserves existing content that is not Sim4Life PATH related, including AX_USE_UNSUPPORTED_CARDS and other custom environment variables.</p> Source code in <code>goliat/utils/bashrc.py</code> <pre><code>def update_bashrc(selected_python_path, base_dir=None):\n    \"\"\"Creates/updates a project-local .bashrc with PATH entries for Sim4Life Python.\n\n    This creates a .bashrc in the project directory (non-intrusive).\n    If base_dir is provided and user preference is set, also syncs to ~/.bashrc.\n\n    Preserves existing content that is not Sim4Life PATH related, including\n    AX_USE_UNSUPPORTED_CARDS and other custom environment variables.\n    \"\"\"\n    bashrc_path = os.path.join(os.getcwd(), \".bashrc\")\n    _, python_line, scripts_line = _to_bash_path(selected_python_path)\n    preserved_lines, preserved_vars, has_ax_unsupported, has_pythonioencoding = _parse_existing_bashrc(bashrc_path)\n    new_lines = _build_bashrc_lines(python_line, scripts_line, preserved_lines, preserved_vars, has_ax_unsupported, has_pythonioencoding)\n\n    with open(bashrc_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(new_lines))\n        if new_lines:\n            f.write(\"\\n\")\n\n    logging.info(\"'.bashrc' has been updated. Please restart your shell or run 'source .bashrc'.\")\n\n    if base_dir:\n        prefs = get_user_preferences(base_dir)\n        if prefs.get(\"sync_bashrc_to_home\", False):\n            sync_bashrc_to_home(base_dir)\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.setup.check_package_installed","title":"check_package_installed","text":"<pre><code>check_package_installed()\n</code></pre> <p>Check if goliat is installed as a package (editable or regular).</p> Source code in <code>goliat/utils/package.py</code> <pre><code>def check_package_installed():\n    \"\"\"Check if goliat is installed as a package (editable or regular).\"\"\"\n    try:\n        # Check if goliat module can be imported\n        spec = importlib.util.find_spec(\"goliat\")\n        if spec is None:\n            return False\n        # Check if goliat is installed via pip by checking pip list\n        try:\n            result = subprocess.run([sys.executable, \"-m\", \"pip\", \"list\", \"--format=json\"], capture_output=True, text=True, check=True)\n\n            installed_packages = json.loads(result.stdout)\n            # Check if goliat is in the pip list\n            return any(pkg[\"name\"].lower() == \"goliat\" for pkg in installed_packages)\n        except (subprocess.CalledProcessError, json.JSONDecodeError):\n            # Fallback: check if .egg-info exists in project root\n            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../..\"))\n            egg_info_dir = os.path.join(base_dir, \"goliat.egg-info\")\n            return os.path.exists(egg_info_dir)\n    except ImportError:\n        return False\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.setup.check_repo_root","title":"check_repo_root","text":"<pre><code>check_repo_root()\n</code></pre> <p>Checks if the script is running from the root of the repository. It does this by checking for the existence of 'configs/' and 'goliat/' directories.</p> Source code in <code>goliat/utils/package.py</code> <pre><code>def check_repo_root():\n    \"\"\"\n    Checks if the script is running from the root of the repository.\n    It does this by checking for the existence of 'configs/' and 'goliat/' directories.\n    \"\"\"\n    is_root = os.path.isdir(\"configs\") and os.path.isdir(\"goliat\")\n    if not is_root:\n        logging.error(\"This script must be run from the root directory of the GOLIAT repository.\")\n        sys.exit(1)\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.setup.find_sim4life_python_executables","title":"find_sim4life_python_executables","text":"<pre><code>find_sim4life_python_executables()\n</code></pre> <p>Scans all drives for Sim4Life Python directories (versions 8.2 and 9.2). Windows-only function - should not be called on Linux/AWS.</p> <p>Returns paths sorted by preference (9.2 before 8.2), excluding unsupported versions like 9.0.</p> <p>Returns:</p> Name Type Description <code>list</code> <p>Sorted list of paths to Sim4Life Python directories.</p> Source code in <code>goliat/utils/python_interpreter.py</code> <pre><code>def find_sim4life_python_executables():\n    \"\"\"\n    Scans all drives for Sim4Life Python directories (versions 8.2 and 9.2).\n    Windows-only function - should not be called on Linux/AWS.\n\n    Returns paths sorted by preference (9.2 before 8.2), excluding unsupported\n    versions like 9.0.\n\n    Returns:\n        list: Sorted list of paths to Sim4Life Python directories.\n    \"\"\"\n    if sys.platform != \"win32\":\n        return []\n\n    drives = [f\"{d}:\\\\\" for d in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" if os.path.exists(f\"{d}:\\\\\")]\n    found_python_dirs = []\n\n    for drive in drives:\n        # Support both 8.x and 9.x versions\n        for version_pattern in [\"Sim4Life_8.*\", \"Sim4Life_9.*\"]:\n            pattern = os.path.join(drive, \"Program Files\", version_pattern, \"Python\")\n            found_python_dirs.extend(m for m in glob.glob(pattern) if os.path.isdir(m))\n\n    # Sort by preference (9.2 first) and filter out unsupported versions (9.0)\n    return sort_versions_by_preference(found_python_dirs)\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.setup.initial_setup","title":"initial_setup","text":"<pre><code>initial_setup()\n</code></pre> <p>Performs all initial checks and setup procedures. - Ensures correct python interpreter is used. - Prompts user before installing dependencies. - Installs package in editable mode if not already installed. - Sets up config files in current directory. - Prepares data files.</p> Source code in <code>goliat/utils/setup.py</code> <pre><code>def initial_setup():\n    \"\"\"\n    Performs all initial checks and setup procedures.\n    - Ensures correct python interpreter is used.\n    - Prompts user before installing dependencies.\n    - Installs package in editable mode if not already installed.\n    - Sets up config files in current directory.\n    - Prepares data files.\n    \"\"\"\n    global _setup_already_run\n\n    # Guard against double execution\n    if _setup_already_run:\n        return\n    _setup_already_run = True\n\n    # Skip everything in CI/test environment\n    if os.environ.get(\"CI\") or os.environ.get(\"PYTEST_CURRENT_TEST\"):\n        return\n\n    # Determine base_dir: prefer cwd if it looks like a repo, otherwise use cwd for PyPI installs\n    cwd = os.getcwd()\n    if os.path.isdir(os.path.join(cwd, \"configs\")) and os.path.isdir(os.path.join(cwd, \"goliat\")):\n        # Running from repo root\n        base_dir = cwd\n    else:\n        # Running from somewhere else (PyPI install or different directory)\n        base_dir = cwd\n\n    # Check if goliat is installed as a package\n    package_installed = check_package_installed()\n\n    if not package_installed:\n        # Prompt user for permission to install\n        print(\"=\" * 80)\n        print(\"GOLIAT Package Installation\")\n        print(\"=\" * 80)\n        print(\"GOLIAT needs to be installed as a Python package to work properly.\")\n        print(\"This will install:\")\n        print(\"  - Python dependencies from pyproject.toml\")\n        print(\"  - GOLIAT package in editable mode (allows code modifications)\")\n        print()\n        print(\"This is a one-time setup. You can modify the code and changes will\")\n        print(\"be reflected immediately without reinstalling.\")\n        print()\n        response = input(\"Do you want to install dependencies and GOLIAT package? [Y/n]: \").strip().lower()\n\n        if response and response != \"y\" and response != \"yes\":\n            print(\"Installation cancelled. GOLIAT cannot run without installation.\")\n            sys.exit(1)\n\n        # Install editable package (this installs dependencies from pyproject.toml automatically)\n        # Only try editable install if we're in a repo structure\n        if os.path.isdir(os.path.join(cwd, \"goliat\")) and os.path.exists(os.path.join(cwd, \"pyproject.toml\")):\n            print(\"\\nInstalling GOLIAT package and dependencies in editable mode...\")\n            try:\n                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", base_dir])\n                print(\"GOLIAT package installed successfully!\")\n            except subprocess.CalledProcessError as e:\n                logging.error(f\"Failed to install GOLIAT package: {e}\")\n                sys.exit(1)\n        else:\n            print(\"\\nInstalling GOLIAT package and dependencies...\")\n            try:\n                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"goliat\"])\n                print(\"GOLIAT package installed successfully!\")\n            except subprocess.CalledProcessError as e:\n                logging.error(f\"Failed to install GOLIAT package: {e}\")\n                sys.exit(1)\n\n    # Verify package is importable\n    try:\n        import importlib.util\n\n        spec = importlib.util.find_spec(\"goliat\")\n        if spec is None:\n            raise ImportError(\"goliat module not found\")\n    except ImportError:\n        logging.error(\"GOLIAT package could not be imported. Please ensure installation completed successfully.\")\n        sys.exit(1)\n\n    # Setup config files in current directory (only if they don't exist)\n    configs_dir = os.path.join(base_dir, \"configs\")\n    configs_exist = os.path.isdir(configs_dir) and any(\n        f.endswith(\".json\") for f in os.listdir(configs_dir) if os.path.isfile(os.path.join(configs_dir, f))\n    )\n\n    if not configs_exist:\n        print(\"\\nSetting up configuration files...\")\n        try:\n            setup_configs(base_dir=base_dir, overwrite=False)\n        except Exception as e:\n            logging.warning(f\"Could not set up config files: {e}\")\n            logging.info(\"You can manually copy configs from the repository if needed.\")\n\n    # Rest of setup (data preparation, etc.)\n    data_dir = os.path.join(base_dir, \"data\")\n    os.makedirs(data_dir, exist_ok=True)\n    lock_file = os.path.join(data_dir, \".setup_done\")\n\n    # Pull Git LFS files (specifically itis_v5.db for multisine dispersion)\n    _pull_lfs_files(base_dir)\n\n    # Always run prepare_data() - it has its own checks to determine what needs to be done\n    # This allows repair of incomplete setups (e.g., if user canceled during antenna preparation)\n    prepare_data(base_dir)\n\n    # Only run expensive one-time checks if lock file doesn't exist\n    if not os.path.exists(lock_file):\n        # Only check repo root if we're in a repo structure (for editable installs)\n        if os.path.isdir(os.path.join(base_dir, \"goliat\")):\n            try:\n                check_repo_root()\n            except SystemExit:\n                # If not in repo root, that's OK for PyPI installs\n                pass\n        # Skip interpreter check in CI/test environment\n        if not os.environ.get(\"CI\") and not os.environ.get(\"PYTEST_CURRENT_TEST\"):\n            check_python_interpreter(base_dir=base_dir)  # This function now handles AWS detection internally\n            # Prompt user about copying .bashrc to home directory (optional)\n            prompt_copy_bashrc_to_home(base_dir)\n        # Create lock file after all one-time checks pass\n        with open(lock_file, \"w\") as f:\n            f.write(\"Setup complete.\")\n    else:\n        # Skip interpreter check in CI/test environment\n        if not os.environ.get(\"CI\") and not os.environ.get(\"PYTEST_CURRENT_TEST\"):\n            check_python_interpreter(base_dir=base_dir)  # This function now handles AWS detection internally\n</code></pre>"},{"location":"reference/api_reference/#skin-voxel-utils","title":"Skin Voxel Utils","text":""},{"location":"reference/api_reference/#goliat.utils.skin_voxel_utils","title":"goliat.utils.skin_voxel_utils","text":"<p>Utilities for extracting skin voxel locations from Sim4Life _Input.h5 files.</p> <p>This module enables efficient worst-case SAPD search by identifying skin voxels (~88k) instead of processing the full phantom volume (~8M voxels).</p>"},{"location":"reference/api_reference/#goliat.utils.skin_voxel_utils-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.skin_voxel_utils.extract_skin_voxels","title":"extract_skin_voxels","text":"<pre><code>extract_skin_voxels(input_h5_path: str, skin_keywords: Optional[Sequence[str]] = None) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict[int, str]]\n</code></pre> <p>Extract skin voxel mask and grid axes from a Sim4Life _Input.h5 file.</p> <p>Parameters:</p> Name Type Description Default <code>input_h5_path</code> <code>str</code> <p>Path to the _Input.h5 file.</p> required <code>skin_keywords</code> <code>Optional[Sequence[str]]</code> <p>Keywords to match skin tissues (case-insensitive). Defaults to [\"skin\"].</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray, ndarray, Dict[int, str]]</code> <p>Tuple of: - skin_mask: Boolean array (Nx, Ny, Nz) where True = skin voxel - axis_x: X-axis coordinates (Nx,) - axis_y: Y-axis coordinates (Ny,) - axis_z: Z-axis coordinates (Nz,) - tissue_map: Dict mapping voxel ID -&gt; tissue name (for debugging)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no mesh with voxel data is found.</p> Source code in <code>goliat/utils/skin_voxel_utils.py</code> <pre><code>def extract_skin_voxels(\n    input_h5_path: str,\n    skin_keywords: Optional[Sequence[str]] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict[int, str]]:\n    \"\"\"Extract skin voxel mask and grid axes from a Sim4Life _Input.h5 file.\n\n    Args:\n        input_h5_path: Path to the _Input.h5 file.\n        skin_keywords: Keywords to match skin tissues (case-insensitive).\n            Defaults to [\"skin\"].\n\n    Returns:\n        Tuple of:\n            - skin_mask: Boolean array (Nx, Ny, Nz) where True = skin voxel\n            - axis_x: X-axis coordinates (Nx,)\n            - axis_y: Y-axis coordinates (Ny,)\n            - axis_z: Z-axis coordinates (Nz,)\n            - tissue_map: Dict mapping voxel ID -&gt; tissue name (for debugging)\n\n    Raises:\n        ValueError: If no mesh with voxel data is found.\n    \"\"\"\n    if skin_keywords is None:\n        skin_keywords = [\"skin\"]\n\n    with h5py.File(input_h5_path, \"r\") as f:\n        # Step 1: Build UUID -&gt; material_name mapping from AllMaterialMaps\n        uuid_to_name = _build_uuid_material_map(f)\n\n        # Step 2: Find mesh with voxel data and extract\n        for mesh_key in f[\"Meshes\"].keys():\n            mesh = f[f\"Meshes/{mesh_key}\"]\n            if \"voxels\" not in mesh:\n                continue\n\n            voxels = mesh[\"voxels\"][:]\n            id_map = mesh[\"id_map\"][:]\n            axis_x = mesh[\"axis_x\"][:]\n            axis_y = mesh[\"axis_y\"][:]\n            axis_z = mesh[\"axis_z\"][:]\n\n            # Step 3: Map voxel IDs to tissue names\n            voxel_id_to_name = _build_voxel_id_map(id_map, uuid_to_name)\n\n            # Step 4: Find skin voxel IDs\n            skin_ids = []\n            for voxel_id, name in voxel_id_to_name.items():\n                name_lower = name.lower()\n                if any(kw.lower() in name_lower for kw in skin_keywords):\n                    skin_ids.append(voxel_id)\n\n            # Step 5: Create boolean mask\n            skin_mask = np.isin(voxels, skin_ids)\n\n            return skin_mask, axis_x, axis_y, axis_z, voxel_id_to_name\n\n    raise ValueError(f\"No mesh with voxel data found in {input_h5_path}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.skin_voxel_utils.get_skin_voxel_coordinates","title":"get_skin_voxel_coordinates","text":"<pre><code>get_skin_voxel_coordinates(skin_mask: ndarray, axis_x: ndarray, axis_y: ndarray, axis_z: ndarray) -&gt; np.ndarray\n</code></pre> <p>Get physical coordinates of skin voxels.</p> <p>Parameters:</p> Name Type Description Default <code>skin_mask</code> <code>ndarray</code> <p>Boolean mask from extract_skin_voxels.</p> required <code>axis_x, axis_y, axis_z</code> <p>Grid axes from extract_skin_voxels.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of shape (N_skin_voxels, 3) with [x, y, z] coordinates in meters.</p> Source code in <code>goliat/utils/skin_voxel_utils.py</code> <pre><code>def get_skin_voxel_coordinates(\n    skin_mask: np.ndarray,\n    axis_x: np.ndarray,\n    axis_y: np.ndarray,\n    axis_z: np.ndarray,\n) -&gt; np.ndarray:\n    \"\"\"Get physical coordinates of skin voxels.\n\n    Args:\n        skin_mask: Boolean mask from extract_skin_voxels.\n        axis_x, axis_y, axis_z: Grid axes from extract_skin_voxels.\n\n    Returns:\n        Array of shape (N_skin_voxels, 3) with [x, y, z] coordinates in meters.\n    \"\"\"\n    indices = np.argwhere(skin_mask)  # Shape: (N, 3) with [ix, iy, iz]\n\n    # Convert indices to physical coordinates (voxel centers)\n    # Note: axis arrays define node positions, voxel center is between nodes\n    coords = np.zeros((len(indices), 3), dtype=np.float64)\n    for i, (ix, iy, iz) in enumerate(indices):\n        # Clamp to valid range for center calculation\n        ix_clamped = min(ix, len(axis_x) - 2)\n        iy_clamped = min(iy, len(axis_y) - 2)\n        iz_clamped = min(iz, len(axis_z) - 2)\n\n        coords[i, 0] = (axis_x[ix_clamped] + axis_x[ix_clamped + 1]) / 2\n        coords[i, 1] = (axis_y[iy_clamped] + axis_y[iy_clamped + 1]) / 2\n        coords[i, 2] = (axis_z[iz_clamped] + axis_z[iz_clamped + 1]) / 2\n\n    return coords\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.skin_voxel_utils.extract_air_voxels","title":"extract_air_voxels","text":"<pre><code>extract_air_voxels(input_h5_path: str, background_keywords: Optional[Sequence[str]] = None) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict[int, str]]\n</code></pre> <p>Extract air/background voxel mask from a Sim4Life _Input.h5 file.</p> <p>Detects air/background voxels using multiple strategies: 1. Look for materials matching background_keywords (default: \"background\") 2. Find unmapped voxel IDs (not in AllMaterialMaps) 3. If still no air found, log a warning</p> <p>Parameters:</p> Name Type Description Default <code>input_h5_path</code> <code>str</code> <p>Path to the _Input.h5 file.</p> required <code>background_keywords</code> <code>Optional[Sequence[str]]</code> <p>Keywords to match background materials (default: [\"background\"]).</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray, ndarray, Dict[int, str]]</code> <p>Tuple of: - air_mask: Boolean array (Nx, Ny, Nz) where True = air voxel - axis_x: X-axis coordinates (Nx,) - axis_y: Y-axis coordinates (Ny,) - axis_z: Z-axis coordinates (Nz,) - tissue_map: Dict mapping voxel ID -&gt; tissue name (for debugging)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no mesh with voxel data is found.</p> Source code in <code>goliat/utils/skin_voxel_utils.py</code> <pre><code>def extract_air_voxels(\n    input_h5_path: str,\n    background_keywords: Optional[Sequence[str]] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict[int, str]]:\n    \"\"\"Extract air/background voxel mask from a Sim4Life _Input.h5 file.\n\n    Detects air/background voxels using multiple strategies:\n    1. Look for materials matching background_keywords (default: \"background\")\n    2. Find unmapped voxel IDs (not in AllMaterialMaps)\n    3. If still no air found, log a warning\n\n    Args:\n        input_h5_path: Path to the _Input.h5 file.\n        background_keywords: Keywords to match background materials (default: [\"background\"]).\n\n    Returns:\n        Tuple of:\n            - air_mask: Boolean array (Nx, Ny, Nz) where True = air voxel\n            - axis_x: X-axis coordinates (Nx,)\n            - axis_y: Y-axis coordinates (Ny,)\n            - axis_z: Z-axis coordinates (Nz,)\n            - tissue_map: Dict mapping voxel ID -&gt; tissue name (for debugging)\n\n    Raises:\n        ValueError: If no mesh with voxel data is found.\n    \"\"\"\n    import logging\n\n    logger = logging.getLogger(\"progress\")\n\n    if background_keywords is None:\n        background_keywords = [\"background\"]\n\n    with h5py.File(input_h5_path, \"r\") as f:\n        # Step 1: Build UUID -&gt; material_name mapping from AllMaterialMaps\n        uuid_to_name = _build_uuid_material_map(f)\n\n        # Step 2: Find mesh with voxel data and extract\n        for mesh_key in f[\"Meshes\"].keys():\n            mesh = f[f\"Meshes/{mesh_key}\"]\n            if \"voxels\" not in mesh:\n                continue\n\n            voxels = mesh[\"voxels\"][:]\n            id_map = mesh[\"id_map\"][:]\n            axis_x = mesh[\"axis_x\"][:]\n            axis_y = mesh[\"axis_y\"][:]\n            axis_z = mesh[\"axis_z\"][:]\n\n            # Step 3: Map voxel IDs to tissue names\n            voxel_id_to_name = _build_voxel_id_map(id_map, uuid_to_name)\n\n            # Strategy 1: Find IDs mapped to background-like materials\n            background_ids = []\n            for vid, name in voxel_id_to_name.items():\n                name_lower = name.lower()\n                if any(kw.lower() in name_lower for kw in background_keywords):\n                    background_ids.append(vid)\n                    logger.info(f\"  Found background material: ID {vid} = '{name}'\")\n\n            # Strategy 2: Find unmapped IDs\n            unique_ids = np.unique(voxels)\n            unmapped_ids = [vid for vid in unique_ids if vid not in voxel_id_to_name]\n            if unmapped_ids:\n                logger.info(f\"  Found {len(unmapped_ids)} unmapped voxel IDs (treating as air)\")\n                background_ids.extend(unmapped_ids)\n\n            # Create boolean mask\n            if background_ids:\n                air_mask = np.isin(voxels, background_ids)\n            else:\n                # Fallback: everything NOT a body tissue is air\n                # This is a last resort - treat voxel ID 0 as background\n                logger.warning(\"  No background material found, using voxel ID 0 as fallback\")\n                air_mask = voxels == 0\n\n            return air_mask, axis_x, axis_y, axis_z, voxel_id_to_name\n\n    raise ValueError(f\"No mesh with voxel data found in {input_h5_path}\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.skin_voxel_utils.find_valid_air_focus_points","title":"find_valid_air_focus_points","text":"<pre><code>find_valid_air_focus_points(input_h5_path: str, cube_size_mm: float = 50.0, skin_keywords: Optional[Sequence[str]] = None, shell_size_mm: float = 10.0) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n</code></pre> <p>Find air voxels that are valid focus point candidates (near skin).</p> <p>Uses scipy.ndimage.binary_dilation for efficient vectorized detection of air voxels that are within shell_size_mm of skin voxels.</p> <p>Parameters:</p> Name Type Description Default <code>input_h5_path</code> <code>str</code> <p>Path to _Input.h5.</p> required <code>cube_size_mm</code> <code>float</code> <p>Size of the cube (in mm) for scoring.</p> <code>50.0</code> <code>skin_keywords</code> <code>Optional[Sequence[str]]</code> <p>Keywords to match skin tissues (default: [\"skin\"]).</p> <code>None</code> <code>shell_size_mm</code> <code>float</code> <p>Size of shell around skin for finding valid air points.</p> <code>10.0</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray, ndarray, ndarray]</code> <p>Tuple of: - valid_air_indices: Array (N_valid, 3) of [ix, iy, iz] indices - axis_x: X-axis coordinates - axis_y: Y-axis coordinates - axis_z: Z-axis coordinates - skin_mask: The skin boolean mask (for reuse)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no valid air focus points are found.</p> Source code in <code>goliat/utils/skin_voxel_utils.py</code> <pre><code>def find_valid_air_focus_points(\n    input_h5_path: str,\n    cube_size_mm: float = 50.0,\n    skin_keywords: Optional[Sequence[str]] = None,\n    shell_size_mm: float = 10.0,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Find air voxels that are valid focus point candidates (near skin).\n\n    Uses scipy.ndimage.binary_dilation for efficient vectorized detection\n    of air voxels that are within shell_size_mm of skin voxels.\n\n    Args:\n        input_h5_path: Path to _Input.h5.\n        cube_size_mm: Size of the cube (in mm) for scoring.\n        skin_keywords: Keywords to match skin tissues (default: [\"skin\"]).\n        shell_size_mm: Size of shell around skin for finding valid air points.\n\n    Returns:\n        Tuple of:\n            - valid_air_indices: Array (N_valid, 3) of [ix, iy, iz] indices\n            - axis_x: X-axis coordinates\n            - axis_y: Y-axis coordinates\n            - axis_z: Z-axis coordinates\n            - skin_mask: The skin boolean mask (for reuse)\n\n    Raises:\n        ValueError: If no valid air focus points are found.\n    \"\"\"\n    import time\n    import logging\n    from scipy import ndimage\n\n    logger = logging.getLogger(\"progress\")\n\n    t0 = time.perf_counter()\n    air_mask, ax_x, ax_y, ax_z, _ = extract_air_voxels(input_h5_path)\n    logger.info(f\"  [timing] extract_air_voxels: {time.perf_counter() - t0:.2f}s\")\n\n    t0 = time.perf_counter()\n    skin_mask, _, _, _, _ = extract_skin_voxels(input_h5_path, skin_keywords)\n    logger.info(f\"  [timing] extract_skin_voxels: {time.perf_counter() - t0:.2f}s\")\n\n    logger.info(f\"  Grid shape: {air_mask.shape}, Air voxels: {np.sum(air_mask):,}, Skin voxels: {np.sum(skin_mask):,}\")\n\n    dx = np.mean(np.diff(ax_x))\n    dy = np.mean(np.diff(ax_y))\n    dz = np.mean(np.diff(ax_z))\n    logger.info(f\"  Voxel spacing: dx={dx * 1000:.2f}mm, dy={dy * 1000:.2f}mm, dz={dz * 1000:.2f}mm\")\n\n    # Use iterative dilation for large shells (much faster than single large kernel)\n    # Smaller step = more iterations = better progress visibility + faster due to cache locality\n    step_size_mm = 2.0  # 2mm per iteration for better progress tracking\n    n_iterations = max(1, int(np.ceil(shell_size_mm / step_size_mm)))\n    effective_step_mm = shell_size_mm / n_iterations\n\n    step_size_m = effective_step_mm / 1000.0\n    half_nx = max(1, int(np.ceil(step_size_m / (2 * dx))))\n    half_ny = max(1, int(np.ceil(step_size_m / (2 * dy))))\n    half_nz = max(1, int(np.ceil(step_size_m / (2 * dz))))\n\n    struct_size = (2 * half_nx + 1, 2 * half_ny + 1, 2 * half_nz + 1)\n    logger.info(f\"  Dilation: {n_iterations} iterations \u00d7 {struct_size} kernel (~{shell_size_mm}mm total)\")\n\n    t0 = time.perf_counter()\n    struct = np.ones(struct_size, dtype=bool)\n\n    # Import tqdm for progress tracking\n    try:\n        from tqdm import tqdm\n\n        use_tqdm = True\n    except ImportError:\n        use_tqdm = False\n\n    # Multi-core CPU with Dask\n    try:\n        import dask.array as da\n        import multiprocessing\n\n        n_cores = multiprocessing.cpu_count()\n        logger.info(f\"  Using multi-core CPU with Dask ({n_cores} cores available)\")\n        logger.info(f\"  Starting multi-core binary dilation ({n_iterations} iterations)...\")\n\n        # Convert to Dask array with intelligent chunking\n        # Chunk size: balance between overhead and parallelism\n        chunk_size = max(50, skin_mask.shape[0] // (n_cores * 2))\n        skin_dask = da.from_array(skin_mask, chunks=(chunk_size, chunk_size, -1))\n\n        dilated_skin = skin_dask\n        iterator = tqdm(range(n_iterations), desc=\"  Dilation (CPU-Dask)\", unit=\"iter\") if False else range(n_iterations)\n\n        for i in iterator:\n            # Use scipy's ndimage on each chunk in parallel\n            dilated_skin = dilated_skin.map_overlap(\n                lambda block: ndimage.binary_dilation(block, structure=struct),\n                depth={0: half_nx, 1: half_ny, 2: half_nz},\n                boundary=\"reflect\",\n                dtype=bool,\n            )\n            if not use_tqdm:\n                logger.info(f\"    Dilation iteration {i + 1}/{n_iterations}: building task graph...\")\n\n        # Compute result with progress bar\n        logger.info(f\"  Computing result across {n_cores} cores...\")\n        # Disabled: with ProgressBar():\n        dilated_skin = dilated_skin.compute()\n\n    except ImportError:\n        # Fallback to single-core scipy if Dask not available\n        logger.warning(\"  Dask not available, falling back to single-core CPU (slow!)\")\n        logger.warning(\"  Install for speedup: python -m pip install dask[array]\")\n        dilated_skin = skin_mask.copy()\n        iterator = tqdm(range(n_iterations), desc=\"  Dilation (CPU-single)\", unit=\"iter\") if False else range(n_iterations)\n        for i in iterator:\n            dilated_skin = ndimage.binary_dilation(dilated_skin, structure=struct)\n\n    logger.info(f\"  [timing] binary_dilation ({n_iterations}x): {time.perf_counter() - t0:.2f}s\")\n\n    # Valid air focus points: air AND within shell around skin\n    valid_air_mask = air_mask &amp; dilated_skin\n\n    # Get indices of valid air voxels\n    t0 = time.perf_counter()\n    valid_air_indices = np.argwhere(valid_air_mask)\n    logger.info(f\"  [timing] argwhere: {time.perf_counter() - t0:.2f}s, found {len(valid_air_indices):,} valid air points\")\n\n    if len(valid_air_indices) == 0:\n        raise ValueError(f\"No valid air focus points found. Try increasing shell_size_mm (current: {shell_size_mm}mm).\")\n\n    return valid_air_indices, ax_x, ax_y, ax_z, skin_mask\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.skin_voxel_utils.compute_distance_to_skin","title":"compute_distance_to_skin","text":"<pre><code>compute_distance_to_skin(skin_mask: ndarray, axis_x: ndarray, axis_y: ndarray, axis_z: ndarray) -&gt; np.ndarray\n</code></pre> <p>Compute Euclidean distance from every voxel to the nearest skin voxel.</p> <p>Uses scipy's distance_transform_edt for efficient computation. The result is a 3D array where each voxel contains its distance (in mm) to the nearest skin voxel.</p> <p>Performance: O(N) where N is total voxels. For a 500\u00b3 grid, takes ~5-10 seconds.</p> <p>Parameters:</p> Name Type Description Default <code>skin_mask</code> <code>ndarray</code> <p>Boolean array (Nx, Ny, Nz) where True = skin voxel.</p> required <code>axis_x, axis_y, axis_z</code> <p>Grid axes in meters.</p> required <p>Returns:</p> Name Type Description <code>distance_map</code> <code>ndarray</code> <p>Array (Nx, Ny, Nz) with distance to nearest skin in mm. Skin voxels have distance 0.</p> Source code in <code>goliat/utils/skin_voxel_utils.py</code> <pre><code>def compute_distance_to_skin(\n    skin_mask: np.ndarray,\n    axis_x: np.ndarray,\n    axis_y: np.ndarray,\n    axis_z: np.ndarray,\n) -&gt; np.ndarray:\n    \"\"\"Compute Euclidean distance from every voxel to the nearest skin voxel.\n\n    Uses scipy's distance_transform_edt for efficient computation. The result\n    is a 3D array where each voxel contains its distance (in mm) to the nearest\n    skin voxel.\n\n    Performance: O(N) where N is total voxels. For a 500\u00b3 grid, takes ~5-10 seconds.\n\n    Args:\n        skin_mask: Boolean array (Nx, Ny, Nz) where True = skin voxel.\n        axis_x, axis_y, axis_z: Grid axes in meters.\n\n    Returns:\n        distance_map: Array (Nx, Ny, Nz) with distance to nearest skin in mm.\n            Skin voxels have distance 0.\n    \"\"\"\n    from scipy.ndimage import distance_transform_edt\n\n    logger = logging.getLogger(\"progress\")\n    t0 = time.perf_counter()\n\n    # Compute voxel spacing in mm\n    dx_mm = np.mean(np.diff(axis_x)) * 1000\n    dy_mm = np.mean(np.diff(axis_y)) * 1000\n    dz_mm = np.mean(np.diff(axis_z)) * 1000\n\n    # EDT on inverted mask: distance FROM non-skin TO skin\n    # skin_mask=True means skin, we want distance from air to nearest skin\n    distance_map = distance_transform_edt(~skin_mask, sampling=(dx_mm, dy_mm, dz_mm))\n\n    logger.info(\n        f\"  [timing] distance_transform_edt: {time.perf_counter() - t0:.2f}s, \"\n        f\"shape={distance_map.shape}, range=[{distance_map.min():.1f}, {distance_map.max():.1f}] mm\"\n    )\n\n    return distance_map.astype(np.float32)  # float32 saves memory, sufficient precision\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.skin_voxel_utils.get_distances_at_indices","title":"get_distances_at_indices","text":"<pre><code>get_distances_at_indices(distance_map: ndarray, indices: ndarray) -&gt; np.ndarray\n</code></pre> <p>Look up distances to skin for given voxel indices.</p> <p>Parameters:</p> Name Type Description Default <code>distance_map</code> <code>ndarray</code> <p>3D distance map from compute_distance_to_skin().</p> required <code>indices</code> <code>ndarray</code> <p>Array (N, 3) of [ix, iy, iz] voxel indices.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array (N,) of distances in mm.</p> Source code in <code>goliat/utils/skin_voxel_utils.py</code> <pre><code>def get_distances_at_indices(\n    distance_map: np.ndarray,\n    indices: np.ndarray,\n) -&gt; np.ndarray:\n    \"\"\"Look up distances to skin for given voxel indices.\n\n    Args:\n        distance_map: 3D distance map from compute_distance_to_skin().\n        indices: Array (N, 3) of [ix, iy, iz] voxel indices.\n\n    Returns:\n        Array (N,) of distances in mm.\n    \"\"\"\n    # Clamp indices to valid range\n    ix = np.minimum(indices[:, 0], distance_map.shape[0] - 1)\n    iy = np.minimum(indices[:, 1], distance_map.shape[1] - 1)\n    iz = np.minimum(indices[:, 2], distance_map.shape[2] - 1)\n\n    return distance_map[ix, iy, iz]\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.skin_voxel_utils.print_tissue_summary","title":"print_tissue_summary","text":"<pre><code>print_tissue_summary(voxels: ndarray, tissue_map: Dict[int, str]) -&gt; None\n</code></pre> <p>Print summary of tissue voxel counts.</p> Source code in <code>goliat/utils/skin_voxel_utils.py</code> <pre><code>def print_tissue_summary(voxels: np.ndarray, tissue_map: Dict[int, str]) -&gt; None:\n    \"\"\"Print summary of tissue voxel counts.\"\"\"\n    unique, counts = np.unique(voxels, return_counts=True)\n    print(\"\\nTissue voxel counts:\")\n    print(\"-\" * 40)\n    for voxel_id, count in sorted(zip(unique, counts), key=lambda x: -x[1]):\n        name = tissue_map.get(voxel_id, f\"Unknown (ID={voxel_id})\")\n        print(f\"  {name:30s}: {count:&gt;10,}\")\n</code></pre>"},{"location":"reference/api_reference/#version","title":"Version","text":""},{"location":"reference/api_reference/#goliat.utils.version","title":"goliat.utils.version","text":"<p>Sim4Life version detection and compatibility utilities.</p> <p>This module provides functions for detecting the Sim4Life version and enabling version-specific behavior throughout GOLIAT.</p> <p>Supported versions: - 8.2.x: Original supported version - 9.2.x: Added in 2026, requires startup order fixes and stdout workarounds</p> <p>NOT supported: - 9.0.x: Internal/beta release, not officially supported</p>"},{"location":"reference/api_reference/#goliat.utils.version-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.version.get_sim4life_version","title":"get_sim4life_version  <code>cached</code>","text":"<pre><code>get_sim4life_version() -&gt; Optional[Tuple[int, int, int]]\n</code></pre> <p>Detect the current Sim4Life version.</p> <p>Tries multiple methods: 1. From the Python executable path (e.g., C:\\Program Files\\Sim4Life_9.2.0.12345\\Python) 2. From sys.base_prefix (for venvs with --system-site-packages) 3. From s4l_v1 module if available</p> <p>Returns:</p> Name Type Description <code>Optional[Tuple[int, int, int]]</code> <p>Tuple of (major, minor, patch) version numbers, or None if not detected.</p> <code>Example</code> <code>Optional[Tuple[int, int, int]]</code> <p>(9, 2, 0) for Sim4Life 9.2.0</p> Note <p>Results are cached for performance. Call get_sim4life_version.cache_clear() to reset if needed (e.g., in tests).</p> Source code in <code>goliat/utils/version.py</code> <pre><code>@lru_cache(maxsize=1)\ndef get_sim4life_version() -&gt; Optional[Tuple[int, int, int]]:\n    \"\"\"Detect the current Sim4Life version.\n\n    Tries multiple methods:\n    1. From the Python executable path (e.g., C:\\\\Program Files\\\\Sim4Life_9.2.0.12345\\\\Python)\n    2. From sys.base_prefix (for venvs with --system-site-packages)\n    3. From s4l_v1 module if available\n\n    Returns:\n        Tuple of (major, minor, patch) version numbers, or None if not detected.\n        Example: (9, 2, 0) for Sim4Life 9.2.0\n\n    Note:\n        Results are cached for performance. Call get_sim4life_version.cache_clear()\n        to reset if needed (e.g., in tests).\n    \"\"\"\n    # Method 1: Check executable path\n    version = _parse_version_from_path(sys.executable)\n    if version:\n        return version\n\n    # Method 2: Check base_prefix (for venvs)\n    if hasattr(sys, \"base_prefix\") and sys.base_prefix != sys.prefix:\n        version = _parse_version_from_path(sys.base_prefix)\n        if version:\n            return version\n\n    # Method 3: Try to get from s4l_v1 module (if already imported)\n    if \"s4l_v1\" in sys.modules:\n        try:\n            import s4l_v1\n\n            version_str = getattr(s4l_v1, \"__version__\", None) or getattr(s4l_v1, \"VERSION\", None)\n            if version_str:\n                return _parse_version_string(version_str)\n        except (ImportError, AttributeError):\n            pass\n\n    return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.version.get_sim4life_major_minor","title":"get_sim4life_major_minor","text":"<pre><code>get_sim4life_major_minor() -&gt; Optional[Tuple[int, int]]\n</code></pre> <p>Get just the major.minor version (e.g., (9, 2) for Sim4Life 9.2.x).</p> <p>Returns:</p> Type Description <code>Optional[Tuple[int, int]]</code> <p>Tuple of (major, minor) or None if version not detected.</p> Source code in <code>goliat/utils/version.py</code> <pre><code>def get_sim4life_major_minor() -&gt; Optional[Tuple[int, int]]:\n    \"\"\"Get just the major.minor version (e.g., (9, 2) for Sim4Life 9.2.x).\n\n    Returns:\n        Tuple of (major, minor) or None if version not detected.\n    \"\"\"\n    version = get_sim4life_version()\n    if version:\n        return (version[0], version[1])\n    return None\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.version.is_sim4life_92_or_later","title":"is_sim4life_92_or_later","text":"<pre><code>is_sim4life_92_or_later() -&gt; bool\n</code></pre> <p>Check if the current Sim4Life version is 9.2 or later.</p> <p>This is useful for enabling 9.2-specific behavior like: - Skipping deprecation warnings that were fixed in 9.2 - Using new API features available only in 9.2+ - Applying stdout workarounds needed in 9.2+</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if running on Sim4Life 9.2 or later, False otherwise.</p> Source code in <code>goliat/utils/version.py</code> <pre><code>def is_sim4life_92_or_later() -&gt; bool:\n    \"\"\"Check if the current Sim4Life version is 9.2 or later.\n\n    This is useful for enabling 9.2-specific behavior like:\n    - Skipping deprecation warnings that were fixed in 9.2\n    - Using new API features available only in 9.2+\n    - Applying stdout workarounds needed in 9.2+\n\n    Returns:\n        True if running on Sim4Life 9.2 or later, False otherwise.\n    \"\"\"\n    version = get_sim4life_version()\n    if not version:\n        return False\n    return version &gt;= (9, 2, 0)\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.version.is_version_supported","title":"is_version_supported","text":"<pre><code>is_version_supported(version: Optional[Tuple[int, int, int]] = None) -&gt; bool\n</code></pre> <p>Check if a Sim4Life version is officially supported by GOLIAT.</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>Optional[Tuple[int, int, int]]</code> <p>Version tuple to check. If None, checks current version.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the version is supported (8.2.x or 9.2.x), False otherwise.</p> Source code in <code>goliat/utils/version.py</code> <pre><code>def is_version_supported(version: Optional[Tuple[int, int, int]] = None) -&gt; bool:\n    \"\"\"Check if a Sim4Life version is officially supported by GOLIAT.\n\n    Args:\n        version: Version tuple to check. If None, checks current version.\n\n    Returns:\n        True if the version is supported (8.2.x or 9.2.x), False otherwise.\n    \"\"\"\n    if version is None:\n        version = get_sim4life_version()\n\n    if version is None:\n        return False\n\n    major_minor = (version[0], version[1])\n\n    # Check if it's an unsupported version (like 9.0)\n    if major_minor in UNSUPPORTED_VERSIONS:\n        return False\n\n    # Check if it's a supported major.minor version\n    return major_minor in SUPPORTED_MAJOR_VERSIONS\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.version.get_version_display_string","title":"get_version_display_string","text":"<pre><code>get_version_display_string() -&gt; str\n</code></pre> <p>Get a human-readable version string for display.</p> <p>Returns:</p> Type Description <code>str</code> <p>String like \"9.2.0\" or \"unknown\" if version not detected.</p> Source code in <code>goliat/utils/version.py</code> <pre><code>def get_version_display_string() -&gt; str:\n    \"\"\"Get a human-readable version string for display.\n\n    Returns:\n        String like \"9.2.0\" or \"unknown\" if version not detected.\n    \"\"\"\n    version = get_sim4life_version()\n    if version:\n        return f\"{version[0]}.{version[1]}.{version[2]}\"\n    return \"unknown\"\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.version.sort_versions_by_preference","title":"sort_versions_by_preference","text":"<pre><code>sort_versions_by_preference(python_paths: list[str]) -&gt; list[str]\n</code></pre> <p>Sort a list of Sim4Life Python paths by version preference.</p> <p>Prefers newer supported versions (9.2 over 8.2) and filters out unsupported versions like 9.0.</p> <p>Parameters:</p> Name Type Description Default <code>python_paths</code> <code>list[str]</code> <p>List of paths to Sim4Life Python directories.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>Sorted list with preferred versions first, unsupported versions removed.</p> Source code in <code>goliat/utils/version.py</code> <pre><code>def sort_versions_by_preference(python_paths: list[str]) -&gt; list[str]:\n    \"\"\"Sort a list of Sim4Life Python paths by version preference.\n\n    Prefers newer supported versions (9.2 over 8.2) and filters out\n    unsupported versions like 9.0.\n\n    Args:\n        python_paths: List of paths to Sim4Life Python directories.\n\n    Returns:\n        Sorted list with preferred versions first, unsupported versions removed.\n    \"\"\"\n\n    def version_key(path: str) -&gt; Tuple[int, int, int]:\n        \"\"\"Return (major, minor, patch) tuple for sorting, (0,0,0) if unknown.\"\"\"\n        version = _parse_version_from_path(path)\n        if version:\n            # Higher versions get higher priority (will sort to end, then we reverse)\n            return version\n        # Unknown versions go last\n        return (0, 0, 0)\n\n    # Filter out unsupported versions (like 9.0.x)\n    filtered = []\n    for path in python_paths:\n        version = _parse_version_from_path(path)\n        if version:\n            major_minor = (version[0], version[1])\n            if major_minor in UNSUPPORTED_VERSIONS:\n                continue  # Skip 9.0.x\n        filtered.append(path)\n\n    # Sort by version, highest first\n    return sorted(filtered, key=version_key, reverse=True)\n</code></pre>"},{"location":"reference/api_reference/#scripts","title":"Scripts","text":""},{"location":"reference/api_reference/#goliat.utils.scripts.cancel_all_jobs","title":"goliat.utils.scripts.cancel_all_jobs","text":""},{"location":"reference/api_reference/#goliat.utils.scripts.cancel_all_jobs-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.scripts.cancel_all_jobs.setup_console_logging","title":"setup_console_logging","text":"<pre><code>setup_console_logging()\n</code></pre> <p>Sets up a basic console logger with color.</p> Source code in <code>goliat/utils/scripts/cancel_all_jobs.py</code> <pre><code>def setup_console_logging():\n    \"\"\"Sets up a basic console logger with color.\"\"\"\n    init_colorama()\n    logger = logging.getLogger(\"osparc_batch\")\n    logger.setLevel(logging.INFO)\n    handler = logging.StreamHandler()\n    handler.setFormatter(logging.Formatter(\"%(message)s\"))\n    logger.addHandler(handler)\n    return logger\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.scripts.cancel_all_jobs.get_osparc_client_config","title":"get_osparc_client_config","text":"<pre><code>get_osparc_client_config(config, osparc_module)\n</code></pre> <p>Initializes and returns the oSPARC client configuration.</p> Source code in <code>goliat/utils/scripts/cancel_all_jobs.py</code> <pre><code>def get_osparc_client_config(config, osparc_module):\n    \"\"\"Initializes and returns the oSPARC client configuration.\"\"\"\n    creds = config.get_osparc_credentials()\n    if not all(k in creds for k in [\"api_key\", \"api_secret\", \"api_server\"]):\n        raise ValueError(\"Missing oSPARC credentials in configuration.\")\n\n    return osparc_module.Configuration(\n        host=creds[\"api_server\"],\n        username=creds[\"api_key\"],\n        password=creds[\"api_secret\"],\n    )\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.scripts.cancel_all_jobs.cancel_all_jobs","title":"cancel_all_jobs","text":"<pre><code>cancel_all_jobs(config_path: str, max_jobs: int, base_dir: Optional[str] = None)\n</code></pre> <p>Cancels all running jobs on the oSPARC platform.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>Path to the configuration file.</p> required <code>max_jobs</code> <code>int</code> <p>Maximum number of jobs to check.</p> required <code>base_dir</code> <code>Optional[str]</code> <p>Base directory (defaults to current working directory).</p> <code>None</code> Source code in <code>goliat/utils/scripts/cancel_all_jobs.py</code> <pre><code>def cancel_all_jobs(config_path: str, max_jobs: int, base_dir: Optional[str] = None):\n    \"\"\"Cancels all running jobs on the oSPARC platform.\n\n    Args:\n        config_path: Path to the configuration file.\n        max_jobs: Maximum number of jobs to check.\n        base_dir: Base directory (defaults to current working directory).\n    \"\"\"\n    import osparc as osparc_module\n\n    from goliat.config import Config\n\n    if base_dir is None:\n        base_dir = os.getcwd()\n\n    config = Config(base_dir, config_path)\n\n    client_cfg = get_osparc_client_config(config, osparc_module)\n\n    solver_key = \"simcore/services/comp/isolve-gpu\"\n    solver_version = \"2.2.212\"\n\n    with osparc_module.ApiClient(client_cfg) as api_client:\n        solvers_api = osparc_module.SolversApi(api_client)\n\n        main_logger.info(f\"{colorama.Fore.MAGENTA}--- Fetching recent jobs (up to {max_jobs}) ---\")\n        all_jobs = []\n        try:\n            limit = 50\n            offset = 0\n            page_num = 0\n            while True:\n                main_logger.info(f\"Fetching page {page_num} (offset: {offset}, limit: {limit})...\")\n                page = solvers_api.get_jobs_page(solver_key, solver_version, limit=limit, offset=offset)\n                if page.items:\n                    main_logger.info(f\"Found {len(page.items)} jobs on this page.\")\n                    all_jobs.extend(page.items)\n                    if len(all_jobs) &gt;= max_jobs:\n                        main_logger.warning(f\"Reached job limit of {max_jobs}. Not fetching any more jobs.\")\n                        break\n                    offset += limit\n                    page_num += 1\n                    time.sleep(0.5)\n                else:\n                    main_logger.info(\"No more jobs found on subsequent pages.\")\n                    break\n        except Exception as e:\n            main_logger.error(f\"{colorama.Fore.RED}An error occurred while fetching jobs: {e}{colorama.Style.RESET_ALL}\")\n\n        if not all_jobs:\n            main_logger.info(\"No jobs found to cancel.\")\n            return\n\n        main_logger.info(f\"\\n--- Found a total of {len(all_jobs)} jobs. Now checking status and cancelling active ones ---\")\n\n        cancelled_jobs_count = 0\n        for job in all_jobs:\n            try:\n                status = solvers_api.inspect_job(solver_key, solver_version, job.id)\n                if status.state in [\n                    \"PENDING\",\n                    \"PUBLISHED\",\n                    \"WAITING_FOR_CLUSTER\",\n                    \"WAITING_FOR_RESOURCES\",\n                    \"STARTED\",\n                    \"RETRYING\",\n                ]:\n                    main_logger.info(f\"Cancelling job {job.id} with status {status.state}...\")\n                    solvers_api.stop_job(solver_key, solver_version, job.id)\n                    main_logger.info(f\"{colorama.Fore.GREEN}Successfully sent cancel signal to job {job.id}.{colorama.Style.RESET_ALL}\")\n                    cancelled_jobs_count += 1\n                else:\n                    pass\n            except Exception as e:\n                main_logger.error(f\"{colorama.Fore.RED}Failed to inspect or cancel job {job.id}: {e}{colorama.Style.RESET_ALL}\")\n\n        main_logger.info(\"\\n--- Summary ---\")\n        main_logger.info(f\"Successfully sent cancellation signals to {cancelled_jobs_count} jobs.\")\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.scripts.prepare_antennas","title":"goliat.utils.scripts.prepare_antennas","text":""},{"location":"reference/api_reference/#goliat.utils.scripts.prepare_antennas-functions","title":"Functions","text":""},{"location":"reference/api_reference/#goliat.utils.scripts.prepare_antennas.center_antenna_and_export_sab","title":"center_antenna_and_export_sab","text":"<pre><code>center_antenna_and_export_sab(file_path, output_dir)\n</code></pre> <p>Opens an antenna .smash file, standardizes its name, centers it, conditionally rotates it, adds a final bounding box, and exports the antenna and its bounding box to a .sab file.</p> Source code in <code>goliat/utils/scripts/prepare_antennas.py</code> <pre><code>def center_antenna_and_export_sab(file_path, output_dir):\n    \"\"\"\n    Opens an antenna .smash file, standardizes its name, centers it,\n    conditionally rotates it, adds a final bounding box, and exports the antenna\n    and its bounding box to a .sab file.\n    \"\"\"\n    logger.info(f\"Processing: {os.path.basename(file_path)}\")\n    document.Open(file_path)\n\n    # --- 1. Identify Target Group and Standardize Name ---\n    base_name = os.path.basename(file_path)\n    freq_match = re.search(r\"\\d+\", base_name)\n    if not freq_match:\n        logger.error(\"  - Error: Could not extract frequency from filename. Skipping.\")\n        document.Close()\n        return\n\n    freq_mhz = int(freq_match.group())\n    freq_str = str(freq_mhz)\n\n    all_groups = [e for e in model.AllEntities() if isinstance(e, model.EntityGroup)]\n    antenna_group = next((g for g in all_groups if g.Name == \"Antenna\"), None)\n    if not antenna_group:\n        antenna_candidates = [g for g in all_groups if g.Name.startswith(\"Antenna\")]\n        if len(antenna_candidates) == 1:\n            antenna_group = antenna_candidates[0]\n    if not antenna_group:\n        mhz_candidates = [g for g in all_groups if \"MHz\" in g.Name]\n        if len(mhz_candidates) == 1:\n            antenna_group = mhz_candidates[0]\n\n    if not antenna_group:\n        logger.error(\"  - Error: Could not identify a unique antenna group. Skipping.\")\n        document.Close()\n        return\n\n    antenna_group.Name = f\"Antenna {freq_str} MHz\"\n\n    # --- 2. Center the Antenna ---\n    bbox = model.GetBoundingBox(antenna_group.Entities)\n    center_point = (np.array(bbox[0]) + np.array(bbox[1])) / 2.0\n\n    translation_transform = XCoreModeling.Transform()\n    translation_transform.Translation = Vec3(-center_point)\n    antenna_group.ApplyTransform(translation_transform)\n\n    # --- 3. Conditionally Rotate the Antenna ---\n    if freq_str not in [\"700\", \"835\"]:\n        scale = model.Vec3(1, 1, 1)\n        rotation = model.Vec3(np.deg2rad(90), 0, 0)\n        translation = model.Vec3(0, 0, 0)\n        rotation_transform = model.Transform(scale, rotation, translation)\n        antenna_group.ApplyTransform(rotation_transform)\n\n    # --- 4. Create Final Bounding Box ---\n    final_bbox = model.GetBoundingBox(antenna_group.Entities)\n    bbox_entity = XCoreModeling.CreateWireBlock(Vec3(final_bbox[0]), Vec3(final_bbox[1]))\n    bbox_entity.Name = \"Antenna bounding box\"\n\n    # --- 5. Export to .sab and Close ---\n    save_filename = f\"{freq_mhz}MHz_centered.sab\"\n    save_path = os.path.join(output_dir, save_filename)\n\n    entities_to_export = [antenna_group, bbox_entity]\n\n    logger.info(f\"  -&gt; Exporting to: {os.path.basename(save_path)}\")\n    model.Export(entities_to_export, save_path)\n    document.Close()\n</code></pre>"},{"location":"reference/api_reference/#goliat.utils.scripts.prepare_antennas.main","title":"main","text":"<pre><code>main(base_dir: str)\n</code></pre> <p>Main entry point for preparing antennas.</p> <p>Parameters:</p> Name Type Description Default <code>base_dir</code> <code>str</code> <p>Base directory of the project (where data/ directory is located).</p> required Source code in <code>goliat/utils/scripts/prepare_antennas.py</code> <pre><code>def main(base_dir: str):\n    \"\"\"Main entry point for preparing antennas.\n\n    Args:\n        base_dir: Base directory of the project (where data/ directory is located).\n    \"\"\"\n    run_application(disable_ui_plugins=True)\n\n    source_dir = os.path.join(base_dir, \"data\", \"antennas\", \"downloaded_from_drive\")\n    centered_dir = os.path.join(base_dir, \"data\", \"antennas\", \"centered\")\n\n    os.makedirs(centered_dir, exist_ok=True)\n\n    files_to_process = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if f.endswith(\".smash\")]\n\n    if not files_to_process:\n        logger.warning(f\"No .smash files found to process in '{source_dir}'.\")\n        return\n\n    logger.info(f\"Found {len(files_to_process)} files to process...\")\n    for file_path in files_to_process:\n        try:\n            center_antenna_and_export_sab(file_path, centered_dir)\n        except Exception as e:\n            logger.error(f\"An unexpected error occurred while processing {os.path.basename(file_path)}: {e}\")\n            if s4l_v1.document.IsOpen():\n                s4l_v1.document.Close()\n\n    logger.info(\"\\nProcessing complete.\")\n</code></pre>"},{"location":"reference/api_reference/#cli-commands","title":"CLI Commands","text":"<p>Entry point commands for running studies and analysis.</p> <p>CLI Commands</p> <p>These are top-level CLI commands. Run <code>goliat --help</code> for full usage information.</p> Command Description <code>goliat study</code> Run a simulation study <code>goliat analyze</code> Run post-processing analysis <code>goliat parallel</code> Run parallel study batches <code>goliat worker</code> Run as a cloud worker <code>goliat free-space</code> Run free-space validation <code>goliat init</code> Initialize GOLIAT environment <code>goliat status</code> Show setup status <code>goliat validate</code> Validate configuration files <code>goliat version</code> Show version information"},{"location":"reference/full_features_list/","title":"Full List of Features","text":"<p>A list of all user-facing features in GOLIAT, organized by category.</p> <p>This document provides a complete reference of every feature available in GOLIAT. Each feature is listed with a brief description. For detailed information on how to use these features, see the User Guide, Configuration Guide, and Advanced Features Guide.</p>"},{"location":"reference/full_features_list/#installation-and-setup","title":"Installation and setup","text":"<ul> <li>Install GOLIAT package in editable mode using <code>python -m pip install -e .</code> (installs dependencies automatically)</li> <li>Initialize GOLIAT environment using <code>goliat init</code> command (verifies setup, downloads data files)</li> <li>Verify Sim4Life Python interpreter is being used</li> <li>Prepare data files (phantoms, antennas) during initialization</li> <li>Automatic prompt for installation when running <code>goliat study</code> if not initialized</li> <li>Check setup status with <code>goliat status</code> command</li> <li>Show GOLIAT version information with <code>goliat version</code> command</li> <li>Configure Sim4Life Python path via <code>.bashrc</code> file</li> <li>Support for Sim4Life bundled Python distribution (no separate Python installation required)</li> </ul>"},{"location":"reference/full_features_list/#configuration-system","title":"Configuration system","text":"<ul> <li>Hierarchical JSON configuration with inheritance from <code>base_config.json</code></li> <li>Study-specific configs extend base config (e.g., <code>near_field_config.json</code>)</li> <li>Override only specific parameters without duplicating settings</li> <li>Validate configuration files with <code>goliat validate</code> command</li> <li>Automatic configuration merging with child configs overriding parent values</li> <li>Support for nested configuration paths using dot notation (e.g., <code>simulation_parameters.global_auto_termination</code>)</li> <li>Config inheritance supports multiple levels of nesting</li> <li>Config file synchronization scripts (<code>scripts/sync_configs.py</code>, <code>scripts/validate_config_sync.py</code>)</li> <li>CI validation to ensure <code>configs/</code> and <code>goliat/config/defaults/</code> stay synchronized</li> </ul>"},{"location":"reference/full_features_list/#study-types","title":"Study types","text":""},{"location":"reference/full_features_list/#near-field-studies","title":"Near-field studies","text":"<ul> <li>Simulate device exposure scenarios (e.g., mobile phones close to body)</li> <li>Support for multiple antenna types (PIFA, IFA)</li> <li>Configure antenna placement scenarios (by_cheek, front_of_eyes, by_belly, on_wrist, etc.)</li> <li>Automatic antenna positioning relative to phantom anatomical landmarks</li> <li>Support for free-space antenna simulations (without phantom body)</li> <li>Calculate localized SAR values (head SAR, trunk SAR)</li> <li>Extract peak spatial-average SAR (psSAR10g) in sensitive tissues</li> <li>Scene alignment optimization for by_cheek placements (aligns entire scene with phone orientation)</li> <li>Phantom rotation towards phone for precise by_cheek contact (automatic angle detection)</li> <li>Configurable phantom rotation angle offset (additional rotation after contact detection)</li> <li>Binary search algorithm for finding exact touching angle (0-30 degrees, 0.5 degree precision)</li> <li>Surface Absorbed Power Density (SAPD): Extract peak and spatial-averaged power density on the skin surface (compliant with IEC/IEEE 63195-2:2022)</li> <li>Fast SAPD calculation via mesh slicing around peak SAR locations</li> <li>H5 slicing optimization for reduced data overhead during SAPD processing</li> <li>Caching system for merged skin surface entities to significantly speed up repeated runs</li> </ul>"},{"location":"reference/full_features_list/#far-field-studies","title":"Far-field studies","text":"<ul> <li>Simulate whole-body environmental exposure (plane waves)</li> <li>Configure incident directions (x_pos, x_neg, y_pos, y_neg, z_pos, z_neg)</li> <li>Support for multiple polarizations (theta, phi) per direction</li> <li>Calculate whole-body average SAR</li> <li>Aggregate results over multiple directions and polarizations</li> <li>Create transfer functions between E-field values and absorption values</li> <li>Support for environmental exposure scenarios</li> <li>Auto-induced exposure mode: Simulate worst-case MaMIMO beamforming by combining environmental results with optimal phase weights</li> <li>Air-based focus search: Searches for beam focus points in air near the body surface (physically correct model of MaMIMO beamforming)</li> <li>Shell-based validity: Only air points within configurable distance (<code>shell_size_mm</code>) from skin surface are considered</li> <li>Hotspot scoring: Ranks focus candidates by mean |E_combined|\u00b2 over nearby skin voxels (proxy for SAPD)</li> <li>Percentile-based selection: Candidates selected from top percentile (<code>selection_percentile</code>) of scored points</li> <li>Diversity constraint: Minimum distance between candidates (<code>min_candidate_distance_mm</code>) ensures body-wide coverage</li> <li>Phase-only weighting with equal amplitudes (1/\u221aN normalization) for realistic base station modeling</li> <li>Legacy skin-based search mode available for comparison (<code>search.mode: \"skin\"</code>)</li> <li>Top-N candidate evaluation: Evaluate multiple focus candidates and report worst-case SAPD</li> <li>Sliced field combination: Only combine fields in configurable cube around focus point for speed</li> <li>Mesh slicing via PlanarCut operations for fast SAPD computation on localized skin region</li> <li>Automatic SAPD extraction using existing IEC-compliant <code>SapdExtractor</code> infrastructure</li> <li>Integrated post-processing: Auto-induced runs automatically after all environmental sims complete for each (phantom, frequency) pair</li> <li>CSV export of all proxy scores and proxy-SAPD correlation data for analysis</li> <li>Caching: Skip auto-induced if <code>auto_induced_summary.json</code> exists and is newer than all <code>_Output.h5</code> files</li> <li>Spherical tessellation support: Generate arbitrary number of incident directions via <code>theta_divisions</code> and <code>phi_divisions</code></li> <li>Multi-sine excitation: Simulate multiple frequencies in a single run using <code>\"700+2450\"</code> config syntax</li> <li>UserDefined waveform with superimposed sinusoids for multi-frequency excitation</li> <li>Automatic DFT extraction at each frequency component via <code>ExtractedFrequencies</code> setting</li> <li>Simulation time automatically extended to capture beat period requirements (multi-sine)</li> <li>Frequency-dependent material dispersion fitting via pole-zero model for multi-sine accuracy</li> <li>Per-frequency SAR extraction with traceback logging for frequency-specific failures</li> <li>~4\u00d7 speedup for widely-spaced frequencies (&gt; 200 MHz apart)</li> <li>Pre-computed phantom cross-sectional areas for each incident direction (stored in <code>data/phantom_skins/</code>)</li> <li>Configurable power balance method: bounding box (sanity check) or phantom cross-section (absorption efficiency)</li> </ul>"},{"location":"reference/full_features_list/#phantom-management","title":"Phantom management","text":"<ul> <li>Automatic phantom model download on first use</li> <li>Support for multiple phantoms (thelonious, eartha, duke_posable, etc.)</li> <li>Configure phantom-specific settings (distances, placements, anatomical landmarks)</li> <li>Enable/disable specific placements per phantom</li> <li>Define separation distances per placement type (cheek, eye, belly)</li> <li>Configure anatomical reference points (nasion, tragus, belly_button)</li> <li>Relative offset coordinates for anatomical landmarks</li> <li>Automatic geometric center calculation for eye, ear, and trunk bounding boxes</li> <li>Phantom licensing handled through email prompt or environment variable</li> <li>Manual phantom download option for offline use</li> </ul>"},{"location":"reference/full_features_list/#antenna-configuration","title":"Antenna configuration","text":"<ul> <li>Frequency-specific antenna configuration</li> <li>Define antenna model type (PIFA, IFA)</li> <li>Configure antenna source name (e.g., \"Lines 1\")</li> <li>Map antenna CAD components to Sim4Life materials</li> <li>Configure gridding strategies per antenna component</li> <li>Support for automatic gridding refinement levels (VeryFine, Fine, Default, Coarse, VeryCoarse)</li> <li>Manual gridding with millimeter step sizes</li> <li>Subgridding support for specific antenna components</li> <li>Subgridding level multipliers (x9, x3, etc.)</li> <li>Subgridding auto-refinement levels (VeryFine, Fine, Default)</li> <li>Subgridding overrides manual gridding for specified components</li> <li>Isolated subgridding: Separate grid settings object to prevent contamination of regular grid</li> <li>Antenna file fallback: Auto-fallback to nearest available frequency when exact match not found</li> </ul>"},{"location":"reference/full_features_list/#placement-scenarios","title":"Placement scenarios","text":"<ul> <li>Define multiple placement scenarios per study</li> <li>Configure positions as [x, y, z] offsets</li> <li>Define orientations as rotation sequences</li> <li>Support for dictionary format orientations (for phantom rotation)</li> <li>Configure bounding box selection (default, head, trunk, whole_body)</li> <li>Specify phantom reference points for placement calculations</li> <li>Configure antenna reference points (e.g., distance_from_top)</li> <li>Automatic default bounding box selection (head for eye/cheek, trunk for belly)</li> <li>Multiple orientations per position (e.g., base, up, rotate_z)</li> </ul>"},{"location":"reference/full_features_list/#simulation-parameters","title":"Simulation parameters","text":"<ul> <li>Configure solver termination criteria (GlobalAutoTerminationWeak, GlobalAutoTerminationUserDefined)</li> <li>Set custom convergence level in decibels (dB)</li> <li>Configure simulation time multiplier</li> <li>Set number of point sensors (default: 8)</li> <li>Configure point sensor placement order (8 corners of bounding box)</li> <li>Select excitation type (Harmonic for single frequency, Gaussian for frequency sweep)</li> <li>Configure Gaussian excitation bandwidth in MHz</li> <li>Gaussian excitation for near-field antenna detuning detection</li> <li>Custom Gaussian waveform support (k parameter) for faster pulses</li> <li>Resonance frequency extraction from Gaussian pulse results</li> <li>Set bounding box padding for far-field simulations (millimeters)</li> <li>Configure free-space antenna bounding box expansion [x, y, z] in millimeters</li> <li>Antenna detuning calibration: Apply calibrated frequency shifts to account for body loading effects</li> <li>Detuning values stored per-frequency in config (e.g., <code>\"700\": -15</code> for 15 MHz lower)</li> <li><code>detuning_enabled</code> config flag to enable/disable detuning compensation</li> <li>Keep-awake functionality (<code>keep_awake</code> config) to prevent system sleep during long simulations</li> </ul>"},{"location":"reference/full_features_list/#gridding-configuration","title":"Gridding configuration","text":"<ul> <li>Global gridding mode selection (automatic or manual)</li> <li>Automatic gridding refinement levels (VeryFine, Fine, Default, Coarse, VeryCoarse)</li> <li>Manual gridding with maximum step size fallback (millimeters)</li> <li>Per-frequency manual grid step sizes for far-field studies</li> <li>Padding mode selection (automatic or manual)</li> <li>Manual padding configuration for bottom and top of domain [x, y, z]</li> <li>Intelligent gridding around critical areas (finer cells near antenna/phantom surface)</li> <li>Automatic gridding optimization for computational efficiency</li> <li>Phantom bounding box reduction (far-field): Automatically truncate phantom height for high-frequency simulations to reduce cell count</li> <li>Cubic frequency scaling: height_factor = (reference_freq / current_freq)\u00b3</li> <li>Manual per-frequency height limits override automatic calculation</li> <li>Symmetry reduction: Cut phantom bbox at x=0 to exploit human bilateral symmetry (~50% cell reduction)</li> </ul>"},{"location":"reference/full_features_list/#solver-configuration","title":"Solver configuration","text":"<ul> <li>Select solver kernel (Software/CPU, Acceleware/GPU, CUDA/GPU)</li> <li>Configure boundary conditions type (UpmlCpml)</li> <li>Set boundary condition strength (Weak, Medium, Strong)</li> <li>Enable manual iSolve execution (bypasses Ares scheduler bug)</li> <li>Export material properties to pickle file (advanced option)</li> <li>Enable line-by-line code profiling for specific functions</li> <li>Configure profiling targets (subtasks and function names)</li> </ul>"},{"location":"reference/full_features_list/#execution-control","title":"Execution control","text":"<ul> <li>Enable/disable setup phase (<code>do_setup</code>)</li> <li>Enable/disable run phase (<code>do_run</code>)</li> <li>Enable/disable extract phase (<code>do_extract</code>)</li> <li>Write input file only without running solver (<code>only_write_input_file</code>)</li> <li>Enable batch run mode for oSPARC cloud (<code>batch_run</code>)</li> <li>Automatic cleanup of previous results (<code>auto_cleanup_previous_results</code>)</li> <li>Selective cleanup options: output files (_Output.h5), input files (*_Input.h5), project files (.smash)</li> <li>Cleanup incompatible with parallel or batch runs (serial workflows only)</li> <li>Automatic project file handling (create new or open existing based on do_setup flag)</li> <li>Bypass caching system with <code>--no-cache</code> command-line flag</li> </ul>"},{"location":"reference/full_features_list/#project-management","title":"Project management","text":"<ul> <li>Automatic Sim4Life project file (<code>.smash</code>) creation</li> <li>Project file validation (checks for file locks and HDF5 structure)</li> <li>File lock detection and handling (<code>.s4l_lock</code> files)</li> <li>Automatic project file cleanup on corruption detection</li> <li>Centralized project save logic with retry mechanism (<code>save_retry_count</code> config parameter)</li> <li>Structured results directory organization (<code>results/{study_type}/{phantom}/{frequency}MHz/{scenario}/</code>)</li> <li>Unique project file per simulation scenario</li> <li>Project isolation for reliability</li> </ul>"},{"location":"reference/full_features_list/#verify-and-resume-caching-system","title":"Verify and resume (caching system)","text":"<ul> <li>Configuration hashing (SHA256) for simulation fingerprinting</li> <li>Surgical configuration creation (single simulation parameters only)</li> <li>Metadata validation (config.json in results directory)</li> <li>Deliverable-first verification approach</li> <li>Check for run phase deliverables (*_Output.h5 file)</li> <li>Check for extract phase deliverables (sar_results.json, sar_stats_all_tissues.pkl, sar_stats_all_tissues.html)</li> <li>Modification timestamp validation (deliverables newer than setup timestamp)</li> <li>Automatic phase skipping for completed simulations</li> <li>Dynamic status reporting (setup_done, run_done, extract_done flags)</li> <li>Metadata update after successful phase completion</li> <li>Resilient to interrupted runs or manual file deletions</li> <li>Override cache with <code>--no-cache</code> flag (deletes existing project and reruns all phases)</li> </ul>"},{"location":"reference/full_features_list/#simulation-execution","title":"Simulation execution","text":""},{"location":"reference/full_features_list/#local-execution","title":"Local execution","text":"<ul> <li>Direct invocation of Sim4Life <code>iSolve.exe</code> solver</li> <li>Real-time solver output logging</li> <li>Progress milestone logging (0%, 33%, 66% completion with time estimates)</li> <li>Non-blocking reader thread for solver output capture</li> <li>Manual iSolve execution (bypasses Ares scheduler)</li> <li>Infinite retry mechanism for failed iSolve runs (retries until successful)</li> <li>Support for GPU acceleration (Acceleware, CUDA kernels)</li> <li>CPU fallback option (Software kernel)</li> <li>Power normalization to 1W input for consistency</li> </ul>"},{"location":"reference/full_features_list/#cloud-execution-osparc","title":"Cloud execution (oSPARC)","text":"<ul> <li>Generate solver input files (<code>.h5</code>) for cloud submission</li> <li>Automatic batch job submission to oSPARC platform</li> <li>Job status monitoring (PENDING \u2192 RUNNING \u2192 SUCCESS)</li> <li>Automatic result download upon job completion</li> <li>Support for API key authentication via <code>.env</code> file</li> <li>Retry mechanism for failed submissions (3 automatic retries)</li> <li>Logging in dedicated directory (<code>logs/osparc_submission_logs/</code>)</li> <li>Maximum ~61 parallel jobs (oSPARC platform limit)</li> <li>Job cancellation script (<code>scripts/cancel_all_jobs.py --config &lt;config&gt;</code>)</li> <li>Cancel specific number of recent jobs (<code>--max-jobs</code> argument, default: 500)</li> <li>Paginated job fetching (50 jobs per page)</li> <li>Cancel jobs by status (PENDING, PUBLISHED, WAITING_FOR_CLUSTER, WAITING_FOR_RESOURCES, STARTED, RETRYING)</li> <li>Cost monitoring via oSPARC dashboard</li> <li>Execution strategy pattern (ISolveManualStrategy, Sim4LifeAPIStrategy, OSPARCDirectStrategy)</li> </ul>"},{"location":"reference/full_features_list/#results-extraction","title":"Results extraction","text":"<ul> <li>Extract whole-body average SAR</li> <li>Extract localized SAR (head SAR, trunk SAR)</li> <li>Extract peak spatial-average SAR over 10g tissue cubes (psSAR10g)</li> <li>Extract SAR for specific tissues (eyes, brain, skin, genitals)</li> <li>Extract SAR for all tissues defined by Sim4Life</li> <li>Calculate power balance (energy conservation check, ideally ~100%)</li> <li>Normalize all SAR values to 1W input power</li> <li>Generate JSON summary file (<code>sar_results.json</code>)</li> <li>Generate detailed pickle file (<code>sar_stats_all_tissues.pkl</code>)</li> <li>Generate HTML report (<code>sar_results_all_tissues.html</code>)</li> <li>Extract point sensor data (electric field magnitude)</li> <li>Generate point sensor plots (<code>point_sensor_data.png</code>)</li> <li>Extract tissue-specific SAR statistics</li> <li>Tissue group aggregation (eyes, head, skin, genitals) via material name mapping</li> <li>Explicit configuration-based tissue matching (no keyword fallbacks)</li> <li>Preservation of original Sim4Life tissue names (e.g., \"Eye (Cornea)\" vs \"Eye (Lens)\")</li> <li>Phantom suffix handling in tissue name display</li> <li>Antenna detuning detection (frequency shift relative to nominal frequency)</li> <li>SAPD Extraction: Extract surface absorbed power density metrics (peak value and location)</li> <li>Automated ModelToGrid filtering for skin surface extraction</li> <li>Configurable SAPD averaging area (default: 4cm\u00b2) and threshold (default: 10mm)</li> <li>Simulation metadata export: Automatically export timing, performance, and file size data to pickle and JSON files after extraction</li> <li>Metadata includes: timing breakdown (all phases + subtasks), solver config (iterations, time step, grid resolution, total cell-iterations, power balance), hardware info (GPU model/memory, peak RAM), performance metrics (MCells/s), grid info (MCells with PML), and file sizes (_Output.h5, SAPD H5, .smash)</li> </ul>"},{"location":"reference/full_features_list/#analysis-and-visualization","title":"Analysis and visualization","text":"<ul> <li>Aggregate results across multiple simulations</li> <li>Generate CSV files (normalized_results_detailed.csv, normalized_results_summary.csv)</li> <li>Automatic Excel generation: Export results to <code>.xlsx</code> files during analysis</li> <li>Create SAR heatmaps by tissue and frequency</li> <li>Generate bar charts comparing SAR in different regions</li> <li>Create boxplots showing SAR distributions</li> <li>Generate line plots for peak spatial-average SAR</li> <li>Run analysis with <code>goliat analyze --config</code> command</li> <li>Strategy-based analysis (NearFieldAnalysisStrategy, FarFieldAnalysisStrategy)</li> <li>Per-simulation detailed data export</li> <li>Summary statistics by frequency and scenario</li> <li>Plot generation in dedicated plots directory</li> <li>Automated LaTeX paper generation (<code>goliat generate-paper</code>) - Check out the auto-generated first draft paper (only results)</li> <li>UGent vs CNR comparison tool for cross-institution validation</li> <li>CDF plots with linestyle cycling for visual distinction</li> <li>Slanted tick labels and academic styling for publication-ready plots</li> </ul>"},{"location":"reference/full_features_list/#gui-and-monitoring","title":"GUI and monitoring","text":"<ul> <li>Real-time graphical user interface (PySide6-based)</li> <li>Overall progress tracking (e.g., 5 out of 108 simulations complete)</li> <li>Stage progress tracking (setup, run, extract phases for current simulation)</li> <li>Estimated time remaining (ETA) calculation</li> <li>Live log display with color-coding</li> <li>Status message updates</li> <li>Progress bar animations for long-running phases</li> <li>Smooth animation system (50ms timer ticks)</li> <li>Weighted progress calculation based on phase durations</li> <li>Session-based timing configuration files</li> <li>Unique session hash for timing file identification</li> <li>Progress tracking CSV files (time_remaining, overall_progress)</li> <li>Timing data visualization (pie charts, tables)</li> <li>System utilization monitoring (CPU, RAM, GPU, VRAM) with real-time plots</li> <li>System utilization data export to CSV for analysis</li> <li>System tray integration for background operation</li> <li>Responsive GUI (multiprocessing architecture prevents freezing)</li> <li>Headless mode option (<code>use_gui: false</code> for console-only operation)</li> <li>Window title customization via <code>--title</code> command-line argument</li> <li>GUI screenshot streaming to web dashboard for remote monitoring (1 FPS)</li> <li>NTP-based timestamps for plot accuracy (bypasses VM clock drift issues)</li> <li>Smart batching for web dashboard to adapt to network latency</li> <li>Message ordering with timestamps and sequence numbers</li> </ul>"},{"location":"reference/full_features_list/#logging-system","title":"Logging system","text":"<ul> <li>Dual logger system (progress and verbose)</li> <li>Progress logger for high-level user-facing messages</li> <li>Verbose logger for detailed internal messages</li> <li>Progress logs saved to <code>*.progress.log</code></li> <li>Verbose logs saved to <code>*.log</code></li> <li>Automatic log rotation (keeps maximum 15 log file pairs)</li> <li>Automatic deletion of oldest logs when limit exceeded</li> <li>Color-coded console output</li> <li>File handlers and stream handlers for each logger</li> <li>Log propagation control (prevents duplicate output)</li> <li>Process ID support for unique log identification (<code>--pid</code> flag)</li> </ul>"},{"location":"reference/full_features_list/#profiling-and-timing","title":"Profiling and timing","text":"<ul> <li>Phase-level timing tracking (setup, run, extract)</li> <li>Subtask-level timing tracking</li> <li>Session-specific profiling configuration files</li> <li>Average time calculation per phase and subtask</li> <li>ETA calculation based on historical timing data</li> <li>Weighted progress calculation using phase durations</li> <li>Timing data persistence in JSON format</li> <li>Automatic cleanup of old profiling files (keeps maximum 50 files)</li> <li>Timestamp and hash-based file naming for profiling configs</li> <li>Real-time elapsed time tracking for current simulation</li> </ul>"},{"location":"reference/full_features_list/#parallel-execution","title":"Parallel execution","text":""},{"location":"reference/full_features_list/#local-parallel-execution","title":"Local parallel execution","text":"<ul> <li>Split configuration into multiple subsets (<code>goliat parallel</code>)</li> <li>Configure number of splits (<code>--num-splits</code> argument)</li> <li>Automatic splitting logic (by phantoms, frequencies, or combinations)</li> <li>Launch multiple <code>goliat study</code> processes simultaneously</li> <li>One GUI per parallel process</li> <li>Skip splitting step with existing parallel directory (<code>--skip-split</code> flag)</li> <li>Results automatically merged in shared <code>results/</code> directory</li> <li>Support for multi-core CPU utilization</li> <li>Important limitation: On a single-GPU machine, iSolve run phases execute sequentially (only setup and extract phases benefit from parallelization)</li> <li>For true parallel iSolve execution: Use oSPARC batch or multiple Windows PCs</li> </ul>"},{"location":"reference/full_features_list/#splitting-logic","title":"Splitting logic","text":"<ul> <li>2 splits: Halve phantoms</li> <li>4 splits: One per first 4 phantoms</li> <li>8 splits: Split phantoms, then halve frequencies</li> <li>Automatic factor-based splitting for any positive integer</li> </ul>"},{"location":"reference/full_features_list/#cloud-computing-setup","title":"Cloud computing setup","text":"<ul> <li>Deploy Windows VM with GPU support from cloud providers</li> <li>Remote Desktop Protocol (RDP) connection support</li> <li>Unified setup script (<code>setup.bat</code>) with automatic mode detection</li> <li>Auto-detection: Script checks if <code>goliat/</code> exists to determine fresh install vs reconnection</li> <li>Fresh install mode: Full automated setup (~10 minutes)</li> <li>Reconnection mode: Quick VPN + git pull + ready terminal (~15 seconds)</li> <li>Automatic OpenVPN client installation and connection</li> <li>Automatic Python 3.11 installation</li> <li>Automatic Git installation</li> <li>Automatic Sim4Life download and installation</li> <li>VPN configuration file download from Google Drive</li> <li>Parallel launch of Sim4Life license installer, File Explorer, and Git Bash</li> <li>Automatic GOLIAT repository cloning</li> <li>Automatic Git Bash initialization (pip install, git config, git pull, goliat init)</li> <li>File Explorer opens at goliat/ directory automatically</li> <li>Python script for API-based VM deployment (<code>deploy_windows_vm.py</code>)</li> <li>Support for multiple cloud providers (TensorDock, AWS, GCP, Azure)</li> <li>Cost estimation and monitoring</li> <li>Per-second billing support</li> <li>Instance stopping when not in use</li> <li>Cloud setup validation (NVIDIA GPU driver checks, computer name validation)</li> <li>Pre-flight checks before simulation execution</li> <li>Error handling and safeguards to prevent premature execution</li> </ul>"},{"location":"reference/full_features_list/#data-management","title":"Data management","text":"<ul> <li>Automatic phantom model download</li> <li>Automatic antenna model download</li> <li>Email-based phantom licensing (via DOWNLOAD_EMAIL environment variable)</li> <li>Data file preparation during initialization</li> <li>Automatic cleanup of old CSV and JSON files in data directory (keeps maximum 50 files)</li> <li>Timestamp-based file naming for easy identification</li> <li>Automatic disk space management for serial workflows</li> <li>Manual file cleanup options</li> <li>Manual cleanup script for simulation output files (<code>scripts/cleanup_results.py</code>)</li> <li>Filter cleanup by study type (near-field, far-field)</li> <li>Filter cleanup by frequency (specific frequencies in MHz)</li> <li>Interactive confirmation prompt before deletion</li> <li>Scan and list files to be deleted before confirmation</li> </ul>"},{"location":"reference/full_features_list/#command-line-interface","title":"Command-line interface","text":""},{"location":"reference/full_features_list/#study-commands","title":"Study commands","text":"<ul> <li><code>goliat study &lt;config&gt;</code> - Run a dosimetric assessment study</li> <li><code>goliat study &lt;config&gt; --no-cache</code> - Bypass caching and rerun all phases</li> <li><code>goliat study &lt;config&gt; --reupload-results</code> - Re-upload existing extract deliverables to web dashboard (works with GOLIAT_SKIP_IF_EXISTS)</li> <li><code>goliat study &lt;config&gt; --title &lt;title&gt;</code> - Set GUI window title</li> <li><code>goliat study &lt;config&gt; --pid &lt;pid&gt;</code> - Set process ID for logging</li> </ul>"},{"location":"reference/full_features_list/#analysis-commands","title":"Analysis commands","text":"<ul> <li><code>goliat analyze --config &lt;config&gt;</code> - Run analysis for near-field or far-field studies</li> <li><code>goliat analyze --config &lt;config&gt; --generate-paper</code> - Generate LaTeX paper after analysis</li> <li><code>goliat analyze --config &lt;config&gt; --no-gui</code> - Run analysis without GUI (default is GUI enabled)</li> <li><code>goliat stats &lt;path&gt;</code> - Parse simulation logs and generate statistics (auto-detects file vs directory mode)</li> </ul>"},{"location":"reference/full_features_list/#parallel-commands","title":"Parallel commands","text":"<ul> <li><code>goliat parallel &lt;config&gt; --num-splits &lt;n&gt;</code> - Split config and run studies in parallel</li> <li><code>goliat parallel &lt;config&gt; --skip-split</code> - Run from existing parallel directory</li> <li><code>goliat parallel &lt;config&gt; --no-cache</code> - Bypass caching in parallel runs</li> </ul>"},{"location":"reference/full_features_list/#utility-commands","title":"Utility commands","text":"<ul> <li><code>goliat init</code> - Initialize GOLIAT environment (install dependencies, check setup)</li> <li><code>goliat status</code> - Show setup status and environment information</li> <li><code>goliat validate &lt;config&gt;</code> - Validate a GOLIAT config file</li> <li><code>goliat version</code> - Show GOLIAT version information</li> <li><code>goliat free-space</code> or <code>goliat freespace</code> - Run free-space validation runs</li> </ul>"},{"location":"reference/full_features_list/#configuration-commands","title":"Configuration commands","text":"<ul> <li><code>goliat config show</code> - Display current settings and detected Sim4Life version</li> <li><code>goliat config set-version</code> - Interactive version picker for switching between installed Sim4Life versions</li> </ul>"},{"location":"reference/full_features_list/#utility-scripts","title":"Utility scripts","text":"<ul> <li><code>python scripts/cancel_all_jobs.py --config &lt;config&gt;</code> - Cancel all running oSPARC jobs</li> <li><code>python scripts/cancel_all_jobs.py --config &lt;config&gt; --max-jobs &lt;n&gt;</code> - Cancel up to N recent oSPARC jobs (default: 500)</li> <li><code>python scripts/cleanup_results.py --near-field</code> - Clean up near-field simulation output files</li> <li><code>python scripts/cleanup_results.py --far-field</code> - Clean up far-field simulation output files</li> <li><code>python scripts/cleanup_results.py --near-field --far-field --frequencies &lt;freq1&gt; &lt;freq2&gt;</code> - Clean up specific frequencies across study types</li> </ul>"},{"location":"reference/full_features_list/#file-outputs","title":"File outputs","text":""},{"location":"reference/full_features_list/#result-files","title":"Result files","text":"<ul> <li><code>sar_results.json</code> - Normalized SAR values summary (includes SAPD if extraction enabled)</li> <li><code>sar_stats_all_tissues.pkl</code> - Detailed tissue-specific SAR data (Python pickle), includes SAPD results</li> <li><code>sar_stats_all_tissues.html</code> - HTML table of tissue SAR values</li> <li><code>simulation_metadata.pkl</code> - Comprehensive simulation metadata (timing, performance, hardware, file sizes) in pickle format</li> <li><code>simulation_metadata.json</code> - Same metadata in human-readable JSON format for paper analysis</li> <li><code>sliced_output_{freq}MHz.h5</code> - Sliced H5 file around peak SAR location (for faster SAPD calculation)</li> <li><code>point_sensor_data.png</code> - Electric field magnitude plot at monitoring points</li> <li><code>*_Output.h5</code> - Simulation output file (HDF5 format)</li> <li><code>*_Input.h5</code> - Solver input file (HDF5 format)</li> <li><code>*.smash</code> - Sim4Life project file</li> <li><code>config.json</code> - Metadata file with configuration hash and completion flags</li> </ul>"},{"location":"reference/full_features_list/#analysis-files","title":"Analysis files","text":"<ul> <li><code>normalized_results_detailed.csv</code> - Per-simulation detailed data</li> <li><code>normalized_results_summary.csv</code> - Summary statistics by frequency/scenario</li> <li>Plots directory with various visualizations (heatmaps, bar charts, boxplots, line plots)</li> </ul>"},{"location":"reference/full_features_list/#log-files","title":"Log files","text":"<ul> <li><code>*.progress.log</code> - High-level progress logs</li> <li><code>*.log</code> - Detailed verbose logs</li> <li><code>logs/osparc_submission_logs/</code> - Cloud submission logs</li> </ul>"},{"location":"reference/full_features_list/#data-files","title":"Data files","text":"<ul> <li><code>profiling_config_DD-MM_HH-MM-SS_hash.json</code> - Session-specific timing configuration</li> <li><code>time_remaining_DD-MM_HH-MM-SS_hash.csv</code> - Time remaining tracking data</li> <li><code>overall_progress_DD-MM_HH-MM-SS_hash.csv</code> - Overall progress tracking data</li> </ul>"},{"location":"reference/full_features_list/#environment-variables","title":"Environment variables","text":"<ul> <li><code>OSPARC_API_KEY</code> - oSPARC cloud API key (in <code>.env</code> file)</li> <li><code>OSPARC_API_SECRET</code> - oSPARC cloud API secret (in <code>.env</code> file)</li> <li><code>DOWNLOAD_EMAIL</code> - Email for phantom model downloads (in <code>.env</code> file)</li> <li><code>GOLIAT_SKIP_IF_EXISTS</code> - Skip simulation if extract deliverables already exist</li> <li><code>GOLIAT_AUTO_CLEANUP</code> - Enable automatic cleanup of simulation files after extraction</li> </ul>"},{"location":"reference/full_features_list/#platform-support","title":"Platform support","text":"<ul> <li>Windows platform support (primary)</li> <li>Linux/Cloud execution environment detection</li> <li>Automatic platform adaptation for file locking mechanisms</li> <li>Sim4Life Web (sim4life.science) compatibility with limitations</li> <li>Cross-platform compatibility considerations</li> </ul>"},{"location":"reference/full_features_list/#sim4life-web-limitations","title":"Sim4Life Web limitations","text":"<ul> <li>GUI unavailable in JupyterLab environments</li> <li>Most phantoms require licensing through \"The Shop\"</li> <li><code>duke_posable</code> phantom available without additional licensing</li> <li>iSolve.exe not present in JupyterLab app environment</li> <li>Setup-only runs supported for proof-of-concept</li> </ul>"},{"location":"reference/full_features_list/#error-handling-and-troubleshooting","title":"Error handling and troubleshooting","text":"<ul> <li>Automatic file lock detection and handling</li> <li>Project file corruption detection and recovery</li> <li>Automatic retry for oSPARC job submissions (3 attempts)</li> <li>Detailed error logging for debugging</li> <li>Graceful handling of missing dependencies</li> <li>Clear error messages for common issues</li> <li>File validation before operations</li> </ul>"},{"location":"reference/full_features_list/#performance-optimizations","title":"Performance optimizations","text":"<ul> <li>Scene alignment optimization for by_cheek placements (reduces simulation time)</li> <li>Gridding optimization for computational efficiency</li> <li>GPU acceleration support (Acceleware, CUDA)</li> <li>Automatic cleanup for disk space management</li> <li>Efficient caching system to avoid redundant computations</li> <li>Parallel execution for multi-core utilization</li> <li>Cloud batching for large-scale parallel runs</li> </ul>"},{"location":"reference/full_features_list/#ai-assistant","title":"AI Assistant","text":"<ul> <li>Natural Language Querying: Ask questions about codebase, docs, and configs in plain English</li> <li>RAG-based Architecture: Retrieves relevant context from indexed project files</li> <li>Recursive Indexing: Automatically indexes all Python files, Markdown docs, and JSON schemas</li> <li>Interactive Mode: Multi-turn conversation support (<code>goliat ai --interactive</code>)</li> <li>Single-shot Mode: Quick answers via CLI (<code>goliat ai \"query\"</code>)</li> <li>Code Citations: Direct references to source files and lines of code</li> <li>Markdown Formatting: Syntax highlighted code blocks and structured answers</li> <li>Smart Context: Aware of project structure, key components, and user's current environment</li> <li>Local Execution: Runs locally using configured LLM provider (no data leaks)</li> </ul>"},{"location":"reference/useful_s4l_snippets/","title":"Useful Sim4Life API snippets","text":"<p>Practical code examples for common Sim4Life Python API tasks, extracted from real-world usage. Organized by functionality.</p>"},{"location":"reference/useful_s4l_snippets/#dictionary-like-access-patterns","title":"Dictionary-like access patterns","text":"<p>Many Sim4Life API objects behave like dictionaries and can be accessed directly by name or key, not just iterated. For example:</p> <pre><code># Direct access by name\nentity = s4l_v1.model.AllEntities()[\"Entity Name\"]\nsimulation = s4l_v1.document.AllSimulations[\"Simulation Name\"]\noutput = algorithm.Outputs[\"Output Name\"]\nextractor = simulation_extractor[\"Overall Field\"]\n\n# Instead of always iterating\nfor entity in s4l_v1.model.AllEntities():\n    if entity.Name == \"Entity Name\":\n        # found it\n        break\n</code></pre> <p>Common dictionary-like collections: <code>AllEntities()</code>, <code>AllSimulations</code>, <code>AllSettings</code>, <code>AllAlgorithms</code>, <code>Outputs</code>, and result extractors. Use direct access when you know the name/key.</p>"},{"location":"reference/useful_s4l_snippets/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Application control</li> <li>Project management</li> <li>Model and geometry</li> <li>Materials</li> <li>Simulation setup</li> <li>Simulation execution</li> <li>Results extraction</li> <li>Data and downloads</li> <li>Analysis algorithms</li> <li>Rendering and UI</li> </ol>"},{"location":"reference/useful_s4l_snippets/#1-application-control","title":"1. Application control","text":""},{"location":"reference/useful_s4l_snippets/#how-can-i-start-the-sim4life-application-programmatically","title":"How can I start the Sim4Life application programmatically?","text":"<pre><code>from s4l_v1._api import application\n\nif application.get_app_safe() is None:\n    application.run_application(disable_ui_plugins=True)\n</code></pre> <p>Use <code>disable_ui_plugins=True</code> for headless execution. Check if the app is already running before starting it.</p> <p>Used in: <code>goliat/utils/core.py</code> (ensure_s4l_running)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-suppress-sim4life-logging-output","title":"How can I suppress Sim4Life logging output?","text":"<pre><code>import XCore\n\nold_log_level = XCore.SetLogLevel(XCore.eLogCategory.Error)\n# ... perform operations ...\nXCore.SetLogLevel(old_log_level)\n</code></pre> <p>Save the old log level to restore it later. Use <code>XCore.eLogCategory.Error</code> to suppress most output.</p> <p>Used in: <code>goliat/setups/base_setup.py</code> (_finalize_setup)</p>"},{"location":"reference/useful_s4l_snippets/#2-project-management","title":"2. Project management","text":""},{"location":"reference/useful_s4l_snippets/#how-can-i-create-a-new-sim4life-project","title":"How can I create a new Sim4Life project?","text":"<pre><code>import s4l_v1.document\n\ns4l_v1.document.New()\n</code></pre> <p>Creates an unsaved project in memory. Automatically closes any existing document before creating a new one.</p> <p>Used in: <code>goliat/project_manager.py</code>, <code>goliat/utils/core.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-open-an-existing-sim4life-project-file","title":"How can I open an existing Sim4Life project file?","text":"<pre><code>import s4l_v1.document\n\nproject_path = \"path/to/project.smash\"\ns4l_v1.document.Open(project_path)\n</code></pre> <p>Raises an exception if the file doesn't exist or is corrupted.</p> <p>Used in: <code>goliat/project_manager.py</code>, <code>goliat/utils/core.py</code>, <code>goliat/simulation_runner.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-save-a-sim4life-project","title":"How can I save a Sim4Life project?","text":"<pre><code>import s4l_v1.document\n\nproject_path = \"path/to/project.smash\"\ns4l_v1.document.SaveAs(project_path)\n</code></pre> <p>Use <code>SaveAs</code> even for existing projects (it overwrites). You may want to add retry logic if save operations occasionally fail.</p> <p>Used in: <code>goliat/project_manager.py</code>, <code>goliat/simulation_runner.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-close-a-sim4life-project","title":"How can I close a Sim4Life project?","text":"<pre><code>import s4l_v1.document\n\nif s4l_v1.document.IsOpen():\n    s4l_v1.document.Close()\n</code></pre> <p>Check <code>IsOpen()</code> before closing to avoid errors. Closing releases file locks on .smash files.</p> <p>Used in: <code>goliat/project_manager.py</code>, <code>goliat/simulation_runner.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-get-the-current-project-file-path","title":"How can I get the current project file path?","text":"<pre><code>import s4l_v1.document\n\nproject_path = s4l_v1.document.FilePath\n</code></pre> <p>Returns empty string if the project hasn't been saved yet.</p> <p>Used in: <code>goliat/project_manager.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-access-all-simulations-in-a-project","title":"How can I access all simulations in a project?","text":"<pre><code>import s4l_v1.document\n\nall_simulations = s4l_v1.document.AllSimulations\n\n# Find simulation by name\nsimulation = next(\n    (s for s in all_simulations if s.Name == \"simulation_name\"),\n    None\n)\n\n# Remove all simulations\nfor sim in list(all_simulations):\n    all_simulations.Remove(sim)\n</code></pre> <p>Use <code>list()</code> when iterating and modifying to avoid iterator issues.</p> <p>Used in: <code>goliat/project_manager.py</code></p>"},{"location":"reference/useful_s4l_snippets/#3-model-and-geometry","title":"3. Model and geometry","text":""},{"location":"reference/useful_s4l_snippets/#how-can-i-get-all-entities-in-the-model","title":"How can I get all entities in the model?","text":"<pre><code>import s4l_v1.model\nimport XCoreModeling\n\nall_entities = s4l_v1.model.AllEntities()\n\n# Filter entities by type\nphantom_parts = [e for e in all_entities if isinstance(e, XCoreModeling.TriangleMesh)]\n\n# Find entity by name\nentity = next(\n    (e for e in all_entities if hasattr(e, \"Name\") and e.Name == \"entity_name\"),\n    None\n)\n</code></pre> <p>Returns an iterable collection of entity objects. Filter by type or name as needed.</p> <p>Used in: <code>goliat/setups/base_setup.py</code>, <code>goliat/setups/near_field_setup.py</code>, <code>goliat/setups/material_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-get-the-bounding-box-of-entities","title":"How can I get the bounding box of entities?","text":"<pre><code>import s4l_v1.model\n\nentities = [entity1, entity2]\nbbox_min, bbox_max = s4l_v1.model.GetBoundingBox(entities)\n\n# With transform\nfrom XCoreMath import Transform\ntransform = Transform(...)\nbbox_min, bbox_max = s4l_v1.model.GetBoundingBox(entities, transform=transform)\n\n# Control tightness (exact=True is slower but tighter, exact=False is faster but looser)\nbbox_min, bbox_max = s4l_v1.model.GetBoundingBox(entities, exact=True)\n</code></pre> <p>Returns two Vec3 objects: minimum and maximum corners. Can pass a single entity or a list. The <code>exact</code> parameter controls tightness: <code>exact=True</code> computes a tighter box but takes longer, <code>exact=False</code> is faster but may be looser.</p> <p>Used in: <code>goliat/setups/base_setup.py</code>, <code>goliat/setups/near_field_setup.py</code>, <code>goliat/setups/gridding_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-create-geometric-entities","title":"How can I create geometric entities?","text":"<pre><code>import s4l_v1.model\nimport XCoreModeling\n\n# Create a point\npoint_pos = s4l_v1.model.Vec3(10.0, 20.0, 30.0)\npoint_entity = s4l_v1.model.CreatePoint(point_pos)\npoint_entity.Name = \"Point Sensor 1\"\n\n# Create a solid block\nmin_corner = s4l_v1.model.Vec3(0, 0, 0)\nmax_corner = s4l_v1.model.Vec3(100, 100, 100)\nsolid_block = s4l_v1.model.CreateSolidBlock(min_corner, max_corner)\n\n# Create a wire block (bounding box)\nwire_block = XCoreModeling.CreateWireBlock(min_corner, max_corner)\nwire_block.Name = \"simulation_bbox\"\n</code></pre> <p>Points are used for point sensors. Wire blocks are typically used for simulation bounding boxes.</p> <p>Used in: <code>goliat/setups/base_setup.py</code> (CreatePoint)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-import-models-from-files","title":"How can I import models from files?","text":"<pre><code>import s4l_v1.model\nimport XCoreModeling\n\nsab_path = \"path/to/model.sab\"\nimported_entities = list(s4l_v1.model.Import(sab_path))\n\n# Or using XCoreModeling\nimported_entities = list(XCoreModeling.Import(sab_path))\n\n# Find specific imported entity\nentity = next(\n    (e for e in imported_entities if \"Antenna\" in e.Name),\n    None\n)\n</code></pre> <p>Returns an iterable of imported entities. Convert to list if you need to iterate multiple times.</p> <p>Used in: <code>goliat/setups/phantom_setup.py</code>, <code>goliat/scripts/prepare_antennas.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-export-entities-to-files","title":"How can I export entities to files?","text":"<pre><code>import s4l_v1.model\n\nentities_to_export = [entity1, entity2]\nexport_path = \"path/to/export.sab\"\ns4l_v1.model.Export(entities_to_export, export_path)\n</code></pre> <p>Can export single entity or list of entities. Common format: .sab.</p> <p>Used in: <code>goliat/scripts/prepare_antennas.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-transform-entities-translate-rotate-scale","title":"How can I transform entities (translate, rotate, scale)?","text":"<pre><code>from XCoreMath import Transform, Rotation, Translation, Vec3\nimport numpy as np\n\n# Create a rotation around Z-axis\nrotation = Rotation(Vec3(0, 0, 1), np.deg2rad(90))\n\n# Create a translation\ntranslation = Translation(Vec3(10, 20, 30))\n\n# Compose transforms (order matters)\nfinal_transform = Transform()\nfinal_transform = rotation * final_transform\nfinal_transform = translation * final_transform\n\n# Apply transform to entity\nentity.ApplyTransform(final_transform)\n</code></pre> <p>Transform multiplication order matters (right-to-left application). Use <code>np.deg2rad()</code> to convert degrees to radians.</p> <p>Used in: <code>goliat/setups/placement_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-calculate-distance-between-entities","title":"How can I calculate distance between entities?","text":"<pre><code>import XCoreModeling\n\ndistance_result, _ = XCoreModeling.GetEntityEntityDistance(entity1, entity2)\nmin_distance = distance_result.Distance  # Distance in mm\n</code></pre> <p>Returns a distance result object with <code>.Distance</code> property. Distance is typically in millimeters.</p> <p>Used in: <code>goliat/setups/placement_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-delete-entities","title":"How can I delete entities?","text":"<pre><code># Delete a single entity\nentity.Delete()\n\n# Delete multiple entities\nentities_to_delete = [e for e in all_entities if e.Name in [\"old_bbox\", \"temp_entity\"]]\nfor entity in entities_to_delete:\n    entity.Delete()\n</code></pre> <p>Deletion is immediate and permanent. Make sure entities exist before deleting.</p> <p>Used in: Various setup modules</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-create-vec3-vectors","title":"How can I create Vec3 vectors?","text":"<pre><code>import s4l_v1.model\nfrom XCoreMath import Vec3\nfrom QTech import Vec3 as QTechVec3\n\n# Using s4l_v1.model\nvec = s4l_v1.model.Vec3(10.0, 20.0, 30.0)\n\n# Using XCoreMath\nvec = Vec3(10.0, 20.0, 30.0)\n\n# Using QTech (for view directions)\nview_dir = QTechVec3(1, 0, 0)\n</code></pre> <p>Different modules have their own Vec3 classes. Use the appropriate one for the API you're calling.</p> <p>Used in: <code>goliat/setups/base_setup.py</code>, <code>goliat/setups/placement_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-identify-and-work-with-entity-groups","title":"How can I identify and work with entity groups?","text":"<pre><code>import s4l_v1.model\n\nall_entities = s4l_v1.model.AllEntities()\n\n# Find entity groups\nall_groups = [e for e in all_entities if isinstance(e, s4l_v1.model.EntityGroup)]\n\n# Find specific group by name\nantenna_group = next((g for g in all_groups if g.Name == \"Antenna\"), None)\n\n# Access entities in a group\nif antenna_group:\n    for entity in antenna_group.Entities:\n        # Work with child entity\n        pass\n\n# Apply transform to entire group\ntransform = s4l_v1.model.Transform(...)\nantenna_group.ApplyTransform(transform)\n\n# Set group name\nantenna_group.Name = \"Antenna 700 MHz\"\n</code></pre> <p>Groups contain multiple entities. Use <code>isinstance(e, s4l_v1.model.EntityGroup)</code> to identify them. Groups can be transformed and renamed like other entities.</p> <p>Used in: <code>goliat/scripts/prepare_antennas.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-access-child-entities-in-a-group","title":"How can I access child entities in a group?","text":"<pre><code># Access entities in a group\ngroup = next((e for e in all_entities if e.Name.startswith(\"Group \")), None)\nif group and hasattr(group, \"Entities\"):\n    for entity in group.Entities:\n        if hasattr(entity, \"History\") and \"Union\" in entity.History:\n            # Get children of union operations\n            children = entity.GetChildren()\n        else:\n            # Direct child\n            pass\n</code></pre> <p><code>Entities</code> property is for entity groups. <code>GetChildren()</code> is for entities created by boolean operations (Union, etc.).</p> <p>Used in: <code>goliat/scripts/prepare_antennas.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-decompose-a-transform-into-rotation-and-translation","title":"How can I decompose a transform into rotation and translation?","text":"<pre><code>from XCoreMath import Transform\n\n# Get transform from entity\ntransform = entity.Transform\n\n# Decompose into rotation and translation\nrotation = transform.DecomposeRotation  # Returns Vec3 of Euler angles\ntranslation = transform.Translation      # Returns Vec3 of translation\n\n# Modify components\nrotation[2] = np.deg2rad(-90)  # Modify Z rotation\ntranslation[1] = 0              # Modify Y translation\n\n# Create new transform\nnew_transform = Transform(Vec3(1, 1, 1), rotation, translation)\n</code></pre> <p>Rotation is Euler angles [rx, ry, rz] in radians. Translation is [tx, ty, tz] in model units.</p> <p>Used in: <code>goliat/setups/placement_setup.py</code>, <code>goliat/setups/near_field_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-invert-a-transform","title":"How can I invert a transform?","text":"<pre><code>from XCoreMath import Rotation, Vec3\nimport numpy as np\n\n# Create a rotation\nrotation = Rotation(Vec3(0, 0, 1), np.deg2rad(30))\n\n# Get the inverse (to undo the rotation)\ninverse_rotation = rotation.Inverse()\n\n# Apply forward transformation\nentity.ApplyTransform(rotation)\n\n# Apply inverse to undo\nentity.ApplyTransform(inverse_rotation)\n</code></pre> <p>Useful for temporarily transforming entities to check distances or positions, then reverting.</p> <p>Used in: <code>goliat/setups/near_field_setup.py</code> (_find_touching_angle)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-clone-an-entity","title":"How can I clone an entity?","text":"<pre><code># Clone creates a copy of the entity\ncloned_entity = entity.Clone()\ncloned_entity.Name = \"Entity_Copy\"\n\n# Clone multiple entities\nclones = [e.Clone() for e in entities]\n</code></pre> <p>Cloning is non-destructive: the original entity is unchanged. Useful when you need to modify geometry without affecting the source.</p> <p>Used in: <code>goliat/extraction/sapd_extractor.py</code> (_unite_skin_entities)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-unite-boolean-union-multiple-entities","title":"How can I unite (boolean union) multiple entities?","text":"<pre><code>import s4l_v1.model\n\n# Unite multiple entities into one\nentities_to_unite = [entity1, entity2, entity3]\nunited_entity = s4l_v1.model.Unite(entities_to_unite)\nunited_entity.Name = \"Merged_Entity\"\n</code></pre> <p>Boolean union combines overlapping or touching meshes into a single entity. Original entities are consumed.</p> <p>Used in: <code>goliat/extraction/sapd_extractor.py</code> (_unite_skin_entities)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-cut-a-mesh-with-a-plane","title":"How can I cut a mesh with a plane?","text":"<pre><code>import XCoreModeling\nfrom QTech import Vec3  # use QTech.Vec3 for S4L 9.2+, or s4l_v1.model.Vec3\n\n# Define cut plane by a point and normal vector\npoint = Vec3(50.0, 0.0, 0.0)   # Point on the plane\nnormal = Vec3(1, 0, 0)          # Normal direction (keeps positive side)\n\n# Cut the mesh\ncut_entity = XCoreModeling.PlanarCut(entity, point, normal)\n\n# Multiple cuts to create a bounding box\ncenter = [100, 200, 150]  # mm\nhalf_side = 50.0\ncuts = [\n    (Vec3(center[0] - half_side, center[1], center[2]), Vec3(1, 0, 0)),\n    (Vec3(center[0] + half_side, center[1], center[2]), Vec3(-1, 0, 0)),\n    (Vec3(center[0], center[1] - half_side, center[2]), Vec3(0, 1, 0)),\n    (Vec3(center[0], center[1] + half_side, center[2]), Vec3(0, -1, 0)),\n    (Vec3(center[0], center[1], center[2] - half_side), Vec3(0, 0, 1)),\n    (Vec3(center[0], center[1], center[2] + half_side), Vec3(0, 0, -1)),\n]\nfor pt, n in cuts:\n    entity = XCoreModeling.PlanarCut(entity, pt, n)\n</code></pre> <p>PlanarCut keeps the part of the mesh on the positive side of the plane (where the normal points). Chain multiple cuts to create a bounding cube.</p> <p>In S4L 9.2+, the API signature explicitly uses <code>QTech.Vec3</code>. In 8.2, unqualified <code>Vec3</code> was accepted. For cross-version compatibility, <code>s4l_v1.model.Vec3</code> works in both versions.</p> <p>Used in: <code>goliat/extraction/sapd_extractor.py</code> (_slice_skin_mesh)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-repair-and-remesh-a-triangle-mesh","title":"How can I repair and remesh a triangle mesh?","text":"<pre><code>import XCoreModeling\n\n# Remove back-to-back (duplicate/overlapping) triangles\nXCoreModeling.RemoveBackToBackTriangles(entity)\n\n# Repair mesh: fill holes and fix self-intersections\nXCoreModeling.RepairTriangleMesh(\n    [entity],\n    fill_holes=True,\n    repair_intersections=True,\n    min_components_size=10,\n)\n\n# Remesh with specific edge length\nmesh_opts = XCoreModeling.MeshingOptions()\nmesh_opts.EdgeLength = 2.0           # Target edge length (mm)\nmesh_opts.MinEdgeLength = 1.0        # Minimum edge length (mm)\nmesh_opts.FeatureAngle = 30.0        # Preserve features above this angle (degrees)\nmesh_opts.MaxSpanAngle = 20.0        # Max angle span per triangle\nmesh_opts.MergeCoincidentNodes = True\nmesh_opts.RepairIntersections = True\nXCoreModeling.RemeshTriangleMesh(entity, mesh_opts)\n</code></pre> <p>Use after planar cuts or boolean operations to clean up mesh quality. Operations may silently fail on invalid geometry.</p> <p>Version note: In S4L 9.2+, <code>RepairTriangleMesh</code> requires a <code>Sequence[TriangleMesh]</code> (stricter typing). In 8.2, <code>Any</code> was accepted. Both versions work with <code>[entity]</code> list syntax.</p> <p>Used in: <code>goliat/extraction/sapd_extractor.py</code> (_cleanup_mesh)</p>"},{"location":"reference/useful_s4l_snippets/#4-materials","title":"4. Materials","text":""},{"location":"reference/useful_s4l_snippets/#how-can-i-access-the-material-database","title":"How can I access the material database?","text":"<pre><code>import s4l_v1.materials.database\n\ndatabase = s4l_v1.materials.database\nmaterial = database[\"IT'IS 4.2\"][\"Brain\"]\n</code></pre> <p>Common database: \"IT'IS 4.2\" for tissue properties. Materials are accessed by name as strings. Raises KeyError if material not found.</p> <p>Used in: <code>goliat/setups/material_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-link-a-material-from-the-database-to-a-simulation","title":"How can I link a material from the database to a simulation?","text":"<pre><code>import s4l_v1.materials.database\nimport s4l_v1.simulation.emfdtd as emfdtd\n\ndatabase = s4l_v1.materials.database\nmaterial_settings = emfdtd.MaterialSettings()\n\n# Link material from database (Option 1: Material object)\ndb_material = database[\"IT'IS 4.2\"][\"Brain\"]\nsimulation.LinkMaterialWithDatabase(material_settings, db_material)\n\n# Link material from database (Option 2: string name)\nsimulation.LinkMaterialWithDatabase(material_settings, \"Brain\")\n\n# Assign to entities\nsimulation.Add(material_settings, [entity1, entity2])\n</code></pre> <p>The <code>material</code> parameter can be either a Material object from the database or a string name. Material settings must be linked before adding to simulation. Material properties are frequency-dependent (set simulation frequency first).</p> <p>Used in: <code>goliat/setups/material_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-access-material-properties","title":"How can I access material properties?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\n\nfor settings in simulation.AllSettings:\n    if isinstance(settings, emfdtd.MaterialSettings):\n        name = settings.Name\n        permittivity = settings.ElectricProps.RelativePermittivity\n        conductivity = settings.ElectricProps.Conductivity\n        density = settings.MassDensity\n</code></pre> <p>Properties are frequency-dependent (based on simulation frequency). Access via <code>simulation.AllSettings</code> to iterate all material settings.</p> <p>Used in: <code>goliat/setups/material_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-update-material-properties-after-frequency-changes","title":"How can I update material properties after frequency changes?","text":"<pre><code>import XCore\n\n# Suppress logging during update\nold_log_level = XCore.SetLogLevel(XCore.eLogCategory.Error)\nsimulation.UpdateAllMaterials()\nXCore.SetLogLevel(old_log_level)\n</code></pre> <p>Must be called after changing simulation frequency. Should be called before voxelization.</p> <p>Used in: <code>goliat/setups/base_setup.py</code> (_finalize_setup)</p>"},{"location":"reference/useful_s4l_snippets/#5-simulation-setup","title":"5. Simulation setup","text":""},{"location":"reference/useful_s4l_snippets/#how-can-i-create-an-em-fdtd-simulation","title":"How can I create an EM-FDTD simulation?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\nimport s4l_v1.document\n\nsimulation = emfdtd.Simulation()\nsimulation.Name = \"EM_FDTD_simulation\"\nsimulation.Frequency = 700, s4l_v1.units.MHz\n\n# Add to document\ndocument = s4l_v1.document\ndocument.AllSimulations.Add(simulation)\n</code></pre> <p>Set frequency before assigning materials (affects material properties). Simulation must be added to document to be saved.</p> <p>Used in: <code>goliat/setups/near_field_setup.py</code>, <code>goliat/setups/far_field_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-configure-solver-settings-kernel-etc","title":"How can I configure solver settings (kernel, etc.)?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\n\nsolver = simulation.SolverSettings\n\n# Set kernel type\nkernel_type = \"cuda\"  # or \"acceleware\" or \"software\"\nif kernel_type == \"acceleware\":\n    solver.Kernel = solver.Kernel.enum.AXware\nelif kernel_type == \"cuda\":\n    solver.Kernel = solver.Kernel.enum.Cuda\nelse:\n    solver.Kernel = solver.Kernel.enum.Software\n</code></pre> <p>Kernel enum values: <code>AXware</code>, <code>Cuda</code>, <code>Software</code>. GPU kernels require compatible hardware.</p> <p>Used in: <code>goliat/setups/base_setup.py</code> (_setup_solver_settings)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-set-simulation-time-and-termination-criteria","title":"How can I set simulation time and termination criteria?","text":"<pre><code>import s4l_v1.units\n\n# Set simulation time (in periods of the simulation frequency)\nsim_time_periods = 100  # Number of periods\nsimulation.SetupSettings.SimulationTime = (\n    sim_time_periods,\n    s4l_v1.units.Periods,\n)\n\n# Set termination criteria\nterm_level = \"GlobalAutoTerminationWeak\"  # or \"GlobalAutoTerminationUserDefined\"\nterm_options = simulation.SetupSettings.GlobalAutoTermination.enum\nsimulation.SetupSettings.GlobalAutoTermination = getattr(term_options, term_level)\n\n# If user-defined, set convergence level\nif term_level == \"GlobalAutoTerminationUserDefined\":\n    convergence_db = -30\n    simulation.SetupSettings.ConvergenceLevel = convergence_db\n</code></pre> <p>Time is typically set in periods (cycles) of the simulation frequency. Calculate the required number of periods based on your simulation domain size and frequency. Termination options: <code>GlobalAutoTerminationWeak</code>, <code>GlobalAutoTerminationMedium</code>, <code>GlobalAutoTerminationStrong</code>, <code>GlobalAutoTerminationUserDefined</code>.</p> <p>Used in: <code>goliat/setups/base_setup.py</code> (_apply_simulation_time_and_termination)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-add-an-edge-source-antenna-excitation","title":"How can I add an edge source (antenna excitation)?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\nimport s4l_v1.units\n\nedge_source_settings = emfdtd.EdgeSourceSettings()\nexcitation_enum = edge_source_settings.ExcitationType.enum\n\n# For harmonic (single frequency)\nedge_source_settings.ExcitationType = excitation_enum.Harmonic\nedge_source_settings.Frequency = frequency_mhz, s4l_v1.units.MHz\nedge_source_settings.CenterFrequency = frequency_mhz, s4l_v1.units.MHz\n\n# For Gaussian (frequency sweep)\nedge_source_settings.ExcitationType = excitation_enum.Gaussian\nedge_source_settings.CenterFrequency = frequency_mhz, s4l_v1.units.MHz\nedge_source_settings.Bandwidth = bandwidth_mhz, s4l_v1.units.MHz  # Set appropriate bandwidth\n\n# Add to simulation\nsource_entity = antenna_line_entity\nsimulation.Add(edge_source_settings, [source_entity])\n</code></pre> <p>Harmonic for single-frequency simulations. Gaussian for frequency sweeps. Source entity is typically a line/edge in the antenna CAD model.</p> <p>Used in: <code>goliat/setups/source_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-add-a-plane-wave-source-far-field","title":"How can I add a plane wave source (far-field)?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\nimport s4l_v1.units\n\nplane_wave_source = emfdtd.PlaneWaveSourceSettings()\nplane_wave_source.CenterFrequency = frequency_mhz, s4l_v1.units.MHz\n\n# Set direction (theta, phi in degrees)\nplane_wave_source.Theta = 90  # Elevation angle\nplane_wave_source.Phi = 0      # Azimuth angle\n\n# Set polarization (psi angle)\nplane_wave_source.Psi = 0   # Theta polarization\n# or\nplane_wave_source.Psi = 90  # Phi polarization\n\n# Add to simulation bounding box\nsimulation.Add(plane_wave_source, [bbox_entity])\n</code></pre> <p>Theta/Phi define wave propagation direction. Psi=0 for theta polarization, Psi=90 for phi polarization. Applied to simulation bounding box entity.</p> <p>Used in: <code>goliat/setups/source_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-add-sensors-edge-point-far-field","title":"How can I add sensors (edge, point, far-field)?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\nimport s4l_v1.units\n\n# Edge sensor (for power monitoring)\nedge_sensor_settings = emfdtd.EdgeSensorSettings()\nsimulation.Add(edge_sensor_settings, [source_entity])\n\n# Point sensor (for E-field monitoring at specific locations)\npoint_entity = model.CreatePoint(model.Vec3(x, y, z))\npoint_sensor = emfdtd.PointSensorSettings()\npoint_sensor.Name = \"Point Sensor 1\"\nsimulation.Add(point_sensor, [point_entity])\n\n# Far-field sensor (for radiation patterns)\nfar_field_sensor_settings = simulation.AddFarFieldSensorSettings()\n\n# Configure extracted frequencies for Gaussian source\nif excitation_type == \"gaussian\":\n    center_freq_hz = frequency_mhz * 1e6\n    bandwidth_hz = bandwidth_mhz * 1e6  # Set appropriate bandwidth\n    start_freq_hz = center_freq_hz - (bandwidth_hz / 2)\n    end_freq_hz = center_freq_hz + (bandwidth_hz / 2)\n    num_samples = 21  # Choose number of frequency samples\n    extracted_frequencies_hz = [\n        start_freq_hz + i * (bandwidth_hz / (num_samples - 1))\n        for i in range(num_samples)\n    ]\n    far_field_sensor_settings.ExtractedFrequencies = (\n        extracted_frequencies_hz,\n        s4l_v1.units.Hz,\n    )\n</code></pre> <p>Edge sensors monitor power at source edges. Point sensors monitor E-field at specific 3D locations. Far-field sensors extract radiation patterns. Note that far-field sensors use <code>ExtractedFrequencies</code> (plural) while sensor extractors use <code>ExtractedFrequency</code> (singular).</p> <p>Used in: <code>goliat/setups/base_setup.py</code> (_add_point_sensors), <code>goliat/setups/source_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-configure-automatic-gridding","title":"How can I configure automatic gridding?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\n\n# Set global gridding mode\nsimulation.GlobalGridSettings.DiscretizationMode = \"Automatic\"\nsimulation.GlobalGridSettings.BoundingBox = model.GetBoundingBox([sim_bbox_entity])\n\n# Add automatic grid for simulation bounding box\nadded_grid_settings = simulation.AddAutomaticGridSettings([sim_bbox_entity])\n\n# Set refinement level\nrefinement_mapping = {\n    \"Very Fine\": \"AutoRefinementVeryFine\",\n    \"Fine\": \"AutoRefinementFine\",\n    \"Default\": \"AutoRefinementDefault\",\n    \"Coarse\": \"AutoRefinementCoarse\",\n    \"Very Coarse\": \"AutoRefinementVeryCoarse\",\n}\ns4l_refinement = refinement_mapping[\"Default\"]\n\nsimulation.GlobalGridSettings.AutoRefinement = s4l_refinement\nadded_grid_settings.AutoRefinement = s4l_refinement\n</code></pre> <p>Refinement levels: <code>AutoRefinementVeryFine</code>, <code>AutoRefinementFine</code>, <code>AutoRefinementDefault</code>, <code>AutoRefinementCoarse</code>, <code>AutoRefinementVeryCoarse</code>. Must set both global and added grid settings.</p> <p>Used in: <code>goliat/setups/gridding_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-configure-manual-gridding","title":"How can I configure manual gridding?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\nimport s4l_v1.units\nimport numpy as np\n\n# Set global gridding mode\nsimulation.GlobalGridSettings.DiscretizationMode = \"Manual\"\nsimulation.GlobalGridSettings.BoundingBox = model.GetBoundingBox([sim_bbox_entity])\n\n# Add manual grid for simulation bounding box\nadded_manual_grid = simulation.AddManualGridSettings([sim_bbox_entity])\n\n# Set maximum step size (in mm)\nmax_step_mm = 2.0\nmax_step_setting = (\n    np.array([max_step_mm] * 3),  # Same for x, y, z\n    s4l_v1.units.MilliMeters,\n)\n\nsimulation.GlobalGridSettings.MaxStep = max_step_setting\nadded_manual_grid.MaxStep = max_step_setting\n</code></pre> <p>MaxStep is a 3-element array [x, y, z] in millimeters. Can use different sizes per axis if needed. Must set both global and added grid settings.</p> <p>Used in: <code>goliat/setups/gridding_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-configure-subgridding","title":"How can I configure subgridding?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\n\n# Find the automatic grid settings\nautomatic_grid_settings = next(\n    (x for x in simulation.AllSettings\n     if isinstance(x, emfdtd.AutomaticGridSettings) and x.Name == \"Automatic\"),\n    None\n)\n\nif automatic_grid_settings:\n    # Add automatic grid to components that need subgridding\n    simulation.Add(automatic_grid_settings, components_to_subgrid)\n    \n    # Configure subgridding parameters\n    automatic_grid_settings.SubGridMode = automatic_grid_settings.SubGridMode.enum.Box\n    automatic_grid_settings.SubGridLevel = automatic_grid_settings.SubGridLevel.enum.x9\n    automatic_grid_settings.AutoRefinement = automatic_grid_settings.AutoRefinement.enum.AutoRefinementVeryFine\n    \n    # When converting strings to enums, use getattr() for flexibility\n    subgrid_mode = \"Box\"\n    automatic_grid_settings.SubGridMode = getattr(automatic_grid_settings.SubGridMode.enum, subgrid_mode)\n</code></pre> <p>Subgridding overrides manual gridding for specified components. Common levels: <code>x9</code>, <code>x3</code> (9x or 3x finer than base grid). When converting strings to enum values, <code>getattr(enum_class, string_value)</code> is more flexible than direct enum access.</p> <p>Used in: <code>goliat/setups/gridding_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-configure-grid-padding","title":"How can I configure grid padding?","text":"<pre><code>import s4l_v1.units\nimport numpy as np\n\nglobal_grid_settings = simulation.GlobalGridSettings\n\n# Automatic padding\nglobal_grid_settings.PaddingMode = global_grid_settings.PaddingMode.enum.Automatic\n\n# Manual padding\nglobal_grid_settings.PaddingMode = global_grid_settings.PaddingMode.enum.Manual\nbottom_padding = np.array([10, 10, 10])  # mm\ntop_padding = np.array([10, 10, 10])     # mm\nglobal_grid_settings.BottomPadding = bottom_padding, s4l_v1.units.MilliMeters\nglobal_grid_settings.TopPadding = top_padding, s4l_v1.units.MilliMeters\n</code></pre> <p>Padding is specified per axis [x, y, z] in millimeters. Automatic padding is usually sufficient.</p> <p>Used in: <code>goliat/setups/gridding_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-configure-boundary-conditions-pml","title":"How can I configure boundary conditions (PML)?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\n\n# Set global boundary type\nglobal_boundaries = simulation.GlobalBoundarySettings\nbc_enum = global_boundaries.GlobalBoundaryType.enum\nglobal_boundaries.GlobalBoundaryType = bc_enum.UpmlCpml\n\n# Set PML strength\n# Boundary settings are created automatically when simulation is added\nboundary_settings_list = [\n    x for x in simulation.AllSettings\n    if isinstance(x, emfdtd.BoundarySettings)\n]\nif boundary_settings_list:\n    boundary_settings = boundary_settings_list[0]\n    strength_enum = boundary_settings.PmlStrength.enum\n    boundary_settings.PmlStrength = strength_enum.Medium  # or Weak, Strong\n</code></pre> <p>Boundary types: <code>UpmlCpml</code> (most common), although there are others available. PML strength: <code>Weak</code>, <code>Medium</code>, <code>Strong</code>. Boundary settings are created automatically when the simulation is added to the document, so you can access them via <code>simulation.AllSettings</code>.</p> <p>Used in: <code>goliat/setups/boundary_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-add-voxeler-settings-and-create-voxels","title":"How can I add voxeler settings and create voxels?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\n\n# Add automatic voxeler to all simulation parts\nvoxeler_settings = emfdtd.AutomaticVoxelerSettings()\nall_simulation_parts = [phantom_entities, antenna_parts, bbox_entity]\nsimulation.Add(voxeler_settings, all_simulation_parts)\n\n# Update materials (frequency-dependent properties)\nsimulation.UpdateAllMaterials()\n\n# Update grid\nsimulation.UpdateGrid()\n\n# Create voxels\nsimulation.CreateVoxels()\n</code></pre> <p>Must update materials and grid before creating voxels. Voxelization is computationally expensive.</p> <p>Used in: <code>goliat/setups/base_setup.py</code> (_finalize_setup)</p>"},{"location":"reference/useful_s4l_snippets/#6-simulation-execution","title":"6. Simulation execution","text":""},{"location":"reference/useful_s4l_snippets/#how-can-i-write-the-solver-input-file","title":"How can I write the solver input file?","text":"<pre><code>if hasattr(simulation, \"WriteInputFile\"):\n    simulation.WriteInputFile()\n    # Save project to flush files\n    document.SaveAs(project_path)\n</code></pre> <p>Input file is written to project directory. File name can be retrieved with <code>simulation.GetInputFileName()</code>. Save project after writing to ensure file is flushed.</p> <p>Used in: <code>goliat/simulation_runner.py</code> (run)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-run-a-simulation-locally","title":"How can I run a simulation locally?","text":"<pre><code>import s4l_v1.simulation\n\n# Run on localhost (default)\nsimulation.RunSimulation(wait=True)\n\n# Run on specific server\nserver_name = \"MyLargeGPUMachine\"\navailable_servers = s4l_v1.simulation.GetAvailableServers()\nserver_id = next(\n    (s for s in available_servers if server_name.lower() in s.lower()),\n    None\n)\nif server_id:\n    simulation.RunSimulation(wait=True, server_id=server_id)\n</code></pre> <p><code>wait=True</code> blocks until simulation completes. Server ID can be partial name (searches available servers).</p> <p>Used in: <code>goliat/simulation_runner.py</code> (run)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-run-isolveexe-manually","title":"How can I run iSolve.exe manually?","text":"<pre><code>import os\nimport subprocess\n\n# Find iSolve.exe using GOLIAT's helper function (works for both direct Python and venvs)\nfrom goliat.utils.python_interpreter import find_sim4life_root\n\ns4l_root = find_sim4life_root()\nisolve_path = os.path.join(s4l_root, \"Solvers\", \"iSolve.exe\")\n\n# Get input file path\ninput_file_path = os.path.join(project_dir, simulation.GetInputFileName())\n\n# Run iSolve\ncommand = [isolve_path, \"-i\", input_file_path]\nprocess = subprocess.Popen(\n    command,\n    stdout=subprocess.PIPE,\n    stderr=subprocess.PIPE,\n    text=True,\n    creationflags=subprocess.CREATE_NO_WINDOW,\n)\n\n# Wait for completion\nreturn_code = process.wait()\nif return_code != 0:\n    raise RuntimeError(f\"iSolve.exe failed with return code {return_code}\")\n\n# Reload project to load results\ndocument.Close()\ndocument.Open(project_path)\n</code></pre> <p>iSolve.exe is typically in <code>{Sim4Life}/Solvers/iSolve.exe</code>. Must reload project after completion to see results.</p> <p>Used in: <code>goliat/simulation_runner.py</code> (_run_isolve_manual)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-submit-a-simulation-to-osparc-cloud","title":"How can I submit a simulation to oSPARC cloud?","text":"<pre><code>import XOsparcApiClient\nimport time\n\n# Initialize client\nclient = XOsparcApiClient.OsparcApiClient(\n    api_key=\"your_api_key\",\n    api_secret=\"your_api_secret\",\n    api_server=\"https://api.sim4life.science\",\n    api_version=\"v0\",\n)\n\n# Prepare job submission\ninput_file_path = os.path.join(project_dir, simulation.GetInputFileName())\njob_data = XOsparcApiClient.JobSubmissionData()\njob_data.InputFilePath = input_file_path\njob_data.ResourceName = \"osparc-1\"\njob_data.SolverKey = \"sim4life-isolve\"\njob_data.SolverVersion = \"\"\n\n# Create and start job\ncreate_response = client.CreateJob(job_data)\njob_id = create_response.Content.get(\"id\")\n\nstart_response = client.StartJob(job_data, job_id)\n\n# Poll for completion\nwhile True:\n    status_response = client.GetJobStatus(\n        job_data.SolverKey,\n        job_data.SolverVersion,\n        job_id\n    )\n    status = status_response.Content.get(\"state\")\n    if status in [\"SUCCESS\", \"FAILED\", \"ABORTED\"]:\n        break\n    time.sleep(30)\n\n# Reload project after completion\ndocument.Close()\ndocument.Open(project_path)\n</code></pre> <p>Requires Sim4Life 9.2+ for XOsparcApiClient module. Job states: PENDING, RUNNING, SUCCESS, FAILED, ABORTED. Must poll status until completion. The <code>api_server</code> depends on your platform: <code>api.sim4life.science</code> for ZMT/IT'IS cloud, <code>api.osparc.io</code> for NIH SPARC. For 8.2 or headless batch runs, use the osparc PyPI package instead.</p> <p>Used in: <code>goliat/runners/osparc_direct_strategy.py</code></p>"},{"location":"reference/useful_s4l_snippets/#whats-the-difference-between-xosparcapiclient-and-the-osparc-pypi-package","title":"What's the difference between XOsparcApiClient and the osparc PyPI package?","text":"<p>XOsparcApiClient (Sim4Life 9.2+ only): <pre><code>import XOsparcApiClient\n\nclient = XOsparcApiClient.OsparcApiClient(\n    api_key=\"key\", api_secret=\"secret\",\n    api_server=\"https://api.sim4life.science\", api_version=\"v0\",\n)\njob_data = XOsparcApiClient.JobSubmissionData()\njob_data.InputFilePath = input_file_path\njob_data.SolverKey = \"sim4life-isolve\"\nresponse = client.CreateJob(job_data)\nclient.StartJob(job_data, response.Content.get(\"id\"))\n</code></pre></p> <p>osparc PyPI package (<code>pip install osparc</code>): <pre><code>import osparc\n\nconfig = osparc.Configuration(\n    host=\"https://api.sim4life.science\",\n    username=\"key\", password=\"secret\",\n)\nwith osparc.ApiClient(config) as api_client:\n    files_api = osparc.FilesApi(api_client)\n    solvers_api = osparc.SolversApi(api_client)\n    uploaded = files_api.upload_file(file=input_file_path)\n    solver = solvers_api.get_solver_release(solver_key, solver_version)\n    job = solvers_api.create_job(\n        solver.id, solver.version,\n        job_inputs=osparc.JobInputs({\"input_1\": uploaded}),\n    )\n    solvers_api.start_job(solver.id, solver.version, job.id)\n</code></pre></p> <p>XOsparcApiClient is a C++ extension built into Sim4Life 9.2. The osparc package works outside Sim4Life and on 8.2. Same API underneath.</p> <p>Used in: <code>goliat/runners/osparc_direct_strategy.py</code> (XOsparcApiClient), <code>goliat/osparc_batch/osparc_client.py</code> (osparc)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-get-the-input-file-name-from-a-simulation","title":"How can I get the input file name from a simulation?","text":"<pre><code># Get relative path from simulation\nrelative_path = simulation.GetInputFileName()\n\n# Construct full path\nproject_dir = os.path.dirname(project_path)\ninput_file_path = os.path.join(project_dir, relative_path)\n</code></pre> <p>Returns relative path (e.g., \"EM_FDTD_..._Input.h5\"). Must combine with project directory for full path.</p> <p>Used in: <code>goliat/simulation_runner.py</code></p>"},{"location":"reference/useful_s4l_snippets/#7-results-extraction","title":"7. Results extraction","text":""},{"location":"reference/useful_s4l_snippets/#how-can-i-access-simulation-results","title":"How can I access simulation results?","text":"<pre><code>simulation_extractor = simulation.Results()\n\n# Access specific result\noverall_field = simulation_extractor[\"Overall Field\"]\ninput_power = simulation_extractor[\"Input Power\"]\npoint_sensor = simulation_extractor[\"Point Sensor Entity 1\"]\n</code></pre> <p>Result names depend on what was configured (sources, sensors, etc.). Common names: \"Overall Field\", \"Input Power\", \"Point Sensor Entity N\".</p> <p>Used in: <code>goliat/results_extractor.py</code> (extract)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-use-e-field-data-as-input-to-analysis-algorithms","title":"How can I use E-field data as input to analysis algorithms?","text":"<pre><code>import s4l_v1.document\nimport s4l_v1.analysis\n\n# Get E-field extractor\nem_sensor_extractor = simulation_extractor[\"Overall Field\"]\nem_sensor_extractor.FrequencySettings.ExtractedFrequency = \"All\"\n\n# Add to document algorithms and update\ndocument = s4l_v1.document\ndocument.AllAlgorithms.Add(em_sensor_extractor)\nem_sensor_extractor.Update()\n\n# Use E-field output as input to analysis algorithms (e.g., SAR evaluator)\ne_field_output = em_sensor_extractor.Outputs[\"EM E(x,y,z,f0)\"]\ninputs = [e_field_output]\nsar_evaluator = s4l_v1.analysis.em_evaluators.SarStatisticsEvaluator(inputs=inputs)\n# ... configure and use evaluator ...\n\n# Clean up\ndocument.AllAlgorithms.Remove(em_sensor_extractor)\n</code></pre> <p>E-field data is typically used as input to analysis algorithms like SAR evaluators. Must add extractor to document before updating. Remove extractor when done to free memory.</p> <p>Used in: <code>goliat/extraction/sar_extractor.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-extract-sar-statistics","title":"How can I extract SAR statistics?","text":"<pre><code>import s4l_v1.analysis\nimport s4l_v1.document\nimport s4l_v1.units as units\n\n# Get E-field data\nem_sensor_extractor = simulation_extractor[\"Overall Field\"]\nem_sensor_extractor.FrequencySettings.ExtractedFrequency = \"All\"\ndocument.AllAlgorithms.Add(em_sensor_extractor)\nem_sensor_extractor.Update()\n\n# Create SAR statistics evaluator\ninputs = [em_sensor_extractor.Outputs[\"EM E(x,y,z,f0)\"]]\nsar_stats_evaluator = s4l_v1.analysis.em_evaluators.SarStatisticsEvaluator(inputs=inputs)\nsar_stats_evaluator.PeakSpatialAverageSAR = True\nsar_stats_evaluator.PeakSAR.TargetMass = 10.0, units.Unit(\"g\")\nsar_stats_evaluator.UpdateAttributes()\n\n# Compute SAR statistics\ndocument.AllAlgorithms.Add(sar_stats_evaluator)\nsar_stats_evaluator.Update()\n\n# Access results (check if results exist first)\nstats_output = sar_stats_evaluator.Outputs\nif len(stats_output) &gt; 0 and hasattr(stats_output.item_at(0), \"Data\"):\n    results = stats_output.item_at(0).Data\n    columns = [\"Tissue\"] + [cap for cap in results.ColumnMainCaptions]\n    data = [\n        [results.RowCaptions[i]] + [results.Value(i, j) for j in range(results.NumberOfColumns())]\n        for i in range(results.NumberOfRows())\n    ]\n\n# Clean up\ndocument.AllAlgorithms.Remove(sar_stats_evaluator)\n</code></pre> <p>TargetMass typically 10g for IEEE/IEC compliance. Results are in table format with tissues as rows.</p> <p>Used in: <code>goliat/extraction/sar_extractor.py</code> (extract_sar_statistics)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-extract-peak-sar-location-details","title":"How can I extract peak SAR location details?","text":"<pre><code>import s4l_v1.document\nimport s4l_v1.analysis\nimport s4l_v1.units as units\n\n# First, set up and update the overall field extractor\nem_sensor_extractor = simulation_extractor[\"Overall Field\"]\nem_sensor_extractor.FrequencySettings.ExtractedFrequency = \"All\"\ndocument.AllAlgorithms.Add(em_sensor_extractor)\nem_sensor_extractor.Update()\n\n# Use SAR output as input to average SAR field evaluator\ninputs = [em_sensor_extractor.Outputs[\"SAR(x,y,z,f0)\"]]\n\n# Create average SAR field evaluator\naverage_sar_field_evaluator = s4l_v1.analysis.em_evaluators.AverageSarFieldEvaluator(inputs=inputs)\naverage_sar_field_evaluator.TargetMass = 10.0, units.Unit(\"g\")\naverage_sar_field_evaluator.UpdateAttributes()\n\ndocument.AllAlgorithms.Add(average_sar_field_evaluator)\naverage_sar_field_evaluator.Update()\n\n# Get peak SAR details\npeak_sar_output = average_sar_field_evaluator.Outputs[\"Peak Spatial SAR (psSAR) Results\"]\npeak_sar_output.Update()\n\ndata_collection = peak_sar_output.Data.DataSimpleDataCollection\npeak_sar_details = {\n    key: data_collection.FieldValue(key, 0)\n    for key in data_collection.Keys()\n}\n\n# Clean up\ndocument.AllAlgorithms.Remove(average_sar_field_evaluator)\ndocument.AllAlgorithms.Remove(em_sensor_extractor)\n</code></pre> <p>Provides 3D coordinates, tissue name, mass, etc. for peak SAR. The extractor must be updated first to compute SAR field data. Data collection contains various metadata fields.</p> <p>Used in: <code>goliat/extraction/sar_extractor.py</code> (extract_peak_sar_location)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-extract-input-power","title":"How can I extract input power?","text":"<pre><code>import s4l_v1.document\n\n# Get input power extractor\ninput_power_extractor = simulation_extractor[\"Input Power\"]\ndocument.AllAlgorithms.Add(input_power_extractor)\ninput_power_extractor.Update()\n\n# Method 1: Use GetPower() if available\nif hasattr(input_power_extractor, \"GetPower\"):\n    power_w, _ = input_power_extractor.GetPower(0)\n\n# Method 2: Extract from harmonic data\nelse:\n    input_power_output = input_power_extractor.Outputs[\"EM Input Power(f)\"]\n    input_power_output.Update()\n    \n    if hasattr(input_power_output, \"GetHarmonicData\"):\n        power_complex = input_power_output.GetHarmonicData(0)\n        power_w = abs(power_complex)\n    else:\n        power_data = input_power_output.Data.GetComponent(0)\n        power_w = power_data.item()  # Single value\n\ndocument.AllAlgorithms.Remove(input_power_extractor)\n</code></pre> <p>GetPower() is preferred but not always available. Harmonic data extraction is fallback method.</p> <p>Used in: <code>goliat/extraction/power_extractor.py</code> (extract_input_power)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-extract-power-balance","title":"How can I extract power balance?","text":"<pre><code>import s4l_v1.document\n\n# Get overall field extractor\nem_sensor_extractor = simulation_extractor[\"Overall Field\"]\n\n# Access power balance output\npower_balance_extractor = em_sensor_extractor.Outputs[\"Power Balance\"]\npower_balance_extractor.Update()\n\n# Extract power balance data\ndata_collection = power_balance_extractor.Data.DataSimpleDataCollection\npower_balance_data = {\n    key: data_collection.FieldValue(key, 0)\n    for key in data_collection.Keys()\n    if key != \"Balance\"\n}\n\n# Calculate balance percentage\npin = power_balance_data.get(\"Pin\", 0.0)\np_out = power_balance_data.get(\"DielLoss\", 0.0) + power_balance_data.get(\"RadPower\", 0.0)\nbalance = 100 * (p_out / pin) if pin &gt; 1e-9 else float(\"nan\")\n</code></pre> <p>Balance should be close to 100% for good energy conservation. Keys: \"Pin\", \"DielLoss\", \"RadPower\", \"Balance\".</p> <p>Used in: <code>goliat/extraction/power_extractor.py</code> (extract_power_balance)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-extract-point-sensor-data","title":"How can I extract point sensor data?","text":"<pre><code>import s4l_v1.document\nimport numpy as np\n\nsensor_name = \"Point Sensor Entity 1\"\nem_sensor_extractor = simulation_extractor[sensor_name]\n\ndocument.AllAlgorithms.Add(em_sensor_extractor)\n\n# Access E-field time data\nem_output = em_sensor_extractor.Outputs[\"EM E(t)\"]\nem_output.Update()\n\n# Extract time axis and E-field components\ntime_axis = em_output.Data.Axis\nex = em_output.Data.GetComponent(0)  # E_x component\ney = em_output.Data.GetComponent(1)  # E_y component\nez = em_output.Data.GetComponent(2)  # E_z component\n\n# Calculate magnitude\ne_mag = np.sqrt(ex**2 + ey**2 + ez**2)\n\ndocument.AllAlgorithms.Remove(em_sensor_extractor)\n</code></pre> <p>Sensor name format: \"Point Sensor Entity N\". Time axis is in seconds. E-field components are in V/m.</p> <p>Used in: <code>goliat/extraction/sensor_extractor.py</code></p>"},{"location":"reference/useful_s4l_snippets/#8-data-and-downloads","title":"8. Data and downloads","text":""},{"location":"reference/useful_s4l_snippets/#how-can-i-get-available-model-downloads","title":"How can I get available model downloads?","text":"<pre><code>import s4l_v1.data\n\navailable_downloads = s4l_v1.data.GetAvailableDownloads()\n\n# Find specific phantom\nphantom_name = \"thelonious\"\nphantom_to_download = next(\n    (item for item in available_downloads\n     if phantom_name.lower() in item.Name.lower()),\n    None\n)\n</code></pre> <p>Returns iterable of download items. Each item has <code>.Name</code> property.</p> <p>Used in: <code>goliat/setups/phantom_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-download-a-model","title":"How can I download a model?","text":"<pre><code>import s4l_v1.data\nimport os\n\ndownload_email = \"user@example.com\"\ndownload_directory = os.path.join(base_dir, \"data\", \"phantoms\")\n\ns4l_v1.data.DownloadModel(\n    phantom_to_download,\n    email=download_email,\n    directory=download_directory,\n)\n</code></pre> <p>Email may be required for licensing. Downloads to specified directory. File is saved as .sab format.</p> <p>Used in: <code>goliat/setups/phantom_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#9-analysis-algorithms","title":"9. Analysis algorithms","text":""},{"location":"reference/useful_s4l_snippets/#how-can-i-add-an-algorithm-to-the-document","title":"How can I add an algorithm to the document?","text":"<pre><code>import s4l_v1.document\n\ndocument = s4l_v1.document\ndocument.AllAlgorithms.Add(algorithm)\nalgorithm.Update()\n</code></pre> <p>Algorithms must be added before updating. Add to document to persist and manage lifecycle.</p> <p>Used in: <code>goliat/extraction/sar_extractor.py</code>, <code>goliat/extraction/power_extractor.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-remove-an-algorithm-from-the-document","title":"How can I remove an algorithm from the document?","text":"<pre><code>import s4l_v1.document\n\ndocument = s4l_v1.document\ndocument.AllAlgorithms.Remove(algorithm)\n</code></pre> <p>Always remove algorithms when done to free memory. Should be done in finally blocks for error handling.</p> <p>Used in: <code>goliat/extraction/sar_extractor.py</code>, <code>goliat/extraction/power_extractor.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-access-algorithm-outputs","title":"How can I access algorithm outputs?","text":"<pre><code># Update algorithm first\nalgorithm.Update()\n\n# Access outputs dictionary\noutputs = algorithm.Outputs\n\n# Get specific output (example: SAR evaluator output)\noutput = outputs[\"Peak Spatial SAR (psSAR) Results\"]\noutput.Update()  # May need to update output\n\n# Access data\ndata = output.Data\n# Or for data collections:\ndata_collection = output.Data.DataSimpleDataCollection\nvalue = data_collection.FieldValue(\"key\", 0)\n\n# For table data (SAR statistics):\nresults = outputs.item_at(0).Data\ncolumns = [\"Tissue\"] + [cap for cap in results.ColumnMainCaptions]\ndata = [\n    [results.RowCaptions[i]] + [results.Value(i, j) for j in range(results.NumberOfColumns())]\n    for i in range(results.NumberOfRows())\n]\n</code></pre> <p>Output names depend on algorithm type. Common examples: \"Peak Spatial SAR (psSAR) Results\", \"EM E(x,y,z,f0)\", \"Power Balance\". Some outputs need Update() before accessing data. Table data has rows/columns structure. Data collections are key-value structures.</p> <p>Used in: <code>goliat/extraction/sar_extractor.py</code>, <code>goliat/extraction/power_extractor.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-access-all-simulation-settings","title":"How can I access all simulation settings?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\n\n# Iterate all settings\nfor settings in simulation.AllSettings:\n    if isinstance(settings, emfdtd.MaterialSettings):\n        name = settings.Name\n        permittivity = settings.ElectricProps.RelativePermittivity\n    \n    elif isinstance(settings, emfdtd.AutomaticGridSettings):\n        if settings.Name == \"Automatic\":\n            # Found the automatic grid\n            pass\n    \n    elif isinstance(settings, emfdtd.BoundarySettings):\n        strength = settings.PmlStrength\n</code></pre> <p>Contains materials, grids, boundaries, sources, sensors, etc. Filter by type using <code>isinstance()</code>.</p> <p>Used in: <code>goliat/setups/gridding_setup.py</code>, <code>goliat/setups/boundary_setup.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-set-frequency-extraction-settings","title":"How can I set frequency extraction settings?","text":"<pre><code># Set to extract all frequencies\nextractor.FrequencySettings.ExtractedFrequency = \"All\"\n\n# Or extract specific frequency\nextractor.FrequencySettings.ExtractedFrequency = frequency_hz, units.Hz\n</code></pre> <p>Important distinction: sensor extractors use <code>ExtractedFrequency</code> (singular), while far-field sensor settings use <code>ExtractedFrequencies</code> (plural). Must be set before calling <code>Update()</code>. \"All\" extracts all computed frequencies.</p> <p>Used in: <code>goliat/extraction/sar_extractor.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-load-simulation-results-from-a-custom-h5-file","title":"How can I load simulation results from a custom H5 file?","text":"<pre><code>import s4l_v1.analysis\nimport s4l_v1.document\n\n# Create simulation extractor from file\nsliced_extractor = s4l_v1.analysis.extractors.SimulationExtractor(inputs=[])\nsliced_extractor.Name = \"Custom_Results_Extractor\"\nsliced_extractor.FileName = \"/path/to/custom_output.h5\"  # Full path to H5\nsliced_extractor.UpdateAttributes()\n\n# Add to document and use\ndocument.AllAlgorithms.Add(sliced_extractor)\n\n# Use as you would a normal simulation extractor\nem_sensor_extractor = sliced_extractor[\"Overall Field\"]\n# ... proceed with analysis ...\n\n# Clean up\ndocument.AllAlgorithms.Remove(sliced_extractor)\n</code></pre> <p>Useful for loading sliced/reduced H5 files (e.g., for faster SAPD calculation on a subset of the domain). Must set FileName before UpdateAttributes().</p> <p>Used in: <code>goliat/extraction/sapd_extractor.py</code> (_setup_extractor)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-create-a-surface-mesh-on-grid-for-analysis","title":"How can I create a surface mesh on grid for analysis?","text":"<pre><code>import s4l_v1.analysis\nimport s4l_v1.document\n\n# Create ModelToGridFilter\nmodel_to_grid_filter = s4l_v1.analysis.core.ModelToGridFilter(inputs=[])\nmodel_to_grid_filter.Name = \"Skin_Surface_Source\"\nmodel_to_grid_filter.Entity = skin_entity  # Entity whose surface to map to grid\nmodel_to_grid_filter.UpdateAttributes()\n\ns4l_v1.document.AllAlgorithms.Add(model_to_grid_filter)\n\n# Access the surface output for use in other evaluators\nsurface_output = model_to_grid_filter.Outputs[\"Surface\"]\n</code></pre> <p>ModelToGridFilter generates a surface representation on the simulation grid. Used as input for SAPD and other surface-based evaluators.</p> <p>Used in: <code>goliat/extraction/sapd_extractor.py</code> (_setup_sapd_evaluator)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-compute-surface-absorbed-power-density-sapd","title":"How can I compute Surface Absorbed Power Density (SAPD)?","text":"<pre><code>import s4l_v1.analysis\nimport s4l_v1.document\nimport s4l_v1.units as units\n\n# First, setup field extractor and get Poynting vector\nem_sensor_extractor = simulation_extractor[\"Overall Field\"]\ns4l_v1.document.AllAlgorithms.Add(em_sensor_extractor)\nem_sensor_extractor.Update()\n\n# Setup surface using ModelToGridFilter (see separate snippet)\nmodel_to_grid_filter = s4l_v1.analysis.core.ModelToGridFilter(inputs=[])\nmodel_to_grid_filter.Entity = skin_entity\nmodel_to_grid_filter.UpdateAttributes()\ns4l_v1.document.AllAlgorithms.Add(model_to_grid_filter)\n\n# Create SAPD evaluator with two inputs: Poynting vector + Surface\ninputs = [\n    em_sensor_extractor.Outputs[\"S(x,y,z,f0)\"],  # Poynting vector\n    model_to_grid_filter.Outputs[\"Surface\"],     # Surface mesh\n]\nsapd_evaluator = s4l_v1.analysis.em_evaluators.GenericSAPDEvaluator(inputs=inputs)\nsapd_evaluator.AveragingArea = 4.0, units.SquareCentiMeters  # 4 cm\u00b2 per ICNIRP &lt; 30 GHz\nsapd_evaluator.Threshold = 0.01, units.Meters  # 10 mm threshold\nsapd_evaluator.UpdateAttributes()\n\ns4l_v1.document.AllAlgorithms.Add(sapd_evaluator)\nsapd_evaluator.Update()\n\n# Extract results\nsapd_report = sapd_evaluator.Outputs[\"Spatial-Averaged Power Density Report\"]\nsapd_report.Update()\n\ndata_collection = sapd_report.Data.DataSimpleDataCollection\npeak_sapd = data_collection.FieldValue(\"Peak Power Density\", 0)\npeak_location = data_collection.FieldValue(\"Peak Location\", 0)\n\n# Clean up\ns4l_v1.document.AllAlgorithms.Remove(sapd_evaluator)\ns4l_v1.document.AllAlgorithms.Remove(model_to_grid_filter)\ns4l_v1.document.AllAlgorithms.Remove(em_sensor_extractor)\n</code></pre> <p>AveragingArea is 4 cm\u00b2 per ICNIRP guidelines below 30 GHz. Threshold controls surface discretization (mesh resolution). Requires both Poynting vector and surface mesh inputs.</p> <p>Used in: <code>goliat/extraction/sapd_extractor.py</code> (extract_sapd)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-add-an-overall-field-sensor-with-frequency-extraction-settings","title":"How can I add an overall field sensor with frequency extraction settings?","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\n\n# Add overall field sensor to simulation\nfield_sensor_settings = simulation.AddOverallFieldSensorSettings()\n\n# Configure for multi-frequency extraction\nfrequencies_hz = [900e6, 1800e6, 2600e6]  # Multiple frequencies\nfield_sensor_settings.ExtractedFrequencies = frequencies_hz\n\n# Enable on-the-fly DFT for frequency-domain recording\nfield_sensor_settings.OnTheFlyDFT = True\n\n# Configure what to record\nfield_sensor_settings.RecordEField = True\nfield_sensor_settings.RecordHField = True\n\n# Set recording domain to frequency\ndomain_enum = field_sensor_settings.RecordingDomain.enum\nfield_sensor_settings.RecordingDomain = domain_enum.RecordInFrequencyDomain\n</code></pre> <p><code>AddOverallFieldSensorSettings()</code> creates a sensor that records fields over the entire domain. Use <code>ExtractedFrequencies</code> (plural) for multi-sine simulations. <code>OnTheFlyDFT</code> required for frequency-domain extraction during simulation.</p> <p>Used in: <code>goliat/setups/far_field_setup.py</code> (_create_simulation_entity)</p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-enable-console-logging-in-s4l-92","title":"How can I enable console logging in S4L 9.2?","text":"<pre><code>from goliat.utils.version import is_sim4life_92_or_later\n\nif is_sim4life_92_or_later():\n    try:\n        import XCore\n        XCore.RedirectToStdOut(True)\n    except (ImportError, AttributeError):\n        pass  # Not available\n</code></pre> <p>In 9.2, S4L internal messages need an explicit <code>RedirectToStdOut(True)</code> call after starting the app, in particular if called in a child-process. Was automatic in 8.2.</p> <p>Used in: <code>goliat/utils/core.py</code> (ensure_s4l_running)</p>"},{"location":"reference/useful_s4l_snippets/#10-rendering-and-ui","title":"10. Rendering and UI","text":""},{"location":"reference/useful_s4l_snippets/#how-can-i-set-the-view-direction","title":"How can I set the view direction?","text":"<pre><code>import s4l_v1.renderer\nfrom QTech import Vec3\n\n# Set view direction vectors\nviews = {\n    \"x_pos\": Vec3(1, 0, 0),\n    \"x_neg\": Vec3(-1, 0, 0),\n    \"y_pos\": Vec3(0, 1, 0),\n    \"y_neg\": Vec3(0, -1, 0),\n    \"z_pos\": Vec3(0, 0, 1),\n    \"z_neg\": Vec3(0, 0, -1),\n}\n\ns4l_v1.renderer.SetViewDirection(views[\"x_pos\"])\n</code></pre> <p>Direction is a unit vector (Vec3). Use QTech.Vec3 for renderer API.</p> <p>Used in: <code>goliat/analysis/screenshot_analysis/get_screenshot.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-zoom-to-an-entity","title":"How can I zoom to an entity?","text":"<pre><code>import s4l_v1.renderer\n\ns4l_v1.renderer.ZoomToEntity(entity)\n</code></pre> <p>Entity must be visible in the model.</p> <p>Used in: <code>goliat/analysis/screenshot_analysis/get_screenshot.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-capture-a-screenshot","title":"How can I capture a screenshot?","text":"<pre><code>import s4l_v1.renderer\nimport s4l_v1.model\nimport XCoreUI\nimport os\nimport time\n\n# Hide grid if needed\ngrid_entity = s4l_v1.model.AllEntities()[\"Grid\"]\ngrid_entity.Visible = False\n\n# Force UI update\nui_app = XCoreUI.GetUIApp()\nif ui_app and ui_app.MainFrame:\n    ui_app.MainFrame.UpdateView()\n\n# Wait for rendering to complete\ntime.sleep(1)\n\n# Capture screenshot\nfolder = os.path.dirname(file_path)\nfilename_prefix = os.path.splitext(os.path.basename(file_path))[0]\ns4l_v1.renderer.SaveScreenCapture(\n    output_folder=folder,\n    output_prefix=filename_prefix\n)\n</code></pre> <p>Takes separate folder and prefix (not full path). Saves as PNG format. Force a UI update before capture and optionally hide the grid for cleaner screenshots. A short sleep after the UI update ensures rendering completes.</p> <p>Used in: <code>goliat/analysis/screenshot_analysis/get_screenshot.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-change-the-current-ui-mode","title":"How can I change the current UI mode?","text":"<pre><code>import s4l_v1.ui\n\ns4l_v1.ui.ChangeCurrentMode(\"Simulation\")\n</code></pre> <p>Mode names: \"Simulation\", \"Modeling\", etc. May need to force UI update after mode change.</p> <p>Used in: <code>goliat/analysis/screenshot_analysis/get_screenshot.py</code></p>"},{"location":"reference/useful_s4l_snippets/#how-can-i-control-entity-visibility","title":"How can I control entity visibility?","text":"<pre><code># Hide grid\ngrid_entity = s4l_v1.model.AllEntities()[\"Grid\"]\ngrid_entity.Visible = False\n\n# Force UI update\nimport XCoreUI\nui_app = XCoreUI.GetUIApp()\nif ui_app and ui_app.MainFrame:\n    ui_app.MainFrame.UpdateView()\n</code></pre> <p>Visibility changes may require UI update to take effect.</p> <p>Used in: <code>goliat/analysis/screenshot_analysis/get_screenshot.py</code></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/","title":"Sim4Life Python API Changes: Version 8.2 \u2192 9.2","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#executive-summary","title":"Executive Summary","text":"<p>This document provides a comprehensive analysis of the changes between the Sim4Life Python API versions 8.2 and 9.2. The update represents a major modernization effort with significant improvements to type safety, API consistency, and feature additions. However, it also introduces breaking changes that will require code modifications for existing scripts.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#quick-statistics","title":"Quick Statistics","text":"Metric Count New API Modules 9 Removed API Modules 3 Modified API Modules 104 Total Files Changed ~154 MB of documentation"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Breaking Changes</li> <li>Type System Improvements</li> <li>New Modules</li> <li>Removed Modules</li> <li>Module-by-Module Changes</li> <li>Migration Guide</li> <li>New Features by Category</li> </ol>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#1-breaking-changes","title":"1. Breaking Changes","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#11-enum-system-overhaul-critical","title":"1.1 Enum System Overhaul \u26a0\ufe0f CRITICAL","text":"<p>The most significant breaking change is the complete replacement of the enum system.</p> <p>Before (8.2): <pre><code>from Boost.Python import enum\n# Enums were custom Boost.Python types\nclass eCompression:\n    __slots__ = ()\n    kHigh\n    kLossless\n    kMedium\n    kNone\n    names  # Dictionary of names\n    values  # Dictionary of values\n</code></pre></p> <p>After (9.2): <pre><code>import enum\n# Enums are now standard Python IntEnum\nclass eCompression(enum.IntEnum):\n    __members__: mappingproxy\n    __name__ = 'eCompression'\n    kHigh: Extractors.eCompression\n    kLossless: Extractors.eCompression\n    kMedium: Extractors.eCompression\n    kNoCompression: Extractors.eCompression  # Note: kNone \u2192 kNoCompression\n</code></pre></p> <p>Impact: - Code using <code>.names</code> or <code>.values</code> will break - Use <code>list(EnumClass)</code> or <code>EnumClass.__members__</code> instead - Some enum values have been renamed (e.g., <code>kNone</code> \u2192 <code>kNoCompression</code>) - Enum values now have proper type annotations</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#12-argument-name-standardization","title":"1.2 Argument Name Standardization","text":"<p>Function argument indices have been re-indexed from 1-based to 0-based.</p> <p>Before (8.2): <pre><code>def SomeFunction(arg1: Any, arg2: Any, arg3: Any) -&gt; None\n</code></pre></p> <p>After (9.2): <pre><code>def SomeFunction(arg0: Type1, arg1: Type2, arg2: Type3) -&gt; None\n</code></pre></p> <p>Affected Modules: Nearly all modules with positional arguments.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#13-vector-type-standardization","title":"1.3 Vector Type Standardization","text":"<p>Vector types have been consolidated.</p> <p>Before (8.2): <pre><code>XCoreModeling.Vec3\nXCoreMath.Vec3\n</code></pre></p> <p>After (9.2): <pre><code>QTech.Vec3  # Primary vector type\nXCoreMath.Vec3  # Still available for transforms\n</code></pre></p> <p>Examples of affected functions: - <code>Compose(arg2: XCoreMath.Vec3, ...)</code> \u2192 <code>Compose(arg0: QTech.Vec3, ...)</code> - <code>Transform(vec3: Vec3)</code> \u2192 <code>Transform(vec3: QTech.Vec3)</code></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#14-return-type-changes","title":"1.4 Return Type Changes","text":"<p>Many functions now return <code>list</code> instead of <code>tuple</code>.</p> <p>Before (8.2): <pre><code>def GetNeuronEntities() -&gt; tuple[XCoreModeling.Entity]\ndef GetSectionNames(...) -&gt; tuple[str]\ndef FindEntities(filter) -&gt; tuple\n</code></pre></p> <p>After (9.2): <pre><code>def GetNeuronEntities() -&gt; list[XCoreModeling.Entity]\ndef GetSectionNames(...) -&gt; list[str]\ndef FindEntities(filter: Callable[[Entity], bool]) -&gt; list[Entity]\n</code></pre></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#2-type-system-improvements","title":"2. Type System Improvements","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#21-replacement-of-any-with-specific-types","title":"2.1 Replacement of <code>Any</code> with Specific Types","text":"<p>The most pervasive change is the replacement of generic <code>Any</code> types with precise Python types.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#numeric-types","title":"Numeric Types","text":"Before (8.2) After (9.2) <code>Any</code> <code>SupportsFloat</code> <code>Any</code> <code>SupportsInt</code> <code>Any</code> <code>float</code> <code>Any</code> <code>int</code> <code>Any</code> <code>bool</code> <code>Any</code> <code>complex</code>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#collection-types","title":"Collection Types","text":"Before (8.2) After (9.2) <code>Any</code> <code>collections.abc.Sequence[T]</code> <code>Any</code> <code>list[T]</code> <code>Any</code> <code>dict[K, V]</code> <code>Any</code> <code>set[T]</code> <code>tuple</code> <code>list[T]</code> (in many cases)"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#callable-types","title":"Callable Types","text":"Before (8.2) After (9.2) <code>Any</code> <code>collections.abc.Callable[[Args], ReturnType]</code> <code>Any</code> <code>collections.abc.typing.Callable[[str], bool]</code>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#numpy-types","title":"NumPy Types","text":"Before (8.2) After (9.2) <code>Any</code> <code>numpy.ndarray</code> <code>Any</code> <code>numpy.typing.NDArray[numpy.float64]</code> <code>Any</code> <code>Annotated[numpy.typing.ArrayLike, numpy.float32]</code>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#22-path-type-improvements","title":"2.2 Path Type Improvements","text":"<p>File path parameters now accept multiple types:</p> <p>Before (8.2): <pre><code>def ImportImage(file_path: str) -&gt; Image\n</code></pre></p> <p>After (9.2): <pre><code>def ImportImage(file_path: os.PathLike | str | bytes) -&gt; Image\n</code></pre></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#23-optional-type-annotations","title":"2.3 Optional Type Annotations","text":"<p>Proper use of <code>None</code> types and union types:</p> <p>Before (8.2): <pre><code>def Update(output_index: int = 0, iteration_indices: list[int] = ...) -&gt; bool\n</code></pre></p> <p>After (9.2): <pre><code>def Update(output_index: int | str | None = None, iteration_indices: list[int] | None = None) -&gt; bool\n</code></pre></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#3-new-modules","title":"3. New Modules","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#31-chromiumui","title":"3.1 ChromiumUI","text":"<p>Replaces the deprecated <code>Chromium</code> module for browser-based UI components.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#32-helpui","title":"3.2 HelpUI","text":"<p>New module for help system integration within the UI.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#33-josuacontrollerinterface","title":"3.3 JosuaControllerInterface","text":"<p>Interface for JOSUA (presumably a simulation controller or optimizer).</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#34-lazysocks","title":"3.4 LazySocks","text":"<p>Lazy socket implementation for deferred connections.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#35-s4l_v1_apipybindutils","title":"3.5 s4l_v1._api.pybindutils","text":"<p>Internal utilities for pybind11 bindings.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#36-syssimappbase","title":"3.6 SysSimAppBase","text":"<p>Base application class for system simulations.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#37-testkit_spok","title":"3.7 TestKit_Spok","text":"<p>Testing utilities for Spok framework.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#38-toolkitfus","title":"3.8 ToolkitFUS","text":"<p>Focused Ultrasound (FUS) toolkit - new simulation capabilities.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#39-xosparcapiclient","title":"3.9 XOsparcApiClient","text":"<p>Client for o\u00b2S\u00b2PARC platform integration (cloud computing).</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#4-removed-modules","title":"4. Removed Modules","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#41-chromium","title":"4.1 Chromium","text":"<p>Replacement: <code>ChromiumUI</code></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#42-imagepostpro","title":"4.2 ImagePostPro","text":"<p>Status: Deprecated/merged into other modules</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#43-xndarray","title":"4.3 XNdArray","text":"<p>Status: Functionality absorbed into NumPy integration</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#5-module-by-module-changes","title":"5. Module-by-Module Changes","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#51-core-framework-xcore","title":"5.1 Core Framework (XCore)","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-classes","title":"New Classes","text":"<ul> <li><code>FileFilter</code> - File type filtering for dialogs</li> <li><code>Exception</code> - Custom exception handling</li> <li><code>AlignmentEnum</code> - UI alignment constants</li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-methods","title":"New Methods","text":"<ul> <li><code>AddRow()</code> - Table row operations</li> <li><code>GetCell(row, col)</code> - Cell access</li> <li><code>GetRowAsJson(row)</code> - JSON serialization</li> <li><code>GetTable()</code> - Full table retrieval</li> <li><code>GetColumnDefinitions()</code> - Schema access</li> <li><code>GetDataAsVariantMap()</code> - Data export</li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#signal-improvements","title":"Signal Improvements","text":"<p>All signals now have proper callable type hints: <pre><code># Before\nConnect(slot: Any) -&gt; Connection\n\n# After\nConnect(slot: collections.abc.Callable[[DataIndex], None]) -&gt; Connection\nConnect(slot: collections.abc.Callable[[Property, PropertyModificationTypeEnum], None]) -&gt; Connection\nConnect(slot: collections.abc.Callable[[SupportsFloat], None]) -&gt; Connection\n# ... and many more specific signatures\n</code></pre></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#unit-constants","title":"Unit Constants","text":"<p>Now properly typed as <code>ClassVar[Unit]</code>: <pre><code>Ampere: ClassVar[Unit]\nCelsius: ClassVar[Unit]\nCentiMeter: ClassVar[Unit]\n# etc.\n</code></pre></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#52-modeling-xcoremodeling","title":"5.2 Modeling (XCoreModeling)","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-functions","title":"New Functions","text":"Function Description <code>CreateDBSElectrode()</code> Create Deep Brain Stimulation electrodes <code>CreatePaddleElectrode()</code> Create paddle-style electrodes <code>GeodesicIsolinePatches()</code> Geodesic isoline computation <code>GeodesicVoronoiDiagram()</code> Voronoi diagrams on surfaces <code>IdentifyInterface()</code> Interface identification between regions <code>AttachLocalCoordinateSystem()</code> Attach coordinate systems to vertices <code>DeleteTriangleMeshPatches()</code> Batch patch deletion"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-classes_1","title":"New Classes","text":"<ul> <li><code>DBSElectrodeParameters</code> - DBS electrode configuration</li> <li><code>ePaddleElectrodeContactShape</code> - Paddle electrode shapes (Circular, etc.)</li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#removedconsolidated","title":"Removed/Consolidated","text":"<ul> <li><code>CreateTrianglePatch</code> \u2192 Use <code>NewPatch</code> instead</li> <li><code>DeleteTrianglePatch</code> \u2192 Use <code>DeletePatch</code> instead</li> <li><code>NewTrianglePatch*</code> methods consolidated</li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#type-improvements","title":"Type Improvements","text":"<pre><code># Before\ndef FindEntities(filter: Any) -&gt; tuple\n\n# After\ndef FindEntities(filter: collections.abc.Callable[[Entity], bool]) -&gt; list[Entity]\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#53-image-processing-imagemodeling-s4l_v1modelimage","title":"5.3 Image Processing (ImageModeling / s4l_v1.model.image)","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-functions_1","title":"New Functions","text":"Function Description <code>BodyModelGeneration(image, modality)</code> Generate body models from images <code>Predict1010SystemLandmarks(image)</code> Predict 10-10 EEG system landmarks"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#enhanced-functions","title":"Enhanced Functions","text":"<pre><code># HeadModelGeneration - Simplified signature\n# Before (8.2)\ndef HeadModelGeneration(images: Any, bias_correction: Any = True,\n                        closing_radius: Any = 30, ...) -&gt; LabelField\n\n# After (9.2)\ndef HeadModelGeneration(images: collections.abc.Sequence[XCoreModeling.Image]) -&gt; LabelField\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-enum-values","title":"New Enum Values","text":"<ul> <li><code>kCC</code> - Cross-correlation metric</li> <li><code>kMI</code> - Mutual information metric</li> <li><code>kNoInit</code> - No initialization option</li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#54-post-processing-analysis","title":"5.4 Post-Processing (Analysis)","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-algorithm","title":"New Algorithm","text":"<p><code>ScalarProductFieldEvaluator</code> - Computes scalar (dot) product between two vector fields - Useful for: E\u00b7J calculations, power density, projection analysis</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-methods-across-all-analysis-modules","title":"New Methods Across All Analysis Modules","text":"<pre><code>UpdateAll() -&gt; bool  # Update all outputs at once\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#update-method-enhancement","title":"Update Method Enhancement","text":"<pre><code># Before\ndef Update(output_index: int = 0, iteration_indices: list[int] = ...) -&gt; bool\n\n# After\ndef Update(output_index: int | str | None = None,\n           iteration_indices: list[int] | None = None) -&gt; bool\ndef Update(key: str) -&gt; bool  # New overload\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#viewer-enhancements","title":"Viewer Enhancements","text":"<p>New properties: - <code>Center</code> - Center point property - <code>Point1</code>, <code>Point2</code> - Line/probe endpoints - <code>Resolution</code> - Output resolution</p> <p>Enhanced functions: <pre><code># ExportIsoSurfaceToModel now accepts name parameter\ndef ExportIsoSurfaceToModel(name: str = 'Iso-Surface')\n</code></pre></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#55-electromagnetic-simulations","title":"5.5 Electromagnetic Simulations","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#em-fdtd-s4l_v1simulationemfdtd","title":"EM FDTD (s4l_v1.simulation.emfdtd)","text":"<p>New properties: | Property | Description | |----------|-------------| | <code>AnalyticMethod</code> | Analytical method selection | | <code>CongruentVoxeling</code> | Congruent voxelization option | | <code>ConvergenceLevel</code> | Convergence criteria | | <code>GlobalAutoTermination</code> | Auto-termination settings | | <code>GlobalBoundaryType</code> | Global boundary configuration | | <code>TimeStepFactor</code> | Time step control | | <code>VoxelEngine</code> | Voxelization engine selection |</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#em-lf-s4l_v1simulationemlf","title":"EM LF (s4l_v1.simulation.emlf)","text":"<p>New properties: | Property | Description | |----------|-------------| | <code>AbsoluteSolverTolerance</code> | Absolute solver tolerance | | <code>AbsoluteTolerance</code> | General absolute tolerance | | <code>RelativeSolverTolerance</code> | Relative solver tolerance | | <code>RelativeTolerance</code> | General relative tolerance | | <code>DivergenceSolverTolerance</code> | Divergence solver tolerance | | <code>MaxLinearIterations</code> | Maximum linear iterations | | <code>PredefinedTolerances</code> | Predefined tolerance presets | | <code>EnforceCoulombGaugingOfVectorPotential</code> | Coulomb gauge enforcement |</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#shared-em-properties","title":"Shared EM Properties","text":"<p>All EM simulations now have: - <code>SimulationUuid</code> - Unique simulation identifier - <code>SimulationNotes</code> - User notes field - <code>JobPriority</code> / <code>JobPriorityEnum</code> - Job scheduling priority - <code>NumberOfGpus</code>, <code>NumberOfProcesses</code>, <code>NumberOfThreads</code> - Parallelization - <code>Parallelization</code> - Parallelization mode - <code>MaxFraction</code> - Maximum fraction setting - <code>VoxelEngine</code> - Voxelization engine</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#56-thermal-simulations","title":"5.6 Thermal Simulations","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-functionality","title":"New Functionality","text":"<p><pre><code>CloneAsTIncrease() -&gt; ThermalSimulator.ThermalSimulation\n</code></pre> Clone simulation configured for temperature increase studies.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-properties","title":"New Properties","text":"Property Description <code>BloodVolume</code> Blood volume for bio-heat <code>Duration</code> Simulation duration <code>InitTime</code> Initialization time <code>LastSnapshot</code> Last snapshot option <code>MassDensity</code> Mass density setting <code>SpecificHeatCapacity</code> Heat capacity <code>ThermalConductivity</code> Thermal conductivity <code>UseBodyCoreHeating</code> Body core heating model <code>OverallTemperature</code> Overall temperature sensor <code>ThermalUnstructuredModel</code> Unstructured mesh model"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#57-acoustic-simulations","title":"5.7 Acoustic Simulations","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-properties_1","title":"New Properties","text":"Property Description <code>CongruentVoxeling</code> Congruent voxelization <code>Frequency</code> Operating frequency <code>Harmonics</code> Harmonic analysis settings <code>Periods</code> Number of periods <code>ModelType</code> Acoustic model type <code>SolverType</code> Solver selection"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#58-neuron-simulations","title":"5.8 Neuron Simulations","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#return-type-updates","title":"Return Type Updates","text":"<pre><code># Before\ndef GetNeuronEntities() -&gt; tuple[XCoreModeling.Entity]\ndef GetSectionNames(...) -&gt; tuple[str]\n\n# After\ndef GetNeuronEntities() -&gt; list[XCoreModeling.Entity]\ndef GetSectionNames(...) -&gt; list[str]\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#59-posingdeformation-xposer","title":"5.9 Posing/Deformation (XPoser)","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#major-restructuring","title":"Major Restructuring","text":"<p>Removed: - <code>BoneEnvelope</code> class - <code>BoneMeshControl</code> class - <code>CreateBone()</code> function - <code>IsBone()</code> function - Individual bone control methods (<code>AddMeshes</code>, <code>RemoveMeshes</code>, <code>Start</code>, <code>Stop</code>, etc.)</p> <p>New Functions: | Function | Description | |----------|-------------| | <code>ApplyMorphing(bone_system, posture, displacements_file)</code> | Apply morphing with displacement field | | <code>ConcatenateDeformation(input1, input2, output, scale)</code> | Concatenate deformation fields | | <code>InterpolateDeformation(input, target, output)</code> | Interpolate deformation to new mesh | | <code>InvertDeformation(input, output)</code> | Invert deformation field | | <code>UntangleDeformation(input, output, ...)</code> | Fix tangled/inverted elements | | <code>FixSkinThickness(old_skin, new_skin, max_thickness)</code> | Fix skin thickness issues | | <code>SubdivideFemMesh(bone_mesh, max_edge_length)</code> | Subdivide FEM mesh | | <code>MakePosable(mesh, bone_links, regions)</code> | Make mesh posable | | <code>RemoveDomain0(input, output, domain_array)</code> | Remove domain 0 | | <code>SaveProblemRegionVertexIds(...)</code> | Save problematic regions |</p> <p>New Class: <code>MaterialRegion</code> <pre><code>class MaterialRegion:\n    CommaSeparatedSettings: str\n    Names: list[str]\n    PoissonRatio: float\n    VolumeGrowth: float\n    YoungsModulus: float\n</code></pre></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#510-rendering-xrendererxrendererui","title":"5.10 Rendering (XRenderer/XRendererUI)","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-functions_2","title":"New Functions","text":"<pre><code>def RenderToImage(width: int = 1024, height: int = 1024,\n                  output_file: str = '', use_alpha: bool = False) -&gt; None\n\ndef UpdateRenderer() -&gt; None\n\ndef DebugQueueFrameCapture(path: str) -&gt; bool\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#api-improvements","title":"API Improvements","text":"<pre><code># SetViewDirection - Enhanced signature\n# Before\ndef SetViewDirection(arg1: QTech.Vec3) -&gt; None\n\n# After\ndef SetViewDirection(look: QTech.Vec3, right: QTech.Vec3 = Vec3(0, 0, 0)) -&gt; None\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#property-type-fixes","title":"Property Type Fixes","text":"<p>All <code>Any</code> properties replaced with specific types: <pre><code># Before\nproperty Distance: Any\nproperty PerspectiveMode: Any\nproperty ViewDirection: Any\nproperty Viewpoint: Any\n\n# After\nproperty Distance: float\nproperty PerspectiveMode: bool\nproperty ViewDirection: list[float]\nproperty Viewpoint: QTech.Vec3\n</code></pre></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#511-simulation-framework-xsimulator","title":"5.11 Simulation Framework (XSimulator)","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-class","title":"New Class","text":"<pre><code>class DiscretizationSimulation:\n    # Specialized simulation for discretization studies\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-function","title":"New Function","text":"<p><pre><code>def ScanNetwork(ip_start: str, ip_end: str, ports: str,\n                wait_for_resources: int) -&gt; list[tuple[XCore.Uuid, dict[str, str]]]\n</code></pre> Scan network for available compute resources.</p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#type-improvements_1","title":"Type Improvements","text":"<pre><code># Before\ndef CollectAllComponents() -&gt; Any\ndef CollectSettingsIf(concept: ConceptInfo) -&gt; Any\n\n# After\ndef CollectAllComponents() -&gt; list[Component]\ndef CollectSettingsIf(concept: ConceptInfo) -&gt; list[ConceptSettings]\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#512-plotting-xplotlib","title":"5.12 Plotting (XPlotLib)","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#major-cleanup","title":"Major Cleanup","text":"<p>All enum constants consolidated to <code>ClassVar</code> pattern: <pre><code># Before - Separate entries\nAxis0Left\nAxis0Left\nAxis0Right\nAxis0Right\n# ... repeated for all axes\n\n# After - ClassVar type hints\nAxis0Left: ClassVar[PlottingAxis]\nAxis0Right: ClassVar[PlottingAxis]\n</code></pre></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#type-improvements-for-plot-data","title":"Type Improvements for Plot Data","text":"<pre><code># Before\ndef AddPlot(x_data: Any, y_data: Any, plot_legend: str) -&gt; PlotSettings\n\n# After\ndef AddPlot(x_data: Annotated[numpy.typing.ArrayLike, numpy.float32],\n            y_data: Annotated[numpy.typing.ArrayLike, numpy.float32],\n            plot_legend: str) -&gt; PlotSettings\ndef AddPlot(x_data: collections.abc.Sequence[SupportsFloat],\n            y_data: collections.abc.Sequence[SupportsFloat],\n            plot_legend: str) -&gt; PlotSettings\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#513-virtual-population-vip","title":"5.13 Virtual Population (ViP)","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#new-functions_3","title":"New Functions","text":"Function Description <code>Dilate(radius)</code> Morphological dilation <code>Erode(radius)</code> Morphological erosion <code>SmoothPolylines(entity_list, angle, iterations, refine)</code> Smooth multiple polylines <code>Save(file_path)</code> Save to file"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#removed","title":"Removed","text":"<ul> <li><code>CreateProjectionMask</code> - Removed entirely</li> <li><code>RenderLines</code> - Removed entirely</li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#type-improvements_2","title":"Type Improvements","text":"<p>Extensive replacement of <code>Any</code> with proper types: <pre><code># Before\ndef BatchExtractSelectedTissues(input_file: str, output_dir: str,\n                                 list_tissue_list: Any) -&gt; None\n\n# After\ndef BatchExtractSelectedTissues(input_file: str, output_dir: str,\n                                 list_tissue_list: collections.abc.Sequence[str]) -&gt; None\n</code></pre></p>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#514-materials-database-xmaterials","title":"5.14 Materials Database (XMaterials)","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#property-additions","title":"Property Additions","text":"<pre><code>Active: bool  # New property\nDescription: str  # New property\nType: LinearDispersionPole  # New type annotation\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#type-improvements_3","title":"Type Improvements","text":"<pre><code># Before\ndef FindMaterial(pattern: str, aliases: Any) -&gt; Any\ndef Evaluate(frequencies: Any) -&gt; Any\n\n# After\ndef FindMaterial(pattern: str, aliases: bool) -&gt; list[Material]\ndef Evaluate(frequencies: collections.abc.Sequence[SupportsFloat]) -&gt; list[complex]\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#6-migration-guide","title":"6. Migration Guide","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#61-updating-enum-usage","title":"6.1 Updating Enum Usage","text":"<pre><code># OLD CODE (8.2)\nfrom SomeModule import SomeEnum\nvalue = SomeEnum.kSomeValue\nall_values = SomeEnum.values\nall_names = SomeEnum.names\n\n# NEW CODE (9.2)\nfrom SomeModule import SomeEnum\nvalue = SomeEnum.kSomeValue  # Still works\nall_values = list(SomeEnum)  # Use list() instead\nall_names = SomeEnum.__members__  # Use __members__ instead\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#62-updating-function-calls-with-renamed-arguments","title":"6.2 Updating Function Calls with Renamed Arguments","text":"<pre><code># OLD CODE (8.2) - Positional arguments work\nresult = SomeFunction(arg1, arg2, arg3)\n\n# NEW CODE (9.2) - Still works positionally, but named args changed\nresult = SomeFunction(arg0, arg1, arg2)\n\n# If using keyword arguments, update names:\n# OLD: result = SomeFunction(arg1=val1, arg2=val2)\n# NEW: result = SomeFunction(arg0=val1, arg1=val2)\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#63-updating-vector-types","title":"6.3 Updating Vector Types","text":"<pre><code># OLD CODE (8.2)\nfrom XCoreModeling import Vec3\npoint = Vec3(1.0, 2.0, 3.0)\n\n# NEW CODE (9.2)\nfrom QTech import Vec3\npoint = Vec3(1.0, 2.0, 3.0)\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#64-updating-return-type-handling","title":"6.4 Updating Return Type Handling","text":"<pre><code># OLD CODE (8.2)\nentities = simulation.GetNeuronEntities()  # Returns tuple\nfirst = entities[0]  # Works\n\n# NEW CODE (9.2)\nentities = simulation.GetNeuronEntities()  # Returns list\nfirst = entities[0]  # Still works - lists are indexable too\n# But if you were type checking for tuple, update to list\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#65-using-new-update-methods","title":"6.5 Using New Update Methods","text":"<pre><code># OLD CODE (8.2)\nalgorithm.Update(0, [])  # Update output 0\n\n# NEW CODE (9.2) - Multiple options\nalgorithm.Update()  # Update default\nalgorithm.Update(\"output_name\")  # Update by name\nalgorithm.Update(0, None)  # Update with explicit None\nalgorithm.UpdateAll()  # NEW: Update all outputs\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#66-path-parameters","title":"6.6 Path Parameters","text":"<pre><code># OLD CODE (8.2)\nimage = ImportImage(\"/path/to/image.png\")\n\n# NEW CODE (9.2) - All these work\nfrom pathlib import Path\nimage = ImportImage(\"/path/to/image.png\")  # str still works\nimage = ImportImage(Path(\"/path/to/image.png\"))  # pathlib works\nimage = ImportImage(b\"/path/to/image.png\")  # bytes works\n</code></pre>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#7-new-features-by-category","title":"7. New Features by Category","text":""},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#71-medical-device-modeling","title":"7.1 Medical Device Modeling","text":"<ul> <li>DBS Electrode Creation - <code>CreateDBSElectrode()</code>, <code>DBSElectrodeParameters</code></li> <li>Paddle Electrode Creation - <code>CreatePaddleElectrode()</code>, <code>ePaddleElectrodeContactShape</code></li> <li>10-10 System Landmarks - <code>Predict1010SystemLandmarks()</code></li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#72-mesh-processing","title":"7.2 Mesh Processing","text":"<ul> <li>Geodesic Tools - <code>GeodesicIsolinePatches()</code>, <code>GeodesicVoronoiDiagram()</code>, <code>GeodesicPath()</code></li> <li>Interface Identification - <code>IdentifyInterface()</code></li> <li>Local Coordinate Systems - <code>AttachLocalCoordinateSystem()</code></li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#73-deformationmorphing-xposer","title":"7.3 Deformation/Morphing (XPoser)","text":"<ul> <li>Deformation Operations - Concatenate, Interpolate, Invert, Untangle</li> <li>Morphing Application - <code>ApplyMorphing()</code></li> <li>Mesh Quality - <code>FixSkinThickness()</code>, <code>SubdivideFemMesh()</code></li> <li>Material Regions - New <code>MaterialRegion</code> class</li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#74-simulation-enhancements","title":"7.4 Simulation Enhancements","text":"<ul> <li>Thermal - Temperature increase cloning, body core heating</li> <li>EM LF - Enhanced solver tolerances and options</li> <li>EM FDTD - Auto-termination, analytical methods</li> <li>Acoustic - Harmonic analysis, model types</li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#75-clouddistributed-computing","title":"7.5 Cloud/Distributed Computing","text":"<ul> <li>o\u00b2S\u00b2PARC Integration - <code>XOsparcApiClient</code> module</li> <li>Network Scanning - <code>ScanNetwork()</code> for compute resources</li> <li>Job Priority - <code>JobPriority</code> and <code>JobPriorityEnum</code> across simulations</li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#76-post-processing","title":"7.6 Post-Processing","text":"<ul> <li>Scalar Product Evaluation - <code>ScalarProductFieldEvaluator</code></li> <li>Batch Updates - <code>UpdateAll()</code> method</li> <li>ISO Surface Export - Named exports with <code>ExportIsoSurfaceToModel(name)</code></li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#77-rendering","title":"7.7 Rendering","text":"<ul> <li>Direct Image Render - <code>RenderToImage()</code></li> <li>Renderer Updates - <code>UpdateRenderer()</code></li> <li>Debug Capture - <code>DebugQueueFrameCapture()</code></li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#78-image-processing","title":"7.8 Image Processing","text":"<ul> <li>Body Model Generation - <code>BodyModelGeneration()</code></li> <li>Landmark Prediction - <code>Predict1010SystemLandmarks()</code></li> <li>New Metrics - Cross-correlation (kCC), Mutual Information (kMI)</li> </ul>"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#appendix-a-complete-list-of-renamed-enum-values","title":"Appendix A: Complete List of Renamed Enum Values","text":"Module Old Name New Name Extractors <code>kNone</code> <code>kNoCompression</code> Various <code>Axis4ight</code> <code>Axis4Right</code> (typo fix)"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#appendix-b-removed-propertiesmethods","title":"Appendix B: Removed Properties/Methods","text":"Module Removed Item Replacement XCoreModeling <code>AsVtkImage()</code> Use numpy integration XCoreModeling <code>AsVtkMesh()</code> Use numpy integration XCoreModeling <code>DeleteTrianglePatch()</code> <code>DeletePatch()</code> XCoreModeling <code>NewTrianglePatch()</code> <code>NewPatch()</code> XCoreModeling <code>NewTrianglePatchFromRest()</code> <code>NewPatchFromRest()</code> XPoser <code>BoneEnvelope</code> Removed (new deformation API) XPoser <code>BoneMeshControl</code> Removed (new deformation API) XPoser <code>CreateBone()</code> Removed XPoser <code>IsBone()</code> Removed ViP <code>CreateProjectionMask</code> Removed ViP <code>RenderLines</code> Removed SysSimPrePro Many UI properties Simplified API"},{"location":"reference/s4l_api_migration_8_2_to_9_2/API_CHANGES_SUMMARY/#appendix-c-files-for-further-reference","title":"Appendix C: Files for Further Reference","text":"<ul> <li><code>PythonAPIReference_DIFF_8_2_to_9_2/DIFF_MANIFEST.txt</code> - List of all changed files</li> <li><code>PythonAPIReference_DIFF_8_2_to_9_2/CONTENT_DIFF.md</code> - Detailed line-by-line diff</li> <li><code>PythonAPIReference_8_2/</code> - Original 8.2 documentation</li> <li><code>PythonAPIReference_9_2/</code> - New 9.2 documentation</li> </ul> <p>Document generated: 2026-01-13 Based on comparison of Sim4Life Python API Reference documentation versions 8.2 and 9.2</p>"},{"location":"tasks/separate_disk_io_plot/","title":"Task: Move Disk I/O to Separate Tab","text":""},{"location":"tasks/separate_disk_io_plot/#goal","title":"Goal","text":"<p>Move the SSD Read/Write plotting from the \"System Utilization\" tab to a new dedicated \"Disk I/O\" tab. This frees up the right Y-axis on the main utilization plot for future metrics (e.g., page faults, available memory).</p>"},{"location":"tasks/separate_disk_io_plot/#current-state","title":"Current State","text":""},{"location":"tasks/separate_disk_io_plot/#system-utilization-plot","title":"System Utilization Plot","text":"<ul> <li>Location: <code>goliat/gui/components/plots/system_utilization_plot.py</code></li> <li>Left Y-axis (0-100%): CPU, RAM, GPU, GPU VRAM</li> <li>Right Y-axis (MB/s): Disk Read, Disk Write (using <code>ax.twinx()</code>)</li> </ul> <p>The right axis is currently used for disk I/O, which has different units (MB/s) than the percentage-based metrics.</p>"},{"location":"tasks/separate_disk_io_plot/#data-flow","title":"Data Flow","text":"<ol> <li><code>SystemMonitor</code> (in <code>system_monitor.py</code>) collects all metrics including <code>get_disk_io_throughput()</code></li> <li><code>UtilizationManager</code> (in <code>utilization_manager.py</code>) stores values and calls <code>update_plot()</code> every 2 seconds</li> <li><code>SystemUtilizationPlot.add_data_point()</code> receives all data including <code>disk_read_mbps</code> and <code>disk_write_mbps</code></li> <li>Data is also written to CSV via <code>DataManager.write_system_utilization()</code></li> </ol>"},{"location":"tasks/separate_disk_io_plot/#files-to-modify","title":"Files to Modify","text":""},{"location":"tasks/separate_disk_io_plot/#1-create-goliatguicomponentsplotsdisk_io_plotpy","title":"1. Create: <code>goliat/gui/components/plots/disk_io_plot.py</code>","text":"<p>Create a new plot class similar to <code>TimeRemainingPlot</code> or <code>SystemUtilizationPlot</code>: - Single Y-axis in MB/s - Two lines: Disk Read (green <code>#00ff88</code>) and Disk Write (orange <code>#ff8800</code>) - Same dark theme styling as other plots - Same <code>add_data_point(timestamp, disk_read_mbps, disk_write_mbps)</code> pattern</p>"},{"location":"tasks/separate_disk_io_plot/#2-modify-goliatguicomponentsplots__init__py","title":"2. Modify: <code>goliat/gui/components/plots/__init__.py</code>","text":"<p>Add export for <code>DiskIOPlot</code>: <pre><code>from .disk_io_plot import DiskIOPlot\n__all__ = [..., \"DiskIOPlot\"]\n</code></pre></p>"},{"location":"tasks/separate_disk_io_plot/#3-modify-goliatguicomponentsplotssystem_utilization_plotpy","title":"3. Modify: <code>goliat/gui/components/plots/system_utilization_plot.py</code>","text":"<p>Remove all disk I/O related code: - Remove <code>self.disk_read_data</code> and <code>self.disk_write_data</code> lists - Remove <code>self.disk_available</code> flag - Remove <code>self.ax2</code> secondary axis - Remove <code>disk_read_mbps</code> and <code>disk_write_mbps</code> from <code>add_data_point()</code> signature - Remove disk plotting logic from <code>_refresh()</code></p>"},{"location":"tasks/separate_disk_io_plot/#4-modify-goliatguicomponentsui_builderpy","title":"4. Modify: <code>goliat/gui/components/ui_builder.py</code>","text":"<p>Add new tab builder method (pattern from line 412-418): <pre><code>@staticmethod\ndef _build_disk_io_tab(gui_instance: \"ProgressGUI\") -&gt; None:\n    \"\"\"Builds the Disk I/O tab.\"\"\"\n    disk_io_widget = QWidget()\n    disk_io_layout = QVBoxLayout(disk_io_widget)\n    gui_instance.tabs.addTab(disk_io_widget, \"Disk I/O\")\n    gui_instance.disk_io_plot = DiskIOPlot()\n    disk_io_layout.addWidget(gui_instance.disk_io_plot.canvas)\n</code></pre> Call this from <code>build()</code> method (around line 210).</p> <p>Update import to include <code>DiskIOPlot</code>.</p>"},{"location":"tasks/separate_disk_io_plot/#5-modify-goliatguicomponentsutilization_managerpy","title":"5. Modify: <code>goliat/gui/components/utilization_manager.py</code>","text":"<p>In <code>update_plot()</code> method (line 95-149): - Keep collecting disk I/O data (already done at lines 88-93) - Remove disk params from <code>system_utilization_plot.add_data_point()</code> call - Add new call to <code>disk_io_plot.add_data_point()</code>: <pre><code>if hasattr(self.gui, \"disk_io_plot\"):\n    self.gui.disk_io_plot.add_data_point(\n        timestamp=current_time,\n        disk_read_mbps=self._last_disk_read_mbps,\n        disk_write_mbps=self._last_disk_write_mbps,\n    )\n</code></pre></p>"},{"location":"tasks/separate_disk_io_plot/#6-no-changes-needed-goliatguicomponentsdata_managerpy","title":"6. No changes needed: <code>goliat/gui/components/data_manager.py</code>","text":"<p>CSV format stays the same - disk I/O data continues to be logged.</p>"},{"location":"tasks/separate_disk_io_plot/#reference-existing-plot-patterns","title":"Reference: Existing Plot Patterns","text":""},{"location":"tasks/separate_disk_io_plot/#plot-class-structure-see-time_remaining_plotpy","title":"Plot class structure (see <code>time_remaining_plot.py</code>):","text":"<pre><code>class SomePlot:\n    def __init__(self):\n        self.figure = Figure(figsize=(10, 6), facecolor=\"#2b2b2b\")\n        self.canvas = FigureCanvas(self.figure)\n        self.ax = self.figure.add_subplot(111)\n        self.data = []\n        self._setup()\n    \n    def _setup(self):\n        # Dark theme styling\n        self.ax.set_facecolor(\"#2b2b2b\")\n        # ... axis labels, grid, etc.\n    \n    def add_data_point(self, timestamp, ...):\n        # Validate timestamp, append to data, call _refresh()\n    \n    def _refresh(self):\n        # Clear, re-plot, canvas.draw()\n</code></pre>"},{"location":"tasks/separate_disk_io_plot/#colors-used-in-codebase","title":"Colors used in codebase:","text":"<ul> <li>Background: <code>#2b2b2b</code></li> <li>Text/grid: <code>#f0f0f0</code></li> <li>Legend bg: <code>#3c3c3c</code></li> <li>Disk Read: <code>#00ff88</code> (green, dashed)</li> <li>Disk Write: <code>#ff8800</code> (orange, dashed)</li> </ul>"},{"location":"tasks/separate_disk_io_plot/#imports-needed","title":"Imports needed:","text":"<pre><code>from ._matplotlib_imports import Figure, FigureCanvas, mdates\nfrom .utils import convert_to_utc_plus_one, validate_timestamp, clean_plot_data\n</code></pre>"},{"location":"tasks/separate_disk_io_plot/#testing","title":"Testing","text":"<ol> <li>Run a study with GUI enabled</li> <li>Verify \"System Utilization\" tab shows only CPU/RAM/GPU/VRAM (no right axis)</li> <li>Verify new \"Disk I/O\" tab shows read/write throughput</li> <li>Verify CSV still contains all columns including disk data</li> </ol>"},{"location":"technical/ai_models_literature_review_dec_2025/","title":"AI Models Literature Review for GOLIAT RAG System","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#december-2025","title":"December 2025","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Current GOLIAT AI Implementation</li> <li>Frontier LLM Models Comparison</li> <li>Budget-Friendly &amp; Mid-Tier Models</li> <li>Embedding Models for RAG</li> <li>Cost Analysis &amp; Projections</li> <li>RAG-Specific Frameworks &amp; Techniques</li> <li>Local/Self-Hosted Options</li> <li>Recommendations for GOLIAT</li> <li>Creative Suggestions &amp; Future Directions</li> </ol>"},{"location":"technical/ai_models_literature_review_dec_2025/#current-goliat-ai-implementation","title":"Current GOLIAT AI Implementation","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#architecture-overview","title":"Architecture Overview","text":"<p>GOLIAT currently uses a simple RAG (Retrieval-Augmented Generation) approach:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Codebase       \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Embedding Index \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Vector Search  \u2502\n\u2502  (goliat/, cli/)\u2502     \u2502  (JSON cache)    \u2502     \u2502  (cosine sim)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                          \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  User Query     \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Query Embedding \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n                                                          \u25bc\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502  GPT-4o Response \u2502\u25c0\u2500\u2500\u2500\u2500\u2502  Top-K Chunks   \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502  + System Prompt\u2502\n                                                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"technical/ai_models_literature_review_dec_2025/#current-models-used","title":"Current Models Used","text":"Component Model Cost (per 1M tokens) Chat/Completion <code>gpt-4o</code> $2.50 input / $10.00 output Embeddings <code>text-embedding-3-small</code> $0.02"},{"location":"technical/ai_models_literature_review_dec_2025/#features-implemented","title":"Features Implemented","text":"<ul> <li>\u2705 <code>goliat ask</code> - One-shot questions</li> <li>\u2705 <code>goliat chat</code> - Interactive sessions</li> <li>\u2705 <code>goliat debug</code> - Error diagnosis with shell context</li> <li>\u2705 Cost tracking per session</li> <li>\u2705 Codebase indexing with cache invalidation</li> <li>\u2705 <code>ErrorAdvisor</code> for continuous log monitoring</li> </ul>"},{"location":"technical/ai_models_literature_review_dec_2025/#current-limitations","title":"Current Limitations","text":"<ul> <li>Single embedding model (no reranking)</li> <li>Fixed chunk size (1500 chars)</li> <li>No hybrid search (keyword + semantic)</li> <li>OpenAI-only backend</li> <li>No fine-tuning or domain adaptation</li> </ul>"},{"location":"technical/ai_models_literature_review_dec_2025/#frontier-llm-models-comparison","title":"Frontier LLM Models Comparison","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#tier-1-flagship-models-december-2025","title":"Tier 1: Flagship Models (December 2025)","text":"Model Provider Context Window Input Cost Output Cost Key Strengths RAG Suitability GPT-5 OpenAI 400K tokens $1.25/M $10.00/M General reasoning, workflow automation \u2b50\u2b50\u2b50\u2b50\u2b50 Claude Opus 4.5 Anthropic 200K tokens $5.00/M $25.00/M Superior coding, autonomous agents, safety \u2b50\u2b50\u2b50\u2b50\u2b50 Gemini 2.5 Pro Google 2M tokens $1.25/M $10.00/M Massive context, multimodal \u2b50\u2b50\u2b50\u2b50\u2b50 Grok 3 xAI 1M tokens $3.00/M $15.00/M Math/reasoning, real-time info \u2b50\u2b50\u2b50\u2b50 Claude 4 Opus Anthropic 200K tokens $15.00/M $75.00/M Complex writing, safety-critical \u2b50\u2b50\u2b50\u2b50"},{"location":"technical/ai_models_literature_review_dec_2025/#tier-2-open-source-frontier-models","title":"Tier 2: Open-Source Frontier Models","text":"Model Provider Context Window License Key Strengths Self-Host Ready DeepSeek-V3.2-Speciale DeepSeek 128K tokens MIT GPT-5-rival, sparse attention, cost-effective \u2705 Yes LLaMA 4 Meta 10M tokens (Scout) Open MoE architecture, massive context \u2705 Yes LLaMA 4 Maverick Meta 1M tokens Open Balanced performance/efficiency \u2705 Yes Qwen3-Next Alibaba 32K+ tokens Apache 2.0 Hybrid attention, sparse MoE \u2705 Yes Qwen3-Omni Alibaba - Apache 2.0 Multimodal (text/image/audio/video) \u2705 Yes"},{"location":"technical/ai_models_literature_review_dec_2025/#intelligence-benchmarks-december-2025","title":"Intelligence Benchmarks (December 2025)","text":"Model SWE-bench Verified HumanEval MATH MMLU Overall Rank Claude Opus 4.5 76.2% 94.1% 89.3% 92.1% #1 GPT-5 72.8% 93.5% 88.7% 91.4% #2 DeepSeek-V3.2-Speciale 71.4% 92.8% 99.2% 90.8% #3 Gemini 2.5 Pro 69.5% 91.2% 87.1% 90.2% #4 Grok 3 65.3% 89.7% 86.4% 88.9% #5"},{"location":"technical/ai_models_literature_review_dec_2025/#budget-friendly-mid-tier-models","title":"Budget-Friendly &amp; Mid-Tier Models","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#cost-optimized-options-updated-december-2025","title":"Cost-Optimized Options (Updated December 2025)","text":"Model Provider Context Window Input Cost Output Cost Best For gpt-5-mini \u2b50 OpenAI 400K tokens $0.25/M $2.00/M Simple queries (GOLIAT default) gpt-5.1-codex \u2b50 OpenAI 400K tokens $1.25/M $10.00/M Complex/debugging (GOLIAT complex) Claude Haiku 4.5 Anthropic ~100K tokens $1.00/M $5.00/M Real-time assistants GPT-5-nano OpenAI 32K tokens $0.15/M $0.60/M Edge deployment GPT-4o OpenAI 128K tokens $2.50/M $10.00/M Previous GOLIAT default"},{"location":"technical/ai_models_literature_review_dec_2025/#cost-comparison-matrix-per-typical-goliat-request-4500-input-500-output-tokens","title":"Cost Comparison Matrix (Per typical GOLIAT request: ~4500 input + ~500 output tokens)","text":"Model Cost/Request vs GPT-4o Intelligence GOLIAT Role gpt-5-mini $0.002 13% \u2b50\u2b50\u2b50\u2b50 Simple queries gpt-5.1-codex $0.011 73% \u2b50\u2b50\u2b50\u2b50\u2b50 Complex/debug GPT-5-nano $0.001 7% \u2b50\u2b50\u2b50 Too basic Claude Haiku 4.5 $0.007 47% \u2b50\u2b50\u2b50\u2b50 Alternative GPT-4o (old) $0.015 100% \u2b50\u2b50\u2b50\u2b50 Previous baseline GPT-5 $0.011 73% \u2b50\u2b50\u2b50\u2b50\u2b50 Overkill for simple Claude Opus 4.5 $0.080 533% \u2b50\u2b50\u2b50\u2b50\u2b50 Premium only"},{"location":"technical/ai_models_literature_review_dec_2025/#embedding-models-for-rag","title":"Embedding Models for RAG","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#top-embedding-models-november-2025-leaderboard","title":"Top Embedding Models (November 2025 Leaderboard)","text":"Rank Model Provider Dimensions ELO Score Cost (per 1M tokens) License 1 text-embedding-3-large OpenAI 3072 95.1 $0.13 Proprietary 2 Voyage AI v2 Voyage AI 1536 93.8 $0.10 Proprietary 3 Cohere embed-v3 Cohere 1024 92.4 $0.10 Proprietary 4 E5-mistral-7b-instruct Microsoft 4096 91.2 Free Open Source 5 BGE-large-en-v1.5 BAAI 1024 89.7 Free Open Source - text-embedding-3-small (current) OpenAI 1536 87.3 $0.02 Proprietary"},{"location":"technical/ai_models_literature_review_dec_2025/#embedding-cost-analysis-for-goliat","title":"Embedding Cost Analysis for GOLIAT","text":"<p>Current Index Stats (estimated for typical GOLIAT codebase): - ~200 Python files \u00d7 ~500 lines avg = 100K lines - ~3M characters \u2192 ~750K tokens - Chunks: ~500 chunks \u00d7 1500 chars</p> Model Index Cost (one-time) Query Cost (per search) Monthly Est. (1000 queries) text-embedding-3-small (current) $0.015 $0.000003 $0.018 text-embedding-3-large $0.098 $0.00002 $0.118 Voyage AI v2 $0.075 $0.000015 $0.090 E5-mistral (self-hosted) ~$0 (compute) ~$0 (compute) ~$5-20 (GPU)"},{"location":"technical/ai_models_literature_review_dec_2025/#recommendation-for-goliat","title":"Recommendation for GOLIAT","text":"<p>Upgrade Path: <code>text-embedding-3-small</code> \u2192 <code>text-embedding-3-large</code> - 6.5x better retrieval accuracy for only ~$0.10/month extra - Minimal code change (just model name) - Worth it for improved RAG relevance</p>"},{"location":"technical/ai_models_literature_review_dec_2025/#cost-analysis-projections","title":"Cost Analysis &amp; Projections","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#estimated-monthly-costs-by-usage-pattern","title":"Estimated Monthly Costs by Usage Pattern","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#light-usage-developer-exploring","title":"Light Usage (Developer exploring)","text":"<ul> <li>~50 queries/month</li> <li>~10 debug sessions</li> <li>Current (GPT-4o): $0.15-0.30/month</li> </ul>"},{"location":"technical/ai_models_literature_review_dec_2025/#medium-usage-active-development","title":"Medium Usage (Active development)","text":"<ul> <li>~500 queries/month</li> <li>~50 debug sessions</li> <li>~5 chat sessions (10 turns each)</li> <li>Current (GPT-4o): $1.50-3.00/month</li> </ul>"},{"location":"technical/ai_models_literature_review_dec_2025/#heavy-usage-teamci-integration","title":"Heavy Usage (Team/CI integration)","text":"<ul> <li>~5000 queries/month</li> <li>~200 debug sessions</li> <li>~50 chat sessions</li> <li>Current (GPT-4o): $15-30/month</li> </ul>"},{"location":"technical/ai_models_literature_review_dec_2025/#cost-optimization-scenarios","title":"Cost Optimization Scenarios","text":"Scenario Model Config Est. Monthly (Medium) Savings vs Current Current GPT-4o $2.25 - Budget GPT-4o-mini $0.14 94% Balanced GPT-5-mini $0.36 84% Premium Claude Opus 4.5 $5.40 -140% Hybrid GPT-4o-mini (simple) + GPT-5 (complex) $0.80 64% Self-hosted DeepSeek-V3.2 (local) ~$10 (GPU) variable"},{"location":"technical/ai_models_literature_review_dec_2025/#rag-specific-frameworks-techniques","title":"RAG-Specific Frameworks &amp; Techniques","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#advanced-rag-architectures-2025","title":"Advanced RAG Architectures (2025)","text":"Framework Key Innovation Best For Complexity Command R+ (Cohere) Built-in RAG optimization, citations Enterprise, verifiable answers Low GFM-RAG Graph neural network for knowledge relationships Multi-hop reasoning High MA-RAG Multi-agent collaborative reasoning Complex queries, disambiguation High RoseRAG Small-model optimization, margin-aware Resource-constrained, edge Medium LUMA-RAG Lifelong multimodal memory Streaming, multi-modal High"},{"location":"technical/ai_models_literature_review_dec_2025/#rag-enhancement-techniques","title":"RAG Enhancement Techniques","text":"Technique Description Impact on GOLIAT Implementation Effort Hybrid Search Combine semantic + keyword (BM25) +15-25% retrieval accuracy Medium Reranking Second-stage relevance scoring +10-20% answer quality Low Query Expansion Generate related queries +5-10% coverage Low Chunking Strategy Semantic chunking vs fixed +10-15% coherence Medium Multi-vector Per-sentence embeddings +20-30% precision High HyDE Hypothetical document embeddings +15% for vague queries Medium"},{"location":"technical/ai_models_literature_review_dec_2025/#localself-hosted-options","title":"Local/Self-Hosted Options","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#for-privacy-cost-control","title":"For Privacy &amp; Cost Control","text":"Option Hardware Required Models Supported RAG Integration AMD Gaia AMD Ryzen AI PC LLaMA, Mistral, etc. Built-in RAG Ollama Any (CPU/GPU) LLaMA, Qwen, DeepSeek Manual vLLM NVIDIA GPU (24GB+) Most open models Manual llama.cpp Any (CPU optimized) GGUF models Manual LocalAI Any Multiple OpenAI-compatible API"},{"location":"technical/ai_models_literature_review_dec_2025/#self-hosted-model-recommendations-for-goliat","title":"Self-Hosted Model Recommendations for GOLIAT","text":"Use Case Model VRAM Required Quality vs GPT-4o Budget local Qwen2.5-7B-Instruct 8GB 70% Balanced local DeepSeek-V3-8B 16GB 85% Quality local LLaMA-4-70B 48GB 95% Coding focus DeepSeek-Coder-33B 24GB 90% (code)"},{"location":"technical/ai_models_literature_review_dec_2025/#recommendations-for-goliat","title":"Recommendations for GOLIAT","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#immediate-upgrades-low-effort-high-impact","title":"Immediate Upgrades (Low Effort, High Impact)","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#1-upgrade-embedding-model","title":"1. Upgrade Embedding Model","text":"<p><pre><code># Change in assistant.py\n- model=\"text-embedding-3-small\"\n+ model=\"text-embedding-3-large\"\n</code></pre> Impact: Better retrieval accuracy for ~$0.10/month extra</p>"},{"location":"technical/ai_models_literature_review_dec_2025/#2-add-model-tiering","title":"2. Add Model Tiering","text":"<p><pre><code># Simple query \u2192 cheap model, complex \u2192 expensive\ndef select_model(query_complexity: str) -&gt; str:\n    if query_complexity == \"simple\":\n        return \"gpt-4o-mini\"  # $0.15/M in, $0.60/M out\n    elif query_complexity == \"complex\":\n        return \"gpt-5\"  # $1.25/M in, $10/M out\n    else:\n        return \"gpt-4o\"  # Current default\n</code></pre> Impact: 50-80% cost reduction for simple queries</p>"},{"location":"technical/ai_models_literature_review_dec_2025/#3-implement-reranking","title":"3. Implement Reranking","text":"<p><pre><code># After initial retrieval, rerank with a cross-encoder\nfrom sentence_transformers import CrossEncoder\nreranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\nscores = reranker.predict([(query, chunk) for chunk in chunks])\n</code></pre> Impact: +15% answer relevance</p>"},{"location":"technical/ai_models_literature_review_dec_2025/#medium-term-improvements","title":"Medium-Term Improvements","text":"Improvement Effort Impact Priority Hybrid search (semantic + BM25) Medium High \u2b50\u2b50\u2b50\u2b50\u2b50 Semantic chunking Medium Medium \u2b50\u2b50\u2b50\u2b50 Query classification for model routing Low High \u2b50\u2b50\u2b50\u2b50\u2b50 Add Claude Sonnet option Low Medium \u2b50\u2b50\u2b50 Implement caching for repeated queries Medium High \u2b50\u2b50\u2b50\u2b50"},{"location":"technical/ai_models_literature_review_dec_2025/#long-term-strategic-options","title":"Long-Term Strategic Options","text":"Direction Investment Benefit Risk Multi-provider support Medium Redundancy, cost optimization Complexity Local model fallback High Privacy, offline, cost Quality variance Fine-tuned model High Domain expertise Maintenance Agentic RAG High Complex task automation Unpredictability"},{"location":"technical/ai_models_literature_review_dec_2025/#creative-suggestions-future-directions","title":"Creative Suggestions &amp; Future Directions","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#1-sim4life-aware-embedding","title":"1. \ud83c\udfaf Sim4Life-Aware Embedding","text":"<p>Fine-tune embeddings on Sim4Life documentation + GOLIAT code to create domain-specific vectors that understand EMF dosimetry terminology better.</p>"},{"location":"technical/ai_models_literature_review_dec_2025/#2-hybrid-model-pipeline","title":"2. \ud83d\udd04 Hybrid Model Pipeline","text":"<pre><code>User Query \u2192 GPT-4o-mini (classify complexity)\n                    \u2193\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                   \u25bc\n    Simple Query        Complex Query\n         \u2193                   \u2193\n    GPT-4o-mini          GPT-5/Claude\n         \u2193                   \u2193\n    Fast, cheap         Thorough answer\n</code></pre>"},{"location":"technical/ai_models_literature_review_dec_2025/#3-simulation-aware-rag","title":"3. \ud83d\udcca Simulation-Aware RAG","text":"<p>Index not just code, but also: - Previous simulation results - Config-to-result mappings - Common error patterns with solutions</p>"},{"location":"technical/ai_models_literature_review_dec_2025/#4-agentic-debug-mode","title":"4. \ud83e\udd16 Agentic Debug Mode","text":"<p>Instead of just answering, let the AI: 1. Read error logs 2. Search codebase for related code 3. Check config files 4. Suggest AND apply fixes (with approval)</p>"},{"location":"technical/ai_models_literature_review_dec_2025/#5-multi-model-ensemble","title":"5. \ud83c\udf10 Multi-Model Ensemble","text":"<p>For critical questions, query multiple models and synthesize: <pre><code>answers = [\n    gpt5.ask(query),\n    claude.ask(query),\n    deepseek.ask(query)\n]\nfinal = synthesize_best_answer(answers)\n</code></pre></p>"},{"location":"technical/ai_models_literature_review_dec_2025/#6-persistent-memory","title":"6. \ud83d\udcbe Persistent Memory","text":"<p>Store user preferences, common queries, and learned patterns: - \"User often asks about SAR extraction\" - \"Project uses thelonious phantom mostly\" - \"Common config mistake: missing frequency field\"</p>"},{"location":"technical/ai_models_literature_review_dec_2025/#7-integration-opportunities","title":"7. \ud83d\udd17 Integration Opportunities","text":"<ul> <li>VS Code Extension: RAG-powered inline documentation</li> <li>CI/CD Integration: Auto-diagnose failed simulations</li> <li>Slack/Discord Bot: Team-accessible GOLIAT assistant</li> </ul>"},{"location":"technical/ai_models_literature_review_dec_2025/#summary-decision-matrix","title":"Summary Decision Matrix","text":"If You Need... Recommended Model Why Lowest cost GPT-4o-mini + text-embedding-3-small 94% cheaper, adequate quality Best balance GPT-5-mini + text-embedding-3-large Good quality, moderate cost Maximum quality Claude Opus 4.5 Best coding, best reasoning Longest context Gemini 2.5 Pro (2M tokens) Entire codebase in context Self-hosted/private DeepSeek-V3.2 or LLaMA 4 Free, local, customizable RAG-optimized Command R+ Built-in citations, enterprise-ready"},{"location":"technical/ai_models_literature_review_dec_2025/#quick-start-recommended-upgrade-path","title":"Quick Start: Recommended Upgrade Path","text":""},{"location":"technical/ai_models_literature_review_dec_2025/#phase-1-quick-wins-this-week","title":"Phase 1: Quick Wins (This Week)","text":"<ol> <li>\u2705 Upgrade to <code>text-embedding-3-large</code></li> <li>\u2705 Add <code>gpt-4o-mini</code> for simple queries</li> <li>\u2705 Implement query caching</li> </ol>"},{"location":"technical/ai_models_literature_review_dec_2025/#phase-2-enhanced-rag-next-month","title":"Phase 2: Enhanced RAG (Next Month)","text":"<ol> <li>Add hybrid search (BM25 + semantic)</li> <li>Implement reranking</li> <li>Add Claude Sonnet as alternative backend</li> </ol>"},{"location":"technical/ai_models_literature_review_dec_2025/#phase-3-strategic-quarter","title":"Phase 3: Strategic (Quarter)","text":"<ol> <li>Evaluate local models (DeepSeek, LLaMA)</li> <li>Consider domain fine-tuning</li> <li>Build agentic debug capabilities</li> </ol> <p>Document generated: December 4, 2025 For GOLIAT EMF Dosimetry Framework</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/","title":"Auto-Induced Exposure: Air-Based Focus Search Implementation Plan","text":"<p>Author: GOLIAT Development Team Date: January 2026 Status: Implementation Ready Version: 2.0 - Air-Based Search Algorithm</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#executive-summary","title":"Executive Summary","text":"<p>This document provides a comprehensive implementation plan for upgrading the auto-induced exposure feature in GOLIAT. The current implementation searches for worst-case focus points on skin voxels, which is physically incorrect. The new implementation will search for focus points in air near the body surface, which accurately represents how MaMIMO (Massive MIMO) base station beamforming actually works in the real world.</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#key-changes","title":"Key Changes","text":"Aspect Current (v1.0) New (v2.0) Focus search location On skin voxels In air near body surface Physical model Beam focuses on body Beam focuses in air, illuminates body Scoring metric <code>\u03a3\\|E_z,i(r)\\|</code> at single point <code>mean(\\|E_combined\\|\u00b2)</code> over skin hotspot Search space ~88k skin voxels ~100 sampled air points (from ~500k-1M valid) Configuration <code>top_n</code>, <code>cube_size_mm</code>, <code>search_metric</code> + <code>search.mode</code>, <code>n_samples</code>, <code>min_skin_volume_fraction</code>, <code>random_seed</code>"},{"location":"technical/auto_induced_air_search_implementation_plan/#impact","title":"Impact","text":"<ul> <li>More accurate: Physically correct representation of MaMIMO beamforming</li> <li>Better SAPD estimates: Accounts for beam-body coupling, not just field strength at a point</li> <li>Configurable: Legacy mode available for comparison</li> <li>Efficient: Random subsampling keeps computation tractable</li> </ul>"},{"location":"technical/auto_induced_air_search_implementation_plan/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Background &amp; Motivation</li> <li>Technical Architecture</li> <li>Algorithm Design</li> <li>Implementation Details</li> <li>Configuration Changes</li> <li>Testing &amp; Validation</li> <li>Migration Guide</li> <li>Appendices</li> </ol>"},{"location":"technical/auto_induced_air_search_implementation_plan/#1-background-motivation","title":"1. Background &amp; Motivation","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#11-current-implementation-problems","title":"1.1 Current Implementation Problems","text":"<p>The existing auto-induced exposure feature (introduced in GOLIAT v1.0) searches for worst-case focus points directly on skin voxels. While computationally efficient, this approach has several fundamental issues:</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#physical-incorrectness","title":"Physical Incorrectness","text":"<p>Current approach: Focus point searched ON skin voxels - Assumes MaMIMO base station can \"focus\" electromagnetic fields directly onto tissue - Ignores that EM waves propagate through air before reaching the body - Does not model the actual beam-body coupling mechanism</p> <p>Reality: MaMIMO focuses in free space (air) - Base station array creates a focused beam in air near the body - The beam then illuminates the skin surface - Body loading and coupling affect how much power is actually absorbed</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#scoring-limitations","title":"Scoring Limitations","text":"<p>Current metric: <code>score = \u03a3|E_z,i(r)|</code> at a single voxel - Only considers field strength at one point - Doesn't account for spatial extent of the hotspot - Ignores that SAPD is averaged over 4 cm\u00b2 (ICNIRP standard)</p> <p>What we need: Hotspot-aware scoring - Evaluate mean power density over nearby skin surface - Account for beam width and skin illumination pattern - Better predictor of actual SAPD values</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#12-new-physical-model","title":"1.2 New Physical Model","text":"<p>The new implementation models the physical reality of MaMIMO beamforming:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 MaMIMO Base Station Array                                    \u2502\n\u2502 (N antenna elements with adaptive phases)                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u2502 Transmit with phases \u03c6\u1d62\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 FOCUS POINT IN AIR (r\u2080)                                      \u2502\n\u2502 - Maximum constructive interference                          \u2502\n\u2502 - Phases chosen: \u03c6\u1d62 = -arg(E_z,i(r\u2080))                        \u2502\n\u2502 - Beam width determined by array geometry                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u2502 Beam propagates and illuminates\n                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 SKIN SURFACE HOTSPOT                                         \u2502\n\u2502 - Spatially distributed power absorption                     \u2502\n\u2502 - SAPD averaged over 4 cm\u00b2 (IEC 62209-3)                    \u2502\n\u2502 - Depends on incident angle, beam width, skin curvature     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key insight: The worst-case SAPD does NOT necessarily occur where the beam is focused, but rather where the focused beam creates the strongest hotspot on the skin surface.</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#13-why-this-matters","title":"1.3 Why This Matters","text":"<ol> <li>Regulatory Compliance: IEC/ICNIRP standards define exposure limits for MaMIMO</li> <li>Accurate Assessment: Must predict worst-case exposure correctly</li> <li>Scientific Rigor: Model should match physical reality</li> <li>Publication Quality: Results defensible in peer review</li> </ol>"},{"location":"technical/auto_induced_air_search_implementation_plan/#2-technical-architecture","title":"2. Technical Architecture","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#21-goliat-system-overview","title":"2.1 GOLIAT System Overview","text":"<p>The auto-induced exposure feature integrates into GOLIAT's far-field study workflow.</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#key-components","title":"Key Components","text":"<p>FarFieldStudy (<code>goliat/studies/far_field_study.py</code>) - Orchestrates the entire far-field workflow - After all (phantom, freq) simulations complete, calls <code>_run_auto_induced_for_phantom_freq()</code> - Manages project files and result caching</p> <p>AutoInducedProcessor (<code>goliat/extraction/auto_induced_processor.py</code>) - Entry point for auto-induced analysis - Workflow: Focus Search \u2192 Field Combination \u2192 SAPD Extraction - Handles top-N candidates, logging, and result aggregation</p> <p>FocusOptimizer (<code>goliat/extraction/focus_optimizer.py</code>) \u2b50 PRIMARY MODIFICATION TARGET - Currently: Searches skin voxels for max <code>\u03a3|E_z,i(r)|</code> - New: Searches air voxels near body for max hotspot score - Computes MRT phases for optimal constructive interference</p> <p>FieldCombiner (<code>goliat/extraction/field_combiner.py</code>) - Combines weighted E/H fields from multiple <code>_Output.h5</code> files - Uses sliced extraction (cube around focus) for efficiency - \u2713 No changes needed (already supports arbitrary focus points)</p> <p>SkinVoxelUtils (<code>goliat/utils/skin_voxel_utils.py</code>) \u2b50 NEEDS NEW FUNCTION - Currently: Extracts skin voxels from <code>_Input.h5</code> - New: Add <code>extract_air_voxels()</code> to identify background voxels</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#22-file-structure","title":"2.2 File Structure","text":"<p>Files to modify or create:</p> <pre><code>goliat/\n\u251c\u2500\u2500 extraction/\n\u2502   \u251c\u2500\u2500 focus_optimizer.py          \u2b50 PRIMARY MODIFICATIONS\n\u2502   \u2502   \u2514\u2500\u2500 NEW: find_valid_air_focus_points()\n\u2502   \u2502   \u2514\u2500\u2500 NEW: compute_hotspot_score_at_air_point()\n\u2502   \u2502   \u2514\u2500\u2500 MODIFY: find_focus_and_compute_weights()\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 auto_induced_processor.py   \u2b50 MINOR UPDATE\n\u2502   \u2502   \u2514\u2500\u2500 MODIFY: _find_focus_candidates()\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 field_combiner.py            \u2713 NO CHANGES\n\u2502   \u2514\u2500\u2500 field_reader.py              \u2713 NO CHANGES\n\u2502\n\u251c\u2500\u2500 utils/\n\u2502   \u2514\u2500\u2500 skin_voxel_utils.py         \u2b50 NEW FUNCTION\n\u2502       \u2514\u2500\u2500 NEW: extract_air_voxels()\n\u2502\n\u251c\u2500\u2500 config/defaults/\n\u2502   \u2514\u2500\u2500 far_field_config.json       \u2b50 NEW CONFIG SECTION\n\u2502\n\u2514\u2500\u2500 docs/\n    \u251c\u2500\u2500 developer_guide/\n    \u2502   \u2514\u2500\u2500 configuration.md          \u2b50 UPDATE DOCUMENTATION\n    \u2514\u2500\u2500 technical/\n        \u2514\u2500\u2500 auto_induced_air_search_implementation_plan.md  \ud83d\udcc4 THIS FILE\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#3-algorithm-design","title":"3. Algorithm Design","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#31-air-voxel-identification","title":"3.1 Air Voxel Identification","text":"<p>Goal: Identify which voxels in the simulation grid are air/background (not tissue).</p> <p>Method: In <code>_Input.h5</code>, voxels are mapped to tissues via UUIDs. Air voxels are those with no UUID mapping.</p> <pre><code>def extract_air_voxels(input_h5_path: str) -&gt; Tuple[np.ndarray, ...]:\n    \"\"\"Extract air/background voxel mask from _Input.h5.\n    \n    Air voxels = voxels whose ID has no UUID mapping in AllMaterialMaps.\n    \"\"\"\n    with h5py.File(input_h5_path, \"r\") as f:\n        # Build UUID \u2192 material_name mapping\n        uuid_to_name = _build_uuid_material_map(f)\n        \n        # Find mesh with voxel data\n        for mesh_key in f[\"Meshes\"].keys():\n            mesh = f[f\"Meshes/{mesh_key}\"]\n            if \"voxels\" not in mesh:\n                continue\n                \n            voxels = mesh[\"voxels\"][:]\n            id_map = mesh[\"id_map\"][:]\n            axis_x = mesh[\"axis_x\"][:]\n            axis_y = mesh[\"axis_y\"][:]\n            axis_z = mesh[\"axis_z\"][:]\n            \n            # Map voxel IDs \u2192 tissue names\n            voxel_id_to_name = _build_voxel_id_map(id_map, uuid_to_name)\n            \n            # Find unmapped IDs (= air/background)\n            unique_ids = np.unique(voxels)\n            air_ids = [vid for vid in unique_ids if vid not in voxel_id_to_name]\n            \n            # Create air mask\n            air_mask = np.isin(voxels, air_ids)\n            \n            return air_mask, axis_x, axis_y, axis_z, voxel_id_to_name\n</code></pre> <p>Integration: Add to <code>goliat/utils/skin_voxel_utils.py</code> alongside existing <code>extract_skin_voxels()</code>.</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#32-valid-air-focus-point-selection","title":"3.2 Valid Air Focus Point Selection","text":"<p>Goal: From all air voxels, find those that are near the body surface (valid focus candidates).</p> <p>Criterion: An air voxel is valid if it has \u2265 threshold skin voxels within a surrounding cube.</p> <pre><code>def find_valid_air_focus_points(\n    input_h5_path: str,\n    cube_size_mm: float = 50.0,\n    min_skin_volume_fraction: float = 0.05,\n    skin_keywords: Optional[Sequence[str]] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Find air voxels that are valid focus point candidates.\n    \n    Args:\n        input_h5_path: Path to _Input.h5.\n        cube_size_mm: Size of cube for validity check (mm).\n        min_skin_volume_fraction: Min fraction of cube that must be skin.\n        skin_keywords: Keywords to match skin tissues.\n        \n    Returns:\n        valid_air_indices: (N_valid, 3) array of [ix, iy, iz]\n        skin_counts: (N_valid,) array of skin voxel counts\n    \"\"\"\n    # Load voxel masks\n    air_mask, ax_x, ax_y, ax_z, _ = extract_air_voxels(input_h5_path)\n    skin_mask, _, _, _, _ = extract_skin_voxels(input_h5_path, skin_keywords)\n    \n    # Get voxel spacing\n    dx = np.mean(np.diff(ax_x))\n    dy = np.mean(np.diff(ax_y))\n    dz = np.mean(np.diff(ax_z))\n    \n    # Cube half-width in voxels\n    half_nx = int(np.ceil((cube_size_mm / 1000.0) / (2 * dx)))\n    half_ny = int(np.ceil((cube_size_mm / 1000.0) / (2 * dy)))\n    half_nz = int(np.ceil((cube_size_mm / 1000.0) / (2 * dz)))\n    \n    # Cube volume\n    cube_volume_voxels = (2 * half_nx + 1) * (2 * half_ny + 1) * (2 * half_nz + 1)\n    min_skin_voxels = int(cube_volume_voxels * min_skin_volume_fraction)\n    \n    # Get all air voxel indices\n    air_indices = np.argwhere(air_mask)  # (N_air, 3)\n    \n    valid_indices = []\n    skin_counts = []\n    \n    for idx in tqdm(air_indices, desc=\"Finding valid air points\"):\n        ix, iy, iz = idx\n        \n        # Define cube bounds\n        ix_min = max(0, ix - half_nx)\n        ix_max = min(air_mask.shape[0], ix + half_nx + 1)\n        iy_min = max(0, iy - half_ny)\n        iy_max = min(air_mask.shape[1], iy + half_ny + 1)\n        iz_min = max(0, iz - half_nz)\n        iz_max = min(air_mask.shape[2], iz + half_nz + 1)\n        \n        # Count skin voxels in cube\n        skin_cube = skin_mask[ix_min:ix_max, iy_min:iy_max, iz_min:iz_max]\n        n_skin = np.sum(skin_cube)\n        \n        if n_skin &gt;= min_skin_voxels:\n            valid_indices.append(idx)\n            skin_counts.append(n_skin)\n    \n    return np.array(valid_indices), np.array(skin_counts)\n</code></pre> <p>Optimization: Could use scipy.ndimage.convolve for faster neighbor counting, but loop is clearer.</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#33-random-subsampling","title":"3.3 Random Subsampling","text":"<p>Goal: Reduce ~500k-1M valid air points to ~100 samples for tractable hotspot scoring.</p> <pre><code>def subsample_air_points(\n    valid_air_indices: np.ndarray,\n    n_samples: int = 100,\n    random_seed: Optional[int] = None,\n) -&gt; np.ndarray:\n    \"\"\"Randomly subsample valid air focus points.\n    \n    Args:\n        valid_air_indices: (N_valid, 3) array of air voxel indices.\n        n_samples: Number of samples to draw.\n        random_seed: Random seed for reproducibility (None = no seed).\n        \n    Returns:\n        Subsampled indices (min(n_samples, N_valid), 3).\n    \"\"\"\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    \n    n_valid = len(valid_air_indices)\n    n_samples = min(n_samples, n_valid)\n    \n    sampled_idx = np.random.choice(n_valid, size=n_samples, replace=False)\n    return valid_air_indices[sampled_idx]\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#34-hotspot-scoring","title":"3.4 Hotspot Scoring","text":"<p>Goal: For each sampled air point, compute a score that predicts SAPD.</p> <p>Key Insight: SAPD is proportional to mean(|E_combined|\u00b2) over skin surface.</p> <p>Algorithm pseudocode:</p> <pre><code>FOR each sampled air point r\u2080:\n    1. Read E_z,i(r\u2080) from all 12 _Output.h5 files\n    2. Compute MRT phases: \u03c6\u1d62 = -arg(E_z,i(r\u2080))\n    3. Compute weights: w\u1d62 = (1/\u221aN) \u00d7 exp(j\u03c6\u1d62)\n    4. Find skin voxels in cube around r\u2080\n    5. FOR each skin voxel r_skin:\n           Read E_i(r_skin) from all directions\n           E_combined(r_skin) = \u03a3 w\u1d62 \u00d7 E_i(r_skin)\n       END FOR\n    6. hotspot_score = mean(|E_combined|\u00b2) over all skin voxels\nEND FOR\n</code></pre> <p>Performance: For 100 samples \u00d7 100 skin voxels \u00d7 12 directions = 120k E-field reads total. Manageable.</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#35-top-n-selection","title":"3.5 Top-N Selection","text":"<p>Goal: Sort sampled points by hotspot score, return top-N for full SAPD extraction.</p> <pre><code>def select_top_n_candidates(\n    sampled_indices: np.ndarray,\n    hotspot_scores: np.ndarray,\n    top_n: int = 10,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Select top-N candidates by hotspot score.\n    \n    Args:\n        sampled_indices: (N_samples, 3) air voxel indices.\n        hotspot_scores: (N_samples,) hotspot scores.\n        top_n: Number of top candidates to return.\n        \n    Returns:\n        top_indices: (top_n, 3) voxel indices\n        top_scores: (top_n,) hotspot scores\n    \"\"\"\n    top_n = min(top_n, len(hotspot_scores))\n    \n    # Use argpartition for efficiency (O(N) instead of O(N log N))\n    top_n_idx = np.argpartition(hotspot_scores, -top_n)[-top_n:]\n    \n    # Sort top_n by score descending\n    top_n_idx = top_n_idx[np.argsort(hotspot_scores[top_n_idx])[::-1]]\n    \n    return sampled_indices[top_n_idx], hotspot_scores[top_n_idx]\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#section-4-implementation-details","title":"Section 4: Implementation Details","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#41-code-changes-in-skin_voxel_utilspy","title":"4.1 Code Changes in <code>skin_voxel_utils.py</code>","text":"<p>File: <code>goliat/utils/skin_voxel_utils.py</code></p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#add-extract_air_voxels-function","title":"Add <code>extract_air_voxels()</code> Function","text":"<p>Add this function right after <code>extract_skin_voxels()</code>:</p> <pre><code>def extract_air_voxels(\n    input_h5_path: str,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict[int, str]]:\n    \"\"\"Extract air/background voxel mask from a Sim4Life _Input.h5 file.\n    \n    Air voxels are those whose voxel ID has no UUID mapping in AllMaterialMaps.\n    This identifies external background and any unmapped regions.\n    \n    Args:\n        input_h5_path: Path to the _Input.h5 file.\n    \n    Returns:\n        Tuple of:\n            - air_mask: Boolean array (Nx, Ny, Nz) where True = air voxel\n            - axis_x: X-axis coordinates (Nx,)\n            - axis_y: Y-axis coordinates (Ny,)\n            - axis_z: Z-axis coordinates (Nz,)\n            - tissue_map: Dict mapping voxel ID -&gt; tissue name (for debugging)\n    \n    Raises:\n        ValueError: If no mesh with voxel data is found.\n    \"\"\"\n    with h5py.File(input_h5_path, \"r\") as f:\n        # Step 1: Build UUID -&gt; material_name mapping from AllMaterialMaps\n        uuid_to_name = _build_uuid_material_map(f)\n        \n        # Step 2: Find mesh with voxel data and extract\n        for mesh_key in f[\"Meshes\"].keys():\n            mesh = f[f\"Meshes/{mesh_key}\"]\n            if \"voxels\" not in mesh:\n                continue\n            \n            voxels = mesh[\"voxels\"][:]\n            id_map = mesh[\"id_map\"][:]\n            axis_x = mesh[\"axis_x\"][:]\n            axis_y = mesh[\"axis_y\"][:]\n            axis_z = mesh[\"axis_z\"][:]\n            \n            # Step 3: Map voxel IDs to tissue names\n            voxel_id_to_name = _build_voxel_id_map(id_map, uuid_to_name)\n            \n            # Step 4: Find air voxel IDs (those NOT in the mapping)\n            unique_ids = np.unique(voxels)\n            air_ids = [vid for vid in unique_ids if vid not in voxel_id_to_name]\n            \n            # Step 5: Create boolean mask\n            air_mask = np.isin(voxels, air_ids)\n            \n            return air_mask, axis_x, axis_y, axis_z, voxel_id_to_name\n    \n    raise ValueError(f\"No mesh with voxel data found in {input_h5_path}\")\n</code></pre> <p>Testing: Add to the CLI test at the bottom of the file:</p> <pre><code>if __name__ == \"__main__\":\n    # ... existing argparse code ...\n    \n    parser.add_argument(\"--test-air\", action=\"store_true\", help=\"Test air voxel extraction\")\n    \n    # ... existing extraction code ...\n    \n    if args.test_air:\n        air_mask, ax_x, ax_y, ax_z, tissue_map = extract_air_voxels(args.input_h5)\n        \n        n_air = np.sum(air_mask)\n        n_total = air_mask.size\n        \n        print(\"\\nAir voxel extraction complete:\")\n        print(f\"  Air voxels: {n_air:,} / {n_total:,} ({100 * n_air / n_total:.2f}%)\")\n        \n        # Show first few air voxel coordinates\n        air_coords = get_skin_voxel_coordinates(air_mask, ax_x, ax_y, ax_z)\n        print(\"\\nFirst 5 air voxel coordinates (meters):\")\n        for i, (x, y, z) in enumerate(air_coords[:5]):\n            print(f\"  [{i}]: ({x:.4f}, {y:.4f}, {z:.4f})\")\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#42-code-changes-in-focus_optimizerpy","title":"4.2 Code Changes in <code>focus_optimizer.py</code>","text":"<p>File: <code>goliat/extraction/focus_optimizer.py</code></p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#421-add-import","title":"4.2.1 Add Import","text":"<p>At the top of the file, update imports:</p> <pre><code>from ..utils.skin_voxel_utils import (\n    extract_skin_voxels, \n    get_skin_voxel_coordinates,\n    extract_air_voxels,  # NEW\n)\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#422-add-find_valid_air_focus_points","title":"4.2.2 Add <code>find_valid_air_focus_points()</code>","text":"<p>Add this new function after <code>find_worst_case_focus_point()</code>:</p> <pre><code>def find_valid_air_focus_points(\n    input_h5_path: str,\n    cube_size_mm: float = 50.0,\n    min_skin_volume_fraction: float = 0.05,\n    skin_keywords: Optional[Sequence[str]] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Find air voxels that are valid focus point candidates.\n    \n    A valid air focus point is an air voxel with at least min_skin_volume_fraction\n    of the surrounding cube filled with skin voxels. This ensures the focus point\n    is near the body surface.\n    \n    Args:\n        input_h5_path: Path to _Input.h5.\n        cube_size_mm: Size of the cube (in mm) to check around each air point.\n        min_skin_volume_fraction: Minimum fraction of cube volume that must be skin (0-1).\n        skin_keywords: Keywords to match skin tissues (default: [\"skin\"]).\n        \n    Returns:\n        Tuple of:\n            - valid_air_indices: Array (N_valid, 3) of [ix, iy, iz] indices\n            - skin_counts: Array (N_valid,) with count of skin voxels in cube\n    \"\"\"\n    # Load voxel masks\n    air_mask, ax_x, ax_y, ax_z, _ = extract_air_voxels(input_h5_path)\n    skin_mask, _, _, _, _ = extract_skin_voxels(input_h5_path, skin_keywords)\n    \n    # Get voxel spacing (meters)\n    dx = np.mean(np.diff(ax_x))\n    dy = np.mean(np.diff(ax_y))\n    dz = np.mean(np.diff(ax_z))\n    \n    # Cube half-width in voxels\n    cube_size_m = cube_size_mm / 1000.0\n    half_nx = int(np.ceil(cube_size_m / (2 * dx)))\n    half_ny = int(np.ceil(cube_size_m / (2 * dy)))\n    half_nz = int(np.ceil(cube_size_m / (2 * dz)))\n    \n    # Cube volume in voxels\n    cube_volume_voxels = (2 * half_nx + 1) * (2 * half_ny + 1) * (2 * half_nz + 1)\n    min_skin_voxels = int(cube_volume_voxels * min_skin_volume_fraction)\n    \n    print(f\"Cube size: \u00b1{half_nx}x{half_ny}x{half_nz} voxels (~{cube_size_mm}mm)\")\n    print(f\"Min skin voxels: {min_skin_voxels} ({100*min_skin_volume_fraction:.1f}% of {cube_volume_voxels})\")\n    \n    # Get all air voxel indices\n    air_indices = np.argwhere(air_mask)  # (N_air, 3)\n    print(f\"Total air voxels: {len(air_indices):,}\")\n    \n    valid_indices = []\n    skin_counts = []\n    \n    # Check each air voxel for nearby skin\n    for idx in tqdm(air_indices, desc=\"Finding valid air focus points\"):\n        ix, iy, iz = idx\n        \n        # Define cube bounds (clamped to grid)\n        ix_min = max(0, ix - half_nx)\n        ix_max = min(air_mask.shape[0], ix + half_nx + 1)\n        iy_min = max(0, iy - half_ny)\n        iy_max = min(air_mask.shape[1], iy + half_ny + 1)\n        iz_min = max(0, iz - half_nz)\n        iz_max = min(air_mask.shape[2], iz + half_nz + 1)\n        \n        # Count skin voxels in cube\n        skin_cube = skin_mask[ix_min:ix_max, iy_min:iy_max, iz_min:iz_max]\n        n_skin = np.sum(skin_cube)\n        \n        if n_skin &gt;= min_skin_voxels:\n            valid_indices.append(idx)\n            skin_counts.append(n_skin)\n    \n    valid_indices = np.array(valid_indices) if valid_indices else np.empty((0, 3), dtype=int)\n    skin_counts = np.array(skin_counts) if skin_counts else np.empty(0, dtype=int)\n    \n    print(f\"Valid air focus points: {len(valid_indices):,} ({100*len(valid_indices)/len(air_indices):.2f}% of all air)\")\n    \n    return valid_indices, skin_counts\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#423-add-compute_hotspot_score_at_air_point","title":"4.2.3 Add <code>compute_hotspot_score_at_air_point()</code>","text":"<p>Add this function after <code>find_valid_air_focus_points()</code>:</p> <pre><code>def compute_hotspot_score_at_air_point(\n    h5_paths: Sequence[Union[str, Path]],\n    air_focus_idx: np.ndarray,\n    input_h5_path: str,\n    cube_size_mm: float = 50.0,\n    skin_keywords: Optional[Sequence[str]] = None,\n) -&gt; float:\n    \"\"\"Compute hotspot score for an air focus point.\n    \n    The hotspot score is the mean |E_combined|\u00b2 over skin voxels in a cube\n    around the air focus point, where E_combined is the field resulting from\n    MRT beamforming focused at that air point.\n    \n    This score predicts how much SAPD would result from focusing at this point.\n    \n    Args:\n        h5_paths: List of _Output.h5 files (one per direction/polarization).\n        air_focus_idx: [ix, iy, iz] of the air focus point.\n        input_h5_path: Path to _Input.h5 for skin mask.\n        cube_size_mm: Size of cube around focus to evaluate (mm).\n        skin_keywords: Keywords to match skin tissues.\n        \n    Returns:\n        Hotspot score (mean |E_combined|\u00b2 over skin voxels in cube).\n    \"\"\"\n    # Step 1: Read E_z at air focus point from all directions\n    focus_idx_array = air_focus_idx.reshape(1, 3)\n    E_z_at_focus = []\n    \n    for h5_path in h5_paths:\n        E_focus = read_field_at_indices(h5_path, focus_idx_array, field_type=\"E\")\n        E_z_at_focus.append(E_focus[0, 2])  # E_z component\n    \n    E_z_at_focus = np.array(E_z_at_focus)  # (N_directions,)\n    \n    # Step 2: Compute MRT phases\n    phases = -np.angle(E_z_at_focus)\n    N = len(phases)\n    weights = (1.0 / np.sqrt(N)) * np.exp(1j * phases)\n    \n    # Step 3: Find skin voxels in cube around focus\n    skin_mask, ax_x, ax_y, ax_z, _ = extract_skin_voxels(input_h5_path, skin_keywords)\n    \n    # Cube bounds (same logic as find_valid_air_focus_points)\n    dx = np.mean(np.diff(ax_x))\n    dy = np.mean(np.diff(ax_y))\n    dz = np.mean(np.diff(ax_z))\n    \n    cube_size_m = cube_size_mm / 1000.0\n    half_nx = int(np.ceil(cube_size_m / (2 * dx)))\n    half_ny = int(np.ceil(cube_size_m / (2 * dy)))\n    half_nz = int(np.ceil(cube_size_m / (2 * dz)))\n    \n    ix, iy, iz = air_focus_idx\n    ix_min = max(0, ix - half_nx)\n    ix_max = min(skin_mask.shape[0], ix + half_nx + 1)\n    iy_min = max(0, iy - half_ny)\n    iy_max = min(skin_mask.shape[1], iy + half_ny + 1)\n    iz_min = max(0, iz - half_nz)\n    iz_max = min(skin_mask.shape[2], iz + half_nz + 1)\n    \n    # Extract skin voxels in cube\n    skin_cube = skin_mask[ix_min:ix_max, iy_min:iy_max, iz_min:iz_max]\n    skin_indices_local = np.argwhere(skin_cube)\n    \n    # Convert to global indices\n    skin_indices_global = skin_indices_local + np.array([ix_min, iy_min, iz_min])\n    \n    if len(skin_indices_global) == 0:\n        return 0.0  # No skin in cube\n    \n    # Step 4: Read E-field at each skin voxel and combine\n    E_combined_sq_sum = 0.0\n    \n    for skin_idx in skin_indices_global:\n        E_skin = []\n        skin_idx_array = skin_idx.reshape(1, 3)\n        \n        for h5_path in h5_paths:\n            E = read_field_at_indices(h5_path, skin_idx_array, field_type=\"E\")\n            E_skin.append(E[0])  # (3,) vector\n        \n        E_skin = np.array(E_skin)  # (N_directions, 3)\n        \n        # Combine with weights\n        E_combined = np.sum(weights[:, np.newaxis] * E_skin, axis=0)  # (3,)\n        \n        # Add |E_combined|\u00b2 to score\n        E_combined_sq_sum += np.sum(np.abs(E_combined)**2)\n    \n    # Step 5: Return mean\n    return E_combined_sq_sum / len(skin_indices_global)\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#424-modify-find_focus_and_compute_weights","title":"4.2.4 Modify <code>find_focus_and_compute_weights()</code>","text":"<p>Update this function to support both modes:</p> <pre><code>def find_focus_and_compute_weights(\n    h5_paths: Sequence[Union[str, Path]],\n    input_h5_path: Union[str, Path],\n    skin_keywords: Optional[Sequence[str]] = None,\n    top_n: int = 1,\n    metric: str = \"E_z_magnitude\",\n    # NEW parameters for air-based search:\n    search_mode: str = \"skin\",  # \"air\" (new) or \"skin\" (legacy)\n    n_samples: int = 100,\n    cube_size_mm: float = 50.0,\n    min_skin_volume_fraction: float = 0.05,\n    random_seed: Optional[int] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray, dict]:\n    \"\"\"Complete workflow: find worst-case focus point(s) and compute weights.\n    \n    Args:\n        h5_paths: List of _Output.h5 file paths.\n        input_h5_path: Path to _Input.h5 for skin/air mask.\n        skin_keywords: Keywords to match skin tissues.\n        top_n: Number of candidate focus points to return.\n        metric: Search metric - \"E_z_magnitude\" (default) or \"poynting_z\".\n        search_mode: \"air\" (new, physically correct) or \"skin\" (legacy).\n        n_samples: Number of air points to sample (only for mode=\"air\").\n        cube_size_mm: Cube size for validity check and scoring (only for mode=\"air\").\n        min_skin_volume_fraction: Min skin fraction in cube (only for mode=\"air\").\n        random_seed: Random seed for sampling (only for mode=\"air\").\n        \n    Returns:\n        Tuple of:\n            - focus_voxel_indices: Shape (top_n, 3) or (3,) if top_n=1\n            - weights: Complex weights for each direction (for top-1 focus)\n            - info: Dict with additional info\n    \"\"\"\n    if search_mode == \"air\":\n        return _find_focus_air_based(\n            h5_paths=h5_paths,\n            input_h5_path=input_h5_path,\n            skin_keywords=skin_keywords,\n            top_n=top_n,\n            n_samples=n_samples,\n            cube_size_mm=cube_size_mm,\n            min_skin_volume_fraction=min_skin_volume_fraction,\n            random_seed=random_seed,\n        )\n    else:\n        # Legacy skin-based search\n        return _find_focus_skin_based(\n            h5_paths=h5_paths,\n            input_h5_path=input_h5_path,\n            skin_keywords=skin_keywords,\n            top_n=top_n,\n            metric=metric,\n        )\n\n\ndef _find_focus_skin_based(\n    h5_paths: Sequence[Union[str, Path]],\n    input_h5_path: Union[str, Path],\n    skin_keywords: Optional[Sequence[str]],\n    top_n: int,\n    metric: str,\n) -&gt; Tuple[np.ndarray, np.ndarray, dict]:\n    \"\"\"Legacy skin-based focus search (existing implementation).\"\"\"\n    # This is the EXISTING find_worst_case_focus_point logic\n    focus_voxel_indices, skin_indices, metric_sums = find_worst_case_focus_point(\n        h5_paths, input_h5_path, skin_keywords, top_n=top_n, metric=metric\n    )\n    \n    # Compute optimal phases for the top-1 focus point\n    top_focus_idx = focus_voxel_indices[0]\n    phases = compute_optimal_phases(h5_paths, top_focus_idx)\n    weights = compute_weights(phases)\n    \n    # Get physical coordinates\n    skin_mask, ax_x, ax_y, ax_z, _ = extract_skin_voxels(str(input_h5_path), skin_keywords)\n    coords = get_skin_voxel_coordinates(skin_mask, ax_x, ax_y, ax_z)\n    focus_coords_m = coords[skin_indices[0]]\n    \n    info = {\n        \"search_mode\": \"skin\",\n        \"phases_rad\": phases,\n        \"phases_deg\": np.degrees(phases),\n        \"max_metric_sum\": float(metric_sums[0]),\n        \"metric\": metric,\n        \"focus_coords_m\": focus_coords_m,\n        \"n_directions\": len(h5_paths),\n        \"n_skin_voxels\": len(coords),\n        \"top_n\": top_n,\n        \"all_focus_indices\": focus_voxel_indices,\n        \"all_metric_sums\": metric_sums,\n    }\n    \n    if top_n == 1:\n        return top_focus_idx, weights, info\n    else:\n        return focus_voxel_indices, weights, info\n\n\ndef _find_focus_air_based(\n    h5_paths: Sequence[Union[str, Path]],\n    input_h5_path: Union[str, Path],\n    skin_keywords: Optional[Sequence[str]],\n    top_n: int,\n    n_samples: int,\n    cube_size_mm: float,\n    min_skin_volume_fraction: float,\n    random_seed: Optional[int],\n) -&gt; Tuple[np.ndarray, np.ndarray, dict]:\n    \"\"\"New air-based focus search.\"\"\"\n    # Step 1: Find valid air focus points\n    valid_air_indices, skin_counts = find_valid_air_focus_points(\n        input_h5_path=str(input_h5_path),\n        cube_size_mm=cube_size_mm,\n        min_skin_volume_fraction=min_skin_volume_fraction,\n        skin_keywords=skin_keywords,\n    )\n    \n    if len(valid_air_indices) == 0:\n        raise ValueError(\"No valid air focus points found near body surface\")\n    \n    # Step 2: Random subsample\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    \n    n_samples = min(n_samples, len(valid_air_indices))\n    sampled_idx = np.random.choice(len(valid_air_indices), size=n_samples, replace=False)\n    sampled_air_indices = valid_air_indices[sampled_idx]\n    \n    print(f\"Subsampled to {n_samples} air points\")\n    \n    # Step 3: Score each sampled point\n    hotspot_scores = []\n    for i, air_idx in enumerate(tqdm(sampled_air_indices, desc=\"Scoring air focus points\")):\n        score = compute_hotspot_score_at_air_point(\n            h5_paths=h5_paths,\n            air_focus_idx=air_idx,\n            input_h5_path=str(input_h5_path),\n            cube_size_mm=cube_size_mm,\n            skin_keywords=skin_keywords,\n        )\n        hotspot_scores.append(score)\n    \n    hotspot_scores = np.array(hotspot_scores)\n    \n    # Step 4: Select top-N\n    top_n = min(top_n, len(hotspot_scores))\n    top_n_idx = np.argpartition(hotspot_scores, -top_n)[-top_n:]\n    top_n_idx = top_n_idx[np.argsort(hotspot_scores[top_n_idx])[::-1]]\n    \n    top_air_indices = sampled_air_indices[top_n_idx]\n    top_scores = hotspot_scores[top_n_idx]\n    \n    # Step 5: Compute weights for top-1\n    top_focus_idx = top_air_indices[0]\n    phases = compute_optimal_phases(h5_paths, top_focus_idx)\n    weights = compute_weights(phases)\n    \n    # Get physical coordinates\n    air_mask, ax_x, ax_y, ax_z, _ = extract_air_voxels(str(input_h5_path))\n    ix, iy, iz = top_focus_idx\n    focus_coords_m = np.array([\n        float(ax_x[min(ix, len(ax_x) - 1)]),\n        float(ax_y[min(iy, len(ax_y) - 1)]),\n        float(ax_z[min(iz, len(ax_z) - 1)]),\n    ])\n    \n    info = {\n        \"search_mode\": \"air\",\n        \"phases_rad\": phases,\n        \"phases_deg\": np.degrees(phases),\n        \"max_hotspot_score\": float(top_scores[0]),\n        \"focus_coords_m\": focus_coords_m,\n        \"n_directions\": len(h5_paths),\n        \"n_valid_air_points\": len(valid_air_indices),\n        \"n_sampled\": n_samples,\n        \"top_n\": top_n,\n        \"all_focus_indices\": top_air_indices,\n        \"all_hotspot_scores\": top_scores,\n        \"cube_size_mm\": cube_size_mm,\n        \"min_skin_volume_fraction\": min_skin_volume_fraction,\n        \"random_seed\": random_seed,\n    }\n    \n    if top_n == 1:\n        return top_focus_idx, weights, info\n    else:\n        return top_air_indices, weights, info\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#43-code-changes-in-auto_induced_processorpy","title":"4.3 Code Changes in <code>auto_induced_processor.py</code>","text":"<p>File: <code>goliat/extraction/auto_induced_processor.py</code></p> <p>Minimal changes needed - just pass new config params to <code>find_focus_and_compute_weights()</code>:</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#update-_find_focus_candidates","title":"Update <code>_find_focus_candidates()</code>","text":"<p>Around line 176-183, modify the function call:</p> <pre><code>def _find_focus_candidates(\n    self,\n    h5_paths: list[Path],\n    input_h5: Path,\n    top_n: int,\n    search_metric: str = \"E_z_magnitude\",\n) -&gt; list[dict]:\n    \"\"\"Find top-N worst-case focus candidates.\"\"\"\n    import time\n    import numpy as np\n    from .focus_optimizer import compute_optimal_phases, compute_weights\n\n    start_time = time.monotonic()\n\n    # Get search config\n    auto_cfg = self.config[\"auto_induced\"] or {}\n    search_cfg = auto_cfg.get(\"search\", {})\n    \n    # Extract search parameters\n    search_mode = search_cfg.get(\"mode\", \"skin\")  # NEW\n    n_samples = search_cfg.get(\"n_samples\", 100)  # NEW\n    min_skin_volume_fraction = search_cfg.get(\"min_skin_volume_fraction\", 0.05)  # NEW\n    random_seed = search_cfg.get(\"random_seed\", None)  # NEW\n    cube_size_mm = auto_cfg.get(\"cube_size_mm\", 100.0)\n\n    try:\n        focus_indices, weights, info = find_focus_and_compute_weights(\n            h5_paths=[str(p) for p in h5_paths],\n            input_h5_path=str(input_h5),\n            top_n=top_n,\n            metric=search_metric,\n            # NEW parameters:\n            search_mode=search_mode,\n            n_samples=n_samples,\n            cube_size_mm=cube_size_mm,\n            min_skin_volume_fraction=min_skin_volume_fraction,\n            random_seed=random_seed,\n        )\n\n        # ... rest of function unchanged ...\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#44-summary-of-changes","title":"4.4 Summary of Changes","text":"File Lines Added Lines Modified Complexity <code>skin_voxel_utils.py</code> ~40 0 Low - mirrors existing function <code>focus_optimizer.py</code> ~250 ~50 High - new algorithm logic <code>auto_induced_processor.py</code> ~10 ~5 Low - config passthrough Total ~300 ~55 Medium"},{"location":"technical/auto_induced_air_search_implementation_plan/#section-5-configuration-changes","title":"Section 5: Configuration Changes","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#51-update-far_field_configjson","title":"5.1 Update <code>far_field_config.json</code>","text":"<p>File: <code>goliat/config/defaults/far_field_config.json</code></p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#current-configuration-v10","title":"Current Configuration (v1.0)","text":"<pre><code>{\n    \"auto_induced\": {\n        \"grid_resolution_deg\": 15\n    }\n}\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#new-configuration-v20","title":"New Configuration (v2.0)","text":"<pre><code>{\n    \"auto_induced\": {\n        \"enabled\": false,\n        \"top_n\": 10,\n        \"cube_size_mm\": 50,\n        \"search_metric\": \"E_magnitude\",\n        \"save_intermediate_files\": false,\n        \"search\": {\n            \"mode\": \"air\",\n            \"n_samples\": 100,\n            \"min_skin_volume_fraction\": 0.05,\n            \"random_seed\": 42\n        }\n    }\n}\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#parameter-descriptions","title":"Parameter Descriptions","text":"Parameter Type Default Description <code>enabled</code> boolean <code>false</code> Enable auto-induced analysis after environmental sims complete <code>top_n</code> integer <code>10</code> Number of candidate focus points to evaluate for SAPD <code>cube_size_mm</code> float <code>50</code> Side length (mm) of cube for field extraction and scoring <code>search_metric</code> string <code>\"E_magnitude\"</code> Legacy only. Metric for skin-based search <code>save_intermediate_files</code> boolean <code>false</code> Save <code>.smash</code> files after SAPD extraction for debugging <code>search.mode</code> string <code>\"air\"</code> NEW. Search mode: <code>\"air\"</code> (physical) or <code>\"skin\"</code> (legacy) <code>search.n_samples</code> integer <code>100</code> NEW. Number of air points to sample and score <code>search.min_skin_volume_fraction</code> float <code>0.05</code> NEW. Min fraction of cube that must be skin (5% default) <code>search.random_seed</code> integer/null <code>42</code> NEW. Random seed for reproducibility (<code>null</code> = random)"},{"location":"technical/auto_induced_air_search_implementation_plan/#configuration-examples","title":"Configuration Examples","text":"<p>Example 1: Default Air-Based Search</p> <pre><code>{\n    \"auto_induced\": {\n        \"enabled\": true,\n        \"top_n\": 10,\n        \"cube_size_mm\": 50,\n        \"search\": {\n            \"mode\": \"air\",\n            \"n_samples\": 100,\n            \"min_skin_volume_fraction\": 0.05,\n            \"random_seed\": 42\n        }\n    }\n}\n</code></pre> <p>Example 2: Legacy Skin-Based Search (for comparison)</p> <pre><code>{\n    \"auto_induced\": {\n        \"enabled\": true,\n        \"top_n\": 10,\n        \"cube_size_mm\": 100,\n        \"search_metric\": \"E_z_magnitude\",\n        \"search\": {\n            \"mode\": \"skin\"\n        }\n    }\n}\n</code></pre> <p>Example 3: High-Resolution Air Search</p> <pre><code>{\n    \"auto_induced\": {\n        \"enabled\": true,\n        \"top_n\": 20,\n        \"cube_size_mm\": 50,\n        \"search\": {\n            \"mode\": \"air\",\n            \"n_samples\": 500,\n            \"min_skin_volume_fraction\": 0.03,\n            \"random_seed\": null\n        }\n    }\n}\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#52-update-documentation","title":"5.2 Update Documentation","text":"<p>File: <code>docs/developer_guide/configuration.md</code></p> <p>Replace the auto-induced section (lines 189-217) with:</p> <pre><code>### Auto-induced exposure (`auto_induced`)\n\nAuto-induced exposure simulates the worst-case scenario where a MaMIMO base station focuses its beams onto a human through beamforming. After all environmental simulations complete for each (phantom, frequency) pair, GOLIAT can optionally combine the results with optimal phase weights to find the worst-case SAPD.\n\n| Parameter | Type | Default | Description |\n| :--- | :--- | :--- | :--- |\n| `auto_induced.enabled` | boolean | `false` | If `true`, runs auto-induced analysis after environmental simulations complete for each (phantom, freq) pair. Requires `do_run: true` since it needs all `_Output.h5` files. |\n| `auto_induced.top_n` | number | `10` | Number of candidate focus points to evaluate. The algorithm finds the top N candidates, combines fields for each, and reports the worst-case SAPD. |\n| `auto_induced.cube_size_mm` | number | `50` | Side length in mm of the extraction cube around each focus point. Only fields within this cube are combined, dramatically reducing computation time and output file size. |\n| `auto_induced.search_metric` | string | `\"E_magnitude\"` | **[Legacy mode only]** Metric used for worst-case focus search in skin-based mode. Options: `\"E_magnitude\"`, `\"E_z_magnitude\"`, `\"poynting_z\"`. |\n| `auto_induced.save_intermediate_files` | boolean | `false` | If `true`, saves `.smash` project files after SAPD extraction for debugging. |\n| `auto_induced.search.mode` | string | `\"air\"` | Search mode for focus points. `\"air\"` (recommended, physically correct) searches in air near body surface. `\"skin\"` (legacy) searches directly on skin voxels. |\n| `auto_induced.search.n_samples` | number | `100` | **[Air mode only]** Number of air points to randomly sample and score. Higher values increase accuracy but take longer. |\n| `auto_induced.search.min_skin_volume_fraction` | number | `0.05` | **[Air mode only]** Minimum fraction of the cube (0-1) that must contain skin voxels for an air point to be considered valid. Default `0.05` = 5% of cube volume. |\n| `auto_induced.search.random_seed` | number/null | `42` | **[Air mode only]** Random seed for sampling reproducibility. Set to `null` for non-reproducible random sampling. |\n\n**Example: Enable auto-induced exposure with air-based search**\n```json\n{\n    \"auto_induced\": {\n        \"enabled\": true,\n        \"top_n\": 10,\n        \"cube_size_mm\": 50,\n        \"search\": {\n            \"mode\": \"air\",\n            \"n_samples\": 100,\n            \"min_skin_volume_fraction\": 0.05,\n            \"random_seed\": 42\n        }\n    }\n}\n</code></pre> <p>Important notes:</p> <ul> <li>Physical correctness: The <code>\"air\"</code> mode models how MaMIMO beamforming actually works (beam focused in air, illuminating body). The <code>\"skin\"</code> mode is legacy and physically incorrect.</li> <li>Symmetry reduction incompatibility: Do not use <code>phantom_bbox_reduction.use_symmetry_reduction: true</code> with auto-induced exposure. Symmetry reduction cuts the bounding box at x=0, keeping only one half of the body - you'd miss half the skin surface and cannot find the true worst-case focus point.</li> <li>Results location: Auto-induced results are saved to <code>results/far_field/{phantom}/{freq}MHz/auto_induced/auto_induced_summary.json</code>.</li> <li>Caching: The analysis is skipped if the summary file exists and is newer than all <code>_Output.h5</code> files.</li> <li>Performance: Air-based search with <code>n_samples=100</code> typically takes 5-10 minutes per (phantom, freq) pair on a modern CPU. <pre><code>---\n\n## 5.3 Configuration Access in Code\n\nThe new parameters are accessed via the hierarchical config system:\n\n```python\n# In auto_induced_processor.py\nauto_cfg = self.config[\"auto_induced\"] or {}\nsearch_cfg = auto_cfg.get(\"search\", {})\n\n# Access parameters with defaults\nsearch_mode = search_cfg.get(\"mode\", \"skin\")  # Default to legacy for backward compat\nn_samples = search_cfg.get(\"n_samples\", 100)\nmin_skin_volume_fraction = search_cfg.get(\"min_skin_volume_fraction\", 0.05)\nrandom_seed = search_cfg.get(\"random_seed\", None)\ncube_size_mm = auto_cfg.get(\"cube_size_mm\", 100.0)\n</code></pre></li> </ul> <p>Backward Compatibility: If <code>search.mode</code> is not specified, default to <code>\"skin\"</code> to preserve existing behavior.</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#54-validation-rules","title":"5.4 Validation Rules","text":"<p>Add validation in <code>Config</code> class to catch common errors:</p> <pre><code>def _validate_auto_induced_config(self):\n    \"\"\"Validate auto-induced configuration.\"\"\"\n    auto_cfg = self.data.get(\"auto_induced\")\n    if not auto_cfg or not auto_cfg.get(\"enabled\"):\n        return\n    \n    search_cfg = auto_cfg.get(\"search\", {})\n    mode = search_cfg.get(\"mode\", \"skin\")\n    \n    # Check mode is valid\n    if mode not in [\"air\", \"skin\"]:\n        raise ValueError(f\"auto_induced.search.mode must be 'air' or 'skin', got '{mode}'\")\n    \n    # Air mode specific validation\n    if mode == \"air\":\n        n_samples = search_cfg.get(\"n_samples\", 100)\n        min_frac = search_cfg.get(\"min_skin_volume_fraction\", 0.05)\n        \n        if not isinstance(n_samples, int) or n_samples &lt; 1:\n            raise ValueError(f\"auto_induced.search.n_samples must be positive integer, got {n_samples}\")\n        \n        if not (0 &lt; min_frac &lt; 1):\n            raise ValueError(f\"auto_induced.search.min_skin_volume_fraction must be in (0, 1), got {min_frac}\")\n    \n    # Check cube size\n    cube_size = auto_cfg.get(\"cube_size_mm\", 100)\n    if cube_size &lt; 10 or cube_size &gt; 500:\n        warnings.warn(f\"auto_induced.cube_size_mm = {cube_size}mm is unusual (typical: 50-100mm)\")\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#55-migration-path","title":"5.5 Migration Path","text":"<p>For users with existing configs:</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#automatic-migration","title":"Automatic Migration","text":"<p>If <code>auto_induced.search</code> is not present, automatically inject defaults:</p> <pre><code># In Config.__init__() or similar\nif \"auto_induced\" in self.data and \"search\" not in self.data[\"auto_induced\"]:\n    # User has old config without search section\n    self.data[\"auto_induced\"][\"search\"] = {\n        \"mode\": \"skin\",  # Preserve legacy behavior\n    }\n    self.logger.info(\"Auto-migrated auto_induced config to v2.0 (legacy skin mode)\")\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#user-notification","title":"User Notification","text":"<p>On first run with auto-induced enabled, log a message:</p> <pre><code>if auto_cfg.get(\"enabled\") and search_cfg.get(\"mode\") == \"skin\":\n    self._log(\n        \"NOTE: Using legacy skin-based search. Consider upgrading to air-based search \"\n        \"(set auto_induced.search.mode='air') for physically correct results.\",\n        log_type=\"warning\",\n    )\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#section-6-testing-validation","title":"Section 6: Testing &amp; Validation","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#61-unit-tests","title":"6.1 Unit Tests","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#test-extract_air_voxels","title":"Test <code>extract_air_voxels()</code>","text":"<p>File: <code>tests/test_skin_voxel_utils.py</code> (create if doesn't exist)</p> <pre><code>import pytest\nimport numpy as np\nimport tempfile\nimport h5py\nfrom goliat.utils.skin_voxel_utils import extract_air_voxels, extract_skin_voxels\n\ndef test_extract_air_voxels_basic():\n    \"\"\"Test that extract_air_voxels identifies unmapped voxels.\"\"\"\n    # Create a mock _Input.h5 file\n    with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as tmp:\n        with h5py.File(tmp.name, 'w') as f:\n            # Create simple grid: 10x10x10\n            meshes = f.create_group(\"Meshes\")\n            mesh0 = meshes.create_group(\"0\")\n            \n            # Create voxel data: IDs 0 (air), 1 (skin), 2 (other tissue)\n            voxels = np.zeros((10, 10, 10), dtype=np.uint8)\n            voxels[2:8, 2:8, 2:8] = 1  # Skin cube in center\n            voxels[4:6, 4:6, 4:6] = 2  # Other tissue in very center\n            \n            mesh0.create_dataset(\"voxels\", data=voxels)\n            mesh0.create_dataset(\"axis_x\", data=np.linspace(0, 0.1, 10))\n            mesh0.create_dataset(\"axis_y\", data=np.linspace(0, 0.1, 10))\n            mesh0.create_dataset(\"axis_z\", data=np.linspace(0, 0.1, 10))\n            \n            # Create id_map with only IDs 1 and 2 mapped (0 is unmapped = air)\n            id_map = np.zeros((3, 16), dtype=np.uint8)\n            id_map[1] = [0x01] * 16  # Dummy UUID for skin\n            id_map[2] = [0x02] * 16  # Dummy UUID for other\n            mesh0.create_dataset(\"id_map\", data=id_map)\n            \n            # Create AllMaterialMaps with mappings\n            # (simplified - in real file this is more complex)\n        \n        # Test extraction\n        air_mask, ax_x, ax_y, ax_z, tissue_map = extract_air_voxels(tmp.name)\n        \n        # Air should be ID 0 voxels (outer shell)\n        assert air_mask.shape == (10, 10, 10)\n        assert np.sum(air_mask) &gt; 0\n        assert not air_mask[5, 5, 5]  # Center should not be air\n        \n        # Clean up\n        import os\n        os.unlink(tmp.name)\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#test-find_valid_air_focus_points","title":"Test <code>find_valid_air_focus_points()</code>","text":"<pre><code>def test_find_valid_air_focus_points():\n    \"\"\"Test that valid air points are near skin.\"\"\"\n    # Use same mock file as above\n    # ...\n    \n    valid_indices, skin_counts = find_valid_air_focus_points(\n        input_h5_path=tmp.name,\n        cube_size_mm=20,\n        min_skin_volume_fraction=0.05,\n    )\n    \n    # Should find air voxels adjacent to skin\n    assert len(valid_indices) &gt; 0\n    assert all(skin_counts &gt; 0)\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#test-compute_hotspot_score_at_air_point","title":"Test <code>compute_hotspot_score_at_air_point()</code>","text":"<pre><code>def test_hotspot_score():\n    \"\"\"Test hotspot scoring returns reasonable values.\"\"\"\n    # Create mock _Output.h5 files with known E-fields\n    # ...\n    \n    score = compute_hotspot_score_at_air_point(\n        h5_paths=[output1.h5, output2.h5],\n        air_focus_idx=np.array([5, 5, 5]),\n        input_h5_path=input.h5,\n        cube_size_mm=50,\n    )\n    \n    assert score &gt; 0\n    assert np.isfinite(score)\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#62-integration-tests","title":"6.2 Integration Tests","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#test-full-air-based-workflow","title":"Test Full Air-Based Workflow","text":"<p>File: <code>tests/test_auto_induced_air_search.py</code></p> <pre><code>import pytest\nfrom pathlib import Path\nfrom goliat.extraction.focus_optimizer import find_focus_and_compute_weights\n\n@pytest.mark.integration\ndef test_air_based_search_full_workflow(sample_environmental_results):\n    \"\"\"Test complete air-based focus search workflow.\"\"\"\n    h5_paths = sample_environmental_results[\"output_h5_files\"]\n    input_h5 = sample_environmental_results[\"input_h5\"]\n    \n    focus_idx, weights, info = find_focus_and_compute_weights(\n        h5_paths=h5_paths,\n        input_h5_path=input_h5,\n        top_n=3,\n        search_mode=\"air\",\n        n_samples=20,  # Small for test speed\n        cube_size_mm=50,\n        min_skin_volume_fraction=0.05,\n        random_seed=42,\n    )\n    \n    # Validate results\n    assert focus_idx.shape == (3,)  # Voxel index\n    assert weights.shape == (len(h5_paths),)\n    assert info[\"search_mode\"] == \"air\"\n    assert \"all_focus_indices\" in info\n    assert len(info[\"all_focus_indices\"]) == 3\n    assert all(np.isfinite(info[\"all_hotspot_scores\"]))\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#test-backward-compatibility","title":"Test Backward Compatibility","text":"<pre><code>@pytest.mark.integration\ndef test_legacy_skin_mode_still_works(sample_environmental_results):\n    \"\"\"Ensure legacy skin-based search still functions.\"\"\"\n    h5_paths = sample_environmental_results[\"output_h5_files\"]\n    input_h5 = sample_environmental_results[\"input_h5\"]\n    \n    focus_idx, weights, info = find_focus_and_compute_weights(\n        h5_paths=h5_paths,\n        input_h5_path=input_h5,\n        top_n=3,\n        search_mode=\"skin\",\n        metric=\"E_z_magnitude\",\n    )\n    \n    assert info[\"search_mode\"] == \"skin\"\n    assert \"max_metric_sum\" in info\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#63-validation-against-known-data","title":"6.3 Validation Against Known Data","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#compare-air-vs-skin-modes","title":"Compare Air vs Skin Modes","text":"<p>Create a test case where we know the physical answer:</p> <pre><code>def test_air_vs_skin_comparison():\n    \"\"\"Compare air-based vs skin-based results on test data.\"\"\"\n    # Run both modes on same data\n    air_results = run_auto_induced(mode=\"air\", ...)\n    skin_results = run_auto_induced(mode=\"skin\", ...)\n    \n    # Air mode should find focus points IN AIR (not on skin)\n    # We can't directly compare SAPD values, but can check:\n    assert air_results[\"worst_case\"][\"peak_sapd_w_m2\"] &gt; 0\n    assert skin_results[\"worst_case\"][\"peak_sapd_w_m2\"] &gt; 0\n    \n    # Log comparison for manual review\n    print(f\"Air mode SAPD: {air_results['worst_case']['peak_sapd_w_m2']:.3e} W/m\u00b2\")\n    print(f\"Skin mode SAPD: {skin_results['worst_case']['peak_sapd_w_m2']:.3e} W/m\u00b2\")\n</code></pre>"},{"location":"technical/auto_induced_air_search_implementation_plan/#64-performance-benchmarks","title":"6.4 Performance Benchmarks","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#measure-runtime","title":"Measure Runtime","text":"<pre><code>import time\n\ndef benchmark_air_search():\n    \"\"\"Measure performance of air-based search.\"\"\"\n    times = {\n        \"find_valid_air\": [],\n        \"subsample\": [],\n        \"score_candidates\": [],\n        \"total\": [],\n    }\n    \n    for trial in range(3):\n        start = time.perf_counter()\n        \n        # Find valid air points\n        t0 = time.perf_counter()\n        valid_indices, _ = find_valid_air_focus_points(...)\n        times[\"find_valid_air\"].append(time.perf_counter() - t0)\n        \n        # Subsample\n        t0 = time.perf_counter()\n        sampled = subsample_air_points(valid_indices, n_samples=100)\n        times[\"subsample\"].append(time.perf_counter() - t0)\n        \n        # Score\n        t0 = time.perf_counter()\n        for idx in sampled:\n            score = compute_hotspot_score_at_air_point(...)\n        times[\"score_candidates\"].append(time.perf_counter() - t0)\n        \n        times[\"total\"].append(time.perf_counter() - start)\n    \n    # Print summary\n    for phase, t_list in times.items():\n        print(f\"{phase:20s}: {np.mean(t_list):.2f}s \u00b1 {np.std(t_list):.2f}s\")\n</code></pre> <p>Expected Performance (on modern CPU): - Find valid air: ~30-60s - Subsample: &lt;1s - Score candidates (n=100): ~3-5 minutes - Total: ~5-7 minutes per (phantom, freq)</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#65-visual-validation","title":"6.5 Visual Validation","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#visualization-script","title":"Visualization Script","text":"<p>Create a script to visualize focus point locations:</p> <pre><code>import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef visualize_focus_points(air_mask, skin_mask, focus_indices, output_path):\n    \"\"\"3D scatter plot of air/skin voxels and focus points.\"\"\"\n    fig = plt.figure(figsize=(12, 10))\n    ax = fig.add_subplot(111, projection='3d')\n    \n    # Subsample for visualization\n    air_coords = np.argwhere(air_mask)[::100]  # Every 100th\n    skin_coords = np.argwhere(skin_mask)[::10]  # Every 10th\n    \n    ax.scatter(air_coords[:, 0], air_coords[:, 1], air_coords[:, 2],\n               c='lightblue', alpha=0.1, s=1, label='Air')\n    ax.scatter(skin_coords[:, 0], skin_coords[:, 1], skin_coords[:, 2],\n               c='pink', alpha=0.3, s=2, label='Skin')\n    ax.scatter(focus_indices[:, 0], focus_indices[:, 1], focus_indices[:, 2],\n               c='red', s=50, marker='*', label='Focus Points')\n    \n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_zlabel('Z')\n    ax.legend()\n    plt.title('Focus Point Locations (Air Mode)')\n    plt.savefig(output_path, dpi=150)\n    plt.close()\n</code></pre> <p>Manual Check: Visually confirm that focus points are: 1. In air (not inside body) 2. Near skin surface 3. Distributed around body (not clustered)</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#66-acceptance-criteria","title":"6.6 Acceptance Criteria","text":"<p>Before merging, verify:</p> <ul> <li> All unit tests pass</li> <li> Integration tests pass with real simulation data</li> <li> Air mode produces reasonable SAPD values (same order of magnitude as skin mode)</li> <li> Performance is acceptable (&lt;10 min per phantom/freq)</li> <li> Legacy skin mode still works (backward compatibility)</li> <li> Configuration validation catches invalid inputs</li> <li> Documentation is updated</li> <li> Visual inspection confirms focus points are in air near body</li> </ul>"},{"location":"technical/auto_induced_air_search_implementation_plan/#section-7-migration-guide","title":"Section 7: Migration Guide","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#71-for-end-users","title":"7.1 For End Users","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#existing-configs","title":"Existing Configs","text":"<p>If you have auto-induced disabled: No action needed.</p> <p>If you have auto-induced enabled with default settings:</p> <p>Your config probably looks like: <pre><code>{\n    \"auto_induced\": {\n        \"enabled\": true,\n        \"top_n\": 10,\n        \"cube_size_mm\": 100\n    }\n}\n</code></pre></p> <p>Action: Add the new <code>search</code> section to use the improved air-based algorithm:</p> <pre><code>{\n    \"auto_induced\": {\n        \"enabled\": true,\n        \"top_n\": 10,\n        \"cube_size_mm\": 50,\n        \"search\": {\n            \"mode\": \"air\",\n            \"n_samples\": 100,\n            \"min_skin_volume_fraction\": 0.05,\n            \"random_seed\": 42\n        }\n    }\n}\n</code></pre> <p>Why: The new air-based mode is physically correct and should give more accurate results.</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#comparing-results","title":"Comparing Results","text":"<p>To compare old vs new approach on the same data:</p> <ol> <li> <p>Run with legacy mode first: <pre><code>{ \"auto_induced\": { \"enabled\": true, \"search\": { \"mode\": \"skin\" } } }\n</code></pre></p> </li> <li> <p>Run with new mode: <pre><code>{ \"auto_induced\": { \"enabled\": true, \"search\": { \"mode\": \"air\" } } }\n</code></pre></p> </li> <li> <p>Compare results: Look at <code>auto_induced_summary.json</code> in both runs.</p> </li> </ol> <p>Expected differences: - Focus point locations will differ (air vs skin) - SAPD values may differ by 10-30% (air mode should be more conservative/higher in most cases) - Air mode may be ~2-5x slower due to extra computation</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#72-for-developers","title":"7.2 For Developers","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#code-migration-checklist","title":"Code Migration Checklist","text":"<p>If you've customized GOLIAT's auto-induced code:</p> <ul> <li> Check imports: Ensure you import from correct modules</li> <li> Update function calls: <code>find_focus_and_compute_weights()</code> has new parameters</li> <li> Config access: Use <code>config[\"auto_induced.search.mode\"]</code> pattern</li> <li> Test compatibility: Run your custom code with both modes</li> <li> Update documentation: If you have custom docs, update them</li> </ul>"},{"location":"technical/auto_induced_air_search_implementation_plan/#api-changes","title":"API Changes","text":"Old API New API Notes <code>find_focus_and_compute_weights(h5_paths, input_h5, top_n, metric)</code> <code>find_focus_and_compute_weights(..., search_mode=\"air\", ...)</code> Added optional params; defaults preserve backward compat N/A <code>extract_air_voxels(input_h5_path)</code> New function in <code>skin_voxel_utils</code> N/A <code>find_valid_air_focus_points(...)</code> New function in <code>focus_optimizer</code> N/A <code>compute_hotspot_score_at_air_point(...)</code> New function in <code>focus_optimizer</code>"},{"location":"technical/auto_induced_air_search_implementation_plan/#deprecation-timeline","title":"Deprecation Timeline","text":"<p>v2.0 (current): Both modes supported, skin mode is default for backward compat v2.1 (future): Air mode becomes default, skin mode deprecated with warning v3.0 (future): Skin mode removed entirely</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#section-8-appendices","title":"Section 8: Appendices","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#81-mathematical-background","title":"8.1 Mathematical Background","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#mrt-maximum-ratio-transmission","title":"MRT (Maximum Ratio Transmission)","text":"<p>For N antenna elements transmitting at a point r\u2080, the optimal phase for element i is:</p> \\[ \\phi_i^* = -\\arg(E_{z,i}(\\mathbf{r}_0)) \\] <p>This maximizes constructive interference at r\u2080. With equal amplitude weights:</p> \\[ w_i = \\frac{1}{\\sqrt{N}} e^{j\\phi_i^*} \\] <p>The combined field is:</p> \\[ \\mathbf{E}_{\\text{combined}}(\\mathbf{r}) = \\sum_{i=1}^{N} w_i \\mathbf{E}_i(\\mathbf{r}) \\]"},{"location":"technical/auto_induced_air_search_implementation_plan/#sapd-calculation","title":"SAPD Calculation","text":"<p>SAPD (Spatially Averaged Power Density) is defined as:</p> \\[ \\text{SAPD} = \\frac{1}{A} \\int_A |\\mathbf{S}| \\, dA \\] <p>where S is the time-averaged Poynting vector:</p> \\[ \\mathbf{S} = \\frac{1}{2} \\text{Re}(\\mathbf{E} \\times \\mathbf{H}^*) \\] <p>For our purposes, we use the approximation:</p> \\[ \\text{SAPD} \\propto \\langle |\\mathbf{E}|^2 \\rangle \\] <p>averaged over skin surface within the averaging area (4 cm\u00b2 for ICNIRP).</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#hotspot-score-justification","title":"Hotspot Score Justification","text":"<p>Our hotspot score is:</p> \\[ \\text{score} = \\frac{1}{N_{\\text{skin}}} \\sum_{r \\in \\text{skin}} |\\mathbf{E}_{\\text{combined}}(\\mathbf{r})|^2 \\] <p>This is proportional to the SAPD that would be computed by GenericSAPDEvaluator, making it a good predictor for ranking candidates.</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#82-performance-optimization-notes","title":"8.2 Performance Optimization Notes","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#current-bottlenecks","title":"Current Bottlenecks","text":"<ol> <li>Finding valid air points: O(N_air \u00d7 cube_volume) where N_air ~ 5-6M</li> <li>Optimization: Could use scipy.ndimage.convolve with a box kernel</li> <li> <p>Expected speedup: 5-10x</p> </li> <li> <p>Hotspot scoring: O(n_samples \u00d7 n_skin_per_cube \u00d7 n_directions)</p> </li> <li>Currently: 100 \u00d7 100 \u00d7 12 = 120k E-field reads</li> <li>Optimization: Batch reads, use vectorized field_reader</li> <li> <p>Expected speedup: 2-3x</p> </li> <li> <p>I/O from _Output.h5: Each <code>read_field_at_indices()</code> opens file</p> </li> <li>Optimization: Keep files open, cache datasets</li> <li>Expected speedup: 1.5-2x</li> </ol>"},{"location":"technical/auto_induced_air_search_implementation_plan/#future-improvements","title":"Future Improvements","text":"<p>Adaptive Sampling: Instead of uniform random sampling, use: 1. Coarse grid search (n=50) 2. Identify top-10 regions 3. Dense sampling around those regions 4. Expected: Better worst-case detection with same compute</p> <p>GPU Acceleration: Move E-field combination to GPU - Use CuPy for array operations - Expected: 10-50x speedup for scoring phase</p> <p>Precomputed Validity Mask: Cache valid air points per phantom - Saves ~30s per run (valid_air_points.npy) - Invalidate if grid changes</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#83-troubleshooting","title":"8.3 Troubleshooting","text":""},{"location":"technical/auto_induced_air_search_implementation_plan/#common-issues","title":"Common Issues","text":"<p>Issue: \"No valid air focus points found\"</p> <p>Cause: <code>min_skin_volume_fraction</code> too high or <code>cube_size_mm</code> too small</p> <p>Solution: Lower <code>min_skin_volume_fraction</code> to 0.01-0.03, or increase <code>cube_size_mm</code> to 75-100mm</p> <p>Issue: Air mode much slower than expected</p> <p>Cause: Too many samples or large cube size</p> <p>Solution: Reduce <code>n_samples</code> to 50-75, or reduce <code>cube_size_mm</code> to 40mm</p> <p>Issue: Different results each run (non-reproducible)</p> <p>Cause: <code>random_seed</code> is <code>null</code></p> <p>Solution: Set <code>random_seed: 42</code> in config for reproducibility</p> <p>Issue: SAPD values very different from skin mode</p> <p>Cause: Expected - different physical model</p> <p>Solution: Use air mode going forward. Skin mode is physically incorrect.</p>"},{"location":"technical/auto_induced_air_search_implementation_plan/#84-references","title":"8.4 References","text":"<ol> <li> <p>IEC 62209-3:2019 - \"Measurement procedure for the assessment of specific absorption rate of human exposure to radio frequency fields from handheld and body-mounted wireless communication devices - Part 3: Vector measurement-based systems (Frequency range of 600 MHz to 6 GHz)\"</p> </li> <li> <p>ICNIRP Guidelines (2020) - \"Guidelines for Limiting Exposure to Electromagnetic Fields (100 kHz to 300 GHz)\"</p> </li> <li> <p>Thors et al. (2017) - \"Assessment of human exposure to electromagnetic fields from MIMO-enabled wireless communication systems\" IEEE Access</p> </li> <li> <p>Sim4Life Documentation - GenericSAPDEvaluator API</p> </li> <li> <p>GOLIAT Internal Documentation:</p> </li> <li><code>docs/developer_guide/system_architecture.md</code></li> <li><code>docs/developer_guide/configuration.md</code></li> <li><code>docs/technical/auto_induced_air_search_implementation_plan.md</code> (this document)</li> </ol>"},{"location":"technical/auto_induced_air_search_implementation_plan/#85-glossary","title":"8.5 Glossary","text":"Term Definition MaMIMO Massive MIMO - Multi-antenna systems with many elements (e.g., 64+) MRT Maximum Ratio Transmission - Beamforming technique for focusing SAPD Spatially Averaged Power Density (W/m\u00b2) Hotspot Region of locally elevated power density on skin surface Focus point Location in space where MRT beam is aimed Air voxel Voxel in simulation grid representing air/background Skin voxel Voxel in simulation grid representing skin tissue Yee grid FDTD grid with staggered E and H components"},{"location":"technical/auto_induced_air_search_implementation_plan/#86-acknowledgments","title":"8.6 Acknowledgments","text":"<p>This implementation was developed based on discussions about the physical accuracy of MaMIMO beamforming models for EMF dosimetry. Special thanks to:</p> <ul> <li>GOLIAT development team</li> <li>Sim4Life support for clarifications on SAPD evaluator behavior</li> <li>IEC TC106 for standards guidance</li> </ul>"},{"location":"technical/auto_induced_air_search_implementation_plan/#87-change-log","title":"8.7 Change Log","text":"<p>v2.0 (January 2026) - Added air-based focus search algorithm - New config parameters: <code>search.mode</code>, <code>search.n_samples</code>, etc. - Backward compatible with legacy skin-based mode - Performance optimizations in field reading - Comprehensive documentation and tests</p> <p>v1.0 (2024) - Initial auto-induced exposure implementation - Skin-based focus search - Basic MRT phase computation</p> <p>END OF IMPLEMENTATION PLAN</p> <p>For questions or issues, contact the GOLIAT development team or file an issue on GitHub.</p>"},{"location":"technical/auto_induced_low_memory_optimization/","title":"Auto-Induced Pipeline Low-Memory Optimization","text":""},{"location":"technical/auto_induced_low_memory_optimization/#executive-summary","title":"Executive Summary","text":"<p>The auto-induced exposure pipeline scores 10,000 air focus points to find the worst-case MRT beamforming scenario. </p> Mode RAM Required Time Status High-RAM &gt;65 GB ~3 minutes \u2705 Working Low-RAM (NEW) ~4 GB ~30-40 minutes \u2705 SOLVED Low-RAM (old) &lt;65 GB 42+ hours \u274c Deprecated <p>The solution: Direction-major streaming with skin subsampling.</p>"},{"location":"technical/auto_induced_low_memory_optimization/#the-problem","title":"The Problem","text":""},{"location":"technical/auto_induced_low_memory_optimization/#what-the-pipeline-does","title":"What the Pipeline Does","text":"<p>The auto-induced exposure pipeline simulates a Massive MIMO (MaMIMO) beamforming attack where an adversary focuses RF energy on a person's skin. The pipeline:</p> <ol> <li>Runs 72 FDTD simulations (18 directions \u00d7 4 polarizations) with plane wave excitation</li> <li>Finds the worst-case focus point in air near the skin where beamforming would cause maximum exposure</li> <li>Computes optimal phases for each direction to maximize constructive interference at that point</li> <li>Evaluates the combined field on skin to get the final exposure metric</li> </ol>"},{"location":"technical/auto_induced_low_memory_optimization/#the-scoring-algorithm","title":"The Scoring Algorithm","text":"<p>For each candidate air focus point, we compute a \"hotspot score\":</p> <pre><code>For each air focus point r_air:\n    1. Read E_z(r_air) from all 72 directions\n    2. Compute MRT phases: \u03c6_i = -arg(E_z_i(r_air))\n    3. Compute weights: w_i = (1/\u221a72) * exp(j*\u03c6_i)\n    4. Find all skin voxels in a 50mm cube around r_air (~37,000 voxels)\n    5. For each skin voxel r_skin:\n       - Read E(r_skin) from all 72 directions\n       - Compute E_combined = \u03a3 w_i * E_i(r_skin)\n       - Compute |E_combined|\u00b2\n    6. Score = mean(|E_combined|\u00b2) over all skin voxels\n</code></pre>"},{"location":"technical/auto_induced_low_memory_optimization/#data-sizes","title":"Data Sizes","text":"<ul> <li>Grid size: ~500 \u00d7 500 \u00d7 500 voxels</li> <li>E-field per direction: 500\u00d7500\u00d7500 \u00d7 3 components \u00d7 8 bytes = ~3 GB</li> <li>Total for 72 directions: 72 \u00d7 3 GB = ~216 GB</li> <li>Skin voxels per cube: ~37,000</li> <li>Air focus points to score: 10,000</li> </ul>"},{"location":"technical/auto_induced_low_memory_optimization/#why-previous-approaches-failed","title":"Why Previous Approaches Failed","text":""},{"location":"technical/auto_induced_low_memory_optimization/#the-fundamental-issue","title":"The Fundamental Issue","text":"<p>The naive approach processes point-by-point: for each air focus point, read E-fields at ~37,000 skin voxels from 72 files. This results in:</p> <ul> <li>Scattered I/O: Random access patterns defeat disk caching</li> <li>Massive I/O volume: 10K points \u00d7 37K skin voxels \u00d7 72 files = billions of reads</li> <li>No spatial locality: Skin voxels span the entire z-range of the phantom</li> </ul>"},{"location":"technical/auto_induced_low_memory_optimization/#failed-attempt-chunked-processing-with-deduplication","title":"Failed Attempt: Chunked Processing with Deduplication","text":"<p>Idea: Process 100 air points at a time, deduplicate shared skin voxels.</p> <p>Problem: Even with deduplication, each chunk has ~3.3 million unique skin voxels spread across ~500 z-slices. Reading 3.3M voxels \u00d7 72 directions \u00d7 100 chunks = massive I/O.</p> <p>Result: Still 30-150 hours.</p>"},{"location":"technical/auto_induced_low_memory_optimization/#failed-attempt-slab-based-lru-cache","title":"Failed Attempt: Slab-Based LRU Cache","text":"<p>Idea: Cache z-slabs (32 z-slices at a time) in an LRU cache.</p> <p>Problem: The 10,000 air focus points are randomly distributed. Reading E_z at 10,000 scattered points requires reading almost ALL z-slabs, defeating the cache.</p> <p>Result: Still very slow.</p>"},{"location":"technical/auto_induced_low_memory_optimization/#the-solution-direction-major-streaming","title":"The Solution: Direction-Major Streaming","text":""},{"location":"technical/auto_induced_low_memory_optimization/#key-insight","title":"Key Insight","text":"<p>Instead of processing by air point (which requires reading from all 72 files for each point), we flip the loop order and process by direction:</p> <pre><code>OLD (point-major, slow):\n    For each air point (10,000):\n        For each direction (72):\n            Read E-field at skin voxels\n            \nNEW (direction-major, fast):\n    For each direction (72):\n        Load entire E-field (3 GB)\n        For each air point (10,000):\n            Accumulate weighted contribution\n</code></pre>"},{"location":"technical/auto_induced_low_memory_optimization/#the-algorithm","title":"The Algorithm","text":"<pre><code>def compute_all_hotspot_scores_streaming(h5_paths, air_indices, skin_mask, subsample=4):\n    \"\"\"Score all air points using direction-major streaming.\"\"\"\n    n_air = len(air_indices)\n    n_dirs = len(h5_paths)\n    \n    # Step 1: Precompute SUBSAMPLED skin indices for each air point\n    # Use every Nth skin voxel - score is a mean, so subsampling is unbiased\n    # Memory: 10K \u00d7 600 \u00d7 3 \u00d7 4 bytes = 72 MB\n    air_to_skin = precompute_subsampled_skin_indices(air_indices, skin_mask, subsample)\n    \n    # Step 2: Allocate accumulators for E_combined\n    # Memory: 10K \u00d7 600 \u00d7 3 \u00d7 8 bytes = 144 MB\n    E_combined_accum = [np.zeros((len(skin_idx), 3), dtype=np.complex64) \n                       for skin_idx in air_to_skin]\n    \n    # Step 3: Read E_z at all focus points from all directions (small I/O)\n    E_z_all = np.zeros((n_dirs, n_air), dtype=np.complex64)\n    for dir_idx, h5_path in enumerate(h5_paths):\n        E_z_all[dir_idx, :] = read_E_z_at_points(h5_path, air_indices)\n    \n    # Step 4: Compute all MRT weights\n    phases = -np.angle(E_z_all)  # (n_dirs, n_air)\n    weights = (1/np.sqrt(n_dirs)) * np.exp(1j * phases)  # (n_dirs, n_air)\n    \n    # Step 5: Stream through directions, accumulate weighted E\n    for dir_idx, h5_path in enumerate(h5_paths):\n        # Load ENTIRE E-field for this direction (3 GB, sequential read = fast)\n        E_field = load_full_field(h5_path)  # (Nx, Ny, Nz, 3)\n        \n        # For each air point, accumulate weighted contribution\n        for air_idx in range(n_air):\n            skin_indices = air_to_skin[air_idx]\n            w = weights[dir_idx, air_idx]\n            E_at_skin = E_field[skin_indices[:, 0], skin_indices[:, 1], skin_indices[:, 2], :]\n            E_combined_accum[air_idx] += w * E_at_skin\n        \n        del E_field  # Free memory before loading next\n    \n    # Step 6: Compute final scores\n    scores = np.zeros(n_air)\n    for air_idx in range(n_air):\n        E_sq = np.sum(np.abs(E_combined_accum[air_idx])**2, axis=1)\n        scores[air_idx] = np.mean(E_sq)\n    \n    return scores\n</code></pre>"},{"location":"technical/auto_induced_low_memory_optimization/#why-this-works","title":"Why This Works","text":"<ol> <li>Sequential I/O: Loading an entire 3 GB file sequentially is FAST (~30 seconds)</li> <li>Minimal memory: Only one E-field in memory at a time (3 GB) + accumulators (144 MB)</li> <li>Skin subsampling: Using every 4<sup>th</sup> skin voxel reduces memory by 4x with minimal accuracy loss</li> <li>Total I/O: 72 \u00d7 3 GB = 216 GB sequential reads (vs. billions of random reads)</li> </ol>"},{"location":"technical/auto_induced_low_memory_optimization/#performance-analysis","title":"Performance Analysis","text":"Metric Old Approach New Approach Memory ~65 GB (all fields) or massive paging ~3.5 GB I/O pattern Random (slow) Sequential (fast) I/O volume Billions of small reads 72 large reads Time 42+ hours ~30-40 minutes"},{"location":"technical/auto_induced_low_memory_optimization/#implementation-details","title":"Implementation Details","text":""},{"location":"technical/auto_induced_low_memory_optimization/#key-functions","title":"Key Functions","text":"<ol> <li><code>compute_all_hotspot_scores_streaming()</code> - The new direction-major algorithm</li> <li>Loads one E-field at a time</li> <li>Uses subsampled skin voxels</li> <li> <p>Accumulates weighted contributions incrementally</p> </li> <li> <p><code>_precompute_skin_indices_for_air_points()</code> - Precomputes skin indices</p> </li> <li>Finds skin voxels in cube around each air point</li> <li> <p>Applies subsampling factor</p> </li> <li> <p><code>_find_focus_air_based()</code> - Updated to use streaming mode</p> </li> <li>Auto-detects available RAM</li> <li>Uses streaming mode when RAM &lt; 65 GB</li> <li>Falls back to in-memory mode when RAM is sufficient</li> </ol>"},{"location":"technical/auto_induced_low_memory_optimization/#configuration-parameters","title":"Configuration Parameters","text":"<pre><code>find_focus_and_compute_weights(\n    h5_paths=...,\n    input_h5_path=...,\n    low_memory=None,      # None=auto-detect, True=force streaming, False=force in-memory\n    skin_subsample=4,     # Use every 4th skin voxel (default). Higher=faster but noisier.\n)\n</code></pre>"},{"location":"technical/auto_induced_low_memory_optimization/#skin-subsampling","title":"Skin Subsampling","text":"<p>The score is a mean over skin voxels: <pre><code>Score = mean(|E_combined|\u00b2) over skin voxels\n</code></pre></p> <p>Subsampling gives an unbiased estimate of this mean with some variance. With 37,000 skin voxels and 4x subsampling, we still have ~9,000 samples - more than enough for a reliable estimate.</p> <p>Recommended values: - <code>skin_subsample=2</code>: Most accurate, ~50% slower - <code>skin_subsample=4</code>: Good balance (default) - <code>skin_subsample=8</code>: Fastest, slightly noisier</p>"},{"location":"technical/auto_induced_low_memory_optimization/#memory-budget","title":"Memory Budget","text":"<p>For 10,000 air points with 4x skin subsampling:</p> Component Memory One E-field 3.0 GB Skin indices 72 MB E_combined accumulators 144 MB MRT weights 6 MB Misc overhead ~200 MB Total ~3.5 GB <p>This fits comfortably on machines with 8+ GB RAM.</p>"},{"location":"technical/auto_induced_low_memory_optimization/#usage","title":"Usage","text":""},{"location":"technical/auto_induced_low_memory_optimization/#automatic-mode-selection","title":"Automatic Mode Selection","text":"<p>The pipeline automatically selects the best mode based on available RAM:</p> <pre><code># Auto-detect: uses streaming if RAM &lt; 65 GB\nfocus_idx, weights, info = find_focus_and_compute_weights(\n    h5_paths=h5_paths,\n    input_h5_path=input_h5_path,\n    search_mode=\"air\",\n    n_samples=10000,\n)\n</code></pre>"},{"location":"technical/auto_induced_low_memory_optimization/#force-streaming-mode","title":"Force Streaming Mode","text":"<pre><code># Force streaming mode (useful for testing or when RAM is tight)\nfocus_idx, weights, info = find_focus_and_compute_weights(\n    h5_paths=h5_paths,\n    input_h5_path=input_h5_path,\n    search_mode=\"air\",\n    n_samples=10000,\n    low_memory=True,\n    skin_subsample=4,\n)\n</code></pre>"},{"location":"technical/auto_induced_low_memory_optimization/#check-mode-used","title":"Check Mode Used","text":"<pre><code>print(f\"Used streaming mode: {info['streaming_mode']}\")\nprint(f\"Skin subsample factor: {info['skin_subsample']}\")\n</code></pre>"},{"location":"technical/auto_induced_low_memory_optimization/#summary","title":"Summary","text":"Aspect Before After Low-RAM time 42+ hours ~30-40 minutes Memory required 65+ GB ~3.5 GB Algorithm Point-major (random I/O) Direction-major (sequential I/O) Skin voxels All 37,000 Subsampled to ~9,000 Accuracy Exact Unbiased estimate (negligible error) <p>The new direction-major streaming algorithm makes the auto-induced pipeline practical on any machine with at least 8 GB RAM.</p>"},{"location":"technical/auto_induced_research_plan/","title":"Auto-Induced Exposure Research Plan","text":"<p>Document: Scientific approach for MaMIMO beamforming worst-case SAPD study Date: January 2026 Status: Planning phase</p>"},{"location":"technical/auto_induced_research_plan/#1-research-questions","title":"1. Research Questions","text":""},{"location":"technical/auto_induced_research_plan/#primary-questions","title":"Primary Questions","text":"<ol> <li>Distribution: What is the distribution of induced SAPD when MaMIMO beamforming focuses at arbitrary points near the human body?</li> <li>Is it normal, log-normal, heavy-tailed?</li> <li>What is the range (min to max)?</li> <li> <p>How does it vary across body regions?</p> </li> <li> <p>Worst-Case: What is the maximum achievable SAPD under ideal beamforming conditions?</p> </li> <li>Where on the body does it occur?</li> <li>How does it compare to regulatory limits (IEC 62209-3)?</li> <li> <p>How much margin exists?</p> </li> <li> <p>Proxy Validity: How well does our fast proxy metric predict actual SAPD?</p> </li> <li>What is the correlation coefficient?</li> <li>Are there systematic biases?</li> <li>Is selecting by proxy sufficient to find the true worst-case?</li> </ol>"},{"location":"technical/auto_induced_research_plan/#secondary-questions","title":"Secondary Questions","text":"<ol> <li> <p>Frequency Dependence: How does worst-case SAPD scale with frequency (450 MHz \u2192 5.8 GHz)?</p> </li> <li> <p>Antenna Configuration: How does the number of directions/polarizations affect the result?</p> </li> <li> <p>Body Type Variation: How do results differ across phantoms (child vs adult, male vs female)?</p> </li> <li> <p>Focus Distance: How does SAPD change with distance from skin (10mm vs 50mm)?</p> </li> </ol>"},{"location":"technical/auto_induced_research_plan/#2-current-tool-capabilities","title":"2. Current Tool Capabilities","text":""},{"location":"technical/auto_induced_research_plan/#what-we-have","title":"What We Have","text":"Component Status Performance E-field simulation (Sim4Life) \u2705 Working ~2h per direction Skin/Air voxel extraction \u2705 Working 1.7s Binary dilation (shell finding) \u2705 Working 51s for 25mm shell Field caching \u2705 Working 5GB RAM, 5s load MRT phase optimization \u2705 Working Per-point at focus Hotspot scoring \u2705 Working 646 samples/sec Field combination \u2705 Working 2s per candidate SAPD extraction (Sim4Life) \u2705 Working 10s per candidate Focus point markers \u2705 Working Saved in .smash"},{"location":"technical/auto_induced_research_plan/#key-parameters-current-config","title":"Key Parameters (Current Config)","text":"<pre><code>{\n    \"n_samples\": 10000,        // Number of random focus points scored\n    \"top_n\": 5,                // Candidates for SAPD extraction\n    \"shell_size_mm\": 25,       // Max distance from skin\n    \"cube_size_mm\": 50,        // Scoring cube size\n    \"random_seed\": 42          // Reproducibility\n}\n</code></pre>"},{"location":"technical/auto_induced_research_plan/#performance-summary","title":"Performance Summary","text":"Phase Time Notes Voxel extraction 2s Fixed Dilation 51s Scales with shell_size\u00b2 Field loading 5s Fixed per run Scoring 10K points 15s 646/sec, highly scalable Combine fields (5 candidates) 10s 2s each SAPD extraction (5 candidates) 50s 10s each Total ~2.5 min For 10K samples, 5 candidates"},{"location":"technical/auto_induced_research_plan/#3-critical-features-to-add","title":"3. Critical Features To Add","text":""},{"location":"technical/auto_induced_research_plan/#priority-1-data-export-for-analysis","title":"Priority 1: Data Export (for analysis)","text":"<ul> <li> Save all proxy scores to CSV: <code>[idx, x_mm, y_mm, z_mm, proxy_score]</code></li> <li> Save proxy-SAPD pairs for correlation analysis</li> <li> Export score histogram as data file</li> </ul>"},{"location":"technical/auto_induced_research_plan/#priority-2-improved-candidate-selection","title":"Priority 2: Improved Candidate Selection","text":"<ul> <li> Percentile-based selection: Sample from top 5% (not just top-N)</li> <li> Diversity constraint: Min distance between candidates (e.g., 50mm)</li> <li> Body region stratification: Ensure head, torso, limbs all represented</li> </ul>"},{"location":"technical/auto_induced_research_plan/#priority-3-uniform-spatial-sampling","title":"Priority 3: Uniform Spatial Sampling","text":"<ul> <li> Grid-based sampling: Divide body into 3D grid, sample from each cell</li> <li> Surface-based sampling: Sample along skin surface at regular intervals</li> <li> Farthest Point Sampling (FPS): Maximize spatial coverage</li> </ul>"},{"location":"technical/auto_induced_research_plan/#priority-4-analysis-automation","title":"Priority 4: Analysis Automation","text":"<ul> <li> Correlation plot: Scatter proxy vs SAPD with regression line</li> <li> Histogram generation: Distribution of all 10K scores</li> <li> Body heatmap: 3D visualization of hotspot locations</li> <li> Summary statistics: Table with min/max/mean/std per body region</li> </ul>"},{"location":"technical/auto_induced_research_plan/#4-parameters-to-explore","title":"4. Parameters to Explore","text":""},{"location":"technical/auto_induced_research_plan/#numerical-experiments","title":"Numerical Experiments","text":"Parameter Values to Test Hypothesis <code>shell_size_mm</code> 10, 25, 50, 100 Closer focus \u2192 higher SAPD? <code>n_samples</code> 1K, 10K, 100K Convergence of max SAPD <code>cube_size_mm</code> 25, 50, 100 Larger cube \u2192 smoother scores <code>top_n</code> 5, 10, 20, 50 Diversity vs computation Frequency 450, 2450, 5800 MHz Wavelength effects Phantom Duke, Ella, Thelonious, Eartha Body variation Directions 4, 6, 12 Array size effects"},{"location":"technical/auto_induced_research_plan/#sensitivity-analysis","title":"Sensitivity Analysis","text":"<ol> <li>Random seed variation: Run with seeds 1-10, compare max SAPD</li> <li>Sample size convergence: Plot max(proxy) vs n_samples</li> <li>Shell size sweep: SAPD vs distance from skin</li> </ol>"},{"location":"technical/auto_induced_research_plan/#5-proposed-experimental-protocol","title":"5. Proposed Experimental Protocol","text":""},{"location":"technical/auto_induced_research_plan/#phase-1-methodology-validation-current","title":"Phase 1: Methodology Validation (Current)","text":"<p>Goal: Verify proxy-SAPD correlation</p> <ol> <li>Run with current settings (10K samples, 25mm shell)</li> <li>Select 20 candidates from top 5% with diversity constraint</li> <li>Extract SAPD for all 20</li> <li>Compute correlation coefficient R\u00b2</li> <li>If R\u00b2 &gt; 0.8: proceed; else: investigate bias</li> </ol>"},{"location":"technical/auto_induced_research_plan/#phase-2-distribution-characterization","title":"Phase 2: Distribution Characterization","text":"<p>Goal: Understand proxy score distribution</p> <ol> <li>Run 100K samples (conservative for near-exhaustive search)</li> <li>Save all scores to CSV</li> <li>Generate:</li> <li>Histogram with percentile markers</li> <li>Q-Q plot (normality test)</li> <li>Body region breakdown</li> </ol>"},{"location":"technical/auto_induced_research_plan/#phase-3-worst-case-identification","title":"Phase 3: Worst-Case Identification","text":"<p>Goal: Find and validate maximum SAPD</p> <ol> <li>From 100K samples, select top 50 with diversity</li> <li>Extract SAPD for all 50</li> <li>Report:</li> <li>Maximum SAPD value</li> <li>Location (body region)</li> <li>Comparison to IEC limits</li> </ol>"},{"location":"technical/auto_induced_research_plan/#phase-4-multi-parameter-study","title":"Phase 4: Multi-Parameter Study","text":"<p>Goal: Comprehensive results for paper</p> Run Phantom Frequency Directions Expected Time 1 Thelonious 2450 MHz 4 3 min 2 Thelonious 2450 MHz 6 4 min 3 Thelonious 5800 MHz 6 4 min 4 Duke 2450 MHz 6 4 min 5 Ella 2450 MHz 6 4 min ... ... ... ... ..."},{"location":"technical/auto_induced_research_plan/#6-key-metrics-for-paper","title":"6. Key Metrics for Paper","text":""},{"location":"technical/auto_induced_research_plan/#tables","title":"Tables","text":"<ol> <li> <p>Worst-case SAPD by phantom/frequency    | Phantom | 450 MHz | 2450 MHz | 5800 MHz | IEC Limit |    |---------|---------|----------|----------|-----------|    | Duke    | X W/m\u00b2  | Y W/m\u00b2   | Z W/m\u00b2   | 20 W/m\u00b2   |    | Ella    | ...     | ...      | ...      | ...       |</p> </li> <li> <p>Proxy-SAPD correlation by configuration    | Configuration | R\u00b2 | Slope | Bias |    |---------------|-----|-------|------|</p> </li> </ol>"},{"location":"technical/auto_induced_research_plan/#figures","title":"Figures","text":"<ol> <li>Score distribution histogram (all 10K/100K samples)</li> <li>Proxy vs SAPD scatter plot with regression</li> <li>Body heatmap showing hotspot probabilities</li> <li>Convergence plot: max SAPD vs sample size</li> <li>Distance analysis: SAPD vs focus-to-skin distance</li> </ol>"},{"location":"technical/auto_induced_research_plan/#7-open-questions-decisions-needed","title":"7. Open Questions / Decisions Needed","text":""},{"location":"technical/auto_induced_research_plan/#scientific","title":"Scientific","text":"<ol> <li>How many samples are \"enough\"? </li> <li>10K gives good coverage, 100K near-exhaustive</li> <li> <p>Need convergence analysis</p> </li> <li> <p>What percentile threshold for candidate selection?</p> </li> <li>Top 5% = 500 candidates from 10K</li> <li> <p>Too many for SAPD extraction, need subsampling</p> </li> <li> <p>How to define \"diversity\"?</p> </li> <li>Minimum distance in mm?</li> <li> <p>One per body region?</p> </li> <li> <p>Is E_z the right phase reference?</p> </li> <li>Currently using E_z only</li> <li>Could use full |E| or specific polarization</li> </ol>"},{"location":"technical/auto_induced_research_plan/#technical","title":"Technical","text":"<ol> <li>Storage for 100K samples?</li> <li> <p>~10 MB CSV, negligible</p> </li> <li> <p>Parallel SAPD extraction?</p> </li> <li> <p>Currently sequential, could parallelize on cluster</p> </li> <li> <p>Mesh quality issues?</p> </li> <li>Many \"Failed to cover cut loop\" warnings</li> <li>May need mesh preprocessing</li> </ol>"},{"location":"technical/auto_induced_research_plan/#8-next-steps-immediate","title":"8. Next Steps (Immediate)","text":"<ol> <li> Implement CSV export of all proxy scores</li> <li> Add percentile selection with diversity constraint</li> <li> Run validation experiment: 20 diverse candidates, check correlation</li> <li> Create analysis notebook for histogram/correlation plots</li> <li> Document findings in this file</li> </ol>"},{"location":"technical/auto_induced_research_plan/#9-references","title":"9. References","text":"<ul> <li>IEC 62209-3: SAR/SAPD measurement standards</li> <li>ITU-T K.52: Guidance on EMF exposure</li> <li>Sim4Life SAPD evaluator documentation</li> <li>GOLIAT project technical documentation</li> </ul> <p>Last updated: 2026-01-11</p>"},{"location":"technical/detuning_feature_design/","title":"Antenna Detuning Feature Design","text":""},{"location":"technical/detuning_feature_design/#overview","title":"Overview","text":"<p>This feature allows harmonic simulations to use calibrated detuning frequencies (in MHz) that account for body presence effects. Detuning values are determined through calibration runs (Gaussian excitation) and then applied during harmonic simulations.</p>"},{"location":"technical/detuning_feature_design/#configuration-structure","title":"Configuration Structure","text":""},{"location":"technical/detuning_feature_design/#main-config-fields","title":"Main Config Fields","text":"<p>Add these fields to your harmonic config file:</p> <pre><code>{\n  \"extends\": \"nf_l_nd_f_minimal.json\",\n  \"detuning_enabled\": true,\n  \"detuning_config\": \"../data/detuning_calibration_nf_l_nd_f.json\",\n  \"detuning_write_during_calibration\": true,\n  \"simulation_parameters\": {\n    \"excitation_type\": \"Harmonic\"\n  }\n}\n</code></pre> <p>Fields: - <code>detuning_enabled</code> (boolean): Master switch to enable/disable detuning feature   - <code>true</code>: Enable detuning lookup and application   - <code>false</code>: Disable detuning (ignore <code>detuning_config</code> if provided, warn once at startup)</p> <ul> <li><code>detuning_config</code> (string, optional): Path to detuning JSON file, relative to config file location</li> <li>Only used if <code>detuning_enabled: true</code></li> <li> <p>Example: <code>\"../data/detuning_calibration_nf_l_nd_f.json\"</code> (from <code>configs/</code> folder)</p> </li> <li> <p><code>detuning_write_during_calibration</code> (boolean): Enable writing/updating detuning file during calibration runs</p> </li> <li><code>true</code>: Allow calibration runs to create/update detuning file</li> <li><code>false</code>: Read-only mode (only lookup, never write)</li> </ul>"},{"location":"technical/detuning_feature_design/#detuning-file-structure","title":"Detuning File Structure","text":"<p>The detuning file (<code>data/detuning_calibration_*.json</code>) mirrors the directory structure:</p> <pre><code>results/near_field/{phantom}/{frequencyMHz}/{placement_name}/\n</code></pre> <p>JSON Structure: <pre><code>{\n  \"detuning_data\": {\n    \"thelonious\": {\n      \"700MHz\": {\n        \"by_cheek_tragus_cheek_base\": 20,\n        \"by_cheek_tragus_cheek_up\": 18,\n        \"by_cheek_tragus_cheek_down\": 22,\n        \"front_of_eyes_center_vertical\": -5,\n        \"by_belly_center_vertical\": 10\n      },\n      \"835MHz\": {\n        \"by_cheek_tragus_cheek_base\": 15,\n        \"front_of_eyes_center_vertical\": -8\n      }\n    },\n    \"eartha\": {\n      \"700MHz\": {\n        \"by_cheek_tragus_cheek_base\": 25,\n        \"front_of_eyes_center_vertical\": -3\n      }\n    }\n  }\n}\n</code></pre></p> <p>Structure Rules: - Top level: <code>detuning_data</code> object - Second level: Phantom name (normalized to lowercase for lookup) - Third level: Frequency string in format <code>\"{frequency}MHz\"</code> (e.g., <code>\"700MHz\"</code>) - Fourth level: Placement name (format: <code>{scenario}_{position}_{orientation}</code>) - Leaf values: Detuning amount in MHz (integer or float, can be negative)</p>"},{"location":"technical/detuning_feature_design/#behavior","title":"Behavior","text":""},{"location":"technical/detuning_feature_design/#lookup-logic","title":"Lookup Logic","text":"<p>When setting up a harmonic simulation:</p> <ol> <li>Check if enabled: If <code>detuning_enabled: false</code>, skip detuning lookup</li> <li>Resolve path: Resolve <code>detuning_config</code> relative to config file location</li> <li>Load detuning file: Load JSON file (create empty structure if missing and write mode enabled)</li> <li>Normalize keys:</li> <li>Phantom name: <code>phantom_name.lower()</code></li> <li>Frequency: <code>f\"{frequency_mhz}MHz\"</code></li> <li>Placement name: <code>f\"{scenario_name}_{position_name}_{orientation_name}\"</code></li> <li>Lookup: <code>detuning_data[phantom_lower][freq_str][placement_name]</code></li> <li>Apply: <code>simulation_frequency = center_frequency + detuning_mhz</code></li> <li>If entry missing: default to <code>0</code> (no detuning)</li> <li>If entry found: use the detuning value</li> </ol>"},{"location":"technical/detuning_feature_design/#missing-entry-handling","title":"Missing Entry Handling","text":"<ul> <li>If <code>detuning_enabled: true</code>:</li> <li>Missing entry defaults to <code>0</code> (no detuning)</li> <li>Warn every time a missing entry is found for a specific simulation</li> <li> <p>Warning format: <code>\"WARNING: No detuning data for {phantom}/{frequencyMHz}/{placement_name}, using 0 MHz\"</code></p> </li> <li> <p>If <code>detuning_enabled: false</code> but <code>detuning_config</code> provided:</p> </li> <li>Warn once at startup: <code>\"WARNING: detuning_config provided but detuning_enabled is false, ignoring detuning config\"</code></li> <li>No per-simulation warnings</li> </ul>"},{"location":"technical/detuning_feature_design/#calibration-workflow","title":"Calibration Workflow","text":"<p>When <code>detuning_write_during_calibration: true</code>:</p> <ol> <li>Load existing file: If file exists, load it. If not, create empty structure:    <pre><code>{\n  \"detuning_data\": {}\n}\n</code></pre></li> <li>For each simulation:</li> <li>Check if entry exists: <code>detuning_data[phantom][freq][placement]</code></li> <li>If missing: Add entry with value <code>0</code> (never overwrite existing values)</li> <li>If exists: Skip (preserve existing value)</li> <li>Save file: After calibration completes, save updated file</li> </ol>"},{"location":"technical/detuning_feature_design/#validation","title":"Validation","text":"<ul> <li>Study type check: If <code>detuning_enabled: true</code> and <code>study_type == \"far_field\"</code>, raise error:   <pre><code>ValueError: \"Detuning feature is only supported for near_field studies, not far_field\"\n</code></pre></li> <li>No structure validation: Don't validate that detuning structure matches expected simulations (just do lookups and default to 0)</li> </ul>"},{"location":"technical/detuning_feature_design/#path-resolution","title":"Path Resolution","text":"<p>The <code>detuning_config</code> path is resolved relative to the config file's directory:</p> <ul> <li>Config file: <code>configs/nf_l_nd_f_harmonic.json</code></li> <li>Detuning config: <code>\"../data/detuning_calibration_nf_l_nd_f.json\"</code></li> <li>Resolved: <code>{project_root}/data/detuning_calibration_nf_l_nd_f.json</code></li> </ul> <p>Implementation uses <code>os.path.normpath(os.path.join(os.path.dirname(config_path), detuning_config_path))</code> then converts to absolute path.</p>"},{"location":"technical/detuning_feature_design/#frequency-application","title":"Frequency Application","text":"<p>When detuning is applied:</p> <ul> <li>Original: <code>center_frequency</code> from <code>antenna_config.{frequency}.center_frequency</code></li> <li>Detuning: Lookup value from detuning file (or 0 if missing)</li> <li>Final frequency: <code>center_frequency + detuning_mhz</code></li> <li>Applied to: <code>edge_source_settings.Frequency</code> and <code>edge_source_settings.CenterFrequency</code> in harmonic simulations</li> </ul>"},{"location":"technical/detuning_feature_design/#example-workflow","title":"Example Workflow","text":""},{"location":"technical/detuning_feature_design/#calibration-run-gaussian","title":"Calibration Run (Gaussian)","text":"<ol> <li>Run Gaussian excitation simulations to detect antenna resonance</li> <li>Analyze results to determine detuning amounts</li> <li>Create/update <code>data/detuning_calibration_nf_l_nd_f.json</code> with detected values</li> <li>Missing entries are filled with <code>0</code> (never overwrite existing)</li> </ol>"},{"location":"technical/detuning_feature_design/#harmonic-run","title":"Harmonic Run","text":"<ol> <li>Load config with <code>detuning_enabled: true</code></li> <li>Load detuning file</li> <li>For each simulation:</li> <li>Lookup detuning value</li> <li>Apply: <code>frequency = center_frequency + detuning</code></li> <li>Run harmonic simulation at adjusted frequency</li> <li>Warn if any entries are missing</li> </ol>"},{"location":"technical/detuning_feature_design/#implementation-notes","title":"Implementation Notes","text":"<ul> <li>Phantom name matching is case-insensitive (normalize to lowercase)</li> <li>Frequency format must match exactly: <code>\"700MHz\"</code> (not <code>\"700\"</code> or <code>\"700 MHz\"</code>)</li> <li>Placement name format: <code>{scenario}_{position}_{orientation}</code> (matches directory structure)</li> <li>Detuning values can be positive (shift up) or negative (shift down)</li> <li>File location: <code>data/</code> folder (ephemeral, can be regenerated)</li> </ul>"},{"location":"technical/dispersion_model_guide/","title":"Dispersion Model Fitting and Material Properties Guide","text":"<p>This guide documents how frequency-dependent material properties (dispersion) work in GOLIAT, including the IT'IS database, Cole-Cole model, cache generation, and Lorentz fitting for FDTD simulations.</p>"},{"location":"technical/dispersion_model_guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>IT'IS Material Database</li> <li>Cole-Cole Dispersion Model</li> <li>Material Properties Cache</li> <li>Lorentz Model Fitting for FDTD</li> <li>Sim4Life Python API</li> <li>Complete Workflow</li> </ol>"},{"location":"technical/dispersion_model_guide/#overview","title":"Overview","text":""},{"location":"technical/dispersion_model_guide/#when-dispersion-is-needed","title":"When Dispersion is Needed","text":"<p>For multisine FDTD simulations with multiple frequencies (e.g., 700 MHz and 835 MHz), materials need frequency-dependent properties. Simple constant permittivity/conductivity won't work because biological tissues exhibit significant dispersion.</p>"},{"location":"technical/dispersion_model_guide/#key-relationships","title":"Key Relationships","text":"<pre><code>\u03b5*(\u03c9) = \u03b5'(\u03c9) - j\u03b5''(\u03c9)    # Complex permittivity\n\u03b5'' = \u03c3 / (\u03c9\u00b7\u03b5\u2080)           # Conductivity contribution to imaginary part\n\nWhere:\n- \u03b5'  = real permittivity (dielectric constant)\n- \u03b5'' = imaginary permittivity (loss)\n- \u03c3   = conductivity (S/m)\n- \u03c9   = 2\u03c0f (angular frequency)\n- \u03b5\u2080  = 8.854187817e-12 F/m (vacuum permittivity)\n</code></pre>"},{"location":"technical/dispersion_model_guide/#physical-behavior-of-biological-tissues","title":"Physical Behavior of Biological Tissues","text":"<p>At RF/microwave frequencies (100 MHz - 10 GHz): - \u03b5' decreases with increasing frequency - \u03c3 increases with increasing frequency</p> <p>This is due to various polarization mechanisms (ionic, dipolar) that cannot follow fast-changing fields.</p>"},{"location":"technical/dispersion_model_guide/#itis-material-database","title":"IT'IS Material Database","text":""},{"location":"technical/dispersion_model_guide/#source-itis-foundation-v50-database","title":"Source: IT'IS Foundation V5.0 Database","text":"<p>The IT'IS Foundation provides a comprehensive database of tissue properties based on Gabriel's 4-Cole-Cole model parameters. We use data/itis_v5.db (SQLite format).</p>"},{"location":"technical/dispersion_model_guide/#database-structure","title":"Database Structure","text":"<pre><code>-- Key tables:\nmaterials (mat_id, name, ver_id)          -- Tissue names\nvectors (mat_id, prop_id, vals)           -- Parameter arrays (BLOB)\nproperties (prop_id, name, unit)          -- Property definitions\n\n-- Gabriel Parameters property ID:\n'37f803e4-fc61-4b2b-9a41-39bd6569eb28'\n</code></pre>"},{"location":"technical/dispersion_model_guide/#gabriel-parameters-format","title":"Gabriel Parameters Format","text":"<p>Each tissue has a 14-element float64 array: <pre><code>[ef, del1, tau1, alf1, del2, tau2, alf2, del3, tau3, alf3, del4, tau4, alf4, sigma]\n\nWhere:\n- ef      = \u03b5\u221e (epsilon infinity, high-frequency limit)\n- del1-4  = \u0394\u03b5 for each Cole-Cole pole\n- tau1-4  = relaxation time (units: ps, ns, \u00b5s, ms for poles 1-4)\n- alf1-4  = \u03b1 parameter (0 = Debye, &gt;0 = Cole-Cole broadening)\n- sigma   = ionic conductivity (S/m)\n</code></pre></p>"},{"location":"technical/dispersion_model_guide/#tau-unit-conversion","title":"Tau Unit Conversion","text":"<p>Critical: The database uses mixed time units that must be converted to seconds: <pre><code>tau1_seconds = tau1 * 1e-12  # picoseconds\ntau2_seconds = tau2 * 1e-9   # nanoseconds\ntau3_seconds = tau3 * 1e-6   # microseconds\ntau4_seconds = tau4 * 1e-3   # milliseconds\n</code></pre></p>"},{"location":"technical/dispersion_model_guide/#cole-cole-dispersion-model","title":"Cole-Cole Dispersion Model","text":""},{"location":"technical/dispersion_model_guide/#4-cole-cole-formula","title":"4-Cole-Cole Formula","text":"<p>The Gabriel model uses 4 Cole-Cole poles:</p> <pre><code>\u03b5*(\u03c9) = \u03b5\u221e + \u03a3\u2099 [\u0394\u03b5\u2099 / (1 + (j\u03c9\u03c4\u2099)^(1-\u03b1\u2099))] + \u03c3/(j\u03c9\u03b5\u2080)\n</code></pre> <p>Where: - \u03b5\u221e = high-frequency permittivity - \u0394\u03b5\u2099 = permittivity increment for pole n - \u03c4\u2099 = relaxation time for pole n - \u03b1\u2099 = Cole-Cole broadening parameter (0 = pure Debye) - \u03c3 = ionic conductivity</p>"},{"location":"technical/dispersion_model_guide/#python-implementation","title":"Python Implementation","text":"<pre><code>import numpy as np\n\nEPS_0 = 8.854187817e-12  # F/m\n\ndef cole_cole(f_hz: float, ef: float, poles: list, sigma_ionic: float) -&gt; tuple:\n    \"\"\"\n    Calculate eps_r and sigma at frequency f_hz using 4-Cole-Cole model.\n    \n    Args:\n        f_hz: Frequency in Hz\n        ef: Epsilon infinity\n        poles: List of (delta_eps, tau_seconds, alpha) tuples\n        sigma_ionic: Ionic conductivity in S/m\n        \n    Returns:\n        (eps_r, sigma) - real permittivity and total conductivity\n    \"\"\"\n    omega = 2 * np.pi * f_hz\n    eps_complex = ef + 0j\n    \n    for delta_eps, tau, alpha in poles:\n        if delta_eps != 0 and tau != 0 and alpha &lt; 1:\n            eps_complex += delta_eps / (1 + (1j * omega * tau)**(1 - alpha))\n    \n    # Add ionic conductivity contribution\n    eps_complex -= 1j * sigma_ionic / (omega * EPS_0)\n    \n    eps_r = float(np.real(eps_complex))\n    sigma = float(-omega * EPS_0 * np.imag(eps_complex))\n    \n    return eps_r, sigma\n</code></pre>"},{"location":"technical/dispersion_model_guide/#validated-values","title":"Validated Values","text":"<p>Values computed from IT'IS V5.0 database match Sim4Life GUI exactly:</p> Tissue Frequency \u03b5_r \u03c3 (S/m) Brain (Grey Matter) 700 MHz 53.90 0.860 Muscle 2450 MHz 52.73 1.739 Skin 835 MHz 41.76 0.845 Fat 5800 MHz 9.86 0.832 Bone (Cortical) 450 MHz 13.04 0.096"},{"location":"technical/dispersion_model_guide/#material-properties-cache","title":"Material Properties Cache","text":""},{"location":"technical/dispersion_model_guide/#purpose","title":"Purpose","text":"<p>The cache (<code>data/material_properties_cache.json</code>) stores precomputed \u03b5_r and \u03c3 values at multiple frequencies, avoiding runtime Cole-Cole calculations and enabling fast Lorentz fitting.</p>"},{"location":"technical/dispersion_model_guide/#cache-generation","title":"Cache Generation","text":"<p>Generate from IT'IS V5.0 database:</p> <pre><code># scripts/generate_material_cache_from_excel.py (or use DB directly)\n# Generates: data/material_properties_cache.json\n\nFREQUENCIES_MHZ = [450, 700, 835, 1450, 2140, 2450, 3500, 5200, 5800]\n</code></pre>"},{"location":"technical/dispersion_model_guide/#cache-format","title":"Cache Format","text":"<pre><code>{\n  \"source\": \"IT'IS Foundation Database V5.0 (4-Cole-Cole Gabriel model)\",\n  \"generated\": \"2024-12-14T17:00:00\",\n  \"frequencies_mhz\": [450, 700, 835, 1450, 2140, 2450, 3500, 5200, 5800],\n  \"model\": \"4-pole Cole-Cole\",\n  \"tissues\": {\n    \"Brain (Grey Matter)\": {\n      \"450\": {\"eps_r\": 56.55, \"sigma\": 0.7585},\n      \"700\": {\"eps_r\": 53.90, \"sigma\": 0.8596},\n      ...\n    },\n    ...\n  }\n}\n</code></pre>"},{"location":"technical/dispersion_model_guide/#material-name-mapping","title":"Material Name Mapping","text":"<p>Phantom entity names \u2192 IT'IS database names via <code>data/material_name_mapping.json</code>:</p> <pre><code>{\n  \"thelonious\": {\n    \"Brain_grey_matter\": \"Brain (Grey Matter)\",\n    \"Muscle\": \"Muscle\",\n    \"SAT\": \"SAT (Subcutaneous Fat)\",\n    ...\n  },\n  \"duke\": { ... },\n  \"ella\": { ... },\n  \"eartha\": { ... }\n}\n</code></pre>"},{"location":"technical/dispersion_model_guide/#cache-api","title":"Cache API","text":"<pre><code>from goliat.dispersion import get_material_properties, load_material_cache\n\n# Load cache (cached in memory after first load)\ncache = load_material_cache()\n\n# Get properties at specific frequencies\nprops = get_material_properties(\"Brain (Grey Matter)\", [700, 835])\n# Returns: [{\"eps_r\": 53.90, \"sigma\": 0.86}, {\"eps_r\": 52.28, \"sigma\": 0.99}]\n</code></pre>"},{"location":"technical/dispersion_model_guide/#lorentz-model-fitting-for-fdtd","title":"Lorentz Model Fitting for FDTD","text":""},{"location":"technical/dispersion_model_guide/#why-lorentz","title":"Why Lorentz?","text":"<p>Sim4Life FDTD requires dispersion models in specific formats (Debye, Drude, Lorentz). The two-pole Lorentz model is used because:</p> <ol> <li>Can model both increasing and decreasing \u03b5' with frequency</li> <li>FDTD-stable when operating below resonance</li> <li>Provides good fit with minimal poles</li> </ol>"},{"location":"technical/dispersion_model_guide/#lorentz-formula","title":"Lorentz Formula","text":"<pre><code>\u03b5(\u03c9) = \u03b5\u221e + \u03a3\u1d62 [\u0394\u03b5\u1d62 \u00d7 \u03c9\u2080\u1d62\u00b2 / (\u03c9\u2080\u1d62\u00b2 - \u03c9\u00b2 + j\u03b3\u1d62\u03c9)]\n\nWhere:\n- \u03b5\u221e    = base permittivity\n- \u0394\u03b5\u1d62   = static permittivity contribution\n- \u03c9\u2080\u1d62   = resonance angular frequency\n- \u03b3\u1d62    = damping factor\n</code></pre>"},{"location":"technical/dispersion_model_guide/#fitting-implementation","title":"Fitting Implementation","text":"<pre><code>from goliat.dispersion import fit_two_pole_lorentz\n\n# Target frequencies and properties\nfrequencies_hz = [700e6, 835e6, 2450e6]\neps_r_targets = [53.90, 52.28, 48.46]\nsigma_targets = [0.86, 0.99, 2.00]\n\n# Fit two-pole Lorentz model\nparams = fit_two_pole_lorentz(frequencies_hz, eps_r_targets, sigma_targets)\n\n# params contains:\n# - eps_inf: base permittivity\n# - sigma_dc: DC conductivity\n# - poles: list of PoleFit(delta_eps, f_res_hz, damping_hz)\n# - fit_error: RMS error\n</code></pre>"},{"location":"technical/dispersion_model_guide/#sim4life-python-api","title":"Sim4Life Python API","text":""},{"location":"technical/dispersion_model_guide/#model-types","title":"Model Types","text":"Type Index Use Case Debye 0 Normal dispersion Drude 1 Metallic behavior Lorentz 2 Resonance, works for both directions Generic 3 Custom/inactive"},{"location":"technical/dispersion_model_guide/#creating-dispersive-materials","title":"Creating Dispersive Materials","text":"<pre><code>import s4l_v1.simulation.emfdtd as emfdtd\nimport XMaterials as xm\n\n# Create material with LinearDispersive model\nmaterial_settings = emfdtd.MaterialSettings()\nmaterial_settings.Name = \"Brain (Multisine)\"\nmaterial_settings.ElectricProps.MaterialModel = (\n    material_settings.ElectricProps.MaterialModel.enum.LinearDispersive\n)\n\n# Configure dispersion\ndisp = material_settings.raw.ElectricDispersiveSettings\ndisp.StartFrequency = 350e6\ndisp.EndFrequency = 6e9\ndisp.Permittivity = params.eps_inf\ndisp.Conductivity = params.sigma_dc\n\n# Create Lorentz poles\npoles = []\nfor pole_fit in params.poles:\n    pole = xm.LinearDispersionPole()\n    pole.Active = True\n    pole.Type = xm.LinearDispersionPole.ePoleType.kLorentz\n    pole[xm.LinearDispersionPole.ePoleProperty.kLorentzAmplitude] = 1.0\n    pole[xm.LinearDispersionPole.ePoleProperty.kLorentzFrequency] = pole_fit.f_res_hz\n    pole[xm.LinearDispersionPole.ePoleProperty.kLorentzStaticPermittivity] = pole_fit.delta_eps\n    pole[xm.LinearDispersionPole.ePoleProperty.kLorentzInfinityPermittivity] = 0.0\n    pole[xm.LinearDispersionPole.ePoleProperty.kLorentzDamping] = pole_fit.damping_hz\n    poles.append(pole)\n\n# CRITICAL: Must assign as list, cannot modify in-place\ndisp.Poles = poles\n\n# Add to simulation\nsimulation.Add(material_settings, [entity])\n</code></pre>"},{"location":"technical/dispersion_model_guide/#critical-notes","title":"Critical Notes","text":"<ol> <li>Poles are immutable tuples - you cannot modify <code>disp.Poles[0]</code>, must create new list</li> <li>Frequency units are Hz in the API (not rad/s)</li> <li>Damping is in Hz (already divided by 2\u03c0)</li> </ol>"},{"location":"technical/dispersion_model_guide/#complete-workflow","title":"Complete Workflow","text":""},{"location":"technical/dispersion_model_guide/#1-one-time-generate-material-cache","title":"1. One-time: Generate Material Cache","text":"<pre><code># Option A: From IT'IS V5.0 database (recommended)\npython scripts/generate_material_cache_from_db.py\n\n# Option B: From Excel file\npython scripts/generate_material_cache_from_excel.py\n</code></pre>"},{"location":"technical/dispersion_model_guide/#2-in-goliat-setup-automatic","title":"2. In GOLIAT Setup (Automatic)","text":"<p>The <code>MaterialSetup</code> class automatically handles dispersion for multisine:</p> <pre><code># In goliat/setups/material_setup.py\ndef _assign_phantom_materials_multisine(self):\n    cache = load_material_cache()\n    \n    for material_name, entities in material_groups.items():\n        # Get properties at each frequency\n        props = get_material_properties(material_name, self.frequencies_mhz, cache)\n        \n        # Fit Lorentz model\n        params = fit_two_pole_lorentz(frequencies_hz, eps_r_list, sigma_list)\n        \n        # Create and assign dispersive material...\n</code></pre>"},{"location":"technical/dispersion_model_guide/#3-verification","title":"3. Verification","text":"<p>Check cache values against Sim4Life GUI: 1. Open IT'IS 4.x Database in Materials panel 2. Select tissue, set frequency 3. Compare \u03b5_r and \u03c3 with cache values</p>"},{"location":"technical/dispersion_model_guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"technical/dispersion_model_guide/#cache-not-found","title":"Cache Not Found","text":"<p><pre><code>FileNotFoundError: Material properties cache not found\n</code></pre> Solution: Run cache generation script</p>"},{"location":"technical/dispersion_model_guide/#tissue-not-in-cache","title":"Tissue Not In Cache","text":"<p><pre><code>KeyError: Tissue 'XYZ' not found in material cache\n</code></pre> Solution: Check <code>material_name_mapping.json</code> for correct IT'IS name</p>"},{"location":"technical/dispersion_model_guide/#high-fit-error","title":"High Fit Error","text":"<p><pre><code>WARNING: High fit error (0.05) for 'Muscle'\n</code></pre> Solution: Usually acceptable for &lt;5% error. For higher errors, consider: - Adding more Lorentz poles - Narrowing frequency range - Using database fallback</p>"},{"location":"technical/dispersion_model_guide/#poles-not-visible-in-gui","title":"Poles Not Visible in GUI","text":"<p>Cause: Modified poles in-place instead of creating new objects Solution: Create new <code>LinearDispersionPole()</code> objects and assign as list</p>"},{"location":"technical/dispersion_model_guide/#references","title":"References","text":"<ul> <li>IT'IS Foundation: https://itis.swiss/virtual-population/tissue-properties/database/</li> <li>Gabriel et al.: \"The dielectric properties of biological tissues\" Physics in Medicine &amp; Biology (1996)</li> <li>Sim4Life: Python API reference in <code>PythonAPIReference/</code></li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/","title":"TODO: Gaussian Excitation Support for Near-Field Simulations with Antenna Detuning Detection","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#overview","title":"Overview","text":"<p>This document outlines the complete implementation plan for adding Gaussian excitation support to near-field (phantom) simulations in GOLIAT. Currently, Gaussian excitation is only used for free-space antenna characterization. This work extends it to SAR compliance studies with the primary goal of detecting antenna detuning when devices are near the body.</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#context-and-motivation","title":"Context and Motivation","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#current-state","title":"Current State","text":"<ul> <li>Harmonic excitation: Standard for SAR compliance (single frequency)</li> <li>Gaussian excitation: Currently only for free-space simulations (frequency sweep)</li> <li>Free-space limitation: Code checks <code>free_space</code> flag to determine excitation type</li> <li>Material workaround: Copper\u2192PEC forced only for free-space Gaussian (Sim4Life limitation)</li> <li>No detuning detection: Cannot determine actual antenna resonant frequency in near-field conditions</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#primary-goal-antenna-detuning-detection","title":"Primary Goal: Antenna Detuning Detection","text":"<p>The Problem: - Antennas are narrowband devices (10-30 MHz bandwidth) - When near the body, antenna resonance shifts significantly (50-100 MHz) - Running at nominal frequency may miss the actual resonant frequency - Current harmonic simulations assume antenna operates at design frequency</p> <p>The Solution: - Use Gaussian pulse excitation to sweep a frequency range - Extract continuous frequency response from Sim4Life's automatic FFT - Identify actual resonant frequency (maximum accepted power) - Quantify detuning and assess impact on SAR patterns</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#secondary-goals","title":"Secondary Goals","text":"<ul> <li>Enable frequency-sweep SAR studies</li> <li>Material handling (Copper\u2192PEC workaround for all Gaussian)</li> <li>Proper simulation timing (pulse duration + frequency resolution)</li> <li>Power/SAR extraction at appropriate frequencies</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#critical-realizations","title":"Critical Realizations","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#1-sim4life-performs-automatic-fft-post-processing","title":"1. Sim4Life Performs Automatic FFT Post-Processing","text":"<p>Key Discovery: Sim4Life automatically converts time-domain Gaussian pulse responses into frequency-domain data via FFT.</p> <p>What This Means: - No manual frequency sampling needed: The 21-frequency setup for far-field sensors is ONLY for radiation patterns - Continuous frequency spectra: Edge sensor outputs like <code>\"EM Input Power(f)\"</code> provide complete frequency arrays - Data structure: <code>Data.Axis</code> contains the full frequency array (Hz), <code>Data.GetComponent(0)</code> contains values at each frequency - Resolution: Determined by simulation time: <code>\u0394f = 1/T_sim</code> (NOT by manual sampling!)</p> <p>Example extraction: <pre><code>input_power_output = input_power_extractor.Outputs[\"EM Input Power(f)\"]\nfreq_axis_hz = input_power_output.Data.Axis  # Full frequency array (e.g., 1000+ points)\npower_data_w = input_power_output.Data.GetComponent(0)  # Power at each frequency\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#2-simulation-time-requirements-updated","title":"2. Simulation Time Requirements (UPDATED)","text":"<p>Three constraints determine simulation time:</p> <ol> <li>Propagation time: <code>T_prop = L_bbox/c</code> (with PML, 1\u00d7 is sufficient, NOT 2\u00d7)</li> <li>Pulse duration: <code>T_pulse = 2k\u00b7\u03c3 \u2248 2.22/BW</code> (for complete pulse)</li> <li>Frequency resolution (NEW and DOMINANT): <code>T_resolution = 1/\u0394f_target</code></li> </ol> <p>Critical Finding: For narrowband antenna characterization (BW = 10-30 MHz, detecting 50-100 MHz shifts), frequency resolution dominates: - Required: <code>\u0394f \u2264 5 MHz</code> (at least 2-6 points across antenna bandwidth) - This requires: <code>T_sim \u2265 200 ns</code> (140 periods @ 700 MHz) - Compare to old approach: ~5-10 ns (SEVERELY insufficient!)</p> <p>Updated Formula: <pre><code>T_sim = max(multiplier \u00b7 L_bbox/c, L_bbox/c + 2k\u00b7\u03c3, 1/\u0394f_target)\n</code></pre></p> <p>See <code>docs/technical/gaussian_pulse_timing_analysis.md</code> for complete analysis.</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#3-power-extraction-is-straightforward","title":"3. Power Extraction is Straightforward","text":"<p>Resolution: <code>GetPower()</code> returns total accepted power (integrated, not density).</p> <p>For Gaussian excitation: - Extract full frequency-dependent power: <code>\"EM Input Power(f)\"</code> - Data is already computed by Sim4Life's FFT - Maximum power \u2192 resonant frequency - No integration needed (Sim4Life does it internally)</p> <p>For SAR normalization: - Extract power at center frequency (or detected resonance) - Use this single value for SAR normalization - Consistent with harmonic approach</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#4-practical-antenna-characteristics-from-experiments","title":"4. Practical Antenna Characteristics (From Experiments)","text":"<p>Measured antenna behavior: - Bandwidth: 10-30 MHz (narrowband, high Q \u2248 20-40) - Detuning when near body: 50-100 MHz shift (can be substantial!) - Implications:    - Need excellent frequency resolution (\u22645 MHz)   - Excitation bandwidth must cover potential shift range   - Sharp resonance peaks require dense frequency sampling</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#5-material-limitation","title":"5. Material Limitation","text":"<p>Sim4Life Limitation: Gaussian excitation doesn't support dispersive materials like Copper. Must force to PEC.</p> <p>Current Code: Only applies when <code>free_space AND gaussian</code> Required: Apply for ANY Gaussian excitation (not just free-space)</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#6-recommended-excitation-bandwidths","title":"6. Recommended Excitation Bandwidths","text":"<p>Based on antenna characteristics:</p> <p>Option 1: Narrow bandwidth (50 MHz) - Recommended - Covers \u00b125 MHz around nominal frequency - Better frequency resolution for given simulation time - May need multiple simulations if shift &gt; 25 MHz</p> <p>Option 2: Wide bandwidth (150 MHz) - Better coverage - Covers \u00b175 MHz (handles most detuning cases) - Slightly shorter pulse duration - Wastes computation on non-responsive frequencies</p> <p>Option 3: Two-stage (Optimal but complex) - Stage 1: Wide sweep (150 MHz) for coarse detection - Stage 2: Narrow sweep (30-50 MHz) centered on detected resonance</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#implementation-strategy","title":"Implementation Strategy","text":"<p>Pragmatic Approach: Build First, Optimize Later</p> <p>Rather than trying to validate Sim4Life's internal post-processing before implementation, we'll: 1. \u2705 Build full working implementation with conservative defaults 2. \u2705 Make simulation time tunable via config parameter 3. \u2705 Start conservative (assume standard FFT: <code>\u0394f = 1/T_sim</code>) 4. \u2705 Add speedup factor for later optimization (<code>s4l_arma_speedup_factor</code>) 5. \u2705 Run sensitivity analysis AFTER stable code exists</p> <p>Key insight: We can't validate without working code, so build it first!</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#implementation-tasks","title":"Implementation Tasks","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#phase-0-configuration-design-new-quick-setup","title":"Phase 0: Configuration Design (NEW - Quick Setup)","text":"<p>Purpose: Define config parameters that make implementation tunable and future-proof.</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#01-add-config-parameters-to-base_configjson","title":"0.1 Add Config Parameters to <code>base_config.json</code>","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#task-011-add-gaussian-specific-parameters","title":"Task 0.1.1: Add Gaussian-specific parameters","text":"<ul> <li> Open <code>configs/base_config.json</code></li> <li> Add to <code>simulation_parameters</code> section:</li> </ul> <pre><code>\"simulation_parameters\": {\n    \"excitation_type\": \"Harmonic\",\n    \"bandwidth_mhz\": 50.0,\n    \"target_freq_resolution_mhz\": 5.0,\n    \"s4l_arma_speedup_factor\": 1.0,\n    \"simulation_time_multiplier\": 3.5,\n    \"global_auto_termination\": \"GlobalAutoTerminationUserDefined\",\n    \"convergence_level_dB\": -15,\n    // ... existing params\n}\n</code></pre>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-012-document-new-parameters","title":"Task 0.1.2: Document new parameters","text":"<p>Add inline comments: - [ ] <code>excitation_type</code>: <code>\"Harmonic\"</code> (default) or <code>\"Gaussian\"</code> (broadband frequency sweep) - [ ] <code>bandwidth_mhz</code>: Excitation bandwidth for Gaussian pulse (typical: 50-150 MHz) - [ ] <code>target_freq_resolution_mhz</code>: Desired frequency resolution for antenna characterization (smaller = better resolution = longer sim time) - [ ] <code>s4l_arma_speedup_factor</code>: Speedup multiplier if Sim4Life uses advanced post-processing (1.0 = conservative, no assumptions; 2.0 = assume 2\u00d7 ARMA speedup; test empirically)</p> <p>Estimated Time: 15 minutes Dependencies: None</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#phase-0-summary","title":"Phase 0 Summary","text":"<p>Outcome: Config structure ready for Gaussian implementation with tunable timing.</p> <p>Key Design: The <code>s4l_arma_speedup_factor</code> makes it easy to test different assumptions: - Start with 1.0 (conservative, guaranteed correct) - After implementation, run tests with [1.0, 1.5, 2.0, 3.0, 4.0] - Update default based on empirical findings</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#phase-1-core-code-changes","title":"Phase 1: Core Code Changes","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#11-source-setup-goliatsetupssource_setuppy","title":"1.1 Source Setup (<code>goliat/setups/source_setup.py</code>)","text":"<p>File: <code>goliat/setups/source_setup.py</code> Current Behavior: Hardcodes Harmonic for non-free-space, Gaussian only for free-space Required Changes: Make excitation type config-driven</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-111-replace-free_space-check-with-excitation_type-config","title":"Task 1.1.1: Replace free_space check with excitation_type config","text":"<ul> <li> Remove <code>if self.free_space:</code> check on line 60</li> <li> Read <code>excitation_type</code> from config: <code>self.config[\"simulation_parameters.excitation_type\"]</code></li> <li> Default to <code>\"Harmonic\"</code> if not set</li> <li> Normalize to lowercase for comparison</li> <li> Set excitation type based on config value</li> </ul> <p>Code Pattern: <pre><code>excitation_type = self.config[\"simulation_parameters.excitation_type\"] or \"Harmonic\"\nexcitation_type_lower = excitation_type.lower() if isinstance(excitation_type, str) else \"harmonic\"\n\nif excitation_type_lower == \"gaussian\":\n    # Gaussian setup\nelse:\n    # Harmonic setup\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-112-read-bandwidth-from-config","title":"Task 1.1.2: Read bandwidth from config","text":"<ul> <li> Read <code>bandwidth_mhz</code> from config: <code>self.config[\"simulation_parameters.bandwidth_mhz\"]</code></li> <li> Default to <code>50.0</code> MHz if not set</li> <li> Use config value instead of hardcoded <code>50.0</code> on line 65</li> <li> Add validation: ensure bandwidth is positive and reasonable (e.g., 10-200 MHz)</li> <li> Log bandwidth value being used</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-113-configure-gaussian-excitation","title":"Task 1.1.3: Configure Gaussian excitation","text":"<ul> <li> Set <code>edge_source_settings.ExcitationType = excitation_enum.Gaussian</code></li> <li> Set <code>edge_source_settings.CenterFrequency = self.frequency_mhz, self.units.MHz</code></li> <li> Set <code>edge_source_settings.Bandwidth = bandwidth_mhz, self.units.MHz</code> (from config)</li> <li> Update log message to include bandwidth</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-114-configure-harmonic-excitation-default","title":"Task 1.1.4: Configure Harmonic excitation (default)","text":"<ul> <li> Set <code>edge_source_settings.ExcitationType = excitation_enum.Harmonic</code></li> <li> Set both <code>Frequency</code> and <code>CenterFrequency</code> to <code>self.frequency_mhz</code></li> <li> Keep existing behavior for backward compatibility</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-115-add-far-field-sensors-for-gaussian-not-just-free-space","title":"Task 1.1.5: Add far-field sensors for Gaussian (not just free-space)","text":"<ul> <li> Move far-field sensor setup outside <code>if self.free_space:</code> block</li> <li> Add far-field sensors when <code>excitation_type_lower == \"gaussian\"</code></li> <li> Calculate extracted frequencies using config bandwidth</li> <li> Use same logic as current free-space code (21 frequencies)</li> <li> Update log message to remove \"free-space\" reference</li> </ul> <p>Frequency Calculation: <pre><code>if excitation_type_lower == \"gaussian\":\n    center_freq_hz = self.frequency_mhz * 1e6\n    bandwidth_mhz = self.config[\"simulation_parameters.bandwidth_mhz\"] or 50.0\n    bandwidth_hz = bandwidth_mhz * 1e6\n    start_freq_hz = center_freq_hz - (bandwidth_hz / 2)\n    end_freq_hz = center_freq_hz + (bandwidth_hz / 2)\n    num_samples = 21\n    extracted_frequencies_hz = [\n        start_freq_hz + i * (bandwidth_hz / (num_samples - 1)) \n        for i in range(num_samples)\n    ]\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-116-update-docstring","title":"Task 1.1.6: Update docstring","text":"<ul> <li> Update method docstring to reflect config-driven behavior</li> <li> Remove mention of \"free-space\" determining excitation type</li> <li> Document <code>excitation_type</code> and <code>bandwidth_mhz</code> config parameters</li> <li> Add note about far-field sensors for Gaussian</li> </ul> <p>Estimated Time: 2-3 hours Dependencies: None Testing: Unit tests, manual verification with both Harmonic and Gaussian configs</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#12-material-setup-goliatsetupsmaterial_setuppy","title":"1.2 Material Setup (<code>goliat/setups/material_setup.py</code>)","text":"<p>File: <code>goliat/setups/material_setup.py</code> Current Behavior: Copper\u2192PEC workaround only for <code>free_space AND gaussian</code> Required Changes: Apply workaround for ANY Gaussian excitation</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-121-remove-free_space-condition-from-copper-workaround","title":"Task 1.2.1: Remove free_space condition from Copper workaround","text":"<ul> <li> Remove <code>self.free_space</code> check on line 153</li> <li> Keep <code>excitation_type</code> check</li> <li> Apply PEC workaround whenever <code>excitation_type == \"gaussian\"</code> AND material contains \"Copper\"</li> </ul> <p>Code Pattern: <pre><code>excitation_type = self.config[\"simulation_parameters.excitation_type\"]\nif excitation_type is None:\n    excitation_type = \"Harmonic\"\nexcitation_type_lower = excitation_type.lower() if isinstance(excitation_type, str) else \"harmonic\"\n\n# Sim4Life limitation: Gaussian excitation doesn't support dispersive materials like Copper\nif \"Copper\" in mat_name and excitation_type_lower == \"gaussian\":\n    material_settings.Type = \"PEC\"\n    # ... rest of workaround code\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-122-update-warning-message","title":"Task 1.2.2: Update warning message","text":"<ul> <li> Remove \"free-space\" reference from warning message (lines 161-168)</li> <li> Update to: \"Gaussian excitation with dispersive materials like Copper\"</li> <li> Keep the prominent warning format (80-character separator)</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-123-update-docstring","title":"Task 1.2.3: Update docstring","text":"<ul> <li> Update <code>_assign_antenna_materials</code> docstring (line 132)</li> <li> Remove \"free-space Gaussian\" reference</li> <li> Update to: \"forces PEC for Copper in Gaussian excitation (Sim4Life limitation)\"</li> </ul> <p>Estimated Time: 1 hour Dependencies: Task 1.1.1 (excitation_type config) Testing: Verify Copper components become PEC in Gaussian config, remain normal in Harmonic</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#13-simulation-time-calculation-goliatsetupsbase_setuppy-updated","title":"1.3 Simulation Time Calculation (<code>goliat/setups/base_setup.py</code>) - UPDATED","text":"<p>File: <code>goliat/setups/base_setup.py</code> Method: <code>_apply_simulation_time_and_termination</code> Current Behavior: Simple multiplier approach: <code>multiplier \u00b7 L_bbox/c</code> Required Changes: Add Gaussian pulse duration AND frequency resolution requirements</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-131-detect-excitation-type","title":"Task 1.3.1: Detect excitation type","text":"<ul> <li> Read <code>excitation_type</code> from config in <code>_apply_simulation_time_and_termination</code></li> <li> Check if excitation type is Gaussian</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-132-calculate-pulse-duration-for-gaussian","title":"Task 1.3.2: Calculate pulse duration for Gaussian","text":"<ul> <li> Read <code>bandwidth_mhz</code> from config (default: 50 MHz for narrow bandwidth)</li> <li> Convert to Hz: <code>bandwidth_hz = bandwidth_mhz * 1e6</code></li> <li> Calculate temporal standard deviation: <code>sigma = 0.94 / (np.pi * bandwidth_hz)</code></li> <li> Use conservative threshold: <code>k = 3.7</code> (for 0.1% of peak)</li> <li> Calculate pulse duration: <code>T_pulse = 2 * k * sigma</code></li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-133-calculate-frequency-resolution-requirement-with-arma-speedup-factor-new-critical","title":"Task 1.3.3: Calculate frequency resolution requirement with ARMA speedup factor (NEW - CRITICAL!)","text":"<ul> <li> Read <code>target_freq_resolution_mhz</code> from config (default: 5 MHz for antenna characterization)</li> <li> Read <code>s4l_arma_speedup_factor</code> from config (default: 1.0 = conservative, no ARMA assumptions)</li> <li> Convert to Hz: <code>target_freq_resolution_hz = target_freq_resolution_mhz * 1e6</code></li> <li> Calculate time for resolution WITH speedup: <code>T_resolution = s4l_arma_speedup_factor / target_freq_resolution_hz</code></li> <li> Examples:</li> <li>speedup=1.0, \u0394f=5MHz \u2192 T_resolution = 200 ns (conservative)</li> <li>speedup=2.0, \u0394f=5MHz \u2192 T_resolution = 100 ns (assumes ARMA helps 2\u00d7)</li> <li>speedup=4.0, \u0394f=5MHz \u2192 T_resolution = 50 ns (aggressive)</li> <li> With default (speedup=1.0), resolution typically dominates (~200 ns) over pulse (~44 ns) and propagation (~5 ns)</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-134-calculate-required-time-three-constraints","title":"Task 1.3.4: Calculate required time (THREE constraints)","text":"<ul> <li> Calculate propagation time: <code>T_prop = diagonal_length_m / c</code> (already done)</li> <li> Calculate allocated time: <code>T_allocated = multiplier * T_prop</code> (current approach)</li> <li> Use maximum of ALL THREE constraints: <code>T_sim = max(T_allocated, T_prop + T_pulse, T_resolution)</code></li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-135-convert-to-periods","title":"Task 1.3.5: Convert to periods","text":"<ul> <li> Use <code>T_sim</code> (not <code>T_allocated</code>) for period calculation</li> <li> Convert: <code>sim_time_periods = T_sim / (1 / (frequency_mhz * 1e6))</code></li> <li> Note: This may result in 100-200+ periods (much more than typical 3-10)</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-136-add-comprehensive-logging","title":"Task 1.3.6: Add comprehensive logging","text":"<ul> <li> Log all three time components (propagation, pulse, resolution)</li> <li> Log which constraint dominated</li> <li> Log final simulation time in ns and periods</li> <li> Warn if simulation time seems excessive (&gt; 500 ns)</li> </ul> <p>Updated Code Pattern: <pre><code>excitation_type = self.config[\"simulation_parameters.excitation_type\"]\nexcitation_type_lower = excitation_type.lower() if isinstance(excitation_type, str) else \"harmonic\"\n\ntime_multiplier = self.config[\"simulation_parameters.simulation_time_multiplier\"]\nT_prop = diagonal_length_m / 299792458.0  # c in m/s\n\nif excitation_type_lower == \"gaussian\":\n    # Get configuration\n    bandwidth_mhz = self.config[\"simulation_parameters.bandwidth_mhz\"]\n    target_freq_resolution_mhz = self.config[\"simulation_parameters.target_freq_resolution_mhz\"]\n    arma_speedup = self.config[\"simulation_parameters.s4l_arma_speedup_factor\"]  # Default: conservative\n    \n    # Calculate constraints\n    bandwidth_hz = bandwidth_mhz * 1e6\n    k = 3.7  # Conservative threshold\n    sigma = 0.94 / (np.pi * bandwidth_hz)\n    T_pulse = 2 * k * sigma\n    \n    # Frequency resolution WITH speedup factor\n    # arma_speedup = 1.0 \u2192 conservative (200 ns for 5 MHz)\n    # arma_speedup = 2.0 \u2192 moderate (100 ns for 5 MHz, assumes ARMA helps)\n    # arma_speedup = 4.0 \u2192 aggressive (50 ns for 5 MHz)\n    T_resolution = arma_speedup / (target_freq_resolution_mhz * 1e6)\n    \n    # Three competing requirements\n    T_allocated = time_multiplier * T_prop  # Multiplier approach\n    T_prop_plus_pulse = T_prop + T_pulse    # Propagation + pulse\n    \n    # Take maximum\n    T_sim = max(T_allocated, T_prop_plus_pulse, T_resolution)\n    \n    # Log decision\n    self._log(f\"  - Gaussian excitation timing breakdown:\", log_type=\"info\")\n    self._log(f\"    - Propagation (with multiplier): {T_allocated*1e9:.1f} ns\", log_type=\"info\")\n    self._log(f\"    - Propagation + Pulse: {T_prop_plus_pulse*1e9:.1f} ns\", log_type=\"info\")\n    self._log(f\"    - Frequency resolution ({target_freq_resolution_mhz} MHz, speedup={arma_speedup}): {T_resolution*1e9:.1f} ns\", log_type=\"info\")\n    \n    if T_sim == T_resolution:\n        self._log(f\"  - FREQUENCY RESOLUTION DOMINATES (typical for antenna characterization)\", log_type=\"highlight\")\n    elif T_sim == T_prop_plus_pulse:\n        self._log(f\"  - Pulse duration dominates\", log_type=\"info\")\n    else:\n        self._log(f\"  - Multiplier approach sufficient\", log_type=\"info\")\n    \n    self._log(f\"  - Final simulation time: {T_sim*1e9:.1f} ns\", log_type=\"highlight\")\n    sim_time_periods = T_sim / (1 / (frequency_mhz * 1e6))\n    \nelse:\n    # Harmonic: use multiplier approach\n    sim_time_periods = (time_multiplier * T_prop) / (1 / (frequency_mhz * 1e6))\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-137-add-configuration-parameters-done-in-phase-0","title":"Task 1.3.7: Add configuration parameters (DONE in Phase 0)","text":"<ul> <li> Add to <code>base_config.json</code>: <code>\"target_freq_resolution_mhz\": 5.0</code></li> <li> Add to <code>base_config.json</code>: <code>\"s4l_arma_speedup_factor\": 1.0</code></li> <li> Document that smaller <code>target_freq_resolution_mhz</code> (better resolution) = longer simulation time</li> <li> Document relationship WITH speedup factor: <code>T_sim = speedup/\u0394f</code></li> <li>speedup=1.0, \u0394f=5MHz \u2192 200 ns (conservative)</li> <li>speedup=2.0, \u0394f=5MHz \u2192 100 ns (moderate, test later)</li> <li>speedup=4.0, \u0394f=5MHz \u2192 50 ns (aggressive, test later)</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-138-import-numpy-if-needed","title":"Task 1.3.8: Import numpy if needed","text":"<ul> <li> Ensure <code>numpy</code> is imported as <code>np</code> (check existing imports)</li> </ul> <p>Estimated Time: 3-4 hours (more complex due to three constraints) Dependencies: None Testing: Verify simulation time is appropriate for antenna characterization (expect ~200 ns, 140+ periods)</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#14-power-extraction-goliatextractionpower_extractorpy-clarified","title":"1.4 Power Extraction (<code>goliat/extraction/power_extractor.py</code>) - CLARIFIED","text":"<p>File: <code>goliat/extraction/power_extractor.py</code> Current Behavior: Handles multi-frequency data, extracts at center frequency Status: Already works correctly! Sim4Life does FFT automatically.</p> <p>Key Understanding:  - <code>GetPower()</code> returns total integrated power (NOT density) - For Gaussian, Sim4Life provides frequency-dependent power via FFT - Current code (lines 228-243) already handles multi-frequency correctly</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-141-verify-getpower-behavior-with-gaussian-low-priority","title":"Task 1.4.1: Verify GetPower() behavior with Gaussian (Low priority)","text":"<ul> <li> Test <code>GetPower(0)</code> with Gaussian source to confirm it returns total power</li> <li> RESOLVED: It returns integrated power, not density</li> <li> Document in code comments for future reference</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-142-verify-multi-frequency-extraction","title":"Task 1.4.2: Verify multi-frequency extraction","text":"<ul> <li> Current code (lines 236-243) already handles multi-frequency data</li> <li> Verify it correctly finds center frequency using <code>np.argmin(np.abs(axis - center_freq_hz))</code></li> <li> Test with Gaussian source to ensure it works</li> <li> Add logging to show which frequency was selected</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-143-consider-bandwidth-integration-if-needed","title":"Task 1.4.3: Consider bandwidth integration (if needed)","text":"<ul> <li> If <code>GetPower()</code> returns density, implement integration</li> <li> Integrate <code>EM Input Power(f)</code> over bandwidth range</li> <li> Use trapezoidal rule or simple sum</li> <li> Document integration method</li> </ul> <p>Integration Pattern (if needed): <pre><code># Get frequency axis and power data\naxis = input_power_output.Data.Axis  # Hz\npower_data = input_power_output.Data.GetComponent(0)  # W or W/Hz\n\n# Find bandwidth range\ncenter_freq_hz = self.frequency_mhz * 1e6\nbandwidth_mhz = self.config[\"simulation_parameters.bandwidth_mhz\"] or 50.0\nbandwidth_hz = bandwidth_mhz * 1e6\nstart_freq = center_freq_hz - bandwidth_hz / 2\nend_freq = center_freq_hz + bandwidth_hz / 2\n\n# Find indices in range\nmask = (axis &gt;= start_freq) &amp; (axis &lt;= end_freq)\nfreqs_in_range = axis[mask]\npower_in_range = power_data[mask]\n\n# Integrate (trapezoidal rule)\nif len(freqs_in_range) &gt; 1:\n    total_power = np.trapz(power_in_range, freqs_in_range)\nelse:\n    total_power = power_in_range[0] * bandwidth_hz  # Fallback\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-144-add-excitation-type-detection","title":"Task 1.4.4: Add excitation type detection","text":"<ul> <li> Read <code>excitation_type</code> from config</li> <li> Add logging for Gaussian vs Harmonic</li> <li> Use appropriate extraction method based on type</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-145-update-docstring","title":"Task 1.4.5: Update docstring","text":"<ul> <li> Document Gaussian source handling</li> <li> Explain power extraction strategy</li> <li> Note any limitations or assumptions</li> </ul> <p>Estimated Time: 3-4 hours (includes testing/investigation) Dependencies: Task 1.1.1 (excitation_type config) Testing: Compare power values between Harmonic and Gaussian at center frequency</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#15-sar-extraction-goliatextractionsar_extractorpy","title":"1.5 SAR Extraction (<code>goliat/extraction/sar_extractor.py</code>)","text":"<p>File: <code>goliat/extraction/sar_extractor.py</code> Current Behavior: Uses <code>ExtractedFrequency = \"All\"</code> Status: May work, but needs verification for Gaussian</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-151-investigate-sar-extraction-with-gaussian","title":"Task 1.5.1: Investigate SAR extraction with Gaussian","text":"<ul> <li> Test current <code>ExtractedFrequency = \"All\"</code> approach with Gaussian</li> <li> Verify SAR evaluator handles multi-frequency data correctly</li> <li> Determine: Does it extract SAR at all frequencies or just one?</li> <li> Check if \"f0\" output name means first frequency only</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-152-implement-frequency-selection-strategy","title":"Task 1.5.2: Implement frequency selection strategy","text":"<ul> <li> Option A: Extract at center frequency only</li> <li>Set <code>ExtractedFrequency = center_freq_hz</code> (not \"All\")</li> <li>Simpler, matches Harmonic behavior</li> <li> Option B: Extract at all frequencies, report center</li> <li>Keep \"All\", but select center frequency from results</li> <li>More complex, but preserves all data</li> <li> Option C: Extract at all frequencies, integrate/average</li> <li>Most complex, may not be needed</li> </ul> <p>Recommendation: Start with Option A (center frequency only), test, then consider others if needed.</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-153-add-excitation-type-detection","title":"Task 1.5.3: Add excitation type detection","text":"<ul> <li> Read <code>excitation_type</code> from config</li> <li> Set <code>ExtractedFrequency</code> based on excitation type</li> <li> For Harmonic: use \"All\" (current behavior)</li> <li> For Gaussian: use center frequency (or \"All\" if testing)</li> </ul> <p>Code Pattern: <pre><code>excitation_type = self.config[\"simulation_parameters.excitation_type\"] or \"Harmonic\"\nexcitation_type_lower = excitation_type.lower() if isinstance(excitation_type, str) else \"harmonic\"\n\nem_sensor_extractor = simulation_extractor[\"Overall Field\"]\n\nif excitation_type_lower == \"gaussian\":\n    # Extract at center frequency for Gaussian\n    center_freq_hz = self.frequency_mhz * 1e6\n    em_sensor_extractor.FrequencySettings.ExtractedFrequency = center_freq_hz, self.units.Hz\n    self._log(f\"  - Extracting SAR at center frequency: {self.frequency_mhz} MHz\", log_type=\"info\")\nelse:\n    # Harmonic: extract all frequencies\n    em_sensor_extractor.FrequencySettings.ExtractedFrequency = \"All\"\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-154-verify-sar-normalization","title":"Task 1.5.4: Verify SAR normalization","text":"<ul> <li> Ensure SAR values are normalized correctly</li> <li> Power used for normalization should match extraction method</li> <li> Compare SAR values between Harmonic and Gaussian at center frequency</li> <li> They should be similar (within numerical tolerance)</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-155-update-docstring","title":"Task 1.5.5: Update docstring","text":"<ul> <li> Document frequency selection strategy</li> <li> Explain why center frequency is used for Gaussian</li> <li> Note any limitations</li> </ul> <p>Estimated Time: 3-4 hours (includes testing/investigation) Dependencies: Task 1.1.1 (excitation_type config), Task 1.4 (power extraction) Testing: Compare SAR values between Harmonic and Gaussian, verify normalization</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#16-resonance-frequency-extraction-new-critical-for-antenna-characterization","title":"1.6 Resonance Frequency Extraction (NEW - CRITICAL FOR ANTENNA CHARACTERIZATION)","text":"<p>File: NEW - <code>goliat/extraction/resonance_extractor.py</code> OR add to existing <code>power_extractor.py</code> Purpose: Extract antenna resonant frequency and detuning information from Gaussian results Status: This is the main goal of using Gaussian excitation!</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-161-create-extraction-method","title":"Task 1.6.1: Create extraction method","text":"<p>Core functionality: <pre><code>def extract_resonance_frequency(self, simulation_extractor):\n    \"\"\"Extract antenna resonant frequency from Gaussian pulse results.\n    \n    Analyzes frequency-dependent accepted power to identify resonance peak.\n    Calculates detuning relative to nominal frequency.\n    Generates frequency response plot.\n    \n    Returns:\n        dict: Contains resonant_freq_mhz, detuning_mhz, max_power_w, freq_resolution_mhz\n    \"\"\"\n    # Extract full frequency spectrum\n    input_power_extractor = simulation_extractor[\"Input Power\"]\n    self.document.AllAlgorithms.Add(input_power_extractor)\n    input_power_extractor.Update()\n    \n    input_power_output = input_power_extractor.Outputs[\"EM Input Power(f)\"]\n    input_power_output.Update()\n    \n    # Get continuous frequency data (automatically from FFT)\n    freq_axis_hz = input_power_output.Data.Axis  # Full freq array\n    power_data_w = input_power_output.Data.GetComponent(0)  # Power at each freq\n    \n    # Convert to MHz\n    freq_axis_mhz = freq_axis_hz / 1e6\n    \n    # Find resonant frequency (maximum accepted power)\n    max_idx = np.argmax(power_data_w)\n    resonant_freq_mhz = freq_axis_mhz[max_idx]\n    max_power_w = power_data_w[max_idx]\n    \n    # Calculate detuning\n    nominal_freq_mhz = self.frequency_mhz\n    detuning_mhz = resonant_freq_mhz - nominal_freq_mhz\n    \n    # Calculate frequency resolution\n    freq_resolution_mhz = (freq_axis_hz[1] - freq_axis_hz[0]) / 1e6\n    \n    # Log results\n    self._log(f\"\\n{'='*80}\", log_type=\"highlight\")\n    self._log(f\"  ANTENNA RESONANCE ANALYSIS\", log_type=\"highlight\")\n    self._log(f\"{'='*80}\", log_type=\"highlight\")\n    self._log(f\"  Nominal frequency: {nominal_freq_mhz} MHz\", log_type=\"info\")\n    self._log(f\"  Detected resonance: {resonant_freq_mhz:.2f} MHz\", log_type=\"highlight\")\n    self._log(f\"  Detuning: {detuning_mhz:+.2f} MHz ({detuning_mhz/nominal_freq_mhz*100:+.1f}%)\", \n              log_type=\"highlight\" if abs(detuning_mhz) &gt; 10 else \"info\")\n    self._log(f\"  Max power at resonance: {max_power_w*1000:.2f} mW\", log_type=\"info\")\n    self._log(f\"  Frequency resolution: {freq_resolution_mhz:.2f} MHz\", log_type=\"info\")\n    self._log(f\"  Number of frequency points: {len(freq_axis_hz)}\", log_type=\"info\")\n    self._log(f\"{'='*80}\\n\", log_type=\"highlight\")\n    \n    # Store results\n    resonance_data = {\n        \"resonant_freq_mhz\": float(resonant_freq_mhz),\n        \"nominal_freq_mhz\": float(nominal_freq_mhz),\n        \"detuning_mhz\": float(detuning_mhz),\n        \"detuning_percent\": float(detuning_mhz / nominal_freq_mhz * 100),\n        \"max_power_w\": float(max_power_w),\n        \"freq_resolution_mhz\": float(freq_resolution_mhz),\n        \"num_freq_points\": int(len(freq_axis_hz)),\n        \"frequency_axis_mhz\": freq_axis_mhz.tolist(),  # For plotting\n        \"power_data_w\": power_data_w.tolist(),  # For plotting\n    }\n    \n    # Clean up\n    self.document.AllAlgorithms.Remove(input_power_extractor)\n    \n    return resonance_data\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-162-generate-frequency-response-plot","title":"Task 1.6.2: Generate frequency response plot","text":"<ul> <li> Create matplotlib plot of power vs frequency</li> <li> Mark resonant frequency with vertical line</li> <li> Mark nominal frequency with vertical line</li> <li> Add bandwidth indicators (\u00b1BW/2 at half-power points)</li> <li> Save as PNG in results directory</li> <li> Include in HTML report</li> </ul> <p>Plot code: <pre><code>def plot_frequency_response(self, freq_axis_mhz, power_data_w, \n                           resonant_freq_mhz, nominal_freq_mhz, \n                           output_path):\n    \"\"\"Generate and save frequency response plot.\"\"\"\n    import matplotlib.pyplot as plt\n    \n    fig, ax = plt.subplots(figsize=(12, 7))\n    \n    # Plot power vs frequency\n    ax.plot(freq_axis_mhz, power_data_w * 1000, 'b-', linewidth=2, label='Accepted Power')\n    \n    # Mark resonance\n    ax.axvline(resonant_freq_mhz, color='r', linestyle='--', linewidth=2,\n               label=f'Resonance: {resonant_freq_mhz:.1f} MHz')\n    \n    # Mark nominal\n    ax.axvline(nominal_freq_mhz, color='g', linestyle='--', linewidth=2,\n               label=f'Nominal: {nominal_freq_mhz} MHz')\n    \n    # Labels and formatting\n    detuning = resonant_freq_mhz - nominal_freq_mhz\n    ax.set_xlabel('Frequency (MHz)', fontsize=14)\n    ax.set_ylabel('Accepted Power (mW)', fontsize=14)\n    ax.set_title(f'Antenna Frequency Response\\nDetuning: {detuning:+.1f} MHz ({detuning/nominal_freq_mhz*100:+.1f}%)', \n                 fontsize=16, fontweight='bold')\n    ax.grid(True, alpha=0.3, linestyle=':', linewidth=1)\n    ax.legend(fontsize=12, loc='best')\n    \n    # Format axes\n    ax.tick_params(labelsize=12)\n    \n    plt.tight_layout()\n    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    \n    self._log(f\"  - Frequency response plot saved: {output_path}\", log_type=\"success\")\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-163-integrate-into-results-extraction-pipeline","title":"Task 1.6.3: Integrate into results extraction pipeline","text":"<ul> <li> Call <code>extract_resonance_frequency()</code> from <code>ResultsExtractor.extract()</code> when Gaussian</li> <li> Add to <code>results_data</code> dictionary</li> <li> Include in JSON output</li> <li> Add to HTML report generation</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-164-warning-for-severe-detuning","title":"Task 1.6.4: Warning for severe detuning","text":"<ul> <li> Check if <code>abs(detuning_mhz) &gt; threshold</code> (e.g., 50 MHz)</li> <li> Log prominent warning if antenna is significantly detuned</li> <li> Suggest re-running simulation at detected resonance for better accuracy</li> <li> Document that SAR pattern may be affected by operating off-resonance</li> </ul> <p>Warning code: <pre><code>if abs(detuning_mhz) &gt; 50:\n    self._log(\"\\n\" + \"!\" * 80, log_type=\"warning\")\n    self._log(\"  WARNING: SIGNIFICANT ANTENNA DETUNING DETECTED!\", log_type=\"warning\")\n    self._log(f\"  The antenna has shifted {detuning_mhz:+.1f} MHz from nominal frequency.\", log_type=\"warning\")\n    self._log(\"  Consider:\", log_type=\"warning\")\n    self._log(f\"    1. Re-running simulation at detected resonance ({resonant_freq_mhz:.0f} MHz)\", log_type=\"warning\")\n    self._log(\"    2. Verifying antenna design for this placement scenario\", log_type=\"warning\")\n    self._log(\"    3. Checking if SAR pattern is affected by off-resonance operation\", log_type=\"warning\")\n    self._log(\"!\" * 80 + \"\\n\", log_type=\"warning\")\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-165-add-to-html-report-template","title":"Task 1.6.5: Add to HTML report template","text":"<ul> <li> Create new section \"Antenna Characterization\" in HTML report</li> <li> Display resonance frequency, detuning, and resolution</li> <li> Embed frequency response plot</li> <li> Add interpretation text explaining significance</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-166-unit-tests","title":"Task 1.6.6: Unit tests","text":"<ul> <li> Test with synthetic frequency data (known peak)</li> <li> Test edge cases (peak at boundary, flat response, multiple peaks)</li> <li> Verify calculation accuracy</li> <li> Test plot generation</li> </ul> <p>Estimated Time: 6-8 hours (new functionality, plotting, integration) Dependencies: Task 1.4 (power extraction) Testing:  - Run with Gaussian config - Verify resonance detection matches visual inspection - Compare free-space (no detuning) vs near-field (detuning expected) - Validate plot generation and HTML integration</p> <p>Priority: HIGH - This is the main deliverable for Gaussian excitation support!</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#phase-2-configuration-files","title":"Phase 2: Configuration Files","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#21-harmonic-config-configsnear_field_harmonicjson","title":"2.1 Harmonic Config (<code>configs/near_field_harmonic.json</code>)","text":"<p>Purpose: Baseline config for comparison testing Based on: <code>configs/near_field_config.json</code></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-211-create-config-file","title":"Task 2.1.1: Create config file","text":"<ul> <li> Copy <code>configs/near_field_config.json</code> as template</li> <li> Set <code>excitation_type: \"Harmonic\"</code></li> <li> Reduce to single phantom: <code>[\"thelonious\"]</code></li> <li> Reduce to single frequency: Keep only <code>\"700\"</code> in <code>antenna_config</code></li> <li> Reduce to single placement: Keep only <code>\"front_of_eyes\"</code> with <code>\"center\"</code> position and <code>\"vertical\"</code> orientation</li> <li> Keep all other settings identical (gridding, materials, etc.)</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-212-verify-config-structure","title":"Task 2.1.2: Verify config structure","text":"<ul> <li> Ensure extends <code>base_config.json</code></li> <li> Verify <code>study_type: \"near_field\"</code></li> <li> Check all required fields present</li> <li> Validate JSON syntax</li> </ul> <p>Estimated Time: 30 minutes Dependencies: None Testing: Load config, verify it parses correctly</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#22-gaussian-config-configsnear_field_gaussianjson-updated","title":"2.2 Gaussian Config (<code>configs/near_field_gaussian.json</code>) - UPDATED","text":"<p>Purpose: Test config for Gaussian excitation with antenna characterization Based on: <code>configs/near_field_harmonic.json</code></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-221-create-config-file","title":"Task 2.2.1: Create config file","text":"<ul> <li> Copy <code>configs/near_field_harmonic.json</code> as template</li> <li> Add simulation_parameters section with Gaussian-specific settings:</li> <li><code>\"excitation_type\": \"Gaussian\"</code></li> <li><code>\"bandwidth_mhz\": 50.0</code> (narrow for high resolution, covers \u00b125 MHz)</li> <li><code>\"target_freq_resolution_mhz\": 5.0</code> (for 200 ns simulation time)</li> <li> Keep all other settings identical to harmonic config</li> </ul> <p>Example addition to config: <pre><code>\"simulation_parameters\": {\n    \"excitation_type\": \"Gaussian\",\n    \"bandwidth_mhz\": 50.0,\n    \"target_freq_resolution_mhz\": 5.0,\n    \"simulation_time_multiplier\": 3.5,\n    \"global_auto_termination\": \"GlobalAutoTerminationUserDefined\",\n    \"convergence_level_dB\": -15\n}\n</code></pre></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-222-document-simulation-time-expectations","title":"Task 2.2.2: Document simulation time expectations","text":"<ul> <li> Add comment: \"Note: Simulation time will be ~200 ns (140 periods @ 700 MHz)\"</li> <li> Add comment: \"This is driven by frequency resolution requirement, NOT pulse duration\"</li> <li> Add comment: \"For better resolution, decrease target_freq_resolution_mhz (increases sim time)\"</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-223-create-wide-bandwidth-variant-optional","title":"Task 2.2.3: Create wide-bandwidth variant (optional)","text":"<ul> <li> Create <code>near_field_gaussian_wide.json</code> for comparison</li> <li> Set <code>bandwidth_mhz: 150.0</code> (covers \u00b175 MHz)</li> <li> Keep same frequency resolution</li> <li> Use for cases where large detuning expected</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-224-verify-config-structure","title":"Task 2.2.4: Verify config structure","text":"<ul> <li> Ensure extends <code>base_config.json</code></li> <li> Verify <code>study_type: \"near_field\"</code></li> <li> Check all Gaussian parameters are set correctly</li> <li> Validate JSON syntax</li> </ul> <p>Estimated Time: 45 minutes (includes documentation) Dependencies: Task 2.1.1 Testing: Load config, verify it parses correctly, check simulation time calculation</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#phase-3-testing-validation","title":"Phase 3: Testing &amp; Validation","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#31-unit-tests","title":"3.1 Unit Tests","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#task-311-test-source-setup-with-gaussian","title":"Task 3.1.1: Test source setup with Gaussian","text":"<ul> <li> Test <code>SourceSetup.setup_source_and_sensors()</code> with Gaussian config</li> <li> Verify excitation type is set to Gaussian</li> <li> Verify bandwidth is read from config</li> <li> Verify far-field sensors are added</li> <li> Verify extracted frequencies are correct (21 samples across bandwidth)</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-312-test-material-setup-with-gaussian","title":"Task 3.1.2: Test material setup with Gaussian","text":"<ul> <li> Test <code>MaterialSetup._assign_antenna_materials()</code> with Gaussian config</li> <li> Verify Copper components are forced to PEC</li> <li> Verify warning message is logged</li> <li> Verify other materials (Rogers, PEC) are handled correctly</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-313-test-simulation-time-calculation","title":"Task 3.1.3: Test simulation time calculation","text":"<ul> <li> Test <code>BaseSetup._apply_simulation_time_and_termination()</code> with Gaussian</li> <li> Test with small bbox (should use pulse duration)</li> <li> Test with large bbox (should use multiplier)</li> <li> Verify transition point is correct</li> <li> Verify logging is correct</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-314-test-power-extraction","title":"Task 3.1.4: Test power extraction","text":"<ul> <li> Test <code>PowerExtractor._extract_near_field_power()</code> with Gaussian</li> <li> Verify multi-frequency data is handled</li> <li> Verify center frequency is selected correctly</li> <li> Compare with Harmonic power (should be similar)</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-315-test-sar-extraction","title":"Task 3.1.5: Test SAR extraction","text":"<ul> <li> Test <code>SarExtractor.extract_sar_statistics()</code> with Gaussian</li> <li> Verify frequency selection works</li> <li> Verify SAR values are reasonable</li> <li> Compare with Harmonic SAR (should be similar at center frequency)</li> </ul> <p>Estimated Time: 4-6 hours Dependencies: All Phase 1 tasks Testing: Run test suite, fix any failures</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#32-integration-tests","title":"3.2 Integration Tests","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#task-321-end-to-end-harmonic-test","title":"Task 3.2.1: End-to-end Harmonic test","text":"<ul> <li> Run full simulation with Harmonic config</li> <li> Verify setup, run, and extract phases complete</li> <li> Verify results are reasonable</li> <li> Document baseline values (power, SAR)</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-322-end-to-end-gaussian-test","title":"Task 3.2.2: End-to-end Gaussian test","text":"<ul> <li> Run full simulation with Gaussian config</li> <li> Verify setup, run, and extract phases complete</li> <li> Verify results are reasonable</li> <li> Compare with Harmonic baseline</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-323-compare-results","title":"Task 3.2.3: Compare results","text":"<ul> <li> Power at center frequency: Should be similar between Harmonic and Gaussian</li> <li> SAR at center frequency: Should be similar (within tolerance)</li> <li> Simulation time: Should be longer for Gaussian (due to pulse duration)</li> <li> Material assignment: Copper should be PEC in Gaussian, normal in Harmonic</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-324-test-edge-cases","title":"Task 3.2.4: Test edge cases","text":"<ul> <li> Very small bandwidth (10 MHz): Pulse duration should be very long</li> <li> Very large bandwidth (200 MHz): Pulse duration should be short</li> <li> Very small bbox: Pulse duration should dominate</li> <li> Very large bbox: Multiplier should dominate</li> </ul> <p>Estimated Time: 4-6 hours Dependencies: All Phase 1 and Phase 2 tasks Testing: Run full simulations, analyze results</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#33-validation-against-requirements","title":"3.3 Validation Against Requirements","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#task-331-verify-sim4life-compatibility","title":"Task 3.3.1: Verify Sim4Life compatibility","text":"<ul> <li> Verify simulations run without errors in Sim4Life</li> <li> Verify results can be extracted correctly</li> <li> Verify no Sim4Life API errors</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-332-verify-backward-compatibility","title":"Task 3.3.2: Verify backward compatibility","text":"<ul> <li> Existing Harmonic configs still work</li> <li> No breaking changes to existing functionality</li> <li> Default behavior unchanged (Harmonic)</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-333-verify-power-extraction-accuracy","title":"Task 3.3.3: Verify power extraction accuracy","text":"<ul> <li> Power values are reasonable</li> <li> Power normalization works correctly</li> <li> SAR normalization uses correct power</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-334-verify-sar-accuracy","title":"Task 3.3.4: Verify SAR accuracy","text":"<ul> <li> SAR values match Harmonic at center frequency</li> <li> SAR normalization is correct</li> <li> Peak SAR locations are reasonable</li> </ul> <p>Estimated Time: 2-3 hours Dependencies: Task 3.2 Testing: Manual verification, result analysis</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#phase-4-documentation","title":"Phase 4: Documentation","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#41-code-documentation","title":"4.1 Code Documentation","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#task-411-update-source_setuppy-docstrings","title":"Task 4.1.1: Update source_setup.py docstrings","text":"<ul> <li> Update class docstring</li> <li> Update <code>setup_source_and_sensors()</code> docstring</li> <li> Document <code>excitation_type</code> and <code>bandwidth_mhz</code> parameters</li> <li> Remove free-space references</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-412-update-material_setuppy-docstrings","title":"Task 4.1.2: Update material_setup.py docstrings","text":"<ul> <li> Update <code>_assign_antenna_materials()</code> docstring</li> <li> Document Copper\u2192PEC workaround applies to all Gaussian</li> <li> Remove free-space references</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-413-update-base_setuppy-docstrings","title":"Task 4.1.3: Update base_setup.py docstrings","text":"<ul> <li> Update <code>_apply_simulation_time_and_termination()</code> docstring</li> <li> Document Gaussian pulse duration calculation</li> <li> Explain when pulse duration dominates</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-414-update-power_extractorpy-docstrings","title":"Task 4.1.4: Update power_extractor.py docstrings","text":"<ul> <li> Document Gaussian source handling</li> <li> Explain power extraction strategy</li> <li> Document any integration methods</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-415-update-sar_extractorpy-docstrings","title":"Task 4.1.5: Update sar_extractor.py docstrings","text":"<ul> <li> Document frequency selection for Gaussian</li> <li> Explain why center frequency is used</li> <li> Document any limitations</li> </ul> <p>Estimated Time: 2 hours Dependencies: All Phase 1 tasks Testing: Review docstrings, ensure clarity</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#42-user-documentation","title":"4.2 User Documentation","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#task-421-update-configuration-guide","title":"Task 4.2.1: Update configuration guide","text":"<ul> <li> Document <code>excitation_type</code> parameter</li> <li> Document <code>bandwidth_mhz</code> parameter</li> <li> Add examples of Harmonic vs Gaussian configs</li> <li> Explain when to use each</li> </ul> <p>File: <code>docs/developer_guide/configuration.md</code></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-422-update-technical-guide","title":"Task 4.2.2: Update technical guide","text":"<ul> <li> Add section on Gaussian excitation</li> <li> Explain simulation time calculation</li> <li> Document material limitations</li> <li> Add troubleshooting section</li> </ul> <p>File: <code>docs/developer_guide/technical_guide.md</code></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-423-update-api-reference","title":"Task 4.2.3: Update API reference","text":"<ul> <li> Document new config parameters</li> <li> Update any API changes</li> <li> Add examples</li> </ul> <p>File: <code>docs/reference/api_reference.md</code></p>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-424-create-user-guide-section","title":"Task 4.2.4: Create user guide section","text":"<ul> <li> Explain Gaussian vs Harmonic excitation</li> <li> When to use each</li> <li> Configuration examples</li> <li> Known limitations</li> </ul> <p>File: <code>docs/user_guide/user_guide.md</code> (or new section)</p> <p>Estimated Time: 3-4 hours Dependencies: All implementation tasks Testing: Review documentation, ensure accuracy</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#phase-5-error-handling-edge-cases","title":"Phase 5: Error Handling &amp; Edge Cases","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#51-configuration-validation","title":"5.1 Configuration Validation","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#task-511-validate-excitation_type","title":"Task 5.1.1: Validate excitation_type","text":"<ul> <li> Check if set when needed</li> <li> Validate value is \"Harmonic\" or \"Gaussian\" (case-insensitive)</li> <li> Provide helpful error messages</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-512-validate-bandwidth_mhz","title":"Task 5.1.2: Validate bandwidth_mhz","text":"<ul> <li> Check if set when <code>excitation_type == \"Gaussian\"</code></li> <li> Validate value is positive</li> <li> Validate value is reasonable (e.g., 10-200 MHz)</li> <li> Provide helpful error messages</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-513-validate-frequency-range","title":"Task 5.1.3: Validate frequency range","text":"<ul> <li> Check <code>center_frequency - bandwidth/2 &gt; 0</code></li> <li> Check <code>center_frequency + bandwidth/2</code> is reasonable</li> <li> Provide helpful error messages</li> </ul> <p>Estimated Time: 2 hours Dependencies: Phase 1 tasks Testing: Test with invalid configs, verify error messages</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#52-runtime-error-handling","title":"5.2 Runtime Error Handling","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#task-521-handle-getpower-failures","title":"Task 5.2.1: Handle GetPower() failures","text":"<ul> <li> Graceful fallback if <code>GetPower()</code> not available</li> <li> Fallback to frequency axis extraction</li> <li> Log warnings appropriately</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-522-handle-frequency-extraction-failures","title":"Task 5.2.2: Handle frequency extraction failures","text":"<ul> <li> Handle missing frequency in extracted data</li> <li> Handle empty frequency axis</li> <li> Provide helpful error messages</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-523-handle-sar-extraction-failures","title":"Task 5.2.3: Handle SAR extraction failures","text":"<ul> <li> Handle missing SAR data</li> <li> Handle frequency selection failures</li> <li> Provide helpful error messages</li> </ul> <p>Estimated Time: 2 hours Dependencies: Phase 1 tasks Testing: Test error scenarios, verify graceful handling</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#phase-6-performance-optimization","title":"Phase 6: Performance &amp; Optimization","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#61-performance-considerations","title":"6.1 Performance Considerations","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#task-611-monitor-simulation-time","title":"Task 6.1.1: Monitor simulation time","text":"<ul> <li> Compare simulation times between Harmonic and Gaussian</li> <li> Verify Gaussian doesn't take excessively long</li> <li> Document any performance impacts</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-612-monitor-memory-usage","title":"Task 6.1.2: Monitor memory usage","text":"<ul> <li> Gaussian extracts 21 frequencies vs 1 for Harmonic</li> <li> Verify memory usage is acceptable</li> <li> Document any memory impacts</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#task-613-optimize-if-needed","title":"Task 6.1.3: Optimize if needed","text":"<ul> <li> If performance issues, consider optimizations</li> <li> May need to reduce number of extracted frequencies</li> <li> May need to optimize frequency selection</li> </ul> <p>Estimated Time: 2-3 hours Dependencies: Phase 3 testing Testing: Profile performance, identify bottlenecks</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#summary","title":"Summary","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#estimated-total-time-updated","title":"Estimated Total Time (UPDATED)","text":"<ul> <li>Phase 0 (Config Design): 15 minutes</li> <li>Phase 1 (Core Code): 18-24 hours (includes new resonance extraction)</li> <li>1.1 Source setup: 2-3 hours</li> <li>1.2 Material setup: 1 hour</li> <li>1.3 Simulation time (with tunable speedup factor): 3-4 hours</li> <li>1.4 Power extraction (minimal): 1-2 hours</li> <li>1.5 SAR extraction: 3-4 hours</li> <li>1.6 Resonance extraction (NEW): 6-8 hours \u2190 Critical deliverable</li> <li>Phase 2 (Config Files): 1-2 hours</li> <li>Phase 3 (Testing): 12-18 hours (more comprehensive)</li> <li>Phase 4 (Documentation): 5-6 hours</li> <li>Phase 5 (Error Handling): 4 hours</li> <li>Phase 6 (Performance): 2-3 hours</li> <li>Total: 42-57 hours (original estimate)</li> </ul> <p>Post-Implementation Optimization (Optional): - Phase 7 (Sensitivity Study): 4-6 hours   - Run with <code>s4l_arma_speedup_factor</code> = [1.0, 1.5, 2.0, 3.0, 4.0]   - Compare results, measure accuracy vs. sim time   - Update default based on findings</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#critical-path-updated","title":"Critical Path (UPDATED)","text":"<ol> <li>Config setup (0.1) - Add tunable parameters (15 min)</li> <li>Source setup changes (1.1) - Enable Gaussian excitation</li> <li>Material setup changes (1.2) - Copper\u2192PEC for Sim4Life compatibility</li> <li>Simulation time calculation (1.3) - Implement with <code>s4l_arma_speedup_factor</code> (conservative default)</li> <li>Resonance extraction (1.6) \u2190 PRIMARY GOAL - Detect antenna detuning</li> <li>Power/SAR extraction (1.4, 1.5) - Support frequency-dependent data</li> <li>Integration testing (3.2) - Validate end-to-end workflow</li> <li>Optimization (Phase 7 - OPTIONAL) - Test different speedup factors, update defaults</li> </ol>"},{"location":"technical/gaussian_near_field_implementation_todo/#key-understandings-resolved","title":"Key Understandings (RESOLVED)","text":"<ol> <li>\u2705 Power extraction: <code>GetPower()</code> returns total integrated power (not density)</li> <li>\u2705 Frequency data: Sim4Life automatically provides continuous frequency spectra via FFT</li> <li>\u2705 Frequency resolution: Determined by simulation time (\u0394f = 1/T_sim), NOT manual sampling</li> <li>\u2705 Simulation time: Frequency resolution dominates (~200 ns) over pulse (~44 ns) and propagation (~5 ns)</li> <li>\u2705 PML boundaries: 1\u00d7 propagation time sufficient (waves absorbed, not reflected back)</li> </ol>"},{"location":"technical/gaussian_near_field_implementation_todo/#key-risks-updated","title":"Key Risks (UPDATED)","text":"<ol> <li>Simulation time uncertainty (MITIGATED BY TUNABLE PARAMETER):</li> <li>Theoretical: ~200 ns (140 periods) vs. typical ~5-10 ns</li> <li>Unknown: Sim4Life's internal processing (ARMA, interpolation, zero-padding)</li> <li>Risk mitigation: Start conservative (speedup=1.0), make tunable for later optimization</li> <li> <p>Benefit: Implementation guaranteed correct, can optimize after it works</p> </li> <li> <p>Frequency resolution vs bandwidth trade-off: </p> </li> <li>Narrow bandwidth (50 MHz): Better resolution, may need multiple runs if shift &gt; 25 MHz</li> <li>Wide bandwidth (150 MHz): Single run coverage, but longer simulation</li> <li> <p>Mitigation: Start with 50 MHz (covers \u00b125 MHz), can adjust in config</p> </li> <li> <p>Performance impact (MEASURED POST-IMPLEMENTATION):</p> </li> <li>Conservative default may make simulations 20-40\u00d7 longer (~200 ns vs ~5 ns)</li> <li>But provides much more information (full frequency response)</li> <li> <p>Optional Phase 7 optimization can reduce this after validation</p> </li> <li> <p>Implementation correctness:</p> </li> <li>Conservative defaults guarantee correctness</li> <li>Tunable parameters enable optimization without code changes</li> <li>Phase 7 sensitivity study validates speedup assumptions (optional)</li> </ol>"},{"location":"technical/gaussian_near_field_implementation_todo/#success-criteria-updated","title":"Success Criteria (UPDATED)","text":"<ul> <li> Gaussian config runs end-to-end without errors</li> <li> Resonance frequency extracted accurately from continuous frequency data \u2190 PRIMARY</li> <li> Detuning quantified and reported with clear warnings \u2190 PRIMARY</li> <li> Frequency response plot generated \u2190 PRIMARY</li> <li> Simulation time accounts for frequency resolution requirement (~200 ns)</li> <li> Power extraction works correctly across full frequency range</li> <li> SAR extraction works correctly at center frequency</li> <li> Copper\u2192PEC workaround applies correctly for all Gaussian</li> <li> Backward compatibility maintained (Harmonic simulations unchanged)</li> <li> Frequency resolution adequate for narrowband antennas (\u22645 MHz)</li> <li> Documentation complete with practical examples</li> </ul>"},{"location":"technical/gaussian_near_field_implementation_todo/#next-steps-pragmatic-implementation-approach","title":"Next Steps (PRAGMATIC IMPLEMENTATION APPROACH)","text":"<p>Stage 0: Quick Config Setup (15 minutes) 1. Phase 0 (Config Design) - Add tunable parameters to <code>base_config.json</code></p> <p>Stage 1: Core Infrastructure (18-24 hours) 2. Phase 1.1 (Source Setup) - Enable Gaussian from config 3. Phase 1.2 (Material Setup) - Copper\u2192PEC for all Gaussian 4. Phase 1.3 (Simulation Time) - Implement with <code>s4l_arma_speedup_factor</code> (default: 1.0 = conservative) 5. Phase 1.6 (Resonance Extraction) - PRIMARY DELIVERABLE \u2190 Main goal! 6. Phase 1.4/1.5 (Power/SAR) - Verify existing code works with Gaussian</p> <p>Stage 2: Testing &amp; Validation (17-23 hours) 7. Phase 2 (Config Files) - Create test configs 8. Phase 3 (Testing) - Comprehensive validation    - Free-space: No detuning expected (baseline)    - Near-field: Detect and quantify detuning    - Compare with harmonic at detected resonance</p> <p>Stage 3: Polish (11-15 hours) 9. Phase 4 (Documentation) - User guides and API docs 10. Phase 5 (Error Handling) - Edge cases and validation 11. Phase 6 (Performance) - Monitoring and profiling</p> <p>Stage 4: Optimization (OPTIONAL, 4-6 hours) 12. Phase 7 (Sensitivity Study) - Test different <code>s4l_arma_speedup_factor</code> values    - Run with [1.0, 1.5, 2.0, 3.0, 4.0]    - Measure accuracy vs. sim time tradeoff    - Update default if speedup is validated</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#practical-antenna-characteristics-for-reference","title":"Practical Antenna Characteristics (For Reference)","text":"<p>From experimental measurements: - Antenna bandwidth: 10-30 MHz (narrowband, Q \u2248 20-40) - Maximum detuning: 50-100 MHz when device near body - Required resolution: \u22645 MHz (at least 2-6 points across antenna bandwidth) - Simulation time implication: \u2265200 ns (versus typical 5-10 ns for harmonic)</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#key-formulas-quick-reference","title":"Key Formulas (Quick Reference)","text":"<p>Simulation Time (THREE constraints): <pre><code>T_sim = max(multiplier \u00b7 L_bbox/c, L_bbox/c + 2k\u00b7\u03c3, 1/\u0394f_target)\n</code></pre> Where: - <code>\u03c3 = 0.94/(\u03c0\u00b7BW)</code> (pulse temporal width) - <code>k = 3.7</code> (conservative threshold) - <code>\u0394f_target</code> = target frequency resolution (typically 5 MHz)</p> <p>Typical values for 700 MHz, L_bbox = 0.5 m, BW = 50 MHz: - Component 1 (multiplier): ~6 ns - Component 2 (propagation + pulse): ~46 ns - Component 3 (resolution): 200 ns \u2190 DOMINATES</p> <p>Frequency Resolution: <pre><code>\u0394f = 1 / T_sim\n</code></pre> - T_sim = 200 ns \u2192 \u0394f = 5 MHz - T_sim = 500 ns \u2192 \u0394f = 2 MHz (better resolution, longer simulation)</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#notes","title":"Notes","text":""},{"location":"technical/gaussian_near_field_implementation_todo/#resolved-questions","title":"Resolved Questions","text":"<ol> <li>\u2705 Power extraction: Returns total integrated power (FFT magnitude)</li> <li>\u2705 Frequency data: Continuous arrays from automatic FFT post-processing</li> <li>\u2705 Resolution: Set by simulation time, not manual sampling</li> <li>\u2705 Propagation: 1\u00d7 sufficient with PML boundaries</li> <li>\u2705 Convergence: May be unreliable, use explicit time calculation</li> </ol>"},{"location":"technical/gaussian_near_field_implementation_todo/#remaining-questions-for-implementation","title":"Remaining Questions for Implementation","text":"<p>To be answered during implementation: 1. Optimal bandwidth for different use cases (50 vs 150 MHz)? 2. Should we implement two-stage detection (wide then narrow)? 3. How to handle cases where resonance is outside excitation bandwidth? 4. Can we extract S11 directly if voltage/current outputs exist?</p> <p>To be answered by Phase 7 (Optional Sensitivity Study - AFTER implementation): 5. \u2753 What is the actual minimum T_sim for accurate peak detection? 6. \u2753 Does Sim4Life use ARMA, zero-padding, or other advanced processing? 7. \u2753 Can we achieve &lt;200 ns simulation times with acceptable accuracy? 8. \u2753 What is the optimal <code>s4l_arma_speedup_factor</code> value?</p>"},{"location":"technical/gaussian_near_field_implementation_todo/#references","title":"References","text":"<ul> <li><code>docs/technical/gaussian_pulse_timing_analysis.md</code> - Comprehensive mathematical analysis (UPDATED)</li> <li><code>goliat/setups/source_setup.py</code> - Current source setup</li> <li><code>goliat/setups/material_setup.py</code> - Current material setup  </li> <li><code>goliat/setups/base_setup.py</code> - Current time calculation</li> <li><code>goliat/extraction/power_extractor.py</code> - Current power extraction (lines 228-243: multi-frequency handling)</li> <li><code>goliat/extraction/sar_extractor.py</code> - Current SAR extraction</li> <li><code>docs/reference/useful_s4l_snippets.md</code> - Sim4Life API examples (section 7: Results extraction)</li> </ul>"},{"location":"technical/gaussian_pulse_timing_analysis/","title":"Gaussian Pulse Timing and Frequency Resolution Analysis for FDTD Simulations","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#executive-summary","title":"Executive Summary","text":"<p>This document provides a detailed mathematical analysis of simulation time requirements and frequency resolution for Gaussian-modulated pulse excitations in FDTD simulations, specifically for near-field SAR studies in GOLIAT. The analysis reveals that:</p> <ol> <li> <p>Pulse duration dominates: For typical scenarios with bandwidths of 50-100 MHz and small-to-medium bounding boxes, the pulse duration (\u224818-36 ns) dominates over propagation time (\u22481-3 ns).</p> </li> <li> <p>Sim4Life performs automatic FFT: The solver internally converts time-domain Gaussian pulse responses into frequency-domain data through post-processing, providing continuous frequency spectra.</p> </li> <li> <p>Frequency resolution is critical: For detecting antenna detuning in narrowband antennas (10-30 MHz bandwidth, potential 50-100 MHz shift), frequency resolution \u0394f = 1/T_sim must be sufficiently fine (\u22485 MHz or better).</p> </li> <li> <p>PML boundaries eliminate back-reflection: With Perfectly Matched Layer boundaries, signals propagate forward and are absorbed, so 2\u00d7 propagation time for reflections is NOT needed.</p> </li> </ol> <p>This comprehensive timing analysis ensures both adequate pulse duration for accurate FFT and sufficient simulation time for fine frequency resolution.</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#problem-statement","title":"Problem Statement","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#context","title":"Context","text":"<p>GOLIAT currently supports two excitation types: - Harmonic: Single-frequency continuous wave excitation (standard for SAR compliance) - Gaussian: Frequency-sweep excitation (currently only used for free-space antenna characterization)</p> <p>We are extending Gaussian excitation support to near-field (phantom) simulations. A critical question arises: How long must the simulation run to capture the complete Gaussian pulse response?</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#current-implementation","title":"Current Implementation","text":"<p>The current simulation time calculation (<code>goliat/setups/base_setup.py</code>) uses a simple multiplier approach:</p> <pre><code>time_multiplier = config[\"simulation_parameters.simulation_time_multiplier\"]  # Default: 3.5\ndiagonal_length_m = np.linalg.norm(bbox_max - bbox_min) / 1000.0\ntime_to_travel_s = (time_multiplier * diagonal_length_m) / c\nsim_time_periods = time_to_travel_s / (1 / (frequency_mhz * 1e6))\n</code></pre> <p>This approach assumes: - The simulation needs <code>multiplier</code> times the time for a wave to traverse the bounding box diagonal - For Harmonic excitation, this captures multiple cycles for convergence - The multiplier (typically 3.5) provides sufficient time for steady-state behavior</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#the-challenge","title":"The Challenge","text":"<p>For Gaussian pulses, we must ensure: 1. The pulse propagates from source to all points in the domain 2. The pulse completes its full temporal evolution (ramp-up, peak, decay) 3. The response at the farthest point has time to develop</p> <p>The current multiplier approach may be insufficient because it doesn't account for the finite pulse duration.</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#mathematical-model","title":"Mathematical Model","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#gaussian-modulated-pulse","title":"Gaussian-Modulated Pulse","text":"<p>A Gaussian-modulated pulse in the time domain is:</p> <pre><code>g(t) = A \u00b7 exp(-(t - t\u2080)\u00b2/(2\u03c3\u00b2)) \u00b7 exp(i\u00b72\u03c0\u00b7f\u2080\u00b7t)\n</code></pre> <p>Where: - <code>A</code> = amplitude (arbitrary scaling) - <code>t\u2080</code> = time shift (ramp-up delay to avoid sudden start) - <code>\u03c3</code> = temporal standard deviation (controls pulse width) - <code>f\u2080</code> = center frequency (carrier frequency)</p> <p>Physical interpretation: - The Gaussian envelope <code>exp(-(t - t\u2080)\u00b2/(2\u03c3\u00b2))</code> modulates the carrier wave - The pulse is centered at time <code>t = t\u2080</code> - The pulse width is controlled by <code>\u03c3</code></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#frequency-domain-representation","title":"Frequency Domain Representation","text":"<p>The Fourier transform of the Gaussian pulse is:</p> <pre><code>G(f) = A \u00b7 \u03c3 \u00b7 \u221a(2\u03c0) \u00b7 exp(-2\u03c0\u00b2\u03c3\u00b2(f - f\u2080)\u00b2) \u00b7 exp(-i\u00b72\u03c0\u00b7f\u00b7t\u2080)\n</code></pre> <p>Key properties: - The frequency spectrum is also Gaussian - Centered at <code>f\u2080</code> (the carrier frequency) - Frequency width inversely related to temporal width</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#relationship-between-temporal-and-spectral-width","title":"Relationship Between Temporal and Spectral Width","text":"<p>For a Gaussian pulse, the time-bandwidth product is fundamental:</p> <p>Temporal Full-Width at Half-Maximum (FWHM): <pre><code>\u0394t_FWHM = 2\u221a(2 ln 2) \u00b7 \u03c3 \u2248 2.35\u03c3\n</code></pre></p> <p>Frequency Full-Width at Half-Maximum (FWHM): <pre><code>\u0394f_FWHM = 2\u221a(2 ln 2)/(2\u03c0\u03c3) \u2248 0.94/(\u03c0\u03c3)\n</code></pre></p> <p>Time-bandwidth product: <pre><code>\u0394t_FWHM \u00b7 \u0394f_FWHM = (2\u221a(2 ln 2))\u00b2/(2\u03c0) \u2248 0.87\n</code></pre></p> <p>This is a fundamental limit: narrower pulses in time have wider frequency spectra, and vice versa.</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#relating-to-configured-bandwidth","title":"Relating to Configured Bandwidth","text":"<p>In GOLIAT, we configure: - <code>BW</code> = bandwidth in MHz (e.g., 100 MHz) - <code>f\u2080</code> = center frequency in MHz (e.g., 700 MHz)</p> <p>The configured bandwidth <code>BW</code> represents the frequency range over which significant energy exists. We approximate:</p> <pre><code>\u0394f_FWHM \u2248 BW\n</code></pre> <p>This allows us to solve for <code>\u03c3</code>:</p> <pre><code>\u03c3 \u2248 0.94/(\u03c0\u00b7BW)\n</code></pre> <p>Example: For <code>BW = 100 MHz = 100\u00d710\u2076 Hz</code>: <pre><code>\u03c3 \u2248 0.94/(\u03c0\u00b7100\u00d710\u2076) \u2248 3.0\u00d710\u207b\u2079 s = 3.0 ns\n</code></pre></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#pulse-duration-analysis","title":"Pulse Duration Analysis","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#ramp-up-delay-t0","title":"Ramp-Up Delay (t\u2080)","text":"<p>To avoid numerical artifacts from a sudden start, FDTD solvers shift the Gaussian pulse so it starts near zero at <code>t = 0</code>:</p> <pre><code>g(0) \u2248 0\n</code></pre> <p>This requires: <pre><code>exp(-(0 - t\u2080)\u00b2/(2\u03c3\u00b2)) = exp(-t\u2080\u00b2/(2\u03c3\u00b2)) \u2248 0\n</code></pre></p> <p>Solving for the threshold where the pulse is negligible:</p> <p>For 1% of peak amplitude: <pre><code>exp(-t\u2080\u00b2/(2\u03c3\u00b2)) = 0.01\n-t\u2080\u00b2/(2\u03c3\u00b2) = ln(0.01) \u2248 -4.61\nt\u2080\u00b2 = 9.22\u03c3\u00b2\nt\u2080 \u2248 3.0\u03c3\n</code></pre></p> <p>For 0.1% of peak amplitude (more conservative): <pre><code>exp(-t\u2080\u00b2/(2\u03c3\u00b2)) = 0.001\n-t\u2080\u00b2/(2\u03c3\u00b2) = ln(0.001) \u2248 -6.91\nt\u2080\u00b2 = 13.82\u03c3\u00b2\nt\u2080 \u2248 3.7\u03c3\n</code></pre></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#total-pulse-duration","title":"Total Pulse Duration","text":"<p>The pulse has significant energy from <code>t = t\u2080 - k\u00b7\u03c3</code> to <code>t = t\u2080 + k\u00b7\u03c3</code>, where <code>k</code> determines the threshold.</p> <p>For k = 3 (1% threshold): - Left side: <code>k\u00b7\u03c3</code> before peak - Right side: <code>k\u00b7\u03c3</code> after peak - Total duration: <code>2k\u00b7\u03c3 = 6\u03c3</code></p> <p>For k = 3.7 (0.1% threshold, more conservative): - Total duration: <code>2k\u00b7\u03c3 = 7.4\u03c3</code></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#pulse-duration-in-terms-of-bandwidth","title":"Pulse Duration in Terms of Bandwidth","text":"<p>Substituting <code>\u03c3 \u2248 0.94/(\u03c0\u00b7BW)</code>:</p> <p>For k = 3: <pre><code>T_pulse = 2k\u00b7\u03c3 = 2\u00b73\u00b70.94/(\u03c0\u00b7BW) = 5.64/(\u03c0\u00b7BW) \u2248 1.80/BW\n</code></pre></p> <p>For k = 3.7: <pre><code>T_pulse = 2k\u00b7\u03c3 = 2\u00b73.7\u00b70.94/(\u03c0\u00b7BW) = 6.96/(\u03c0\u00b7BW) \u2248 2.22/BW\n</code></pre></p> <p>Examples: - <code>BW = 100 MHz</code>: <code>T_pulse \u2248 18.0 ns</code> (k=3) or <code>22.2 ns</code> (k=3.7) - <code>BW = 50 MHz</code>: <code>T_pulse \u2248 36.0 ns</code> (k=3) or <code>44.4 ns</code> (k=3.7) - <code>BW = 200 MHz</code>: <code>T_pulse \u2248 9.0 ns</code> (k=3) or <code>11.1 ns</code> (k=3.7)</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#required-simulation-time","title":"Required Simulation Time","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#two-time-components","title":"Two Time Components","text":"<p>For a complete simulation, we need:</p> <ol> <li>Propagation Time (<code>T_prop</code>): Time for the field to travel from source to the farthest point    <pre><code>T_prop = L_bbox / c\n</code></pre>    Where:</li> <li><code>L_bbox</code> = diagonal length of simulation bounding box (meters)</li> <li> <p><code>c = 2.998\u00d710\u2078 m/s</code> = speed of light</p> </li> <li> <p>Pulse Wait Time (<code>T_pulse</code>): Time for the complete pulse to pass through    <pre><code>T_pulse = 2k\u00b7\u03c3 \u2248 1.80/BW  (for k=3)\n</code></pre></p> </li> </ol>"},{"location":"technical/gaussian_pulse_timing_analysis/#total-required-time","title":"Total Required Time","text":"<pre><code>T_required = T_prop + T_pulse = L_bbox/c + 2k\u00b7\u03c3\n</code></pre> <p>Substituting: <pre><code>T_required = L_bbox/c + 1.80/BW  (for k=3)\n</code></pre></p> <p>or more conservatively: <pre><code>T_required = L_bbox/c + 2.22/BW  (for k=3.7)\n</code></pre></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#current-allocation-vs-required-time","title":"Current Allocation vs. Required Time","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#current-implementation_1","title":"Current Implementation","text":"<p>The current code allocates: <pre><code>T_allocated = multiplier \u00b7 L_bbox/c\n</code></pre></p> <p>Where <code>multiplier = 3.5</code> (default from config).</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#comparison-logic","title":"Comparison Logic","text":"<p>We need to check: <pre><code>Is T_allocated \u2265 T_required?\n</code></pre></p> <p>Rearranging: <pre><code>multiplier \u00b7 L_bbox/c \u2265 L_bbox/c + 2k\u00b7\u03c3\n(multiplier - 1) \u00b7 L_bbox/c \u2265 2k\u00b7\u03c3\n</code></pre></p> <p>If TRUE: Current allocation is sufficient If FALSE: Current allocation is insufficient, need at least <code>T_required</code></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#corrected-simulation-time-formula","title":"Corrected Simulation Time Formula","text":"<p>The simulation time should be:</p> <pre><code>T_sim = max(multiplier \u00b7 L_bbox/c, L_bbox/c + 2k\u00b7\u03c3)\n</code></pre> <p>This ensures we always have sufficient time, taking the maximum of: - The current multiplier-based approach (which may be sufficient for large bboxes) - The explicit pulse duration requirement (which dominates for small bboxes)</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#when-does-current-multiplier-fail","title":"When Does Current Multiplier Fail?","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#failure-condition","title":"Failure Condition","text":"<p>The current multiplier approach fails when:</p> <pre><code>multiplier \u00b7 L_bbox/c &lt; L_bbox/c + 2k\u00b7\u03c3\n(multiplier - 1) \u00b7 L_bbox/c &lt; 2k\u00b7\u03c3\nL_bbox/c &lt; 2k\u00b7\u03c3/(multiplier - 1)\n</code></pre> <p>For multiplier = 3.5, k = 3: <pre><code>L_bbox/c &lt; 2\u00b73\u00b7\u03c3/2.5 = 2.4\u00b7\u03c3\nL_bbox &lt; 2.4\u00b7c\u00b7\u03c3\n</code></pre></p> <p>Substituting \u03c3: <pre><code>L_bbox &lt; 2.4\u00b7c\u00b70.94/(\u03c0\u00b7BW)\nL_bbox &lt; 0.72\u00b7c/BW\n</code></pre></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#critical-bounding-box-sizes","title":"Critical Bounding Box Sizes","text":"<p>For BW = 100 MHz: <pre><code>L_bbox &lt; 0.72 \u00b7 3\u00d710\u2078 / (100\u00d710\u2076) = 2.16 m\n</code></pre></p> <p>For BW = 50 MHz: <pre><code>L_bbox &lt; 0.72 \u00b7 3\u00d710\u2078 / (50\u00d710\u2076) = 4.32 m\n</code></pre></p> <p>For BW = 200 MHz: <pre><code>L_bbox &lt; 0.72 \u00b7 3\u00d710\u2078 / (200\u00d710\u2076) = 1.08 m\n</code></pre></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#practical-implications","title":"Practical Implications","text":"<p>For typical near-field scenarios: - Small antenna near head: <code>L_bbox \u2248 0.2-0.5 m</code> - Medium setup with padding: <code>L_bbox \u2248 0.5-1.0 m</code> - Large phantom with extensive padding: <code>L_bbox \u2248 1.0-2.0 m</code></p> <p>Conclusion: For typical near-field bboxes (&lt; 1 m) and bandwidths (50-100 MHz), the current multiplier approach fails because the pulse duration term dominates.</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#detailed-examples","title":"Detailed Examples","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#example-1-small-bbox-100-mhz-bandwidth","title":"Example 1: Small Bbox, 100 MHz Bandwidth","text":"<p>Parameters: - <code>L_bbox = 0.3 m</code> - <code>BW = 100 MHz</code> - <code>f\u2080 = 700 MHz</code> - <code>multiplier = 3.5</code> - <code>k = 3</code></p> <p>Calculations: <pre><code>T_prop = 0.3 / 3\u00d710\u2078 = 1.0\u00d710\u207b\u2079 s = 1.0 ns\nT_pulse = 1.80/(100\u00d710\u2076) = 18.0\u00d710\u207b\u2079 s = 18.0 ns\nT_required = 1.0 + 18.0 = 19.0 ns\nT_allocated = 3.5 \u00d7 1.0 = 3.5 ns\n</code></pre></p> <p>Result: \u274c FAILS - <code>3.5 ns &lt; 19.0 ns</code></p> <p>Required simulation time: <pre><code>T_sim = max(3.5 ns, 19.0 ns) = 19.0 ns\nN_periods = 19.0\u00d710\u207b\u2079 / (1/(700\u00d710\u2076)) = 13.3 periods\n</code></pre></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#example-2-medium-bbox-100-mhz-bandwidth","title":"Example 2: Medium Bbox, 100 MHz Bandwidth","text":"<p>Parameters: - <code>L_bbox = 0.5 m</code> - <code>BW = 100 MHz</code> - <code>multiplier = 3.5</code> - <code>k = 3</code></p> <p>Calculations: <pre><code>T_prop = 0.5 / 3\u00d710\u2078 = 1.67 ns\nT_pulse = 18.0 ns\nT_required = 1.67 + 18.0 = 19.67 ns\nT_allocated = 3.5 \u00d7 1.67 = 5.84 ns\n</code></pre></p> <p>Result: \u274c FAILS - <code>5.84 ns &lt; 19.67 ns</code></p> <p>Required simulation time: <pre><code>T_sim = max(5.84 ns, 19.67 ns) = 19.67 ns\nN_periods = 19.67\u00d710\u207b\u2079 / (1/(700\u00d710\u2076)) = 13.8 periods\n</code></pre></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#example-3-large-bbox-100-mhz-bandwidth","title":"Example 3: Large Bbox, 100 MHz Bandwidth","text":"<p>Parameters: - <code>L_bbox = 1.0 m</code> - <code>BW = 100 MHz</code> - <code>multiplier = 3.5</code> - <code>k = 3</code></p> <p>Calculations: <pre><code>T_prop = 1.0 / 3\u00d710\u2078 = 3.33 ns\nT_pulse = 18.0 ns\nT_required = 3.33 + 18.0 = 21.33 ns\nT_allocated = 3.5 \u00d7 3.33 = 11.67 ns\n</code></pre></p> <p>Result: \u274c FAILS - <code>11.67 ns &lt; 21.33 ns</code></p> <p>Required simulation time: <pre><code>T_sim = max(11.67 ns, 21.33 ns) = 21.33 ns\nN_periods = 21.33\u00d710\u207b\u2079 / (1/(700\u00d710\u2076)) = 14.9 periods\n</code></pre></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#example-4-small-bbox-50-mhz-bandwidth","title":"Example 4: Small Bbox, 50 MHz Bandwidth","text":"<p>Parameters: - <code>L_bbox = 0.3 m</code> - <code>BW = 50 MHz</code> - <code>multiplier = 3.5</code> - <code>k = 3</code></p> <p>Calculations: <pre><code>T_prop = 1.0 ns\nT_pulse = 1.80/(50\u00d710\u2076) = 36.0 ns\nT_required = 1.0 + 36.0 = 37.0 ns\nT_allocated = 3.5 ns\n</code></pre></p> <p>Result: \u274c FAILS - <code>3.5 ns &lt; 37.0 ns</code></p> <p>Required simulation time: <pre><code>T_sim = max(3.5 ns, 37.0 ns) = 37.0 ns\nN_periods = 37.0\u00d710\u207b\u2079 / (1/(700\u00d710\u2076)) = 25.9 periods\n</code></pre></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#example-5-very-large-bbox-100-mhz-bandwidth","title":"Example 5: Very Large Bbox, 100 MHz Bandwidth","text":"<p>Parameters: - <code>L_bbox = 2.5 m</code> - <code>BW = 100 MHz</code> - <code>multiplier = 3.5</code> - <code>k = 3</code></p> <p>Calculations: <pre><code>T_prop = 2.5 / 3\u00d710\u2078 = 8.33 ns\nT_pulse = 18.0 ns\nT_required = 8.33 + 18.0 = 26.33 ns\nT_allocated = 3.5 \u00d7 8.33 = 29.17 ns\n</code></pre></p> <p>Result: \u2705 PASSES - <code>29.17 ns &gt; 26.33 ns</code></p> <p>Required simulation time: <pre><code>T_sim = max(29.17 ns, 26.33 ns) = 29.17 ns\nN_periods = 29.17\u00d710\u207b\u2079 / (1/(700\u00d710\u2076)) = 20.4 periods\n</code></pre></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#key-insights","title":"Key Insights","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#1-pulse-duration-dominates-for-small-bboxes","title":"1. Pulse Duration Dominates for Small Bboxes","text":"<p>For typical near-field scenarios (<code>L_bbox &lt; 1 m</code>), the pulse duration term (<code>T_pulse \u2248 18-36 ns</code>) is much larger than the propagation time (<code>T_prop \u2248 1-3 ns</code>). This means:</p> <ul> <li>The current multiplier approach is insufficient</li> <li>We must explicitly add the pulse duration term</li> <li>The pulse duration is independent of bbox size (depends only on bandwidth)</li> </ul>"},{"location":"technical/gaussian_pulse_timing_analysis/#2-bandwidth-has-strong-impact","title":"2. Bandwidth Has Strong Impact","text":"<p>Wider bandwidths mean shorter pulses, but the relationship is inverse: - <code>BW = 50 MHz</code> \u2192 <code>T_pulse \u2248 36 ns</code> - <code>BW = 100 MHz</code> \u2192 <code>T_pulse \u2248 18 ns</code> - <code>BW = 200 MHz</code> \u2192 <code>T_pulse \u2248 9 ns</code></p> <p>For narrow bandwidths, pulse duration becomes even more dominant.</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#3-conservative-threshold-matters","title":"3. Conservative Threshold Matters","text":"<p>Using <code>k = 3.7</code> (0.1% threshold) instead of <code>k = 3</code> (1% threshold) increases pulse duration by ~23%: - <code>k = 3</code>: <code>T_pulse = 1.80/BW</code> - <code>k = 3.7</code>: <code>T_pulse = 2.22/BW</code></p> <p>For safety, we should use the more conservative value.</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#implementation-formula","title":"Implementation Formula","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#corrected-code-logic","title":"Corrected Code Logic","text":"<p>For Gaussian excitation, the simulation time calculation should be:</p> <pre><code># Calculate base propagation time\ndiagonal_length_m = np.linalg.norm(bbox_max - bbox_min) / 1000.0\nT_prop = diagonal_length_m / c  # seconds, where c = 2.998\u00d710\u2078 m/s\n\nif excitation_type == \"Gaussian\":\n    # Get bandwidth from config\n    bandwidth_mhz = config[\"simulation_parameters.bandwidth_mhz\"] or 50.0\n    bandwidth_hz = bandwidth_mhz * 1e6\n    \n    # Conservative threshold (0.1% of peak)\n    k = 3.7\n    \n    # Calculate temporal standard deviation\n    sigma = 0.94 / (np.pi * bandwidth_hz)  # seconds\n    \n    # Pulse duration (2k\u00b7\u03c3)\n    T_pulse = 2 * k * sigma  # seconds\n    \n    # Required time\n    T_required = T_prop + T_pulse\n    \n    # Allocated time (current multiplier approach)\n    multiplier = config[\"simulation_parameters.simulation_time_multiplier\"] or 3.5\n    T_allocated = multiplier * T_prop\n    \n    # Use the maximum\n    T_sim = max(T_allocated, T_required)\n    \n    # Convert to periods\n    sim_time_periods = T_sim / (1 / (frequency_mhz * 1e6))\n    \n    # Log the decision\n    if T_required &gt; T_allocated:\n        log(f\"  - Gaussian pulse duration ({T_pulse*1e9:.1f} ns) dominates over \"\n            f\"propagation time ({T_prop*1e9:.1f} ns)\")\n        log(f\"  - Using explicit pulse duration requirement: {T_sim*1e9:.1f} ns\")\n    else:\n        log(f\"  - Multiplier approach sufficient: {T_allocated*1e9:.1f} ns\")\n        \nelse:\n    # Harmonic: use multiplier approach\n    multiplier = config[\"simulation_parameters.simulation_time_multiplier\"] or 3.5\n    T_sim = multiplier * T_prop\n    sim_time_periods = T_sim / (1 / (frequency_mhz * 1e6))\n</code></pre>"},{"location":"technical/gaussian_pulse_timing_analysis/#simplified-formula","title":"Simplified Formula","text":"<p>For quick reference, the pulse duration can be approximated as:</p> <pre><code>T_pulse \u2248 2.22/BW  (for k=3.7, BW in Hz)\n</code></pre> <p>So the total required time is:</p> <pre><code>T_sim = max(multiplier \u00b7 L_bbox/c, L_bbox/c + 2.22/BW)\n</code></pre>"},{"location":"technical/gaussian_pulse_timing_analysis/#frequency-extraction-context","title":"Frequency Extraction Context","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#extracted-frequencies","title":"Extracted Frequencies","text":"<p>From <code>goliat/setups/source_setup.py</code>, for Gaussian sources: - Number of samples: <code>N = 21</code> - Frequency spacing: <code>\u0394f_sample = BW / (N - 1) = BW / 20</code> - Frequency range: <code>[f\u2080 - BW/2, f\u2080 + BW/2]</code></p> <p>Example: For <code>f\u2080 = 700 MHz, BW = 100 MHz</code>: - Frequencies: <code>650 MHz, 655 MHz, 660 MHz, ..., 745 MHz, 750 MHz</code> - Spacing: <code>5 MHz</code></p>"},{"location":"technical/gaussian_pulse_timing_analysis/#antenna-detuning-consideration","title":"Antenna Detuning Consideration","text":"<p>Antennas are narrowband devices. If an antenna is tuned to <code>f\u2080</code> but excited at <code>f\u2080 \u00b1 \u0394f_detune</code>, the response is reduced. Typical mobile antennas have: - Quality factor: <code>Q \u2248 10-50</code> - Maximum detuning: <code>\u0394f_detune_max \u2248 f\u2080 / (2Q) \u2248 50-100 MHz</code></p> <p>However, for worst-case timing analysis, we use the full excitation bandwidth, as the pulse still contains energy across the entire bandwidth even if the antenna response is reduced.</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#frequency-resolution-analysis","title":"Frequency Resolution Analysis","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#fft-frequency-resolution","title":"FFT Frequency Resolution","text":"<p>When Sim4Life performs FFT on the time-domain response to extract frequency-domain data, the frequency resolution is determined by the simulation time:</p> <pre><code>\u0394f = 1 / T_sim\n</code></pre> <p>Where: - <code>\u0394f</code> = frequency resolution (Hz) - <code>T_sim</code> = total simulation time (seconds)</p> <p>Practical examples: - <code>T_sim = 20 ns</code> \u2192 <code>\u0394f = 50 MHz</code> (too coarse!) - <code>T_sim = 100 ns</code> \u2192 <code>\u0394f = 10 MHz</code> (marginal) - <code>T_sim = 200 ns</code> \u2192 <code>\u0394f = 5 MHz</code> (good)</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#requirements-for-antenna-detuning-detection","title":"Requirements for Antenna Detuning Detection","text":"<p>Practical antenna characteristics (from experimental data): - Antenna bandwidth (BW): 10-30 MHz (narrowband) - Maximum detuning shift: 50-100 MHz when near body - Typical resonance behavior: Sharp peak with Q \u2248 20-40</p> <p>Required frequency resolution: To accurately detect resonance shift and characterize antenna response: - Minimum requirement: \u0394f \u2264 5 MHz (at least 2-6 points across antenna bandwidth) - Recommended: \u0394f \u2264 2-3 MHz (at least 3-10 points across bandwidth) - Optimal: \u0394f \u2264 1 MHz (dense sampling for accurate peak finding)</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#balancing-pulse-duration-and-frequency-resolution","title":"Balancing Pulse Duration and Frequency Resolution","text":"<p>There's a trade-off between: 1. Pulse duration requirement (minimum time): <code>T_pulse = 2k\u00b7\u03c3 \u2248 2.22/BW_excitation</code> 2. Frequency resolution requirement (longer is better): <code>T_sim \u2265 1/\u0394f_required</code></p> <p>For antenna characterization with narrow bandwidth:</p> <p>If we use <code>BW_excitation = 50 MHz</code> (narrower than typical 100 MHz): - Pulse duration: <code>T_pulse \u2248 44 ns</code> - For <code>\u0394f = 5 MHz</code> resolution: <code>T_sim \u2265 200 ns</code> - Since <code>200 ns &gt; 44 ns</code>, frequency resolution dominates</p> <p>Recommended approach: <pre><code>T_sim = max(multiplier \u00b7 L_bbox/c, L_bbox/c + T_pulse, 1/\u0394f_target)\n</code></pre></p> <p>Where: - <code>\u0394f_target</code> = desired frequency resolution (typically 5 MHz or better) - This ensures adequate time for BOTH pulse completion AND frequency resolution</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#pml-boundaries-and-propagation-time","title":"PML Boundaries and Propagation Time","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#why-1-propagation-time-is-sufficient","title":"Why 1\u00d7 Propagation Time is Sufficient","text":"<p>With PML (Perfectly Matched Layer) boundaries: - Electromagnetic waves propagate forward through the domain - PML boundaries absorb outgoing waves without reflection - Signals do NOT bounce back into the domain</p> <p>The propagation time requirement is for: - Allowing transient fields to propagate from source to domain edges - Letting fields dissipate into the PML (forward propagation only) - NOT for waiting for reflected signals to return</p> <p>Therefore: <code>T_prop = L_bbox/c</code> (1\u00d7) is sufficient, NOT <code>2 \u00d7 L_bbox/c</code></p> <p>The multiplier (3.5\u00d7) provides additional margin for: - Multiple round-trips within the domain before reaching PML - Ensuring complete energy dissipation - Accounting for longer paths than the diagonal</p> <p>Antenna self-reflection (for S11 measurement): - Happens locally at the antenna (L_antenna \u2248 10 cm) - Time scale: <code>L_antenna/c \u2248 0.3 ns</code> (much faster than bbox propagation) - Fully captured within the pulse duration and propagation time</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#convergence-criteria-considerations","title":"Convergence Criteria Considerations","text":"<p>Note on GlobalAutoTermination: - Sim4Life's automatic convergence criteria can be unreliable in some cases - For Gaussian pulses, the criteria are designed for harmonic steady-state - Best practice: Rely on explicit time calculation rather than convergence</p> <p>Validation approach: - Check point sensors at bbox corners - Verify E-field amplitude has decayed to negligible levels - For Gaussian: ensure pulse has fully propagated and decayed</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#practical-implementation-recommendations","title":"Practical Implementation Recommendations","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#recommended-excitation-bandwidths","title":"Recommended Excitation Bandwidths","text":"<p>Based on antenna characteristics (BW = 10-30 MHz, shift up to 100 MHz):</p> <p>Option 1: Narrow bandwidth (Recommended for high resolution) - <code>BW_excitation = 50 MHz</code> (covers \u00b125 MHz around nominal) - Frequency resolution: 5 MHz (T_sim = 200 ns) - Pulse duration: ~44 ns - Pros: Better resolution, less computational cost - Cons: May need to run multiple simulations if shift &gt; 25 MHz</p> <p>Option 2: Wide bandwidth (Better coverage) - <code>BW_excitation = 150 MHz</code> (covers \u00b175 MHz around nominal) - Frequency resolution: 5 MHz (T_sim = 200 ns) - Pulse duration: ~15 ns - Pros: Captures larger shifts in single simulation - Cons: Wastes computation on frequencies where antenna doesn't respond</p> <p>Option 3: Two-stage approach (Optimal) - Stage 1: Wide bandwidth (150 MHz) for coarse detection - Stage 2: Narrow bandwidth (30-50 MHz) centered on detected resonance for refinement</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#updated-simulation-time-formula","title":"Updated Simulation Time Formula","text":"<p>Complete formula accounting for all factors:</p> <pre><code># Constants\nc = 2.998e8  # m/s\nk = 3.7      # Conservative threshold\n\n# Configuration\nbandwidth_mhz = 50  # MHz (narrower for better resolution)\ntarget_freq_resolution_mhz = 5  # MHz (for accurate antenna characterization)\nmultiplier = 3.5  # For propagation with margin\n\n# Calculate components\nsigma = 0.94 / (np.pi * bandwidth_mhz * 1e6)  # seconds\nT_pulse = 2 * k * sigma  # Pulse duration\nT_prop = diagonal_length_m / c  # Propagation time\nT_resolution = 1 / (target_freq_resolution_mhz * 1e6)  # For frequency resolution\n\n# Required simulation time (take maximum of all constraints)\nT_sim = max(\n    multiplier * T_prop,          # Multiplier-based approach\n    T_prop + T_pulse,             # Propagation + pulse duration\n    T_resolution                  # Frequency resolution requirement\n)\n\n# Convert to periods at center frequency\nsim_time_periods = T_sim / (1 / (frequency_mhz * 1e6))\n</code></pre>"},{"location":"technical/gaussian_pulse_timing_analysis/#verification-examples-with-new-formula","title":"Verification Examples with New Formula","text":"<p>Example: 700 MHz antenna, L_bbox = 0.5 m, BW = 50 MHz</p> <pre><code>T_prop = 0.5 / 3e8 = 1.67 ns\nT_pulse = 2.22 / (50e6) = 44.4 ns\nT_resolution = 1 / (5e6) = 200 ns\n\nComponent 1 (multiplier): 3.5 \u00d7 1.67 = 5.84 ns\nComponent 2 (propagation + pulse): 1.67 + 44.4 = 46.1 ns\nComponent 3 (resolution): 200 ns\n\nT_sim = max(5.84, 46.1, 200) = 200 ns  \u2190 FREQUENCY RESOLUTION DOMINATES!\n\nN_periods = 200e-9 / (1/700e6) = 140 periods\n</code></pre> <p>This is a CRITICAL finding: For narrowband antenna characterization, frequency resolution requirements dominate over both propagation and pulse duration!</p> <p>Example: Comparison with 100 MHz bandwidth</p> <pre><code>With BW = 100 MHz:\nT_pulse = 22.2 ns (shorter)\nT_resolution = 200 ns (same, set by target resolution)\nT_sim = 200 ns (still dominated by resolution requirement)\n</code></pre> <p>Conclusion: The excitation bandwidth affects pulse duration, but for accurate antenna characterization, the simulation time is primarily determined by the required frequency resolution, not the pulse width!</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#signal-processing-considerations-and-uncertainties","title":"Signal Processing Considerations and Uncertainties","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#what-we-dont-know-sim4lifes-internal-processing","title":"What We Don't Know: Sim4Life's Internal Processing","text":"<p>Critical caveat: Sim4Life is commercial software with proprietary post-processing. We don't know exactly what it does internally:</p> <p>Potential techniques that could improve frequency resolution: 1. Zero padding: Interpolates FFT spectrum without improving true resolution, but enables better peak localization 2. Windowing: May apply Hanning/Hamming windows to reduce spectral leakage (slightly worsens resolution) 3. ARMA/Prony estimation: The manual mentions ARMA for \"high-Q resonators\" - might extrapolate beyond raw FFT resolution 4. Parabolic/Gaussian interpolation: Sub-bin peak finding (could give 10-100\u00d7 better peak location accuracy)</p> <p>What this means: - The strict <code>\u0394f = 1/T_sim</code> requirement may be overly conservative - For single-peak detection (our use case), interpolation techniques can find the peak much more accurately than bin spacing suggests - A simulation with <code>\u0394f = 20 MHz</code> bins + interpolation might accurately locate a peak to \u00b11-2 MHz</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#the-problem-with-speculation","title":"The Problem with Speculation","text":"<p>We cannot rely on undocumented features. The only scientifically valid approach is: 1. Start with conservative theoretical bounds (this document provides that) 2. Run empirical tests to determine what actually works 3. Update implementation based on measured results</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#theoretical-vs-practical-requirements","title":"Theoretical vs. Practical Requirements","text":"<p>Theoretical (this document): <pre><code>T_sim = max(multiplier \u00b7 L_bbox/c, L_bbox/c + 2k\u00b7\u03c3, 1/\u0394f_target)\n</code></pre> - Conservative bound assuming standard FFT with no advanced post-processing - Guarantees sufficient data for accurate frequency analysis - For 5 MHz resolution: T_sim \u2265 200 ns</p> <p>Practical (needs empirical validation): <pre><code>T_sim = max(multiplier \u00b7 L_bbox/c, L_bbox/c + 2k\u00b7\u03c3, ?)\n</code></pre> - The <code>?</code> depends on Sim4Life's actual post-processing capabilities - Could be as low as 50-100 ns if ARMA/interpolation work well - Or could be 200+ ns if they don't apply to our case</p> <p>Our use case specifics: - Single narrowband resonance (easier to detect than multiple peaks) - Need peak location accuracy (not spectral resolution of two close peaks) - Detecting 50-100 MHz shifts (large compared to potential bin spacing)</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#recommended-approach-implement-with-tunable-parameter","title":"Recommended Approach: Implement with Tunable Parameter","text":"<p>Pragmatic engineering approach:</p> <ol> <li>Implement with conservative defaults:    <pre><code>s4l_arma_speedup_factor = 1.0  # Conservative: assume standard FFT only\nT_resolution = s4l_arma_speedup_factor / (target_freq_resolution_mhz * 1e6)\n</code></pre></li> <li>Guaranteed correct</li> <li>No assumptions about Sim4Life internals</li> <li> <p>For 5 MHz resolution: T_sim = 200 ns</p> </li> <li> <p>Make it tunable via config:    <pre><code>\"simulation_parameters\": {\n    \"target_freq_resolution_mhz\": 5.0,\n    \"s4l_arma_speedup_factor\": 1.0\n}\n</code></pre></p> </li> <li> <p>Test after implementation (optional optimization):</p> </li> <li>Run with speedup factors: [1.0, 1.5, 2.0, 3.0, 4.0]</li> <li>Compare results: accuracy vs. simulation time</li> <li>Find optimal tradeoff</li> <li>Update default if validated</li> </ol> <p>Benefits: - \u2705 Can't break what you haven't built yet (need working code first!) - \u2705 Conservative default guarantees correctness - \u2705 Tunable for optimization without code changes - \u2705 Empirical validation happens after stable implementation - \u2705 Easy to test: just change one config parameter</p> <p>Example optimization tests (run AFTER implementation): <pre><code>speedup=1.0 \u2192 T_sim=200 ns \u2192 \u0394f=5.0 MHz (baseline, guaranteed correct)\nspeedup=1.5 \u2192 T_sim=133 ns \u2192 Test: Does peak detection still work?\nspeedup=2.0 \u2192 T_sim=100 ns \u2192 Test: Does peak detection still work?\nspeedup=3.0 \u2192 T_sim=67 ns  \u2192 Test: Does peak detection still work?\nspeedup=4.0 \u2192 T_sim=50 ns  \u2192 Test: Does peak detection still work?\n</code></pre></p> <p>Find the \"knee\" where accuracy degrades, use that as new default.</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#summary","title":"Summary","text":""},{"location":"technical/gaussian_pulse_timing_analysis/#key-formula-theoretical-conservative-bound","title":"Key Formula (Theoretical Conservative Bound)","text":"<p>Required simulation time for Gaussian excitation with antenna characterization: <pre><code>T_sim = max(multiplier \u00b7 L_bbox/c, L_bbox/c + 2k\u00b7\u03c3, 1/\u0394f_target)\n</code></pre></p> <p>Where: - <code>\u03c3 = 0.94/(\u03c0\u00b7BW)</code> (temporal standard deviation of Gaussian pulse) - <code>k = 3.7</code> (conservative threshold for 0.1% of peak amplitude) - <code>2k\u00b7\u03c3 \u2248 2.22/BW</code> (pulse duration) - <code>\u0394f_target</code> = required frequency resolution (typically 5 MHz for narrowband antennas)</p> <p>\u26a0\ufe0f CAVEAT: This formula assumes standard FFT with no advanced post-processing. Empirical validation required to determine if Sim4Life's internal processing (ARMA, interpolation, zero-padding) allows shorter simulation times.</p>"},{"location":"technical/gaussian_pulse_timing_analysis/#key-findings","title":"Key Findings","text":"<ol> <li> <p>For narrowband antenna characterization (BW = 10-30 MHz), frequency resolution theoretically dominates over pulse duration and propagation time.</p> </li> <li> <p>Theoretical minimum simulation times are much longer than traditional pulse duration estimates:</p> </li> <li>For \u0394f = 5 MHz: T_sim \u2265 200 ns (140 periods @ 700 MHz)</li> <li>For \u0394f = 2 MHz: T_sim \u2265 500 ns (350 periods @ 700 MHz)</li> <li> <p>BUT: Signal processing techniques might relax this significantly</p> </li> <li> <p>Signal processing considerations:</p> </li> <li>Zero padding + interpolation: Better peak location without longer simulation</li> <li>ARMA extrapolation: Sim4Life manual mentions it for \"high-Q resonators\"</li> <li>Sub-bin peak finding: 10-100\u00d7 better accuracy than bin spacing</li> <li> <p>Uncertainty: We don't know what Sim4Life actually does</p> </li> <li> <p>Our use case is favorable for shorter times:</p> </li> <li>Single peak detection (not resolving multiple close peaks)</li> <li>Large detuning detection (50-100 MHz) vs bin spacing</li> <li> <p>Narrowband antenna (high-Q) may benefit from ARMA if implemented</p> </li> <li> <p>PML boundaries absorb outgoing waves, so 1\u00d7 propagation time (with multiplier) is sufficient - no need for 2\u00d7 to account for reflections.</p> </li> <li> <p>Convergence criteria may be unreliable for Gaussian pulses; explicit time calculation is essential.</p> </li> <li> <p>The old multiplier approach (3.5 \u00d7 L_bbox/c) is insufficient for antenna characterization, giving only ~5-10 ns when 50-200+ ns is needed (exact value TBD via testing).</p> </li> </ol>"},{"location":"technical/gaussian_pulse_timing_analysis/#practical-recommendations","title":"Practical Recommendations","text":"<ol> <li>FIRST: Run empirical sensitivity study (see Phase 0.5 in implementation TODO)</li> <li>Test T_sim from 200 ns down to 35 ns</li> <li>Measure actual frequency resolution and peak detection accuracy</li> <li>Determine minimum viable simulation time</li> <li> <p>Document Sim4Life's actual behavior</p> </li> <li> <p>Use narrower excitation bandwidth (50 MHz) for better resolution-to-bandwidth ratio</p> </li> <li> <p>Start conservative (T_sim \u2265 1/\u0394f_target), optimize after empirical validation</p> </li> <li> <p>Validate with point sensors rather than relying solely on convergence criteria</p> </li> <li> <p>Consider two-stage approach: wide bandwidth for detection, narrow for characterization</p> </li> </ol>"},{"location":"technical/gaussian_pulse_timing_analysis/#implementation-impact","title":"Implementation Impact","text":"<p>The implementation will: - Initially use conservative formula (200 ns for 5 MHz resolution) - Include empirical validation phase BEFORE full deployment - Account for frequency resolution requirements (NEW and CRITICAL) - Include pulse duration requirements (as previously analyzed) - Use 1\u00d7 propagation time with appropriate multiplier (NOT 2\u00d7) - Update formula based on empirical findings after validation - Log which constraint dominated (resolution, pulse, or propagation) - Enable accurate detection of 50-100 MHz frequency shifts in narrowband antennas</p> <p>Timeline: 1. Phase 0.5: Sensitivity study (4-6 hours) \u2192 determines actual requirements 2. Phase 1-6: Full implementation with validated formula</p> <p>This ensures both complete Gaussian pulse capture AND sufficient frequency resolution for accurate antenna detuning detection, without over-conservative assumptions that waste computational resources.</p>"},{"location":"technical/isolve_linux_license_tunnel/","title":"Running iSolve on Remote Linux VM with University License Server","text":""},{"location":"technical/isolve_linux_license_tunnel/#the-problem","title":"The Problem","text":"<p>You have: - iSolve/Sim4Life installed on a remote Linux VM (e.g., TensorDock cloud server in the USA) - A university license server (FlexNet) that's only accessible from the university network - Your Windows laptop connected to the university VPN - VNC access to the Linux VM through an SSH tunnel</p> <p>The challenge: The Linux VM cannot directly reach the university license server because it's outside the university network.</p>"},{"location":"technical/isolve_linux_license_tunnel/#the-solution-ssh-reverse-tunnel","title":"The Solution: SSH Reverse Tunnel","text":"<p>Use your Windows laptop (on VPN) as a bridge between the remote Linux VM and the university license server.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     SSH Tunnel      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      VPN        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Linux VM   \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502   Windows   \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 License Server  \u2502\n\u2502  (USA)      \u2502   Reverse Tunnel    \u2502   Laptop    \u2502   University    \u2502 (UGent)         \u2502\n\u2502  iSolve     \u2502   Port 51380        \u2502   (on VPN)  \u2502   Network       \u2502 Port 51380      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"technical/isolve_linux_license_tunnel/#step-by-step-setup","title":"Step-by-Step Setup","text":""},{"location":"technical/isolve_linux_license_tunnel/#1-install-isolve-on-linux-vm","title":"1. Install iSolve on Linux VM","text":"<pre><code># Download and extract the .deb packages\nmkdir ~/Downloads/isolve\ncd ~/Downloads/isolve\n# (transfer your installer files here)\nunzip &lt;installer_archive&gt;\n\n# Install the packages\nsudo apt install ./isolve-sim4life_9.2.1-19976_amd64.deb\n# If dependencies are missing:\nsudo apt-get install -f\n\n# Optionally install neuron package\nsudo apt install ./isolve-neuron_9.2.1-19976_amd64.deb\n</code></pre>"},{"location":"technical/isolve_linux_license_tunnel/#2-find-the-correct-license-server-port","title":"2. Find the Correct License Server Port","text":"<p>The license server port is often NOT the default FlexNet port (27000). To find the actual port:</p> <p>On Windows (while Sim4Life is running): <pre><code>Get-NetTCPConnection | Where-Object {$_.RemoteAddress -eq \"&lt;LICENSE_SERVER_IP&gt;\"} | Select-Object LocalPort, RemotePort, State\n</code></pre></p> <p>In our case, the license server <code>wicacib.private.ugent.be</code> (IP: <code>172.18.30.92</code>) uses port 51380.</p>"},{"location":"technical/isolve_linux_license_tunnel/#3-create-the-ssh-reverse-tunnel","title":"3. Create the SSH Reverse Tunnel","text":"<p>From your Windows laptop (connected to university VPN):</p> <pre><code>ssh -p &lt;VM_SSH_PORT&gt; -i ~/.ssh/&lt;YOUR_KEY&gt; \\\n    -R 51380:&lt;LICENSE_SERVER_IP&gt;:51380 \\\n    user@&lt;VM_IP_ADDRESS&gt;\n</code></pre> <p>Concrete example for this setup: <pre><code>ssh -p 20400 -i ~/.ssh/tensordock_key -R 51380:172.18.30.92:51380 user@174.94.145.71\n</code></pre></p> <p>Combined with VNC tunnel: <pre><code>ssh -p 20400 -i ~/.ssh/tensordock_key \\\n    -L 5901:localhost:5901 \\\n    -R 51380:172.18.30.92:51380 \\\n    user@174.94.145.71\n</code></pre></p>"},{"location":"technical/isolve_linux_license_tunnel/#4-configure-and-run-isolve","title":"4. Configure and Run iSolve","text":"<p>On the Linux VM:</p> <pre><code># Set the license server to use localhost (the tunnel endpoint)\nexport LM_LICENSE_FILE=51380@localhost\n\n# Navigate to iSolve\ncd /usr/local/isolve-sim4life_9.2.1-19976_amd64/bin\n\n# Run iSolve with your simulation file\n./iSolve ~/path/to/your/simulation.h5\n</code></pre>"},{"location":"technical/isolve_linux_license_tunnel/#troubleshooting","title":"Troubleshooting","text":""},{"location":"technical/isolve_linux_license_tunnel/#verify-the-tunnel-is-working","title":"Verify the tunnel is working","text":"<p>On Linux VM: <pre><code># Check if the port is listening\nss -tlnp | grep 51380\n\n# Test connectivity\nnc -zv localhost 51380\n# Should output: Connection to localhost 51380 port [tcp/*] succeeded!\n</code></pre></p>"},{"location":"technical/isolve_linux_license_tunnel/#common-errors-and-fixes","title":"Common errors and fixes","text":"Error Cause Fix <code>License server machine is down or not responding</code> Tunnel not established or wrong port Verify tunnel is running and port is correct <code>Cannot read data from license server system</code> Partial connection, possibly wrong/missing vendor daemon port Check the actual port using PowerShell command above <code>remote port forwarding failed for listen port</code> Port already in use by another SSH session Close all SSH sessions and reconnect <code>Address already in use</code> on local forward Another tunnel is using that port This is fine if it's from another session doing the same thing"},{"location":"technical/isolve_linux_license_tunnel/#x-display-issues-for-gui-apps","title":"X Display issues (for GUI apps)","text":"<p>If running graphical applications through VNC terminal: <pre><code>export DISPLAY=:1\nxhost +local:\n# Now run your GUI app\n</code></pre></p>"},{"location":"technical/isolve_linux_license_tunnel/#quick-reference","title":"Quick Reference","text":""},{"location":"technical/isolve_linux_license_tunnel/#environment-details","title":"Environment Details","text":"<ul> <li>Linux VM: Ubuntu 24.04, TensorDock cloud (174.94.145.71:20400)</li> <li>License Server: wicacib.private.ugent.be (172.18.30.92)</li> <li>License Port: 51380 (NOT the default 27000!)</li> <li>VNC Port: 5901</li> <li>iSolve Version: 9.2.1</li> </ul>"},{"location":"technical/isolve_linux_license_tunnel/#one-liner-command-vnc-license-tunnel","title":"One-liner command (VNC + License Tunnel)","text":"<pre><code>ssh -p 20400 -i ~/.ssh/tensordock_key -L 5901:localhost:5901 -R 51380:172.18.30.92:51380 user@174.94.145.71\n</code></pre>"},{"location":"technical/isolve_linux_license_tunnel/#on-vm-before-running-isolve","title":"On VM before running iSolve","text":"<pre><code>export LM_LICENSE_FILE=51380@localhost\n/usr/local/isolve-sim4life_9.2.1-19976_amd64/bin/iSolve &lt;your_file.h5&gt;\n</code></pre>"},{"location":"technical/isolve_linux_license_tunnel/#key-insights","title":"Key Insights","text":"<ol> <li> <p>Finding the license port is critical - Don't assume it's 27000. Use <code>Get-NetTCPConnection</code> on Windows while the licensed software is running.</p> </li> <li> <p>Use IP address instead of hostname in the tunnel - The hostname resolution happens on your laptop, so it should work either way, but IP is more reliable.</p> </li> <li> <p>Reverse tunnel (-R) vs Forward tunnel (-L):</p> </li> <li><code>-L</code> (forward): Access remote service from local machine</li> <li> <p><code>-R</code> (reverse): Access local network service from remote machine</p> </li> <li> <p>Close old SSH sessions before creating new tunnels to avoid \"port already in use\" errors.</p> </li> </ol>"},{"location":"technical/isolve_linux_license_tunnel/#date","title":"Date","text":"<p>Solution documented: 2026-01-23</p>"},{"location":"technical/multi_sine_excitation_analysis/","title":"Multi-Sine Excitation Analysis: Superposition of Discrete Harmonic Sinusoids","text":""},{"location":"technical/multi_sine_excitation_analysis/#executive-summary","title":"Executive Summary","text":"<p>This document analyzes the feasibility and potential benefits of using a custom multi-sine excitation signal (superposition of harmonic sinusoids at discrete frequencies) for far-field simulations.</p>"},{"location":"technical/multi_sine_excitation_analysis/#key-findings","title":"Key Findings","text":"Aspect Status Physics feasible \u2705 Multi-sine is valid FDTD excitation Dispersive materials \u2705 IT'IS database uses <code>kLinearDispersive</code> - handles all frequencies ExtractedFrequencies \u2705 API confirmed: takes list of frequencies Grid penalty \u2705 None for far-field (already using finest grid for 5800 MHz) Antenna constraint \u2705 None for far-field (plane wave source) Recommended for Far-field only (not near-field due to antenna/grid constraints)"},{"location":"technical/multi_sine_excitation_analysis/#bottom-line","title":"Bottom Line","text":"<p>For far-field: 432 simulations \u2192 48 simulations (89% reduction, ~4\u00d7 speedup)</p> <p>For near-field: Not recommended due to different antenna models per frequency and grid penalties.</p>"},{"location":"technical/multi_sine_excitation_analysis/#context-your-current-problem","title":"Context: Your Current Problem","text":""},{"location":"technical/multi_sine_excitation_analysis/#what-you-have-now","title":"What You Have Now","text":"<ul> <li>Harmonic simulations: Single frequency per run, ~5-10 ns simulation time</li> <li>Multiple configurations: Different phantoms, scenarios, frequencies</li> <li>Bottleneck: Many simulations \u00d7 each frequency = long total campaign time</li> </ul>"},{"location":"technical/multi_sine_excitation_analysis/#why-gaussian-is-appealing-but-problematic","title":"Why Gaussian is Appealing But Problematic","text":"<p>From your existing analysis (<code>gaussian_pulse_timing_analysis.md</code>): - The promise: Single simulation \u2192 full frequency response via FFT - The reality: For 5 MHz frequency resolution, you need ~200 ns simulation time (vs ~5-10 ns for harmonic) - The premium: ~20-40\u00d7 longer per simulation to get wideband data</p>"},{"location":"technical/multi_sine_excitation_analysis/#your-multi-sine-idea","title":"Your Multi-Sine Idea","text":"<p>Instead of: - Gaussian (continuous spectrum, requires long tail for FFT resolution) - Multiple harmonic runs (one frequency each)</p> <p>Why not: - Sum of N sinusoids at discrete frequencies you care about - Each sine reaches steady-state (no decay tail) - Extract each frequency via DFT at those specific frequencies</p>"},{"location":"technical/multi_sine_excitation_analysis/#mathematical-foundation","title":"Mathematical Foundation","text":""},{"location":"technical/multi_sine_excitation_analysis/#multi-sine-signal-definition","title":"Multi-Sine Signal Definition","text":"<p>Your proposed excitation would be:</p> <pre><code>s(t) = \u03a3\u1d62 A\u1d62 \u00b7 cos(2\u03c0\u00b7f\u1d62\u00b7t + \u03c6\u1d62)\n</code></pre> <p>Where: - <code>A\u1d62</code> = amplitude of each tone (typically equal for equal weighting) - <code>f\u1d62</code> = discrete frequency of interest (e.g., 700, 900, 1800 MHz) - <code>\u03c6\u1d62</code> = phase offset (can be zero, but see \"crest factor\" below)</p>"},{"location":"technical/multi_sine_excitation_analysis/#key-properties","title":"Key Properties","text":"<p>1. Steady-State Behavior \u2705 - Unlike Gaussian, sinusoids don't decay to zero - No \"tail problem\" - the signal is perpetually oscillating - Sim4Life can use convergence to steady-state criteria</p> <p>2. Discrete Spectrum \u2705 - Energy exists ONLY at the N chosen frequencies - No spectral leakage to intermediate frequencies - Perfect extraction at known frequencies (if done correctly)</p> <p>3. No DC Component \u2705 - Sum of sines has no DC (assuming no constant offset) - Avoids numerical issues with DC in FDTD</p>"},{"location":"technical/multi_sine_excitation_analysis/#the-critical-question-simulation-time-requirements","title":"The Critical Question: Simulation Time Requirements","text":""},{"location":"technical/multi_sine_excitation_analysis/#why-warmup-is-still-needed-but-finite","title":"Why Warmup is Still Needed (But Finite)","text":"<p>Even though sinusoids are steady-state signals, two time scales matter:</p> <p>1. Transient Propagation Time (<code>T_prop</code>) <pre><code>T_prop = L_bbox / c \u2248 1-5 ns (typical)\n</code></pre> - Fields must propagate from source to observation points - Not the bottleneck</p> <p>2. Beat Period Time (<code>T_beat</code>) - THE KEY ISSUE</p> <p>When you superimpose multiple sinusoids, their sum creates beat patterns:</p> <pre><code>f\u2081 = 700 MHz, f\u2082 = 900 MHz\nBeat frequency = |f\u2082 - f\u2081| = 200 MHz\nBeat period = 1/200 MHz = 5 ns\n</code></pre> <p>For the system to reach a true steady-state where DFT extraction is valid, you need to simulate at least a few beat periods.</p> <p>But here's the catch with widely spaced frequencies:</p> <p>If you have: - f\u2081 = 700 MHz - f\u2082 = 900 MHz - f\u2083 = 1800 MHz</p> <p>The beat frequencies are: - |900-700| = 200 MHz \u2192 T = 5 ns - |1800-700| = 1100 MHz \u2192 T = 0.9 ns - |1800-900| = 900 MHz \u2192 T = 1.1 ns</p> <p>These are all fast beat frequencies because your frequencies are widely spaced!</p> <p>But if frequencies are close (e.g., for antenna detuning detection): - f\u2081 = 700 MHz - f\u2082 = 710 MHz - f\u2083 = 720 MHz</p> <p>Beat frequencies: - |710-700| = 10 MHz \u2192 T = 100 ns - |720-710| = 10 MHz \u2192 T = 100 ns - |720-700| = 20 MHz \u2192 T = 50 ns</p> <p>For close frequencies, you need longer simulation times for beat pattern to establish!</p>"},{"location":"technical/multi_sine_excitation_analysis/#the-periodicity-constraint","title":"The Periodicity Constraint","text":"<p>A crucial mathematical fact: The sum of sinusoids is only periodic if all frequency ratios are rational.</p> <p>Example: - f\u2081 = 700 MHz, f\u2082 = 1400 MHz \u2192 ratio 2:1 \u2192 periodic \u2705 - f\u2081 = 700 MHz, f\u2082 = 900 MHz \u2192 ratio 9:7 \u2192 periodic \u2705 (period = 7 \u00d7 T\u2081 = 9 \u00d7 T\u2082) - f\u2081 = 700 MHz, f\u2082 = 700.001 MHz \u2192 ratio irrational \u2192 never exactly periodic \u274c</p> <p>For practical frequencies like telecom bands (700, 900, 1800, 2100, 3500 MHz), the ratios ARE rational (since frequencies are integers in Hz), so the combined waveform is periodic, just with a potentially very long period.</p>"},{"location":"technical/multi_sine_excitation_analysis/#simulation-time-requirements-multi-sine-vs-alternatives","title":"Simulation Time Requirements: Multi-Sine vs Alternatives","text":""},{"location":"technical/multi_sine_excitation_analysis/#scenario-a-widely-spaced-frequencies-different-bands","title":"Scenario A: Widely Spaced Frequencies (Different Bands)","text":"<p>Goal: Simulate at 700, 900, 1800 MHz in one run</p> Approach Simulation Time Post-Processing Notes 3\u00d7 Harmonic 3 \u00d7 5 ns = 15 ns total None Baseline Gaussian ~200 ns (for 5 MHz res) FFT Overkill for 3 discrete points Multi-Sine (3 tones) ~10-20 ns DFT at 3 frequencies \u2705 Potentially efficient <p>Analysis: For widely-spaced frequencies, multi-sine is promising because: - Beat frequencies are high (short periods) - You only need a few periods of the slowest beat to establish steady-state - Extraction is trivial (lock-in at known frequencies)</p>"},{"location":"technical/multi_sine_excitation_analysis/#scenario-b-closely-spaced-frequencies-detuning-detection","title":"Scenario B: Closely Spaced Frequencies (Detuning Detection)","text":"<p>Goal: Detect resonance shift \u00b125 MHz around 700 MHz (e.g., 675-725 MHz in 5 MHz steps = 11 frequencies)</p> Approach Simulation Time Post-Processing Notes 11\u00d7 Harmonic 11 \u00d7 5 ns = 55 ns total None Many runs Gaussian ~200 ns FFT gives continuous spectrum Standard approach Multi-Sine (11 tones) ~50-100 ns DFT at 11 frequencies Beat periods dominate! <p>Analysis: For closely-spaced frequencies, multi-sine loses advantage because: - Beat frequency = 5 MHz \u2192 requires ~200 ns for clean extraction - You're back to Gaussian-like time requirements!</p>"},{"location":"technical/multi_sine_excitation_analysis/#the-extractedfrequencies-feature-in-sim4life","title":"The ExtractedFrequencies Feature in Sim4Life","text":"<p>You mentioned Sim4Life's <code>ExtractedFrequencies</code> variable. Let me clarify how this works:</p> <pre><code># From your code (source_setup.py):\nfar_field_sensor_settings.ExtractedFrequencies = (\n    extracted_frequencies_hz,  # List of frequencies\n    self.units.Hz,\n)\n</code></pre> <p>What this does: - Tells Sim4Life to compute frequency-domain data at those specific frequencies - Uses DFT (Discrete Fourier Transform) on the time-domain results - Works with ANY excitation type (Gaussian, Harmonic, or custom)</p> <p>Key insight: You can use <code>ExtractedFrequencies</code> with a multi-sine source AND get per-frequency results!</p> <p>This is exactly what you need - you excite with a multi-sine signal, and Sim4Life's post-processing DFT extracts the response at each of your chosen frequencies.</p>"},{"location":"technical/multi_sine_excitation_analysis/#practical-implementation-considerations","title":"Practical Implementation Considerations","text":""},{"location":"technical/multi_sine_excitation_analysis/#1-crest-factor-problem","title":"1. Crest Factor Problem","text":"<p>When you add multiple sinusoids, their peaks can add constructively, creating very high instantaneous amplitudes:</p> <pre><code>N sinusoids in phase: peak amplitude = N \u00d7 individual amplitude\n</code></pre> <p>Issue: This can cause numerical issues or require lower per-tone amplitudes</p> <p>Solution: Use phase offsets (Schroeder phases) to minimize crest factor: <pre><code># Schroeder phase sequence minimizes peak amplitude\nphases = [np.pi * k * (k+1) / N for k in range(N)]\n</code></pre></p>"},{"location":"technical/multi_sine_excitation_analysis/#2-warmup-ramp-still-needed","title":"2. Warmup Ramp Still Needed","text":"<p>Even for multi-sine, you need to ramp the source gradually: <pre><code># Instead of sudden turn-on:\ns(t) = ramp(t) \u00d7 \u03a3\u1d62 A\u1d62 cos(2\u03c0f\u1d62t + \u03c6\u1d62)\n\n# Where ramp(t) transitions smoothly from 0 to 1\n</code></pre></p>"},{"location":"technical/multi_sine_excitation_analysis/#3-frequency-separation-and-orthogonality","title":"3. Frequency Separation and Orthogonality","text":"<p>For clean DFT extraction, the simulation time should be an integer multiple of the period at each frequency: <pre><code>T_sim = K / f_lowest = K \u00d7 T_period_longest\n</code></pre></p> <p>If frequencies don't share a common period, DFT leakage can occur, but this is usually minor for well-separated frequencies.</p>"},{"location":"technical/multi_sine_excitation_analysis/#4-memory-and-computational-cost","title":"4. Memory and Computational Cost","text":"<p>The FDTD computational cost per timestep is the same regardless of excitation type. What matters is: - Total timesteps = T_sim / \u0394t - Post-processing: DFT at N specific frequencies is O(N \u00d7 M) where M = number of time samples   - This is MUCH faster than full FFT O(M log M) for the typical case where N &lt;&lt; M</p>"},{"location":"technical/multi_sine_excitation_analysis/#decision-matrix-when-to-use-which-approach","title":"Decision Matrix: When to Use Which Approach","text":"Use Case Best Approach Reasoning Single frequency SAR Harmonic Simplest, fastest for one-off Many frequencies, same phantom Multi-Sine One sim, multiple extractions Continuous spectrum needed Gaussian Only way to get true broadband Antenna detuning (narrow band sweep) Gaussian Close frequencies = long beat periods anyway Widely spaced bands (700/900/1800) Multi-Sine Beat periods fast, clean separation Maximum accuracy at specific frequency Harmonic No inter-frequency interference"},{"location":"technical/multi_sine_excitation_analysis/#potential-issues-resolved-via-api-verification","title":"Potential Issues (Resolved via API Verification)","text":""},{"location":"technical/multi_sine_excitation_analysis/#1-inter-frequency-coupling-in-nonlinear-systems","title":"1. Inter-Frequency Coupling in Nonlinear Systems","text":"<ul> <li>If your phantom/antenna system has any nonlinearity, multi-sine excitation can create intermodulation products</li> <li>For linear SAR calculations (which yours are), this is NOT an issue</li> <li>FDTD with linear dispersive materials is inherently linear</li> </ul>"},{"location":"technical/multi_sine_excitation_analysis/#2-sar-at-each-frequency","title":"2. SAR at Each Frequency","text":"<ul> <li>SAR is power normalized</li> <li>With multi-sine, the total input power is distributed across frequencies</li> <li>Need to normalize SAR per frequency by the power at that specific frequency</li> </ul>"},{"location":"technical/multi_sine_excitation_analysis/#3-sim4life-compatibility-verified","title":"3. Sim4Life Compatibility: VERIFIED \u2705","text":"<ul> <li><code>UserDefined</code> excitation with custom expression is supported (you already use it for Gaussian)</li> <li>Multi-sine expression would be: <pre><code>expression = \" + \".join([\n    f\"{amp} * cos(2 * pi * {freq} * _t + {phase})\" \n    for amp, freq, phase in zip(amplitudes, frequencies, phases)\n])\n</code></pre></li> </ul>"},{"location":"technical/multi_sine_excitation_analysis/#4-extractedfrequencies-with-multi-sine-verified","title":"4. ExtractedFrequencies with Multi-Sine: VERIFIED \u2705","text":"<p>From Sim4Life Python API Reference:</p> <pre><code># API confirms this works with any excitation type:\nsettings.ExtractedFrequencies = [450e6, 700e6, 835e6, 1450e6, 2140e6, 2450e6, 3500e6, 5200e6, 5800e6]\nsettings.OnTheFlyDFT = True\nsettings.RecordingDomain = 'RecordInFrequencyDomain'\n</code></pre>"},{"location":"technical/multi_sine_excitation_analysis/#5-dispersive-materials-verified","title":"5. Dispersive Materials: VERIFIED \u2705","text":"<p>From Sim4Life Python API Reference (<code>EmFdtdMaterialSettings.eMaterialModel</code>):</p> <pre><code>kConst             # Constant (frequency-independent)\nkLinearDispersive  # \u2190 IT'IS database uses this (frequency-dependent)\nkMetaMaterial      # Metamaterial\n</code></pre> <ul> <li>IT'IS tissues use <code>kLinearDispersive</code> with Debye parameters</li> <li>FDTD solver handles all frequencies correctly via ADE method</li> <li>Each frequency component sees correct \u03b5(f) and \u03c3(f) automatically</li> </ul>"},{"location":"technical/multi_sine_excitation_analysis/#recommendation-a-hybrid-strategy","title":"Recommendation: A Hybrid Strategy","text":"<p>Based on this analysis, I recommend a pragmatic hybrid approach:</p>"},{"location":"technical/multi_sine_excitation_analysis/#for-your-main-workload-different-frequenciesphantomsscenarios","title":"For Your Main Workload (Different Frequencies\u00d7Phantoms\u00d7Scenarios):","text":"<p>Group by frequency separation:</p> <ol> <li>Widely separated frequencies in same simulation (700, 900, 1800 MHz)</li> <li>Use multi-sine with 3-5 tones per group</li> <li>Expect ~15-30 ns simulation time</li> <li>Extract SAR at each frequency via DFT</li> <li> <p>Potential speedup: 3-5\u00d7 fewer simulations</p> </li> <li> <p>Closely spaced frequency sweeps (for detuning or fine analysis)</p> </li> <li>Stick with Gaussian (you need ~200 ns anyway)</li> <li> <p>Or run multiple harmonics if Gaussian overhead is too high</p> </li> <li> <p>Single critical frequency (final validation)</p> </li> <li>Use harmonic for maximum accuracy</li> <li>No inter-frequency artifacts</li> </ol>"},{"location":"technical/multi_sine_excitation_analysis/#implementation-roadmap-if-you-proceed","title":"Implementation Roadmap (If You Proceed):","text":"<p>Phase 1: Proof of Concept (4-8 hours) 1. Create a test config with 3 widely-spaced frequencies 2. Implement multi-sine expression in <code>source_setup.py</code> 3. Run single test, compare each frequency's SAR with harmonic baseline 4. Validate power normalization is correct</p> <p>Phase 2: Full Integration (if Phase 1 succeeds) 1. Add config options for multi-sine 2. Handle extracted frequencies based on source specification 3. Update power/SAR extraction for multi-frequency normalization 4. Create user documentation</p>"},{"location":"technical/multi_sine_excitation_analysis/#mathematical-appendix-beat-period-calculation","title":"Mathematical Appendix: Beat Period Calculation","text":"<p>For N frequencies <code>{f\u2081, f\u2082, ..., f\u2099}</code>, the beat frequencies are all pairwise differences:</p> <pre><code>f_beat(i,j) = |f\u1d62 - f\u2c7c|\n</code></pre> <p>The overall period of the combined waveform (if all frequencies are rationally related) is: <pre><code>T_total = LCM(T\u2081, T\u2082, ..., T\u2099)\n</code></pre></p> <p>Where <code>LCM</code> is the Least Common Multiple and <code>T\u1d62 = 1/f\u1d62</code>.</p> <p>Example Calculation: - f\u2081 = 700 MHz \u2192 T\u2081 = 1.429 ns - f\u2082 = 900 MHz \u2192 T\u2082 = 1.111 ns</p> <p>Integer multiple relationship: - 700 MHz \u00d7 9 = 6300 MHz - 900 MHz \u00d7 7 = 6300 MHz - Period of sum = 9 \u00d7 T\u2081 = 7 \u00d7 T\u2082 = 12.86 ns</p> <p>So you'd need at least ~13 ns to see one complete cycle of the combined waveform, plus propagation and warmup \u2192 ~30-50 ns total should be safe.</p>"},{"location":"technical/multi_sine_excitation_analysis/#conclusion","title":"Conclusion","text":"<p>Your multi-sine idea is physically sound and highly valuable for far-field simulations:</p>"},{"location":"technical/multi_sine_excitation_analysis/#for-far-field-recommended","title":"For Far-Field (RECOMMENDED) \u2705","text":"Benefit Value Simulation reduction 432 \u2192 48 (89%) Time per sim increase ~2.2\u00d7 (beat period overhead) Net speedup ~4\u00d7 <p>\u2705 All 9 frequencies in one simulation \u2705 No antenna model constraint (plane wave) \u2705 No grid penalty (already using 1.0 mm for 5800 MHz) \u2705 Dispersive materials work automatically \u2705 ExtractedFrequencies API supports multi-frequency extraction  </p>"},{"location":"technical/multi_sine_excitation_analysis/#for-near-field-not-recommended","title":"For Near-Field (NOT RECOMMENDED) \u26a0\ufe0f","text":"<ul> <li>Different antenna models per frequency (PIFA vs IFA)</li> <li>Different grid requirements per frequency</li> <li>Limited to grouping only highest 3 frequencies (22% reduction)</li> </ul>"},{"location":"technical/multi_sine_excitation_analysis/#implementation-priority","title":"Implementation Priority","text":"<ol> <li>Far-field multi-sine: High priority, ~4\u00d7 speedup</li> <li>Near-field: Keep using harmonic simulations</li> <li>Detuning detection: Keep Gaussian (need continuous spectrum)</li> </ol> <p>Document created: 2025-12-12 Updated: 2025-12-12 with API verification Related documents: multi_sine_grouping_math.md, gaussian_pulse_timing_analysis.md</p>"},{"location":"technical/multi_sine_grouping_math/","title":"Multi-Sine Frequency Grouping: Practical Math for Your Frequencies","text":""},{"location":"technical/multi_sine_grouping_math/#your-frequencies","title":"Your Frequencies","text":"<p>From <code>near_field_config.json</code> and <code>far_field_config.json</code>:</p> <pre><code>450, 700, 835, 1450, 2140, 2450, 3500, 5200, 5800 MHz\n</code></pre> <p>That's 9 frequencies \u00d7 phantoms \u00d7 placements \u00d7 orientations = a lot of simulations.</p>"},{"location":"technical/multi_sine_grouping_math/#the-core-question-what-limits-how-many-frequencies-you-can-group","title":"The Core Question: What Limits How Many Frequencies You Can Group?","text":""},{"location":"technical/multi_sine_grouping_math/#constraint-1-beat-period-simulation-time","title":"Constraint 1: Beat Period (Simulation Time)","text":"<p>When you combine sinusoids, beats occur at the difference frequencies. The simulation must run long enough for the beat pattern to establish steady-state.</p> <p>Rule of thumb: Need at least 3-5 beat periods to reach steady-state.</p> <p>Minimum simulation time: <pre><code>T_sim \u2248 5 / f_beat_min = 5 / min(|f\u1d62 - f\u2c7c|)\n</code></pre></p>"},{"location":"technical/multi_sine_grouping_math/#constraint-2-grid-resolution-the-physics-killer","title":"Constraint 2: Grid Resolution (The Physics Killer)","text":"<p>THIS IS THE BIG CATCH:</p> <p>FDTD grid step must resolve the highest frequency in the signal: <pre><code>\u0394x \u2264 \u03bb_min / N  where N = 10-20 points per wavelength\n</code></pre></p> <p>If you group 700 MHz with 5800 MHz: - \u03bb(700 MHz) = 428 mm - \u03bb(5800 MHz) = 52 mm</p> <p>Your grid step is set for the highest frequency in the group!</p> <p>From your config, you already have different grid steps per frequency: <pre><code>\"global_gridding_per_frequency\": {\n    \"450\": 2.5 mm,\n    \"700\": 2.5 mm,\n    \"835\": 2.5 mm,\n    \"1450\": 2.5 mm,\n    \"2140\": 1.694 mm,\n    \"2450\": 1.482 mm,\n    \"3500\": 1.0 mm,\n    \"5200\": 1.0 mm,\n    \"5800\": 1.0 mm\n}\n</code></pre></p> <p>Implication: If you group 700 MHz + 5800 MHz, you must use 1.0 mm grid step for the entire simulation (the finest grid), which MASSIVELY increases computational cost.</p>"},{"location":"technical/multi_sine_grouping_math/#constraint-3-antenna-model-more-physics","title":"Constraint 3: Antenna Model (More Physics)","text":"<p>Look at your <code>antenna_config</code>: - 700, 835 MHz \u2192 PIFA antenna - 1450, 2140, 2450, 3500, 5200, 5800 MHz \u2192 IFA antenna</p> <p>You cannot mix different antenna models in one simulation!</p> <p>Each antenna is tuned for specific frequencies. A PIFA operating at 5800 MHz won't behave realistically.</p>"},{"location":"technical/multi_sine_grouping_math/#practical-grouping-analysis","title":"Practical Grouping Analysis","text":""},{"location":"technical/multi_sine_grouping_math/#group-by-antenna-type-mandatory","title":"Group by Antenna Type (MANDATORY)","text":"<p>PIFA Group: 700, 835 MHz IFA Group: 1450, 2140, 2450, 3500, 5200, 5800 MHz</p>"},{"location":"technical/multi_sine_grouping_math/#within-each-group-grid-compatibility","title":"Within Each Group: Grid Compatibility","text":"<p>PIFA Group (700, 835 MHz): - Both use 2.5 mm grid step \u2705 - Can be grouped without grid penalty</p> <p>IFA Group: | Frequency | Grid Step | Can group with... | |-----------|-----------|-------------------| | 1450 MHz  | 2.5 mm    | 1450 only (2.5mm) | | 2140 MHz  | 1.694 mm  | 2140-2450 (similar) | | 2450 MHz  | 1.482 mm  | 2140-2450 | | 3500 MHz  | 1.0 mm    | 3500-5800 | | 5200 MHz  | 1.0 mm    | 3500-5800 | | 5800 MHz  | 1.0 mm    | 3500-5800 |</p>"},{"location":"technical/multi_sine_grouping_math/#beat-period-calculations","title":"Beat Period Calculations","text":""},{"location":"technical/multi_sine_grouping_math/#pifa-group-700-835-mhz","title":"PIFA Group: 700 + 835 MHz","text":"<pre><code>f_beat = |835 - 700| = 135 MHz\nT_beat = 1/135 MHz = 7.4 ns\nT_sim = 5 \u00d7 T_beat = 37 ns\n</code></pre> <p>Compare to: 2 \u00d7 ~5 ns = 10 ns (two harmonic runs)</p> <p>Overhead: 37 ns / 10 ns = 3.7\u00d7 longer per sim</p> <p>But you get 2 frequency results from 1 sim, so: - Total work: 37 ns (multi-sine) vs 10 ns (2\u00d7 harmonic) - Speedup: None! Actually 3.7\u00d7 slower!</p> <p>Wait, that doesn't seem right. Let me reconsider...</p> <p>Actually, the 5 ns harmonic time is for the EM wave to propagate and establish steady-state. The multi-sine beat period constraint is additional to propagation.</p> <p>Revised calculation: - Propagation time: ~5 ns (both cases) - Harmonic: 5 ns \u00d7 2 runs = 10 ns total wall clock - Multi-sine: ~5 ns propagation + 37 ns beats = ~40 ns wall clock</p> <p>Verdict for PIFA group: NOT WORTH IT for this frequency pair (135 MHz is too close to low frequency = long beat period relative to base time).</p>"},{"location":"technical/multi_sine_grouping_math/#ifa-high-frequency-group-3500-5200-5800-mhz","title":"IFA High-Frequency Group: 3500 + 5200 + 5800 MHz","text":"<pre><code>Beat frequencies:\n|5200 - 3500| = 1700 MHz \u2192 T = 0.59 ns\n|5800 - 3500| = 2300 MHz \u2192 T = 0.43 ns\n|5800 - 5200| = 600 MHz  \u2192 T = 1.67 ns\n\nT_beat_slowest = 1.67 ns\nT_sim \u2248 5 \u00d7 1.67 = 8.4 ns\n</code></pre> <p>Compare to: 3 \u00d7 ~5 ns = 15 ns (three harmonic runs)</p> <p>This looks better!</p> <ul> <li>Multi-sine: ~8.4 ns (one sim, 3 frequencies)</li> <li>Harmonic: ~15 ns (three sims)</li> <li>Speedup: 15/8.4 = 1.8\u00d7 </li> </ul> <p>Grid penalty: All three use 1.0 mm, so none!</p>"},{"location":"technical/multi_sine_grouping_math/#ifa-mid-frequency-2140-2450-mhz","title":"IFA Mid-Frequency: 2140 + 2450 MHz","text":"<pre><code>f_beat = |2450 - 2140| = 310 MHz\nT_beat = 3.2 ns\nT_sim \u2248 5 \u00d7 3.2 = 16 ns\n</code></pre> <p>Compare to: 2 \u00d7 ~5 ns = 10 ns</p> <p>Speedup: 10/16 = 0.625\u00d7 (SLOWER!)</p>"},{"location":"technical/multi_sine_grouping_math/#the-math-summary","title":"The Math Summary","text":"<p>Let me calculate this properly with a general formula:</p>"},{"location":"technical/multi_sine_grouping_math/#time-for-n-harmonic-simulations","title":"Time for N Harmonic Simulations","text":"<pre><code>T_harmonic_total = N \u00d7 T_harmonic_single \u2248 N \u00d7 5 ns\n</code></pre>"},{"location":"technical/multi_sine_grouping_math/#time-for-n-frequency-multi-sine-simulation","title":"Time for N-frequency Multi-Sine Simulation","text":"<pre><code>T_multisine = max(T_propagation, 5 \u00d7 T_beat_slowest)\n            = max(5 ns, 5 / min(|f\u1d62 - f\u2c7c|))\n</code></pre>"},{"location":"technical/multi_sine_grouping_math/#condition-for-multi-sine-to-be-faster","title":"Condition for Multi-Sine to be Faster","text":"<pre><code>T_multisine &lt; N \u00d7 T_harmonic_single\n5 / min(\u0394f) &lt; N \u00d7 5 ns\n1 / min(\u0394f) &lt; N ns\nmin(\u0394f) &gt; 1/N GHz = 1000/N MHz\n</code></pre> <p>Rule: Multi-sine is faster when the minimum frequency difference exceeds <code>1000/N MHz</code>.</p> N frequencies min(\u0394f) required 2 &gt; 500 MHz 3 &gt; 333 MHz 4 &gt; 250 MHz 5 &gt; 200 MHz"},{"location":"technical/multi_sine_grouping_math/#applying-to-your-frequencies","title":"Applying to Your Frequencies","text":""},{"location":"technical/multi_sine_grouping_math/#pifa-700-835-mhz","title":"PIFA: 700 + 835 MHz","text":"<ul> <li>\u0394f = 135 MHz</li> <li>Need \u0394f &gt; 500 MHz for 2-group</li> <li>FAILS \u274c</li> </ul>"},{"location":"technical/multi_sine_grouping_math/#ifa-low-mid-1450-2140-2450-mhz","title":"IFA Low-Mid: 1450 + 2140 + 2450 MHz","text":"<ul> <li>Minimum \u0394f = |2450-2140| = 310 MHz</li> <li>Need \u0394f &gt; 333 MHz for 3-group</li> <li>FAILS (barely) \u274c</li> </ul> <p>But wait, let's check 2-groups: - 1450 + 2140: \u0394f = 690 MHz &gt; 500 MHz \u2705 - 2140 + 2450: \u0394f = 310 MHz &lt; 500 MHz \u274c - 1450 + 2450: \u0394f = 1000 MHz &gt; 500 MHz \u2705</p>"},{"location":"technical/multi_sine_grouping_math/#ifa-high-3500-5200-5800-mhz","title":"IFA High: 3500 + 5200 + 5800 MHz","text":"<ul> <li>Minimum \u0394f = |5800-5200| = 600 MHz</li> <li>Need \u0394f &gt; 333 MHz for 3-group</li> <li>PASSES \u2705</li> </ul>"},{"location":"technical/multi_sine_grouping_math/#grid-penalty-consideration","title":"Grid Penalty Consideration","text":"<p>Even when beat periods allow grouping, different grid requirements may cancel the benefit:</p> <p>Example: 1450 + 3500 MHz - Beat: \u0394f = 2050 MHz &gt; 500 MHz \u2705 - Grid: 1450 uses 2.5 mm, 3500 uses 1.0 mm - If combined: must use 1.0 mm throughout</p> <p>Grid cells scale as: <pre><code>N_cells \u221d (1/\u0394x)\u00b3\n</code></pre></p> <p>Going from 2.5 mm to 1.0 mm: <pre><code>Penalty = (2.5/1.0)\u00b3 = 15.6\u00d7\n</code></pre></p> <p>The 1.8\u00d7 speedup from grouping is completely destroyed by the 15.6\u00d7 grid penalty!</p>"},{"location":"technical/multi_sine_grouping_math/#final-recommendations","title":"Final Recommendations","text":""},{"location":"technical/multi_sine_grouping_math/#viable-multi-sine-groups-minimal-overhead","title":"Viable Multi-Sine Groups (minimal overhead):","text":"Group Frequencies \u0394f_min Grid Speedup High-freq IFA 3500, 5200, 5800 600 MHz 1.0 mm (same) ~1.8\u00d7"},{"location":"technical/multi_sine_grouping_math/#not-worth-grouping","title":"NOT Worth Grouping:","text":"Pair/Group Reason 700 + 835 Beat period too slow (\u0394f = 135 MHz) Any PIFA + IFA Different antennas! 1450 + 2140 Grid penalty (2.5\u21921.7 mm) 2140 + 2450 Beat period marginal (\u0394f = 310 MHz) Any low + high freq Massive grid penalty"},{"location":"technical/multi_sine_grouping_math/#practical-strategy","title":"Practical Strategy","text":"<p>For your 9 frequencies:</p> <p>Run separately (8 simulations): - 450 MHz (PIFA? or standalone) - 700 MHz (PIFA) - 835 MHz (PIFA) - 1450 MHz (IFA) - 2140 MHz (IFA) - 2450 MHz (IFA)</p> <p>Group into 1 simulation (saves 2 simulations): - [3500 + 5200 + 5800] MHz (IFA, all 1.0 mm grid)</p> <p>Total: 8 + 1 = 9 simulations \u2192 7 simulations (22% reduction)</p> <p>That's not as dramatic as I hoped, but for your full matrix: - 9 freqs \u00d7 4 phantoms \u00d7 3 placements \u00d7 6 orientations = 648 simulations - With grouping: 7 \u00d7 4 \u00d7 3 \u00d7 6 = 504 simulations - Savings: 144 simulations (~22%)</p>"},{"location":"technical/multi_sine_grouping_math/#alternative-cherry-pick-for-specific-studies","title":"Alternative: Cherry-Pick for Specific Studies","text":"<p>If you only need a subset of frequencies for certain phantoms/placements, the grouping math changes.</p> <p>For example, if you only care about \"telecom bands\": - 700, 1800, 2600 MHz (LTE bands)</p> <pre><code>\u0394f_min = |1800-700| = 1100 MHz &gt; 333 MHz \u2705\n</code></pre> <p>This WOULD work... if they used the same antenna model and similar grids.</p>"},{"location":"technical/multi_sine_grouping_math/#conclusion","title":"Conclusion","text":"<p>Multi-sine grouping is marginally useful for your current setup:</p> <ol> <li>Only viable group: 3500 + 5200 + 5800 MHz (~1.8\u00d7 speedup, 22% fewer sims overall)</li> <li>Main blockers: Different antenna models, different grid requirements, close frequencies</li> <li>The grid penalty is brutal: Mixing grids often costs more than you save</li> </ol> <p>Better speedup strategies (if you haven't already): 1. Cloud parallelization (run all harmonic sims in parallel) 2. Reduce phantom/placement combinations where scientifically appropriate 3. Coarser grids for exploratory runs, fine grids for final results</p> <p>Calculations based on T_propagation \u2248 5 ns and 5 beat periods for steady-state. Actual values may vary with phantom size and convergence criteria.</p>"},{"location":"technical/multi_sine_grouping_math/#correction-far-field-analysis-youre-right","title":"CORRECTION: Far-Field Analysis (You're Right!)","text":""},{"location":"technical/multi_sine_grouping_math/#far-field-is-different","title":"Far-Field is Different!","text":"<p>For far-field simulations, the constraints I listed for near-field don't apply:</p> <ol> <li>\u2705 No antenna models - Plane wave excitation is the same for all frequencies</li> <li>\u2705 Grid already paid for - You MUST use the finest grid (1.0 mm for 5800 MHz) regardless</li> <li>\u2705 Same phantom setup - No placement/orientation complexity per frequency</li> </ol> <p>The ONLY constraint is beat period!</p>"},{"location":"technical/multi_sine_grouping_math/#recalculating-for-far-field","title":"Recalculating for Far-Field","text":"<p>Your frequencies: <code>450, 700, 835, 1450, 2140, 2450, 3500, 5200, 5800 MHz</code></p> <p>Since we're already paying for 1.0 mm grid (for 5800 MHz), let's see what groupings are possible:</p>"},{"location":"technical/multi_sine_grouping_math/#all-9-frequencies-in-one-simulation","title":"All 9 Frequencies in One Simulation?","text":"<pre><code>Frequencies: 450, 700, 835, 1450, 2140, 2450, 3500, 5200, 5800 MHz\n\nMinimum frequency difference: |700 - 450| = 250 MHz\n                              |835 - 700| = 135 MHz  \u2190 SMALLEST\n                              \nT_beat_slowest = 1 / 135 MHz = 7.4 ns\nT_sim \u2248 5 \u00d7 7.4 ns = 37 ns\n</code></pre> <p>Compare to 9 separate harmonic runs: 9 \u00d7 5 ns = 45 ns</p> <p>Speedup: 45/37 = 1.2\u00d7 (but only 1 simulation instead of 9!)</p> <p>Actually wait - the simulation time for each harmonic isn't just 5 ns, let me think about this more carefully...</p>"},{"location":"technical/multi_sine_grouping_math/#correct-time-analysis","title":"Correct Time Analysis","text":"<p>For far-field with full-body phantom (L_bbox ~ 2m diagonal): <pre><code>T_propagation = L_bbox / c = 2.0 m / 3\u00d710\u2078 m/s = 6.7 ns\nWith multiplier (3.5\u00d7): T_harmonic \u2248 23 ns per simulation\n</code></pre></p> <p>For 9 frequencies: - Harmonic approach: 9 \u00d7 23 ns = 207 ns total (but could parallelize) - Multi-sine (9 freqs): max(23 ns, 5 \u00d7 7.4 ns) = max(23 ns, 37 ns) = 37 ns</p> <p>If running serially: 207 ns \u2192 37 ns = 5.6\u00d7 speedup! If parallelized fully: Same wall-clock, but 9\u00d7 fewer GPU-hours</p>"},{"location":"technical/multi_sine_grouping_math/#but-what-about-directions-polarizations","title":"But What About Directions &amp; Polarizations?","text":"<p>From your config: <pre><code>\"incident_directions\": [\"x_pos\", \"x_neg\", \"y_pos\", \"y_neg\", \"z_pos\", \"z_neg\"],\n\"polarizations\": [\"theta\", \"phi\"]\n</code></pre></p> <p>That's 6 \u00d7 2 = 12 simulations per frequency per phantom.</p> <p>Current approach: 9 freqs \u00d7 12 directions = 108 simulations per phantom Multi-sine approach: 1 freq-group \u00d7 12 directions = 12 simulations per phantom</p> <p>Speedup: 9\u00d7 fewer simulations! (with ~1.6\u00d7 longer per sim for beats)</p> <p>Net speedup: 9 / 1.6 \u2248 5.6\u00d7</p>"},{"location":"technical/multi_sine_grouping_math/#optimal-grouping-strategy","title":"Optimal Grouping Strategy","text":"<p>The 135 MHz gap (700-835) is the bottleneck. Options:</p>"},{"location":"technical/multi_sine_grouping_math/#option-a-all-9-frequencies-together","title":"Option A: All 9 frequencies together","text":"<ul> <li>T_beat = 37 ns (limited by 135 MHz gap)</li> <li>Speedup: ~5-6\u00d7 vs serial harmonic</li> <li>Simplest to implement</li> </ul>"},{"location":"technical/multi_sine_grouping_math/#option-b-split-by-gap-size","title":"Option B: Split by gap size","text":"<p>Group frequencies into clusters where min(\u0394f) is large:</p> <p>Group 1: 450, 700 MHz - \u0394f = 250 MHz \u2192 T_beat = 20 ns \u2705</p> <p>Group 2: 835, 1450, 2140, 2450 MHz - Minimum \u0394f = |2450-2140| = 310 MHz \u2192 T_beat = 16 ns \u2705</p> <p>Group 3: 3500, 5200, 5800 MHz - Minimum \u0394f = 600 MHz \u2192 T_beat = 8.3 ns \u2705</p> <p>Total: 3 simulations per direction/polarization instead of 9 - Current: 108 sims per phantom - Grouped: 36 sims per phantom - Speedup: 3\u00d7 (with minimal beat overhead)</p>"},{"location":"technical/multi_sine_grouping_math/#option-c-remove-the-bottleneck","title":"Option C: Remove the bottleneck","text":"<p>If you could skip 835 MHz:</p> <p>8 frequencies without 835: 450, 700, 1450, 2140, 2450, 3500, 5200, 5800 - Minimum \u0394f = |700-450| = 250 MHz \u2192 T_beat = 20 ns</p> <p>Or skip 700 MHz: - Minimum \u0394f = |835-450| = 385 MHz \u2192 T_beat = 13 ns</p>"},{"location":"technical/multi_sine_grouping_math/#summary-table","title":"Summary Table","text":"Strategy Sims/phantom Beat overhead Net speedup All separate 108 0 1\u00d7 (baseline) All 9 together 12 1.6\u00d7 5.6\u00d7 3 smart groups 36 1.1\u00d7 2.7\u00d7 Skip 835, all 8 12 1.0\u00d7 9\u00d7"},{"location":"technical/multi_sine_grouping_math/#grid-reality-check","title":"Grid Reality Check","text":"<p>You mentioned \"we have to run 5800 anyway\". Let's verify the grid situation:</p> <p>For far-field, the grid must resolve the shortest wavelength in the signal: - \u03bb(5800 MHz) = 52 mm - \u03bb/20 = 2.6 mm per cell</p> <p>Your config says 1.0 mm for 5800 MHz. If running multi-sine with all 9 frequencies, you still use 1.0 mm grid.</p> <p>There is NO additional grid penalty - you're already paying for the finest grid!</p>"},{"location":"technical/multi_sine_grouping_math/#conclusion-far-field-multi-sine-is-very-worth-it","title":"Conclusion: Far-Field Multi-Sine is VERY Worth It","text":"<p>For far-field: - 5-9\u00d7 fewer simulations per phantom - No antenna model constraint - No additional grid penalty - Only cost: Slightly longer simulation time per run (~1.6\u00d7 for beat periods)</p> <p>Recommended approach: Group all 9 frequencies, or group into 3 clusters to minimize beat overhead.</p> Phantom Directions Polarizations Sims (old) Sims (new) Savings duke 6 2 108 12-36 67-89% ella 6 2 108 12-36 67-89% eartha 6 2 108 12-36 67-89% thelonious 6 2 108 12-36 67-89% TOTAL - - 432 48-144 67-89% <p>That's potentially 400 fewer simulations just for far-field!</p>"},{"location":"technical/multi_sine_grouping_math/#api-verification-materials-and-extraction","title":"API Verification: Materials and Extraction","text":""},{"location":"technical/multi_sine_grouping_math/#dispersive-materials-confirmed","title":"Dispersive Materials: CONFIRMED \u2705","text":"<p>From Sim4Life Python API (<code>EmFdtdMaterialSettings.eMaterialModel</code>):</p> <pre><code>kConst             # Constant (frequency-independent)\nkLinearDispersive  # Linear dispersive (frequency-dependent!) \u2190 IT'IS uses this\nkMetaMaterial      # Metamaterial\n</code></pre> <p>What this means: - IT'IS database tissues use <code>kLinearDispersive</code> material model - Each frequency in multi-sine signal sees correct \u03b5(f) and \u03c3(f) - No special handling needed - FDTD solver does this automatically via ADE method</p> <p>Debye parameters available: <pre><code>kDebyeAmplitude\nkDebyeDamping  \nkDebyeInfinityPermittivity\nkDebyeStaticPermittivity\n</code></pre></p>"},{"location":"technical/multi_sine_grouping_math/#extractedfrequencies-confirmed","title":"ExtractedFrequencies: CONFIRMED \u2705","text":"<p>From Sim4Life Python API (<code>FieldSensorSettings</code>):</p> <pre><code>settings.ExtractedFrequencies = (2e9,)  # Single frequency\nsettings.ExtractedFrequencies = [1e9, 2e9, 3e9]  # Multiple frequencies\nsettings.ExtractedFrequencies = np.linspace(1e9, 3e9, 11)  # Range\n\nsettings.OnTheFlyDFT = True  # Enable frequency-domain extraction\nsettings.RecordingDomain = 'RecordInFrequencyDomain'  # Or 'RecordInFrequencyAndTimeDomain'\n</code></pre> <p>Works with: - <code>FieldSensorSettings</code> (for SAR extraction) - <code>FarFieldSensorSettings</code> (for radiation patterns) - <code>InterpolatedFieldSensorSettings</code> (for point sensors)</p>"},{"location":"technical/multi_sine_grouping_math/#implementation-path-clear","title":"Implementation Path: CLEAR \u2705","text":"<p>For multi-sine far-field:</p> <ol> <li>Source setup: Use <code>ExcitationType = 'UserDefined'</code> with multi-sine expression</li> <li>Sensor setup: Set <code>ExtractedFrequencies = [450e6, 700e6, ..., 5800e6]</code></li> <li>Extraction: DFT gives per-frequency SAR/field data automatically</li> </ol>"},{"location":"technical/multi_sine_grouping_math/#final-summary","title":"Final Summary","text":""},{"location":"technical/multi_sine_grouping_math/#for-far-field-primary-use-case","title":"For Far-Field (Primary Use Case)","text":"Aspect Status Physics feasible \u2705 Multi-sine is valid Materials handle it \u2705 Dispersive models work automatically Extraction supported \u2705 ExtractedFrequencies takes list Grid penalty \u2705 None (already using finest grid) Antenna constraint \u2705 None (plane wave source) Net speedup ~4\u00d7 fewer simulations"},{"location":"technical/multi_sine_grouping_math/#recommended-implementation","title":"Recommended Implementation","text":"<p>Far-field only (for now): - Group all 9 frequencies: <code>[450, 700, 835, 1450, 2140, 2450, 3500, 5200, 5800]</code> MHz - Set <code>simulation_time_multiplier</code> to accommodate beat period (~2.2\u00d7 current value) - Use <code>ExtractedFrequencies</code> for per-frequency SAR extraction</p> <p>Result:  - 432 simulations \u2192 48 simulations (89% reduction) - ~2.2\u00d7 longer per sim, but 9\u00d7 fewer sims - Net: ~4\u00d7 speedup</p> <p>Document updated: 2025-12-12 API verification performed on Sim4Life Python API Reference</p>"},{"location":"technical/multisine_dispersion_walkthrough/","title":"Multisine Dispersion Integration - Walkthrough","text":""},{"location":"technical/multisine_dispersion_walkthrough/#summary","title":"Summary","text":"<p>Implemented frequency-dependent material dispersion for multisine FDTD simulations. When running multisine (e.g., 700+2450 MHz), materials now get fitted Lorentz dispersion models that accurately reproduce permittivity and conductivity at all excitation frequencies.</p>"},{"location":"technical/multisine_dispersion_walkthrough/#data-source","title":"Data Source","text":"<p>Material properties are computed from the IT'IS Foundation V5.0 Database using the Gabriel 4-Cole-Cole model. This provides accurate, frequency-dependent dielectric properties validated against Sim4Life GUI values.</p>"},{"location":"technical/multisine_dispersion_walkthrough/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    IT'IS V5.0 Database                          \u2502\n\u2502              (data/itis_v5.db)                  \u2502\n\u2502                                                                 \u2502\n\u2502  Contains Gabriel 4-Cole-Cole parameters for 250+ tissues      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            scripts/generate_material_cache_from_db.py           \u2502\n\u2502                                                                 \u2502\n\u2502  \u2022 Reads Gabriel parameters (ef, del, tau, alf, sigma)         \u2502\n\u2502  \u2022 Computes \u03b5_r and \u03c3 at 9 frequencies (450-5800 MHz)          \u2502\n\u2502  \u2022 Outputs JSON cache                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              data/material_properties_cache.json                \u2502\n\u2502                                                                 \u2502\n\u2502  {                                                              \u2502\n\u2502    \"tissues\": {                                                 \u2502\n\u2502      \"Brain (Grey Matter)\": {                                   \u2502\n\u2502        \"700\": {\"eps_r\": 53.90, \"sigma\": 0.86},                 \u2502\n\u2502        \"2450\": {\"eps_r\": 48.46, \"sigma\": 2.00}, ...            \u2502\n\u2502      }, ...                                                     \u2502\n\u2502    }                                                            \u2502\n\u2502  }                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              goliat/dispersion/material_cache.py                \u2502\n\u2502                                                                 \u2502\n\u2502  get_material_properties(\"Brain (Grey Matter)\", [700, 2450])   \u2502\n\u2502  \u2192 [{\"eps_r\": 53.90, \"sigma\": 0.86}, ...]                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              goliat/dispersion/lorentz_fitter.py                \u2502\n\u2502                                                                 \u2502\n\u2502  fit_two_pole_lorentz(frequencies_hz, eps_r_list, sigma_list)  \u2502\n\u2502  \u2192 LorentzParams(eps_inf, sigma_dc, poles, fit_error)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           goliat/setups/material_setup.py                       \u2502\n\u2502                                                                 \u2502\n\u2502  _assign_phantom_materials_multisine()                          \u2502\n\u2502  \u2022 Creates LinearDispersive materials in Sim4Life              \u2502\n\u2502  \u2022 Assigns Lorentz poles to disp.Poles                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"technical/multisine_dispersion_walkthrough/#files-created","title":"Files Created","text":""},{"location":"technical/multisine_dispersion_walkthrough/#dispersion-package","title":"Dispersion Package","text":"File Purpose <code>goliat/dispersion/__init__.py</code> Package init, exports public API <code>goliat/dispersion/lorentz_fitter.py</code> Two-pole Lorentz model fitting using scipy optimization <code>goliat/dispersion/material_cache.py</code> JSON cache loading for precomputed material properties"},{"location":"technical/multisine_dispersion_walkthrough/#scripts","title":"Scripts","text":"File Purpose <code>scripts/generate_material_cache_from_db.py</code> Generate cache from IT'IS V5.0 database (recommended) <code>scripts/generate_material_cache_from_excel.py</code> Alternative: generate from Excel file <code>scripts/generate_material_cache.py</code> Legacy: run in Sim4Life (has API limitations)"},{"location":"technical/multisine_dispersion_walkthrough/#data-files","title":"Data Files","text":"File Purpose <code>data/material_properties_cache.json</code> Precomputed \u03b5_r and \u03c3 at 9 frequencies for 111 tissues <code>data/material_name_mapping.json</code> Maps phantom entity names \u2192 IT'IS tissue names <code>data/itis_v5.db</code> Source SQLite database with Gabriel parameters"},{"location":"technical/multisine_dispersion_walkthrough/#tests","title":"Tests","text":"File Purpose <code>tests/dispersion/test_lorentz_fitter.py</code> Unit tests for fitting (6 tests, all passing)"},{"location":"technical/multisine_dispersion_walkthrough/#files-modified","title":"Files Modified","text":""},{"location":"technical/multisine_dispersion_walkthrough/#material_setuppy","title":"material_setup.py","text":"<p>Added multisine support: - New <code>frequencies_mhz</code> parameter in <code>__init__</code> - <code>is_multisine</code> flag detection - <code>_assign_phantom_materials_multisine()</code> method</p> <pre><code>def __init__(\n    self,\n    config: \"Config\",\n    simulation,\n    antenna,\n    phantom_name: str,\n    verbose_logger: \"Logger\",\n    progress_logger: \"Logger\",\n    free_space: bool = False,\n    frequencies_mhz: list[int] | None = None,  # NEW\n):\n    self.frequencies_mhz = frequencies_mhz\n    self.is_multisine = frequencies_mhz is not None and len(frequencies_mhz) &gt; 1\n</code></pre>"},{"location":"technical/multisine_dispersion_walkthrough/#far_field_setuppy","title":"far_field_setup.py","text":"<p>Passes frequency list to MaterialSetup:</p> <pre><code>material_setup = MaterialSetup(\n    self.config,\n    sim,\n    self.antenna,\n    self.phantom_name,\n    self.verbose_logger,\n    self.progress_logger,\n    free_space=False,\n    frequencies_mhz=self.frequency_mhz if self.is_multisine else None,  # NEW\n)\n</code></pre>"},{"location":"technical/multisine_dispersion_walkthrough/#material-cache-details","title":"Material Cache Details","text":""},{"location":"technical/multisine_dispersion_walkthrough/#source-itis-v50-database","title":"Source: IT'IS V5.0 Database","text":"<p>The cache is generated from data/itis_v5.db using the Gabriel 4-Cole-Cole model:</p> <pre><code>\u03b5*(\u03c9) = \u03b5\u221e + \u03a3\u2099 [\u0394\u03b5\u2099 / (1 + (j\u03c9\u03c4\u2099)^(1-\u03b1\u2099))] + \u03c3/(j\u03c9\u03b5\u2080)\n</code></pre>"},{"location":"technical/multisine_dispersion_walkthrough/#gabriel-parameter-format-14-floats","title":"Gabriel Parameter Format (14 floats)","text":"<pre><code>[ef, del1, tau1_ps, alf1, del2, tau2_ns, alf2, del3, tau3_us, alf3, del4, tau4_ms, alf4, sigma]\n</code></pre>"},{"location":"technical/multisine_dispersion_walkthrough/#frequencies-covered","title":"Frequencies Covered","text":"<pre><code>FREQUENCIES_MHZ = [450, 700, 835, 1450, 2140, 2450, 3500, 5200, 5800]\n</code></pre>"},{"location":"technical/multisine_dispersion_walkthrough/#validated-against-sim4life-gui","title":"Validated Against Sim4Life GUI","text":"Tissue Frequency Cache \u03b5_r Cache \u03c3 S4L GUI Match Brain (Grey Matter) 700 MHz 53.90 0.860 \u2713 \u2705 Muscle 2450 MHz 52.73 1.739 \u2713 \u2705 Skin 835 MHz 41.76 0.845 \u2713 \u2705 Fat 5800 MHz 9.86 0.832 \u2713 \u2705 Bone (Cortical) 450 MHz 13.04 0.096 \u2713 \u2705"},{"location":"technical/multisine_dispersion_walkthrough/#material-name-mapping","title":"Material Name Mapping","text":"<p>Entity names from phantoms map to IT'IS names via <code>data/material_name_mapping.json</code>:</p> <pre><code>{\n  \"thelonious\": {\n    \"Brain_grey_matter\": \"Brain (Grey Matter)\",\n    \"Muscle\": \"Muscle\",\n    \"SAT\": \"SAT (Subcutaneous Fat)\",\n    ...\n  },\n  \"duke\": { ... },\n  \"ella\": { ... },\n  \"eartha\": { ... }\n}\n</code></pre> <p>All 4 phantoms verified: 303 total mappings, all present in cache.</p>"},{"location":"technical/multisine_dispersion_walkthrough/#test-results","title":"Test Results","text":"<pre><code>tests/dispersion/test_lorentz_fitter.py::TestFitTwoPoleLorentz::test_basic_two_frequency_fit PASSED\ntests/dispersion/test_lorentz_fitter.py::TestFitTwoPoleLorentz::test_fit_validation_passes PASSED  \ntests/dispersion/test_lorentz_fitter.py::TestFitTwoPoleLorentz::test_three_frequency_fit PASSED\ntests/dispersion/test_lorentz_fitter.py::TestFitTwoPoleLorentz::test_invalid_input_length_mismatch PASSED\ntests/dispersion/test_lorentz_fitter.py::TestFitTwoPoleLorentz::test_invalid_input_too_few_points PASSED\ntests/dispersion/test_lorentz_fitter.py::TestLorentzParams::test_dataclass_fields PASSED\n\n6 passed in 105.81s\n</code></pre>"},{"location":"technical/multisine_dispersion_walkthrough/#usage","title":"Usage","text":""},{"location":"technical/multisine_dispersion_walkthrough/#1-generate-material-cache-one-time","title":"1. Generate Material Cache (One-time)","text":"<p>Recommended: From IT'IS V5.0 Database</p> <pre><code>python scripts/generate_material_cache_from_db.py\n</code></pre> <p>This creates <code>data/material_properties_cache.json</code> with \u03b5_r and \u03c3 for all tissues at all standard frequencies.</p>"},{"location":"technical/multisine_dispersion_walkthrough/#2-run-multisine-simulation","title":"2. Run Multisine Simulation","text":"<pre><code>python -m goliat run configs/far_field_multisine.json\n</code></pre> <p>The config should have multiple frequencies: <pre><code>{\n  \"frequencies_mhz\": [700, 2450]\n}\n</code></pre></p>"},{"location":"technical/multisine_dispersion_walkthrough/#3-verify-in-sim4life","title":"3. Verify in Sim4Life","text":"<p>After simulation setup, verify: - Materials show \"LinearDispersive\" model type - Dispersion Viewer shows 2 active Lorentz poles per tissue - SAR results match harmonic reference runs</p>"},{"location":"technical/multisine_dispersion_walkthrough/#fallback-behavior","title":"Fallback Behavior","text":"<p>If a material is not found in the cache:</p> <ol> <li>Warning logged: <code>'{material_name}' not in cache, using database fallback</code></li> <li>Database linking used: Standard IT'IS 4.2 database material assigned</li> <li>If database fails: Second warning logged, material skipped</li> </ol> <p>This ensures simulations can still run even with incomplete cache.</p>"},{"location":"technical/multisine_dispersion_walkthrough/#troubleshooting","title":"Troubleshooting","text":""},{"location":"technical/multisine_dispersion_walkthrough/#cache-not-found","title":"Cache Not Found","text":"<p><pre><code>FileNotFoundError: Material properties cache not found at .../material_properties_cache.json\n</code></pre> Solution: Run <code>python scripts/generate_material_cache_from_db.py</code></p>"},{"location":"technical/multisine_dispersion_walkthrough/#tissue-not-in-cache","title":"Tissue Not In Cache","text":"<p><pre><code>KeyError: Tissue 'XYZ' not found in material cache\n</code></pre> Solution:  - Check <code>data/material_name_mapping.json</code> for correct IT'IS name - Verify tissue exists in IT'IS V5.0 database</p>"},{"location":"technical/multisine_dispersion_walkthrough/#high-fit-error","title":"High Fit Error","text":"<p><pre><code>WARNING: High fit error (0.05) for 'Muscle'\n</code></pre> Note: Errors &lt;5% are generally acceptable. Higher errors may indicate: - Extreme dispersion behavior - Consider using database fallback for that tissue</p>"},{"location":"technical/multisine_dispersion_walkthrough/#database-file-missing","title":"Database File Missing","text":"<p><pre><code>sqlite3.OperationalError: unable to open database file\n</code></pre> Solution: Ensure <code>data/itis_v5.db</code> is in project root</p>"},{"location":"technical/multisine_dispersion_walkthrough/#references","title":"References","text":"<ul> <li>IT'IS Foundation: https://itis.swiss/virtual-population/tissue-properties/database/</li> <li>Gabriel et al.: \"The dielectric properties of biological tissues\" Physics in Medicine &amp; Biology (1996)</li> <li>Technical guide: <code>docs/technical/dispersion_model_guide.md</code></li> </ul>"},{"location":"technical/power_normalization_philosophy/","title":"Power Normalization in Computational Dosimetry","text":""},{"location":"technical/power_normalization_philosophy/#the-problem","title":"The Problem","text":"<p>In computational dosimetry, we compare electromagnetic exposure from:</p> <ol> <li>Near-field sources (mobile phones): Antenna fed with measurable input power (e.g., 1 W)</li> <li>Far-field sources (environmental exposure): Plane waves with specified electric field strength (e.g., 1 V/m)</li> </ol> <p>The challenge: How do we normalize results to enable meaningful comparison?</p>"},{"location":"technical/power_normalization_philosophy/#the-core-insight","title":"The Core Insight","text":"<p>For a plane wave, there is no \"source\" \u2014 the field exists uniformly in space. \"1 W\" has no direct meaning.</p> <p>The time-averaged power density (Poynting vector magnitude) is:</p> \\[S = \\frac{E_0^2}{2\\eta_0}\\] <p>Where \u03b7\u2080 = 377 \u03a9. For E\u2080 = 1 V/m: S = 1.326 mW/m\u00b2.</p>"},{"location":"technical/power_normalization_philosophy/#why-bounding-box-power-is-meaningless","title":"Why Bounding Box Power is Meaningless","text":"<p>Some implementations calculate \"input power\" as P = S \u00d7 A_bbox (power through the simulation bounding box).</p>"},{"location":"technical/power_normalization_philosophy/#proof-by-contradiction","title":"Proof by Contradiction","text":"<ol> <li>SAR depends only on the incident field and phantom \u2014 not on the computational domain size.</li> <li>If we define P_input = S \u00d7 A_bbox, then enlarging the bbox 10\u00d7 increases P_input 10\u00d7.</li> <li>But SAR stays exactly the same.</li> <li>Contradiction: A normalization metric that can be made arbitrarily large without changing SAR is physically meaningless.</li> </ol> <p>Conclusion: The simulation bounding box is a computational convenience with no physical significance for power accounting.</p> <p>Note: Sim4Life does not provide an \"EM Input Power(f)\" output for plane wave sources, unlike for antenna (port) sources. This is not an oversight \u2014 it reflects the conceptual difficulty of defining \"input power\" for a plane wave that extends to infinity. The burden of defining a meaningful metric falls on the user.</p>"},{"location":"technical/power_normalization_philosophy/#the-correct-normalization-power-density-1-wm2","title":"The Correct Normalization: Power Density (1 W/m\u00b2)","text":"<p>We define \"1 W\" for far-field to mean 1 W/m\u00b2 power density.</p>"},{"location":"technical/power_normalization_philosophy/#why-this-works","title":"Why This Works","text":"<ol> <li>Intrinsic to the field: Power density is a property of the incident wave, not an artifact of computation</li> <li>Direction-independent: Same S regardless of propagation direction</li> <li>Measurable: Exactly what EMF probes (NARDA, etc.) measure</li> <li>Standard in literature: ICNIRP reference levels are defined in terms of power density</li> <li>Reproducible: No dependence on mesh quality, bbox size, or phantom model</li> </ol>"},{"location":"technical/power_normalization_philosophy/#the-math","title":"The Math","text":"<p>At E = 1 V/m, S = 1.326 mW/m\u00b2. To normalize to 1 W/m\u00b2:</p> \\[E_{\\text{ref}} = \\sqrt{2 \\eta_0} = 27.46 \\text{ V/m}\\] <p>Since SAR \u221d E\u00b2, the scaling factor from 1 V/m simulation to 1 W/m\u00b2 is:</p> \\[\\text{Scale factor} = (27.46)^2 = 754\\]"},{"location":"technical/power_normalization_philosophy/#comparison-with-near-field","title":"Comparison with Near-Field","text":"Exposure \"1 W\" Definition Power Reaching Body Phone at 1 W input 1 W to antenna ~0.3\u20130.5 W (30\u201350% coupling) Plane wave at 1 W/m\u00b2 1 W per m\u00b2 ~0.5 W (frontal area ~0.5 m\u00b2) <p>Both deliver comparable power to the body \u2014 the comparison is physically meaningful.</p>"},{"location":"technical/power_normalization_philosophy/#what-about-phantom-cross-section","title":"What About Phantom Cross-Section?","text":"<p>We have pre-computed the projected cross-sectional area A(\u03b8,\u03c6) for all phantoms (see <code>data/phantom_skins/README.md</code>). This enables computing the actual power intercepted by the body:</p> \\[P_{\\text{intercepted}} = S \\times A_{\\text{phantom}}(\\theta, \\phi)\\]"},{"location":"technical/power_normalization_philosophy/#why-not-use-this-for-normalization","title":"Why Not Use This for Normalization?","text":"<p>While physically meaningful, using phantom cross-section for SAR normalization has problems:</p> <ol> <li>Poor reproducibility: Different phantoms, meshes, and algorithms give different areas</li> <li>Arbitrary choices: Convex hull vs exact boundary? Which mesh resolution?</li> <li>Not standard: Literature uses 1 W/m\u00b2, not \"1 W per phantom cross-section\"</li> <li>Direction-dependent: Same \"1 W\" would mean different things for different directions</li> </ol>"},{"location":"technical/power_normalization_philosophy/#correct-use-of-cross-section-data","title":"Correct Use of Cross-Section Data","text":"<p>The phantom cross-section is valuable for analysis, not normalization:</p> <ul> <li>Absorption efficiency: \u03b7 = P_absorbed / P_intercepted (what fraction of intercepted power is absorbed?)</li> <li>Worst-case direction: Which angle maximizes/minimizes exposure for a given power density?</li> <li>Phantom comparison: Comparing effective target areas across body models</li> </ul> <p>This data is stored in <code>data/phantom_skins/{phantom}/cross_section_pattern.pkl</code>.</p>"},{"location":"technical/power_normalization_philosophy/#power-balance-for-far-field","title":"Power Balance for Far-Field","text":""},{"location":"technical/power_normalization_philosophy/#the-conceptual-issue","title":"The Conceptual Issue","text":"<p>Power balance = (P_absorbed + P_radiated) / P_input \u00d7 100%</p> <p>For near-field, P_input is unambiguous (power to antenna). For far-field, there's no discrete \"input\" \u2014 the plane wave extends infinitely.</p>"},{"location":"technical/power_normalization_philosophy/#understanding-sim4lifes-radpower","title":"Understanding Sim4Life's RadPower","text":"<p>When Sim4Life reports <code>RadPower</code> in the power balance, it computes the total Poynting flux through the simulation boundaries. For a plane wave incident on a phantom:</p> <ul> <li>Power enters through one face of the bounding box</li> <li>Some power is absorbed by the phantom \u2192 <code>DielLoss</code></li> <li>The remaining power exits through all faces \u2192 <code>RadPower</code></li> </ul> <p>Crucially, <code>RadPower</code> includes both: 1. Scattered power: Power redirected by the phantom 2. Transmitted power: The portion of the plane wave that missed the phantom and passed straight through</p> <p>This is why <code>RadPower</code> is closely related to the bounding box size, not just the phantom.</p>"},{"location":"technical/power_normalization_philosophy/#two-approaches-for-p_input","title":"Two Approaches for P_input","text":"<p>GOLIAT supports two configurable methods for defining \"input power\" in far-field power balance. Configure via:</p> <pre><code>{\n    \"power_balance\": {\n        \"input_method\": \"bounding_box\"  // or \"phantom_cross_section\"\n    }\n}\n</code></pre>"},{"location":"technical/power_normalization_philosophy/#1-bounding-box-method-default","title":"1. Bounding Box Method (Default)","text":"\\[P_{\\text{input}} = S \\times A_{\\text{bbox}}(\\theta, \\phi)\\] <p>Uses the projected cross-sectional area of the simulation bounding box as seen from the incident direction.</p> <p>Advantages: - Consistent with Sim4Life: <code>RadPower + DielLoss \u2248 S \u00d7 A_bbox</code>, so balance \u2248 100% - Sanity check: Deviations from 100% indicate numerical issues</p> <p>Disadvantages: - Domain-dependent: Larger bbox \u2192 larger P_input (but same SAR) - No physical meaning: Just verifies FDTD energy conservation</p> <p>For non-orthogonal directions: The projected bbox area is computed as: \\(\\(A_{\\text{projected}} = |n_x| A_{yz} + |n_y| A_{xz} + |n_z| A_{xy}\\)\\) where \\(\\hat{n} = (\\sin\\theta\\cos\\phi, \\sin\\theta\\sin\\phi, \\cos\\theta)\\) is the incident direction.</p>"},{"location":"technical/power_normalization_philosophy/#2-phantom-cross-section-method","title":"2. Phantom Cross-Section Method","text":"\\[P_{\\text{input}} = S \\times A_{\\text{phantom}}(\\theta, \\phi)\\] <p>Uses the pre-computed projected cross-sectional area of the phantom from <code>data/phantom_skins/</code>.</p> <p>Advantages: - Physically meaningful: Represents actual power intercepted by the body - Domain-independent: Same value regardless of simulation bbox size - Enables absorption efficiency: Balance shows what fraction of intercepted power is accounted for</p> <p>Disadvantages: - Balance &gt;&gt; 100%: Expected! <code>RadPower</code> includes power that bypassed the phantom - Not a sanity check: Can't detect numerical errors from balance alone</p>"},{"location":"technical/power_normalization_philosophy/#interpreting-the-balance","title":"Interpreting the Balance","text":"Method Expected Balance Interpretation <code>bounding_box</code> ~100% Energy conservation verified; values \u2260 100% suggest issues <code>phantom_cross_section</code> 150\u2013300% Normal; extra power is plane wave that missed the phantom"},{"location":"technical/power_normalization_philosophy/#implementation-summary","title":"Implementation Summary","text":""},{"location":"technical/power_normalization_philosophy/#in-goliat","title":"In GOLIAT","text":"<ol> <li>Simulations run at E = 1 V/m (standard Sim4Life plane wave)</li> <li>Analysis scales by 754 (<code>far_field_strategy.get_normalization_factor()</code> returns 754.0)</li> <li>Results reported as \"SAR at 1 W/m\u00b2 incident power density\"</li> <li>Power balance uses configurable method (default: <code>bounding_box</code>)</li> </ol>"},{"location":"technical/power_normalization_philosophy/#configuration","title":"Configuration","text":"<pre><code>// In far_field_config.json\n{\n    \"power_balance\": {\n        \"input_method\": \"bounding_box\"  // Options: \"bounding_box\", \"phantom_cross_section\"\n    }\n}\n</code></pre>"},{"location":"technical/power_normalization_philosophy/#output-fields","title":"Output Fields","text":"<p>The extraction writes these fields to <code>sar_results.json</code>: - <code>input_power_W</code>: Computed input power at 1 V/m - <code>power_balance_input_method</code>: Which method was used - <code>cross_section_m2</code>: The area value used - <code>cross_section_source</code>: Description of the source (e.g., \"bbox_x_pos\", \"phantom_duke\")</p>"},{"location":"technical/power_normalization_philosophy/#conversion-formulas","title":"Conversion Formulas","text":"Quantity Value at 1 V/m Value at 1 W/m\u00b2 Electric field E\u2080 1 V/m 27.46 V/m Power density S 1.326 mW/m\u00b2 1 W/m\u00b2 SAR SAR\u2081\u1d65/\u2098 SAR\u2081\u1d65/\u2098 \u00d7 754 <p>Scaling to arbitrary field E: \\(\\(\\text{SAR}(E) = \\text{SAR}_{1\\text{W/m}^2} \\times S = \\text{SAR}_{1\\text{V/m}} \\times E^2\\)\\)</p>"},{"location":"technical/power_normalization_philosophy/#suggested-text-for-publications","title":"Suggested Text for Publications","text":"<p>\"Far-field exposure simulations were performed using plane wave illumination. Results are normalized to an incident power density of 1 W/m\u00b2, corresponding to an electric field amplitude of 27.5 V/m in free space. This normalization was chosen because power density is an intrinsic, measurable property of the incident field that does not depend on computational domain size or phantom-specific geometry \u2014 ensuring reproducibility across studies. SAR values scale quadratically with field strength (SAR \u221d E\u00b2), enabling straightforward translation to any exposure level.\"</p>"},{"location":"technical/power_normalization_philosophy/#further-reading","title":"Further Reading","text":"<ul> <li><code>data/phantom_skins/README.md</code> \u2014 Pre-computed phantom cross-section data</li> <li><code>docs/technical/skin_mesh_pipeline.md</code> \u2014 How phantom outer surfaces were extracted and processed</li> </ul>"},{"location":"technical/s4l_92_compatibility_investigation/","title":"Sim4Life 9.2 Compatibility Investigation - Brain Dump","text":"<p>Date: 2026-01-13 Context: Debugging GOLIAT compatibility issues with Sim4Life 9.2</p>"},{"location":"technical/s4l_92_compatibility_investigation/#the-problem","title":"The Problem","text":"<p>GOLIAT worked perfectly on Sim4Life 8.2 but exhibited these issues on Sim4Life 9.2: - <code>use_gui=false</code>: Segmentation fault - <code>use_gui=true</code>: Hangs forever, then later worked but no terminal logging</p> <p>Initial hypothesis was that <code>multiprocessing.Queue</code> was incompatible with S4L 9.2, but this turned out to be wrong.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#the-diagnostic-process","title":"The Diagnostic Process","text":""},{"location":"technical/s4l_92_compatibility_investigation/#test-1-basic-multiprocessing-test-test_s4l_multiprocessingpy","title":"Test 1: Basic Multiprocessing Test (<code>test_s4l_multiprocessing.py</code>)","text":"<ul> <li>Created a simple test: start S4L, send \"hello world\" through a Queue</li> <li>Result: PASSED on both 8.2 and 9.2</li> <li>Conclusion: <code>multiprocessing.Queue</code> itself is NOT the issue</li> </ul>"},{"location":"technical/s4l_92_compatibility_investigation/#test-2-extended-component-tests-test_s4l_multiprocessing_extendedpy","title":"Test 2: Extended Component Tests (<code>test_s4l_multiprocessing_extended.py</code>)","text":"<p>Progressive tests adding GOLIAT components: 1. Basic S4L startup - PASSED 2. S4L + GOLIAT logging - PASSED 3. S4L + Config loading - PASSED 4. S4L + Document operations - PASSED 5. S4L + PySide6 - PASSED 6. Multiprocess with logging + document - PASSED 7. Full workflow with QueueGUI + Profiler - PASSED 8. NearFieldStudy import (headless) - PASSED 9. NearFieldStudy import (multiprocess) - PASSED</p> <p>Key insight: All individual tests passed! So why does <code>goliat study</code> fail?</p>"},{"location":"technical/s4l_92_compatibility_investigation/#test-3-import-order-tests-test_s4l_import_orderpy","title":"Test 3: Import Order Tests (<code>test_s4l_import_order.py</code>)","text":"<p>Mimicked the exact import order from <code>run_study.py</code>: - Full import order (like run_study.py) \u2192 SEGFAULT</p> <p>This narrowed it down to something about the import order.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#test-4-import-bisect-test_s4l_import_bisectpy","title":"Test 4: Import Bisect (<code>test_s4l_import_bisect.py</code>)","text":"<p>Binary search through imports to find the culprit: - PySide6 + S4L \u2192 PASSED - PySide6 + Config + S4L \u2192 SEGFAULT</p> <p>Wait, but PySide6 alone didn't cause it?</p>"},{"location":"technical/s4l_92_compatibility_investigation/#test-5-final-diagnostic-test_s4l_final_diagnosticpy","title":"Test 5: Final Diagnostic (<code>test_s4l_final_diagnostic.py</code>)","text":"<p>Tested specific orderings:</p> Test Description Result 1 Just PySide6 import SEGFAULT 2 PySide6 + matplotlib SEGFAULT 3 PySide6 + matplotlib.use('Qt5Agg') SEGFAULT 4 PySide6 + matplotlib.use('Agg') SEGFAULT 5 matplotlib.use() FIRST, then PySide6 PASSED 6 S4L FIRST, then PySide6 PASSED"},{"location":"technical/s4l_92_compatibility_investigation/#test-6-full-study-flow-test_full_study_flowpy","title":"Test 6: Full Study Flow (<code>test_full_study_flow.py</code>)","text":"<p>This test mimics the exact <code>goliat study</code> flow: - Main process imports run_study.py (triggers S4L + PySide6 at module level) - Main process spawns child process - Child process should print to terminal</p> <p>Result on 8.2: Child output appears in terminal \u2713 Result on 9.2: Child output MISSING from terminal \u2717</p> <p>This isolated the second issue: when main process has S4L running before spawn, child stdout is broken.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#root-cause-analysis","title":"Root Cause Analysis","text":""},{"location":"technical/s4l_92_compatibility_investigation/#issue-1-segfault-on-s4l-92","title":"Issue 1: Segfault on S4L 9.2","text":"<p>Cause: Sim4Life 9.2 crashes if PySide6 is imported BEFORE Sim4Life starts. This is a breaking change from 8.2 where the order didn't matter.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#issue-2-child-process-stdout-broken","title":"Issue 2: Child process stdout broken","text":"<p>Cause: When the main process starts S4L and then spawns a child process using <code>multiprocessing.spawn</code>, the child inherits broken stdout/stderr file descriptors from the parent. This appears to be something S4L 9.2 does to stdout/stderr that wasn't an issue in 8.2.</p> <p>The child process still writes to log files correctly, and QueueGUI messages still reach the main process's GUI. Only the direct console output from the child is lost.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#the-final-solution","title":"The Final Solution","text":"<p>The fix required changes to three files:</p>"},{"location":"technical/s4l_92_compatibility_investigation/#1-clirun_studypy-module-level-initialization","title":"1. <code>cli/run_study.py</code> - Module-level initialization","text":"<pre><code># --- Pre-check and Setup ---\n# Only run initial_setup in main process (not in spawned children)\n_is_main_process = multiprocessing.current_process().name == \"MainProcess\"\nif _is_main_process and not os.environ.get(\"PYTEST_CURRENT_TEST\") and not os.environ.get(\"CI\"):\n    initial_setup()\n\n# --- S4L 9.2 Compatibility Fix ---\n# Sim4Life 9.2 crashes (segfault) if PySide6 is imported BEFORE S4L starts.\n# IMPORTANT: We only do early S4L init in the MAIN process.\n# Child processes skip this because when the main process has S4L running,\n# spawning a child inherits broken stdout/stderr file descriptors.\n# Child processes will init S4L later via ensure_s4l_running() in study_process_wrapper.\nif _is_main_process and not os.environ.get(\"PYTEST_CURRENT_TEST\") and not os.environ.get(\"CI\"):\n    try:\n        from s4l_v1._api import application as _s4l_app\n        if _s4l_app.get_app_safe() is None:\n            _s4l_app.run_application(disable_ui_plugins=True)\n    except ImportError:\n        pass\n\n# --- PySide6 and GUI imports (main process only) ---\n# Child processes don't need PySide6 or ProgressGUI. Importing ProgressGUI triggers\n# matplotlib.use(\"Qt5Agg\") which conflicts with S4L 9.2 if S4L hasn't started yet.\nif _is_main_process:\n    try:\n        from PySide6.QtWidgets import QApplication\n    except ImportError:\n        # ... error handling ...\n    \n    from goliat.gui_manager import ProgressGUI, QueueGUI\n    # ... rest of imports ...\nelse:\n    # Child process - set these to None\n    QApplication = None\n    ProgressGUI = None\n    QueueGUI = None  # Will be imported directly in study_process_wrapper\n</code></pre>"},{"location":"technical/s4l_92_compatibility_investigation/#2-clirun_studypy-study_process_wrapper-function","title":"2. <code>cli/run_study.py</code> - study_process_wrapper function","text":"<pre><code>def study_process_wrapper(queue, stop_event, config_filename, process_id, no_cache=False, session_timestamp=None):\n    # ... setup loggers ...\n    \n    try:\n        # Import QueueGUI directly here (not at module level) because child processes\n        # skip the gui_manager import to avoid PySide6/matplotlib conflicts on S4L 9.2.\n        from goliat.gui.queue_gui import QueueGUI as _QueueGUI\n\n        gui_proxy = _QueueGUI(queue, stop_event, profiler, progress_logger, verbose_logger)\n        # ... rest of study setup ...\n</code></pre>"},{"location":"technical/s4l_92_compatibility_investigation/#3-goliatguicomponentsqueue_handlerpy-terminal-output","title":"3. <code>goliat/gui/components/queue_handler.py</code> - Terminal output","text":"<pre><code>from colorama import Style\nfrom goliat.colors import get_color\n\nclass QueueHandler:\n    def _handle_status(self, msg: Dict[str, Any]) -&gt; None:\n        \"\"\"Handles status message type.\"\"\"\n        message = msg[\"message\"]\n        log_type = msg.get(\"log_type\", \"default\")\n        # Update GUI\n        self.gui.update_status(message, log_type)\n        # Also print to terminal with colors (child process stdout may be broken on S4L 9.2)\n        color = get_color(log_type)\n        print(f\"{color}{message}{Style.RESET_ALL}\")\n</code></pre>"},{"location":"technical/s4l_92_compatibility_investigation/#why-this-solution-works","title":"Why This Solution Works","text":""},{"location":"technical/s4l_92_compatibility_investigation/#main-process-flow","title":"Main Process Flow:","text":"<ol> <li><code>_is_main_process</code> check \u2192 True</li> <li><code>initial_setup()</code> runs (version warnings, etc.)</li> <li>S4L starts early (before PySide6) \u2192 Avoids segfault</li> <li>PySide6 imported \u2192 Safe now that S4L is running</li> <li><code>gui_manager</code> imported \u2192 ProgressGUI and matplotlib configured</li> <li>Child process spawned</li> <li>QApplication.exec() runs (GUI event loop)</li> <li>QueueHandler receives messages from queue and prints to terminal</li> </ol>"},{"location":"technical/s4l_92_compatibility_investigation/#child-process-flow","title":"Child Process Flow:","text":"<ol> <li>Re-imports run_study.py at module level</li> <li><code>_is_main_process</code> check \u2192 False</li> <li>Skips <code>initial_setup()</code> \u2192 No duplicate warnings</li> <li>Skips S4L early init \u2192 Avoids inheriting broken stdout</li> <li>Skips PySide6 imports \u2192 Doesn't need them</li> <li><code>study_process_wrapper()</code> starts</li> <li>Imports <code>QueueGUI</code> directly from <code>queue_gui.py</code> (not <code>gui_manager</code>)</li> <li>S4L starts via <code>ensure_s4l_running()</code> inside the study</li> <li>All log messages sent through queue \u2192 Main process prints them</li> </ol>"},{"location":"technical/s4l_92_compatibility_investigation/#key-technical-insights","title":"Key Technical Insights","text":""},{"location":"technical/s4l_92_compatibility_investigation/#why-child-stdout-is-broken-on-92","title":"Why child stdout is broken on 9.2","text":"<p>When S4L 9.2 starts, it appears to do something to the underlying file descriptors for stdout/stderr. On Windows with <code>multiprocessing.spawn</code>, the child process may inherit these modified descriptors. Even though we restore <code>sys.stdout</code> and <code>sys.stderr</code> in Python, the underlying C-level file descriptors remain affected.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#why-importing-queuegui-directly-works","title":"Why importing QueueGUI directly works","text":"<p>The import chain matters: - <code>from goliat.gui_manager import QueueGUI</code> \u2192 imports <code>progress_gui.py</code> \u2192 calls <code>matplotlib.use(\"Qt5Agg\")</code> \u2192 imports PySide6 internals - <code>from goliat.gui.queue_gui import QueueGUI</code> \u2192 only imports what QueueGUI needs (no matplotlib, no PySide6)</p>"},{"location":"technical/s4l_92_compatibility_investigation/#why-printing-in-main-process-works","title":"Why printing in main process works","text":"<p>The main process's stdout is fine - it's the parent, not affected by spawn inheritance. Since QueueGUI already sends all log messages through the multiprocessing queue, we just add a <code>print()</code> call in <code>QueueHandler._handle_status()</code> to echo them to terminal.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#logging-architecture-change-explained","title":"Logging Architecture Change Explained","text":""},{"location":"technical/s4l_92_compatibility_investigation/#before-s4l-82-terminal-output-worked","title":"Before (S4L 8.2 - Terminal Output Worked)","text":"<pre><code>Child Process runs the study:\n  \u251c\u2500\u2500 progress_logger (Python logging.Logger)\n  \u2502   \u251c\u2500\u2500 FileHandler \u2192 writes to logs/*.log files \u2713\n  \u2502   \u2514\u2500\u2500 StreamHandler \u2192 writes to sys.stdout\n  \u2502       \u2514\u2500\u2500 ColorFormatter applies colors based on log_type\n  \u2502       \u2514\u2500\u2500 Output appears in TERMINAL \u2713\n  \u2502\n  \u2514\u2500\u2500 QueueGUI sends messages to main process via Queue\n      \u2514\u2500\u2500 Main process updates GUI \u2713\n</code></pre> <p>How it worked: The child process's <code>progress_logger</code> had a <code>StreamHandler</code> that wrote directly to <code>sys.stdout</code>. The <code>ColorFormatter</code> applied colors based on <code>log_type</code>. This output appeared in the terminal.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#after-s4l-92-fix-child-stdout-broken","title":"After S4L 9.2 Fix (Child stdout BROKEN)","text":"<pre><code>Main Process:\n  \u2514\u2500\u2500 Starts S4L early (before PySide6)\n  \u2514\u2500\u2500 Spawns child process\n  \u2514\u2500\u2500 Child inherits BROKEN stdout/stderr file descriptors\n\nChild Process runs the study:\n  \u251c\u2500\u2500 progress_logger (Python logging.Logger)\n  \u2502   \u251c\u2500\u2500 FileHandler \u2192 writes to logs/*.log files \u2713 (STILL WORKS)\n  \u2502   \u2514\u2500\u2500 StreamHandler \u2192 writes to sys.stdout\n  \u2502       \u2514\u2500\u2500 But sys.stdout points to broken file descriptor\n  \u2502       \u2514\u2500\u2500 Output DOES NOT appear in terminal \u2717\n  \u2502\n  \u2514\u2500\u2500 QueueGUI sends messages to main process via Queue \u2713 (STILL WORKS)\n</code></pre> <p>The problem: When the main process starts S4L 9.2, something happens to stdout/stderr at the OS level. When the child is spawned, it inherits these broken file descriptors. The child's <code>StreamHandler</code> writes to what it thinks is stdout, but the data goes nowhere.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#the-workaround-print-in-main-process","title":"The Workaround (Print in Main Process)","text":"<pre><code>Child Process:\n  \u2514\u2500\u2500 LoggingMixin._log() calls:\n      \u251c\u2500\u2500 progress_logger.info() (file handler)\n      \u2514\u2500\u2500 self.gui.log(level=\"progress\") \u2192 queue.put({type: \"status\", ...})\n      \n      OR for verbose:\n      \u251c\u2500\u2500 verbose_logger.info() (file handler)  \n      \u2514\u2500\u2500 self.gui.log(level=\"verbose\") \u2192 queue.put({type: \"terminal_only\", ...})\n\nMain Process (QueueHandler):\n  \u2514\u2500\u2500 queue.get() \u2192 receives message\n  \u2514\u2500\u2500 For type=\"status\":\n      \u251c\u2500\u2500 self.gui.update_status() \u2192 Updates GUI\n      \u2514\u2500\u2500 print(f\"{color}{message}\") \u2192 Echoes to terminal \u2713\n  \u2514\u2500\u2500 For type=\"terminal_only\":\n      \u2514\u2500\u2500 print(f\"{color}{message}\") \u2192 Only prints to terminal (no GUI update)\n</code></pre> <p>The solution: Since the queue communication still works, and the main process's stdout is fine, we add a <code>print()</code> in the main process to echo messages to the terminal. Both progress and verbose logs are now sent through the queue: - Progress logs: type=\"status\" \u2192 Updates GUI AND prints to terminal - Verbose logs: type=\"terminal_only\" \u2192 Only prints to terminal (doesn't clutter GUI)</p> <p>The colors come from the same <code>get_color(log_type)</code> function that <code>ColorFormatter</code> uses.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#whats-the-same-vs-different","title":"What's the Same vs Different","text":"Aspect Before (8.2) After (9.2 fix) Where terminal output comes from Child process StreamHandler Main process print() Color system used ColorFormatter \u2192 get_color() Directly get_color() COLOR_MAP used goliat/colors.py goliat/colors.py (same) log_type values Passed via logger extra dict Passed via queue message Progress logs to terminal \u2713 via StreamHandler \u2713 via queue \u2192 print() Verbose logs to terminal \u2713 via StreamHandler \u2713 via queue \u2192 print() File logging Works Works (unchanged) GUI updates Works via queue Works via queue (unchanged) Web dashboard Works via queue Works via queue (gets both types)"},{"location":"technical/s4l_92_compatibility_investigation/#colors-should-be-identical","title":"Colors Should Be Identical","text":"<p>Both systems use the same <code>get_color(log_type)</code> function from <code>goliat/colors.py</code>:</p> <pre><code>COLOR_MAP = {\n    \"default\": Fore.WHITE,      # Titles/headers should be white\n    \"progress\": Fore.GREEN,     # Progress messages green\n    \"info\": Fore.CYAN,\n    \"success\": Fore.GREEN + Style.BRIGHT,\n    \"warning\": Fore.YELLOW,\n    \"error\": Fore.RED,\n    \"fatal\": Fore.MAGENTA,\n    ...\n}\n</code></pre> <p>If colors look wrong, the issue is likely that the <code>log_type</code> being passed through the queue isn't what's expected. Check what <code>log_type</code> value is being set when calling <code>self._log(message, level=\"progress\", log_type=\"...\")</code> in the study code.</p>"},{"location":"technical/s4l_92_compatibility_investigation/#files-changed","title":"Files Changed","text":"File Change <code>cli/run_study.py</code> Conditional S4L/PySide6 init based on main/child process <code>goliat/gui/components/queue_handler.py</code> Handle 'status' and 'terminal_only' message types, print both to terminal <code>goliat/gui/queue_gui.py</code> Send all log levels through queue (progress as 'status', verbose as 'terminal_only') <code>goliat/logging_manager.py</code> Send verbose logs through GUI too (for terminal output on S4L 9.2) <code>goliat/runners/keep_awake_handler.py</code> Guard <code>sys.stdout.flush()</code> with None check"},{"location":"technical/s4l_92_compatibility_investigation/#test-files-created","title":"Test Files Created","text":"<p>All in <code>tests/</code>: - <code>test_s4l_multiprocessing.py</code> - Basic Queue test - <code>test_s4l_multiprocessing_extended.py</code> - Progressive component tests - <code>test_s4l_import_order.py</code> - Import order tests - <code>test_s4l_import_bisect.py</code> - Binary search for problematic imports - <code>test_s4l_final_diagnostic.py</code> - Final isolation tests - <code>test_child_console.py</code> - Basic child process stdout test - <code>test_child_console_s4l.py</code> - Child stdout with S4L in child - <code>test_child_mimics_study.py</code> - Child imports run_study.py - <code>test_full_study_flow.py</code> - Full main+child flow test</p>"},{"location":"technical/s4l_92_compatibility_investigation/#lessons-learned","title":"Lessons Learned","text":"<ol> <li>Import order matters - Module-level import order can cause segfaults in external C libraries</li> <li>File descriptors vs Python objects - Restoring <code>sys.stdout</code> doesn't fix underlying fd issues</li> <li>Spawn context inheritance - Child processes may inherit unexpected state from parent</li> <li>Test incrementally - Binary search approach was essential for diagnosis</li> <li>Route around the problem - When child stdout is broken, print in the main process instead</li> <li>Main vs child context - Use <code>multiprocessing.current_process().name == \"MainProcess\"</code> to differentiate</li> </ol>"},{"location":"technical/s4l_92_compatibility_investigation/#verification","title":"Verification","text":"<p>To verify the fix works: 1. On S4L 8.2: <code>goliat study far_field_FR3_barebones</code> \u2192 Works with terminal output \u2713 2. On S4L 9.2: <code>goliat study far_field_FR3_barebones</code> \u2192 Works with terminal output \u2713 3. Both versions: GUI shows progress, logs written to files, no segfault, no hang</p>"},{"location":"technical/sim4life_92_compatibility/","title":"GOLIAT Sim4Life 9.2 Compatibility Notes","text":""},{"location":"technical/sim4life_92_compatibility/#status-complete","title":"Status: Complete \u2713","text":"<p>This document tracks the compatibility work for supporting both Sim4Life 8.2 and 9.2 in GOLIAT.</p>"},{"location":"technical/sim4life_92_compatibility/#1-version-detection-module","title":"1. Version Detection Module","text":"<p>A new <code>goliat/utils/version.py</code> module provides version detection and conditional logic:</p> <pre><code>from goliat.utils import (\n    get_sim4life_version,      # Returns (major, minor, patch) tuple\n    is_sim4life_92_or_later,   # True if running 9.2+\n    is_version_supported,       # Checks if version is 8.2.x or 9.2.x\n    get_version_display_string, # Returns \"9.2.0\" or similar\n)\n\n# Example usage\nif is_sim4life_92_or_later():\n    # Use 9.2-specific behavior\n    pass\n</code></pre>"},{"location":"technical/sim4life_92_compatibility/#supported-versions","title":"Supported Versions","text":"<ul> <li>8.2.x: Original supported version</li> <li>9.2.x: Fully supported (recommended for new installations)</li> </ul>"},{"location":"technical/sim4life_92_compatibility/#not-supported","title":"NOT Supported","text":"<ul> <li>9.0.x: Internal/beta release, explicitly excluded</li> </ul>"},{"location":"technical/sim4life_92_compatibility/#hardware-note-blackwell-gpus","title":"Hardware Note: Blackwell GPUs","text":"<ul> <li>RTX 5090, B100, etc.: On Sim4Life 9.2.1.19976, aXware is not supported on Blackwell architecture GPUs. Only the CUDA solver is available.</li> </ul>"},{"location":"technical/sim4life_92_compatibility/#2-code-updates-completed","title":"2. Code Updates Completed \u2713","text":"File Change <code>goliat/utils/version.py</code> NEW - Version detection module <code>goliat/utils/python_interpreter.py</code> Updated to use version module, prioritize 9.2 over 8.2, filter out 9.0 <code>goliat/utils/__init__.py</code> Exports version utilities <code>goliat/runners/osparc_direct_strategy.py</code> Updated version message to \"8.2 or 9.2\" <code>docs/user_guide/quick_start.md</code> Updated to reference 9.2 as recommended version"},{"location":"technical/sim4life_92_compatibility/#already-fixed-on-this-branch","title":"Already Fixed (on this branch)","text":"<ul> <li> Version detection with <code>get_sim4life_version()</code> and <code>is_sim4life_92_or_later()</code></li> <li> Prioritize 9.2 over 8.2 when selecting interpreters</li> <li> Filter out unsupported 9.0 installs</li> <li> Relaxed version check to allow non-8.2 versions (with warning)</li> <li> Fixed startup order: S4L must init before PySide6 import</li> <li> Fixed stdout handling (None stdout in 9.2)</li> <li> Added queue-based logging for child process output</li> <li> Updated all version messages to reference \"8.2 or 9.2\"</li> </ul>"},{"location":"technical/sim4life_92_compatibility/#3-api-changes-summary","title":"3. API Changes Summary","text":"<p>See <code>PythonAPIReference_DIFF_8_2_to_9_2/API_CHANGES_SUMMARY.md</code> for full details. Key breaking changes:</p> <ol> <li>Enum System - <code>Boost.Python.enum</code> \u2192 <code>enum.IntEnum</code> with <code>ClassVar</code> pattern</li> <li>Argument Names - Some functions re-indexed from <code>arg1</code> to <code>arg0</code></li> <li>Vector Types - <code>XCoreModeling.Vec3</code> consolidated to <code>QTech.Vec3</code></li> <li>Return Types - Many <code>tuple</code> returns now <code>list</code></li> <li>Removed Modules - <code>Chromium</code>, <code>ImagePostPro</code>, <code>XNdArray</code></li> </ol>"},{"location":"technical/sim4life_92_compatibility/#already-compatible","title":"Already Compatible \u2713","text":"Pattern Status <code>from QTech import Vec3</code> Used in <code>near_field_setup.py:261</code> - matches 9.2 pattern <code>XCoreMath.Vec3</code> Still available in 9.2 <code>s4l_v1.model.Vec3</code> Works in both versions No <code>kNone</code> enum usage No breaking enum changes found No <code>.names</code>/<code>.values</code> on S4L enums Only used on Python dicts/pandas No <code>AsVtkImage</code>/<code>AsVtkMesh</code> usage Removed in 9.2, not used"},{"location":"technical/sim4life_92_compatibility/#4-bashrc-handling","title":"4. .bashrc Handling","text":"<p>The <code>.bashrc</code> file is automatically updated to use the newest supported Sim4Life version: - When multiple versions are found, 9.2 is preferred over 8.2 - Version 9.0 is filtered out and never offered as an option - The PATH is set to include both Python and Scripts directories</p>"},{"location":"technical/sim4life_92_compatibility/#5-using-version-specific-code","title":"5. Using Version-Specific Code","text":"<p>For code that needs to behave differently between versions:</p> <pre><code>from goliat.utils.version import is_sim4life_92_or_later\n\nif is_sim4life_92_or_later():\n    # 9.2+ specific code\n    import XCore\n    XCore.RedirectToStdOut(True)  # Needed in 9.2, not in 8.2\nelse:\n    # 8.2 specific code\n    pass\n</code></pre> <p>Updated: 2026-01-14</p>"},{"location":"technical/skin_mesh_pipeline/","title":"Skin Mesh Extraction Pipeline","text":"<p>This document describes the unified skin mesh extraction pipeline that converts Sim4Life phantom voxel data into optimized 3D meshes.</p>"},{"location":"technical/skin_mesh_pipeline/#overview","title":"Overview","text":"<p>The pipeline extracts tissue voxels from Sim4Life <code>_Input.h5</code> files and generates optimized STL meshes suitable for visualization, 3D printing, or further processing. It runs entirely in Blender Python.</p>"},{"location":"technical/skin_mesh_pipeline/#workflow","title":"Workflow","text":"<ol> <li>Extract tissue voxels from H5 file (e.g., \"Skin\")</li> <li>Morphological processing (dilate-erode) to connect thin tissue layers</li> <li>Marching cubes mesh generation</li> <li>Trimesh cleanup (component filtering, hole filling)</li> <li>Blender optimization (Remesh + Decimate modifiers)</li> <li>Scale (meters \u2192 millimeters) and export STL</li> </ol>"},{"location":"technical/skin_mesh_pipeline/#prerequisites","title":"Prerequisites","text":""},{"location":"technical/skin_mesh_pipeline/#blender-installation","title":"Blender Installation","text":"<ul> <li>Blender 4.x (tested with 4.4): <code>C:\\Program Files\\Blender Foundation\\Blender 4.4\\blender.exe</code></li> </ul>"},{"location":"technical/skin_mesh_pipeline/#python-dependencies","title":"Python Dependencies","text":"<p>Dependencies (<code>h5py</code>, <code>scipy</code>, <code>scikit-image</code>, <code>trimesh</code>) are auto-installed to <code>~/.blender_packages</code> on first run.</p> <p>If auto-install fails, manually install using a working Python: <pre><code>python -m pip install --target \"C:/Users/&lt;username&gt;/.blender_packages\" h5py scipy scikit-image trimesh --python-version 3.11 --platform win_amd64 --only-binary :all:\n</code></pre></p>"},{"location":"technical/skin_mesh_pipeline/#usage","title":"Usage","text":""},{"location":"technical/skin_mesh_pipeline/#quick-start","title":"Quick Start","text":"<pre><code>\"C:\\Program Files\\Blender Foundation\\Blender 4.4\\blender.exe\" --background --python scripts/skin_mesh_pipeline.py -- configs/skin_mesh_config.json\n</code></pre>"},{"location":"technical/skin_mesh_pipeline/#with-overrides","title":"With Overrides","text":"<pre><code>\"C:\\Program Files\\Blender Foundation\\Blender 4.4\\blender.exe\" --background --python scripts/skin_mesh_pipeline.py -- configs/skin_mesh_config.json --h5-path path/to/Input.h5 --output-dir results/my_mesh --tissue skin\n</code></pre>"},{"location":"technical/skin_mesh_pipeline/#configuration","title":"Configuration","text":"<p>All parameters are specified in <code>configs/skin_mesh_config.json</code>:</p> <pre><code>{\n    \"input\": {\n        \"h5_path\": \"path/to/Input.h5\"\n    },\n    \"output\": {\n        \"base_directory\": \"data/phantom_skins\",\n        \"phantom_name\": \"thelonious\",\n        \"mesh_filename\": \"reduced.stl\",\n        \"save_voxel_pickle\": true,\n        \"save_blend_file\": true\n    },\n    \"tissue_extraction\": {\n        \"tissue_keyword\": \"skin\"\n    },\n    \"morphological_processing\": {\n        \"enabled\": true,\n        \"dilate_iterations\": 2,\n        \"erode_iterations\": 1\n    },\n    \"marching_cubes\": {\n        \"smooth_sigma\": 0.8\n    },\n    \"mesh_processing\": {\n        \"min_component_fraction\": 0.001,\n        \"fill_holes\": true\n    },\n    \"blender_optimization\": {\n        \"enabled\": true,\n        \"remesh\": {\n            \"voxel_size_m\": 0.001,\n            \"adaptivity\": 0.3\n        },\n        \"decimate\": {\n            \"ratio\": 0.3\n        },\n        \"scale\": {\n            \"factor\": 1000\n        }\n    }\n}\n</code></pre> <p>Note: Output will be saved to <code>base_directory/phantom_name/</code> (e.g., <code>data/phantom_skins/thelonious/</code>)</p>"},{"location":"technical/skin_mesh_pipeline/#input-h5-file-requirements","title":"Input H5 File Requirements","text":"<p>The pipeline requires a Sim4Life <code>_Input.h5</code> file containing voxelized phantom data. To generate one:</p> <ol> <li>Use a GOLIAT far-field config with <code>only_write_input_file: true</code></li> <li>Use 1.0 mm gridding for best mesh quality:</li> </ol> <pre><code>{\n    \"gridding_parameters\": {\n        \"global_gridding_per_frequency\": {\n            \"450\": 1.0\n        }\n    }\n}\n</code></pre> <p>Important: Finer voxel resolution (1.0 mm) produces better final meshes than coarser resolution (1.5 mm), even though it seems counterintuitive.</p>"},{"location":"technical/skin_mesh_pipeline/#blender-optimization-details","title":"Blender Optimization Details","text":""},{"location":"technical/skin_mesh_pipeline/#remesh-modifier-voxel-mode","title":"Remesh Modifier (Voxel Mode)","text":"<p>Creates uniform mesh topology from the marching cubes output.</p> Setting Default Description <code>voxel_size_m</code> 0.001 (1mm) Voxel resolution for remeshing <code>adaptivity</code> 0.3 Allows larger faces in flat areas"},{"location":"technical/skin_mesh_pipeline/#decimate-modifier-collapse","title":"Decimate Modifier (Collapse)","text":"<p>Reduces polygon count while preserving shape.</p> Setting Default Description <code>ratio</code> 0.3 Keep 30% of faces"},{"location":"technical/skin_mesh_pipeline/#scale","title":"Scale","text":"<p>Converts from Sim4Life units (meters) to millimeters.</p>"},{"location":"technical/skin_mesh_pipeline/#output-files","title":"Output Files","text":"File Description <code>skin_mesh.stl</code> Optimized mesh (~1-2 MB for skin) <code>skin_voxels.pkl</code> Voxel data for reprocessing <code>*_unapplied.blend</code> Blender file with modifiers NOT applied (for debugging)"},{"location":"technical/skin_mesh_pipeline/#expected-results","title":"Expected Results","text":"<p>With 1.0 mm input resolution:</p> Metric Value Raw mesh vertices ~2M Raw mesh faces ~4.2M Final mesh faces ~26K Final STL size ~1.3 MB"},{"location":"technical/skin_mesh_pipeline/#the-thin-skin-challenge","title":"The Thin Skin Challenge","text":"<p>Human skin in anatomical phantoms is typically only 1-2 mm thick. When voxelized, this creates problems:</p> <ul> <li>Skin may be only 1 voxel thick in many places</li> <li>Small gaps appear between voxels, creating disconnected regions</li> <li>Marching cubes produces thousands of small mesh components</li> </ul>"},{"location":"technical/skin_mesh_pipeline/#solution-dilate-erode-middle","title":"Solution: Dilate-Erode-Middle","text":"<ol> <li>Dilate the skin voxels by N iterations (thickens the layer)</li> <li>Erode back by N/2 iterations (finds the \"middle\" of the thickened layer)</li> <li>Gaussian smooth before marching cubes (creates smooth surface)</li> <li>Blender Remesh creates uniform, watertight topology</li> </ol> <p>This produces a single connected, watertight mesh while preserving the skin's shape.</p>"},{"location":"technical/skin_mesh_pipeline/#troubleshooting","title":"Troubleshooting","text":""},{"location":"technical/skin_mesh_pipeline/#modulenotfounderror-in-blender","title":"\"ModuleNotFoundError\" in Blender","text":"<p>The auto-install failed. Manually install packages (see Prerequisites).</p>"},{"location":"technical/skin_mesh_pipeline/#final-mesh-is-too-large-3-mb","title":"Final mesh is too large (&gt;3 MB)","text":"<p>Check your input H5 file resolution. Use 1.0 mm gridding instead of 1.5 mm.</p>"},{"location":"technical/skin_mesh_pipeline/#mesh-has-holes-or-artifacts","title":"Mesh has holes or artifacts","text":"<ul> <li>Increase <code>dilate_iterations</code> (try 3)</li> <li>Ensure <code>fill_holes</code> is enabled</li> <li>Check input H5 for tissue coverage issues</li> </ul>"},{"location":"technical/skin_mesh_pipeline/#blender-takes-too-long","title":"Blender takes too long","text":"<p>The Remesh modifier is compute-intensive for dense meshes. Expected time: 2-5 minutes for a full phantom skin mesh.</p>"},{"location":"technical/skin_mesh_pipeline/#files","title":"Files","text":"File Purpose <code>scripts/skin_mesh_pipeline.py</code> Main unified pipeline script <code>configs/skin_mesh_config.json</code> Default configuration <code>configs/skin_voxel_4phantoms_1mm.json</code> GOLIAT config for generating 1mm H5 files <code>goliat/utils/skin_voxel_utils.py</code> Core voxel extraction utilities"},{"location":"technical/skin_mesh_pipeline/#change-history","title":"Change History","text":"<ul> <li>2026-01-11: Created unified <code>skin_mesh_pipeline.py</code> replacing:</li> <li><code>extract_skin_to_mesh.py</code> (original dev script)</li> <li><code>voxel_tissue_to_mesh.py</code> (intermediate script)</li> <li><code>blender_optimize_mesh.py</code> (Blender-only optimization)</li> </ul>"},{"location":"technical/skin_mesh_vs_voxel_approach/","title":"Skin Mesh vs Voxel Approach for Air-Based Focus Search","text":"<p>Date: January 2026 Context: Evaluating whether the STL skin mesh from <code>skin_mesh_pipeline</code> could speed up or improve the auto-induced air-based focus search.</p>"},{"location":"technical/skin_mesh_vs_voxel_approach/#conclusion-voxel-based-approach-is-preferred","title":"Conclusion: Voxel-based approach is preferred","text":"<p>The STL mesh (~1 MB per phantom) does not add significant value for the air-based focus search.</p>"},{"location":"technical/skin_mesh_vs_voxel_approach/#reasoning","title":"Reasoning","text":""},{"location":"technical/skin_mesh_vs_voxel_approach/#what-we-need","title":"What we need:","text":"<ol> <li>Find valid air focus points (air voxels near skin)</li> <li>Sample ~100 air points randomly</li> <li>For each sample: compute hotspot score = mean(|E_combined|\u00b2) over skin voxels in a cube</li> </ol>"},{"location":"technical/skin_mesh_vs_voxel_approach/#why-voxel-based-works-better","title":"Why voxel-based works better:","text":"Aspect Voxel Approach Mesh Approach Speed Fast (scipy binary_dilation, seconds) Would require mesh loading + distance queries Coordinate system Same as E-field data (<code>_Output.h5</code>) Would need to map mesh coords back to voxel indices Complexity Simple boolean operations Additional mesh processing code Accuracy Exact match to simulation grid Interpolation/snapping required"},{"location":"technical/skin_mesh_vs_voxel_approach/#where-mesh-would-be-useful","title":"Where mesh WOULD be useful:","text":"<ul> <li>Visualization of results</li> <li>3D printing</li> <li>Generating sample points at exact offset from skin surface (along normals)</li> <li>Geometric queries (ray casting, surface distance)</li> </ul>"},{"location":"technical/skin_mesh_vs_voxel_approach/#decision","title":"Decision:","text":"<p>Continue with binary dilation of skin mask to find air voxels near skin. This is: - Already fast - Consistent with the field grid - Simpler to implement and maintain</p> <p>The STL mesh remains available for other use cases but is not needed for focus point search.</p>"},{"location":"technical/web_monitoring_debugging_summary/","title":"Web Monitoring Dashboard Debugging Summary","text":"<p>Date: November 29, 2025 Status: Issue Not Resolved Problem: Web dashboard shows messages in large bursts with significant lag, and local GUI freezes on exit.</p>"},{"location":"technical/web_monitoring_debugging_summary/#problem-description","title":"Problem Description","text":""},{"location":"technical/web_monitoring_debugging_summary/#initial-symptoms","title":"Initial Symptoms","text":"<ol> <li>Message Ordering Issues:</li> <li>\"Done in\" and \"Assign materials\" messages appeared swapped on the web dashboard</li> <li> <p>Missing \"Done in\" messages for \"Voxelize simulation\" and \"Write input file\" steps</p> </li> <li> <p>Severe Lag:</p> </li> <li>Web dashboard showed nothing initially</li> <li>After a long delay, messages appeared in one large burst</li> <li>Dashboard remained far behind the local GUI state</li> <li> <p>Example: Local GUI showed simulation complete, web dashboard still showing \"Voxelize simulation...\"</p> </li> <li> <p>Application Freeze:</p> </li> <li>Clicking X on local GUI window caused it to freeze</li> <li>Windows showed \"Python does not appear to be responding\"</li> <li>Required force quit to terminate</li> <li>When force quit, all pending messages appeared on web dashboard immediately</li> </ol>"},{"location":"technical/web_monitoring_debugging_summary/#network-characteristics","title":"Network Characteristics","text":"<ul> <li>Screenshot bandwidth: 10-15 MB/min (later reduced to 2-4 MB/min)</li> <li>Messages were being sent successfully (confirmed via verbose logs)</li> <li>Server (Railway) logs showed batches being received and processed</li> </ul>"},{"location":"technical/web_monitoring_debugging_summary/#investigation-findings","title":"Investigation Findings","text":""},{"location":"technical/web_monitoring_debugging_summary/#1-message-ordering-issues","title":"1. Message Ordering Issues","text":"<p>Root Cause Identified: - Messages were being sent in separate batches due to rapid succession - Race conditions on server-side when multiple batches arrived concurrently - Timestamps could be identical for messages sent milliseconds apart</p> <p>Evidence from Logs: <pre><code>[DEBUG] Enqueued status:       - Done in 0.80s\n[DEBUG] Enqueued status:     - Assign materials...\n[DEBUG] Added to batch (size=1):       - Done in 0.80s\n[DEBUG] Sending batch of 1 messages (timeout (1s))\n[DEBUG] Added to batch (size=1):     - Assign materials...\n</code></pre></p> <p>Messages were being split into separate batches, causing potential reordering on the server.</p>"},{"location":"technical/web_monitoring_debugging_summary/#2-missing-messages","title":"2. Missing Messages","text":"<p>Finding: - Verbose logs confirmed messages were being sent successfully:   - <code>[DEBUG] Batch seq=8 sent successfully</code> (contained \"Done in 8.77s\" for voxelize)   - <code>[DEBUG] Batch seq=13 sent successfully</code> (contained \"Done in 4.27s\" for write input file) - Server-side logs showed batches being received - Conclusion: Messages were lost or not displayed on the server side, not a client-side issue</p>"},{"location":"technical/web_monitoring_debugging_summary/#3-lag-and-burst-behavior","title":"3. Lag and Burst Behavior","text":"<p>Root Cause: - Single-threaded executor (<code>max_workers=1</code>) for log requests - When network was slow, requests would take 10+ seconds to timeout - During this time, new messages accumulated in <code>log_batch</code> but couldn't be sent - Once the request completed/timed out, all accumulated messages were sent in one burst - This created a \"burst\" pattern: nothing \u2192 everything at once</p> <p>Evidence: - User reported: \"At the beginning it showed nothing. After a good bit (too long) it eventually showed... in one big burst\" - When clicking X, all pending messages appeared immediately (queue was flushed)</p>"},{"location":"technical/web_monitoring_debugging_summary/#4-application-freeze","title":"4. Application Freeze","text":"<p>Root Cause: - <code>stop()</code> method called <code>log_executor.shutdown(wait=True)</code> - If there were pending HTTP requests in the executor queue, shutdown would wait for them - With 10-second timeouts and retries, this could take 30+ seconds - GUI appeared frozen during this wait</p>"},{"location":"technical/web_monitoring_debugging_summary/#fixes-attempted","title":"Fixes Attempted","text":""},{"location":"technical/web_monitoring_debugging_summary/#fix-1-timestamp-precision-improvement","title":"Fix 1: Timestamp Precision Improvement","text":"<p>File: <code>goliat/gui/queue_gui.py</code></p> <p>Change: - Added monotonic timestamp counter to ensure unique, always-increasing timestamps - Prevents timestamp collisions for rapid messages</p> <p>Status: \u2705 Implemented (helps with ordering but doesn't solve lag)</p>"},{"location":"technical/web_monitoring_debugging_summary/#fix-2-serialized-log-requests-race-condition-prevention","title":"Fix 2: Serialized Log Requests (Race Condition Prevention)","text":"<p>File: <code>goliat/utils/gui_bridge.py</code></p> <p>Change: - Split executors: <code>log_executor</code> (1 worker) for logs, <code>request_executor</code> (4 workers) for screenshots/heartbeats - Ensures log messages are sent sequentially, preventing server-side race conditions</p> <p>Status: \u2705 Implemented (fixes ordering but doesn't solve lag)</p>"},{"location":"technical/web_monitoring_debugging_summary/#fix-3-sequence-numbers-and-batch-indexing","title":"Fix 3: Sequence Numbers and Batch Indexing","text":"<p>File: <code>goliat/utils/gui_bridge.py</code></p> <p>Change: - Added sequence numbers to batches for proper ordering - Added <code>batch_index</code> to each message within a batch - Server can sort by: sequence \u2192 timestamp \u2192 batch_index</p> <p>Status: \u2705 Already implemented (from previous commits)</p>"},{"location":"technical/web_monitoring_debugging_summary/#fix-4-screenshot-bandwidth-reduction","title":"Fix 4: Screenshot Bandwidth Reduction","text":"<p>Files:  - <code>goliat/gui/components/web_bridge_manager.py</code> - <code>goliat/gui/components/screenshot_capture.py</code></p> <p>Changes: - Reduced screenshot capture frequency: 1 FPS \u2192 0.2 FPS (every 5 seconds) - Reduced JPEG quality: 95% \u2192 70% - Bandwidth reduced from 10-15 MB/min \u2192 2-4 MB/min</p> <p>Status: \u2705 Implemented (reduced bandwidth but lag persists)</p>"},{"location":"technical/web_monitoring_debugging_summary/#fix-5-smart-batching-adaptive-to-network-latency","title":"Fix 5: Smart Batching (Adaptive to Network Latency)","text":"<p>File: <code>goliat/utils/gui_bridge.py</code></p> <p>Change: - Added <code>last_log_future</code> tracking to monitor if previous request is still running - Only sends new batch if executor is free OR backlog is critical (\u2265100 messages) - Automatically adapts batch size to network speed</p> <p>Logic: <pre><code>is_executor_free = self.last_log_future is None or self.last_log_future.done()\nif log_batch:\n    if is_backlog_critical:\n        can_send = True  # Force send\n    elif is_executor_free:\n        # Check time/size limits\n        can_send = True if conditions met\n</code></pre></p> <p>Status: \u2705 Implemented (should help but issue persists)</p>"},{"location":"technical/web_monitoring_debugging_summary/#fix-6-adaptive-timeouts","title":"Fix 6: Adaptive Timeouts","text":"<p>Files: - <code>goliat/utils/http_client.py</code> - <code>goliat/utils/gui_bridge.py</code></p> <p>Changes: - Reduced default timeout: 10s \u2192 3s for log updates - Reduced shutdown timeout: 10s \u2192 2s with 1 retry (down from 3) - Progress updates also use 3s timeout</p> <p>Status: \u2705 Implemented (should prevent freeze, but lag issue persists)</p>"},{"location":"technical/web_monitoring_debugging_summary/#current-state","title":"Current State","text":""},{"location":"technical/web_monitoring_debugging_summary/#what-works","title":"What Works","text":"<ul> <li>\u2705 Messages are being sent successfully (confirmed via logs)</li> <li>\u2705 Message ordering is correct (sequence numbers, timestamps, batch_index)</li> <li>\u2705 No race conditions (serialized executor)</li> <li>\u2705 Bandwidth reduced significantly</li> <li>\u2705 Application should not freeze on exit (shorter timeout)</li> </ul>"},{"location":"technical/web_monitoring_debugging_summary/#what-doesnt-work","title":"What Doesn't Work","text":"<ul> <li>\u274c Lag persists: Messages still appear in bursts with significant delay</li> <li>\u274c Dashboard remains behind: Web dashboard shows old state while local GUI is current</li> <li>\u274c Burst behavior: Long periods of no updates, then everything at once</li> </ul>"},{"location":"technical/web_monitoring_debugging_summary/#current-behavior","title":"Current Behavior","text":"<ol> <li>Dashboard shows nothing initially</li> <li>After delay, messages appear in one large burst</li> <li>Dashboard remains far behind local GUI</li> <li>When GUI is closed, all pending messages appear immediately</li> </ol>"},{"location":"technical/web_monitoring_debugging_summary/#root-cause-analysis","title":"Root Cause Analysis","text":""},{"location":"technical/web_monitoring_debugging_summary/#primary-issue-network-latency-single-threaded-executor","title":"Primary Issue: Network Latency + Single-Threaded Executor","text":"<p>The fundamental problem is: 1. Network is slow/unreliable (requests taking 3-10+ seconds) 2. Single-threaded executor means only one request at a time 3. Messages accumulate while waiting for previous request 4. Burst delivery when request finally completes</p>"},{"location":"technical/web_monitoring_debugging_summary/#why-smart-batching-didnt-solve-it","title":"Why Smart Batching Didn't Solve It","text":"<p>Smart Batching helps by: - Not sending new requests while one is pending - Accumulating messages into larger batches</p> <p>But it doesn't solve: - The underlying network slowness - The fact that we still wait for slow requests to complete - The burst behavior when requests finally succeed</p>"},{"location":"technical/web_monitoring_debugging_summary/#why-adaptive-timeouts-didnt-solve-it","title":"Why Adaptive Timeouts Didn't Solve It","text":"<p>Shorter timeouts help by: - Failing faster when network is down - Preventing freeze on exit</p> <p>But they don't solve: - The fact that successful requests still take a long time - The accumulation of messages during slow requests - The burst delivery pattern</p>"},{"location":"technical/web_monitoring_debugging_summary/#potential-solutions-not-yet-implemented","title":"Potential Solutions (Not Yet Implemented)","text":""},{"location":"technical/web_monitoring_debugging_summary/#option-1-parallel-executor-with-backpressure","title":"Option 1: Parallel Executor with Backpressure","text":"<ul> <li>Use multiple workers (e.g., 3-5) for log requests</li> <li>Track queue depth and throttle if too many pending</li> <li>Could improve throughput but might cause ordering issues</li> </ul> <p>Risk: May reintroduce race conditions on server side</p>"},{"location":"technical/web_monitoring_debugging_summary/#option-2-client-side-message-aggregation","title":"Option 2: Client-Side Message Aggregation","text":"<ul> <li>Accumulate messages for longer periods (e.g., 5-10 seconds)</li> <li>Send larger batches less frequently</li> <li>Reduces number of HTTP requests</li> </ul> <p>Risk: Increases latency even more, messages appear even later</p>"},{"location":"technical/web_monitoring_debugging_summary/#option-3-server-side-optimization","title":"Option 3: Server-Side Optimization","text":"<ul> <li>Investigate server-side processing delays</li> <li>Check if database writes are slow</li> <li>Optimize API endpoint performance</li> </ul> <p>Note: This requires access to <code>goliat-monitoring</code> repository/server logs</p>"},{"location":"technical/web_monitoring_debugging_summary/#option-4-websocket-instead-of-http-post","title":"Option 4: WebSocket Instead of HTTP POST","text":"<ul> <li>Replace HTTP POST with WebSocket connection</li> <li>Persistent connection, lower overhead</li> <li>Real-time bidirectional communication</li> </ul> <p>Risk: Requires significant refactoring of both client and server</p>"},{"location":"technical/web_monitoring_debugging_summary/#option-5-message-prioritization","title":"Option 5: Message Prioritization","text":"<ul> <li>Send critical messages (progress, errors) immediately</li> <li>Batch only verbose log messages</li> <li>Use different endpoints for different priorities</li> </ul> <p>Risk: May not solve the fundamental network latency issue</p>"},{"location":"technical/web_monitoring_debugging_summary/#debugging-information-needed","title":"Debugging Information Needed","text":"<p>To further diagnose, we need:</p> <ol> <li>Server-Side Logs (Railway):</li> <li>Average request processing time</li> <li>Database write latency</li> <li>Queue depth on server</li> <li> <p>Any errors or timeouts</p> </li> <li> <p>Network Diagnostics:</p> </li> <li>Latency to server (ping times)</li> <li>Packet loss</li> <li>Bandwidth during operation</li> <li> <p>Connection stability</p> </li> <li> <p>Client-Side Metrics:</p> </li> <li>Time between message enqueue and send</li> <li>Time between send and success</li> <li>Batch sizes being sent</li> <li>Executor queue depth over time</li> </ol>"},{"location":"technical/web_monitoring_debugging_summary/#files-modified","title":"Files Modified","text":"<ol> <li><code>goliat/gui/queue_gui.py</code> - Timestamp precision</li> <li><code>goliat/utils/gui_bridge.py</code> - Smart batching, serialized executor, adaptive timeouts</li> <li><code>goliat/utils/http_client.py</code> - Configurable timeouts</li> <li><code>goliat/gui/components/web_bridge_manager.py</code> - Screenshot frequency</li> <li><code>goliat/gui/components/screenshot_capture.py</code> - JPEG quality</li> </ol>"},{"location":"technical/web_monitoring_debugging_summary/#commits-made","title":"Commits Made","text":"<ol> <li><code>fix(web): Serialize log requests to prevent race conditions and improve timestamp precision</code></li> <li><code>fix(web): Reduce screenshot bandwidth usage (5s interval, 70% quality)</code></li> <li><code>fix(web): Implement smart batching to adapt to network latency and prevent lag/freezes</code></li> <li><code>fix(web): Adaptive timeouts to prevent freeze on exit and improve responsiveness</code></li> </ol>"},{"location":"technical/web_monitoring_debugging_summary/#next-steps","title":"Next Steps","text":"<ol> <li>Investigate server-side performance - Check Railway logs for processing delays</li> <li>Monitor network conditions - Check latency and stability to server</li> <li>Consider architectural changes - WebSocket or parallel executors</li> <li>Add metrics/logging - Track request times, queue depths, batch sizes</li> <li>Test with different network conditions - Verify if issue is network-specific</li> </ol>"},{"location":"technical/web_monitoring_debugging_summary/#conclusion","title":"Conclusion","text":"<p>The issue appears to be fundamentally related to network latency combined with a single-threaded request model. While we've implemented several optimizations (smart batching, shorter timeouts, reduced bandwidth), the core problem persists: slow network requests cause message accumulation and burst delivery.</p> <p>The fixes have improved: - Message ordering (no more race conditions) - Application stability (no freeze on exit) - Bandwidth usage (reduced screenshot overhead)</p> <p>But have not solved: - Lag between local GUI and web dashboard - Burst delivery pattern - Dashboard being far behind current state</p> <p>Further investigation is needed, particularly on the server-side performance and network conditions.</p>"},{"location":"tutorials/01_far_field_basics/","title":"1. Far-Field Basics","text":"<pre><code>from pathlib import Path\nimport importlib.util\n\np = Path.cwd()\nwhile not (p / \"scripts\" / \"notebook_helpers.py\").exists():\n    p = p.parent\nspec = importlib.util.spec_from_file_location(\"_\", p / \"scripts\" / \"notebook_helpers.py\")\nm = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(m)\nrun_bash = m.get_run_bash()\n\nimport IPython\n\nIPython.core.display.max_output_size = None\n</code></pre> <p>This helper function lets you run bash commands from Python cells using <code>run_bash('command')</code>. The setup also disables output truncation so you can see all command output.</p> <p>If you're using bash directly (recommended), ignore the Python code blocks and just run the commands directly. Make sure to always run <code>source .bashrc</code> which adds the Sim4Life python path to your <code>PATH</code> first.</p> <pre><code>run_bash(\"cat configs/tutorial_1_far_field.json\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; cat configs/tutorial_1_far_field.json\n\n------------------------------------------------------------\n{\n  \"extends\": \"base_config.json\",\n  \"study_type\": \"far_field\",\n  \"phantoms\": [\"thelonious\"],\n  \"frequencies_mhz\": [700],\n  \"far_field_setup\": {\n    \"type\": \"environmental\",\n    \"environmental\": {\n      \"incident_directions\": [\"x_pos\", \"z_neg\"],\n      \"polarizations\": [\"theta\", \"phi\"]\n    }\n  },\n  \"execution_control\": {\n    \"do_setup\": true,\n    \"do_run\": true,\n    \"do_extract\": true\n  },\n  \"simulation_parameters\": {\n    \"number_of_point_sensors\": 2\n  }\n}\n\n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <pre><code>run_bash(\"goliat study tutorial_1_far_field\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; goliat study tutorial_1_far_field\n\n------------------------------------------------------------\nStarting Sim4Life application... \nInitializing Application [stdout]\nInitializing Application [stderr]\n[Warn]  Unable to load module 'C:\\Program Files\\Sim4Life_8.2.0.16876\\MusaikInterface.xdll'\nJosua    : [Info]  Sync\nJosua    : [Info]  Sync\nJosua    : [Info]  Command [Query Handshake] &lt;ba838023-b536-461a-9e49-4d8334c0db09;127.0.0.1;WIN10-NEW&gt;\nJosua    : [Info]  Property [CAresSettings]\n[Info]  Connection to local Ares successfully established.\nSim4Life application started. \n--- Starting Far-Field Study: tutorial_1_far_field.json --- [FarFieldStudy._run_study]\n\n--- Processing Simulation 1/4: thelonious, 700MHz, x_pos, theta --- [FarFieldStudy._run_study]\n--- Starting: setup --- [profile]\nProject path set to: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash [ProjectManager.create_or_open_project]\nNo metadata file found at config.json. [ProjectManager.verify_simulation_metadata]\nExisting project is invalid or out of date. A new setup is required. [ProjectManager.create_or_open_project]\n--- Simulation-specific progress logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos\\progress.log --- \n--- Simulation-specific verbose logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos\\verbose.log --- \nCreating a new empty project in memory. [ProjectManager.create_new]\nInitializing model by creating and deleting a dummy block... [ProjectManager.create_new]\nModel initialized, ready for population. [ProjectManager.create_new]\n  - Setup simulation... [FarFieldStudy.subtask]\n--- Setting up single Far-Field sim --- [FarFieldSetup.run_full_setup]\n    - Load phantom... [FarFieldSetup.run_full_setup]\n--- Running Phantom Check --- [PhantomSetup._log]\nFound 2 total entities in the project. [PhantomSetup._log]\n--- Phantom Check Result: Phantom not found in project. --- [PhantomSetup._log]\nPhantom not found in document. Importing from 'C:\\Users\\user\\repo-clean\\data\\phantoms\\thelonious.sab'... [PhantomSetup._log]\n[Info] Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nPhantom imported successfully. [PhantomSetup._log]\n      - Subtask 'setup_load_phantom' done in 8.73s [FarFieldSetup.run_full_setup]\n      - Done in 8.73s [FarFieldSetup.run_full_setup]\n    - Configure scene (bbox, plane wave)... [FarFieldSetup.run_full_setup]\nCreating simulation bounding box for far-field... [FarFieldSetup._create_or_get_simulation_bbox]\n  - Created far-field simulation BBox with 50mm padding. [FarFieldSetup._create_or_get_simulation_bbox]\n  - Creating simulation: EM_FDTD_thelonious_700MHz_x_pos_theta [FarFieldSetup._create_simulation_entity]\n  - Using simulation time multiplier: 3.5 [FarFieldSetup._apply_simulation_time_and_termination]\n  - Simulation time set to 11.44 periods. [FarFieldSetup._apply_simulation_time_and_termination]\n  - Setting termination criteria to: GlobalAutoTerminationUserDefined [FarFieldSetup._apply_simulation_time_and_termination]\n    - Convergence level set to: -15 dB [FarFieldSetup._apply_simulation_time_and_termination]\n      - Subtask 'setup_configure_scene' done in 0.28s [FarFieldSetup.run_full_setup]\n      - Done in 0.28s [FarFieldSetup.run_full_setup]\n    - Assign materials... [FarFieldSetup.run_full_setup]\nAssigning materials... [MaterialSetup.assign_materials]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\n[Info]  \nMass Density has changed from 1000 to 1.2050000000000001\nMass Density has changed from 1.2050000000000001 to 1.2\nRelative Permittivity has changed from 1 to 0\nSimulation : [Warn]  Unable to find any match for following settings properties: Magnetic Conductivity\nSimulation : [Warn]  Unable to find any match for following settings properties: Relative Permeability\n      - Subtask 'setup_materials' done in 5.69s [FarFieldSetup.run_full_setup]\n      - Done in 5.69s [FarFieldSetup.run_full_setup]\n    - Configure solver (gridding, boundaries, sensors)... [FarFieldSetup.run_full_setup]\nSetting up gridding... [GriddingSetup.setup_gridding]\n  - Looking for global grid bounding box: 'far_field_simulation_bbox' [GriddingSetup._setup_main_grid]\n  - Using manual gridding. [GriddingSetup._setup_main_grid]\n  - Global and added manual grid set with global resolution: 3.0 mm. [GriddingSetup._setup_main_grid]\n  - Using automatic padding. [GriddingSetup._setup_main_grid]\n  - No antenna components provided, skipping subgridding. [GriddingSetup.setup_gridding]\nSetting up boundary conditions... [BoundarySetup.setup_boundary_conditions]\n  - Setting global boundary conditions to: UpmlCpml [BoundarySetup.setup_boundary_conditions]\n    - Successfully set GlobalBoundaryType to UpmlCpml [BoundarySetup.setup_boundary_conditions]\n  - Setting PML strength to: Low [BoundarySetup.setup_boundary_conditions]\n    - Successfully set PmlStrength to Low [BoundarySetup.setup_boundary_conditions]\n  - Added point sensor at (Vec3(-231.59, -107.681, -1019.42), Vec3(-231.59, -107.681, -1019.42), Vec3(-231.59, -107.681, -1019.42)) (lower_left_bottom) [FarFieldSetup._add_point_sensors]\n  - Added point sensor at (Vec3(239.048, 205.076, 260.697), Vec3(239.048, 205.076, 260.697), Vec3(239.048, 205.076, 260.697)) (top_right_up) [FarFieldSetup._add_point_sensors]\n  - Configuring solver settings... [FarFieldSetup._setup_solver_settings]\n    - Solver kernel set to: Acceleware (AXware) [FarFieldSetup._setup_solver_settings]\n      - Subtask 'setup_solver' done in 0.16s [FarFieldSetup.run_full_setup]\n      - Done in 0.16s [FarFieldSetup.run_full_setup]\n    - Voxelize simulation... [FarFieldSetup.run_full_setup]\n    - Finalizing setup... [FarFieldSetup._finalize_setup]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tongue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Adrenal Gland\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Anterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Vitreous Humor)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Midbrain\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Testis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Air 1\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood Vessel Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Epididymis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pineal Body\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Urinary Bladder Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone Marrow (Red)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Gallbladder\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypophysis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (White Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spleen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thymus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypothalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skin\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (Grey Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone (Cortical)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Sclera)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tendon\\Ligament\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Medulla)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Medulla Oblongata\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Intervertebral Disc\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Vertebrae\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Lens)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Posterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Cornea)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pharynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Liver\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Cortex)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Fat\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Lung\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Connective Tissue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pons\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spinal Cord\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"SAT (Subcutaneous Fat)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cartilage\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tooth\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Nerve\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Meniscus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skull\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Prostate\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Diaphragm\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mucous Membrane\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Larynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mandible\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hippocampus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebellum\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Penis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Ureter\\Urethra\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pancreas\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebrospinal Fluid\" have been set to their value according to the selected database\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n[Info]  Start voxeling\n[Info]  Topological Voxeler Report: Complete Voxel Scene\n    Voxel Scene Memory Consumption: 0.002876 GB\n    Wall Clock Time: 7.82005 s\n\n[Info]  Voxeling succeeded.\n    - Finalizing setup complete. [FarFieldSetup._finalize_setup]\n      - Subtask 'setup_voxelize' done in 19.22s [FarFieldSetup.run_full_setup]\n      - Done in 19.22s [FarFieldSetup.run_full_setup]\n    - Save project... [FarFieldSetup.run_full_setup]\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\nProject saved. [ProjectManager.save]\n      - Subtask 'setup_save_project' done in 3.41s [FarFieldSetup.run_full_setup]\n      - Done in 3.41s [FarFieldSetup.run_full_setup]\nCommon settings applied. [FarFieldSetup.run_full_setup]\n    - Subtask 'setup_simulation' done in 37.61s [FarFieldStudy.subtask]\n    - Done in 37.61s [FarFieldStudy.subtask]\n  - Saved configuration metadata to config.json [ProjectManager.write_simulation_metadata]\n--- Finished: setup (took 37.69s) --- [profile]\n--- Starting: run --- [profile]\n  - Run simulation total... [FarFieldStudy.subtask]\nRunning simulation: EM_FDTD_thelonious_700MHz_x_pos_theta [SimulationRunner.run]\n    - Write input file... [SimulationRunner.run]\n[Info]  Writing solver input file(s) for EM_FDTD_thelonious_700MHz_x_pos_theta\n[Info]  Writing Rectilinear Discretization to Input File. Elapse Time: 0.36436 s\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n      - Subtask 'run_write_input_file' done in 4.41s [SimulationRunner.run]\n      - Done in 4.41s [SimulationRunner.run]\nRunning iSolve with acceleware on ff4ed249-3a58-4fcc-b6a0-f9e1f28b1fbd_Input.h5 [SimulationRunner._run_isolve_manual]\n    - Execute iSolve... [SimulationRunner._run_isolve_manual]\n\nReading command line \niSolve X, Version 8.2.0 (16876), 64Bit Windows \n\nRunning MPI version 2.0 on 1 process. \n\n\nSimulation 'EM_FDTD_thelonious_700MHz_x_pos_theta'  \n\nInstalled system RAM visible to this process:  16.0 GB \n\nSolver type: EmFdtd, SinglePrecision, Acceleware \nInput file name: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash_Results\\ff4ed249-3a58-4fcc-b6a0-f9e1f28b1fbd_Input.h5 \nInput file generated by: Sim4Life, Version 8.2.0.16876 \nOutput file name: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash_Results\\ff4ed249-3a58-4fcc-b6a0-f9e1f28b1fbd_Output.h5 \n\nUsing commercial license features. \nChecking out license feature 'FDTD_SOLVER', version 8.2, (1). \n\nRunning the EM-FDTD solver with the following settings: \nFloating Point Arithmetic: single (4 Bytes) \nHPC: Acceleware \nUsed Acceleware library is '11.4.1.13550 (x64, 64-bit)'. \nYour NVIDIA display driver is newer than the expected version. \nInstalled version: 15.7680 Expected: 15.3667 (see also http://www.acceleware.com/fdtd-11-4-1) \nReduced performance could be encountered. \n\nSimulation Time Step:   5.72711e-12 sec \nSimulation Iterations:  2853 \nMax Simulated Time: 1.63394e-08 sec \n\nGrid: \nNumber of cells: 229x177x499 = 20225967 cells = 20.2260 MCells \nNumber of cells including PML: 245x193x515 = 24351775 cells = 24.3518 MCells \nX: Range [-0.338659 ... 0.346117] with minimal 0.00297412 and maximal step 0.0029977 [m] \nY: Range [-0.21475 ... 0.312145] with minimal 0.00297412 and maximal step 0.00297865 [m] \nZ: Range [-1.12649 ... 0.367766] with minimal 0.00297403 and maximal step 0.00299799 [m] \n\nBoundaries: \nSide X-: ABC (UPML, 8 layers) \nSide X+: ABC (UPML, 8 layers) \nSide Y-: ABC (UPML, 8 layers) \nSide Y+: ABC (UPML, 8 layers) \nSide Z-: ABC (UPML, 8 layers) \nSide Z+: ABC (UPML, 8 layers) \n\nCreated unified material architecture (UMA) model \n\nMaterials (77): \nBackground: dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nTongue  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=0.865626, mu_r=1.000000, sigma_H=0.000000) \nAdrenal_gland  (Thelonious_6y_V6): dielectric (eps_r=50.989008, sigma_E=0.954350, mu_r=1.000000, sigma_H=0.000000) \nStomach_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \ncommissura_anterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nEye_vitreous_humor  (Thelonious_6y_V6): dielectric (eps_r=68.947390, sigma_E=1.583627, mu_r=1.000000, sigma_H=0.000000) \nVein  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nMidbrain  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nTestis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nAir_internal  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBlood_vessel  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nEpididymis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nPinealbody  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBladder  (Thelonious_6y_V6): dielectric (eps_r=19.149003, sigma_E=0.358399, mu_r=1.000000, sigma_H=0.000000) \nMarrow_red  (Thelonious_6y_V6): dielectric (eps_r=11.451933, sigma_E=0.207759, mu_r=1.000000, sigma_H=0.000000) \nGallbladder  (Thelonious_6y_V6): dielectric (eps_r=59.551663, sigma_E=1.202528, mu_r=1.000000, sigma_H=0.000000) \nHypophysis  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBrain_white_matter  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nSpleen  (Thelonious_6y_V6): dielectric (eps_r=58.688546, sigma_E=1.175182, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nThymus  (Thelonious_6y_V6): dielectric (eps_r=55.600852, sigma_E=1.115237, mu_r=1.000000, sigma_H=0.000000) \nTrachea  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nHeart_muscle  (Thelonious_6y_V6): dielectric (eps_r=61.478559, sigma_E=1.125021, mu_r=1.000000, sigma_H=0.000000) \nMuscle  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nHypothalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nArtery  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nSkin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nBrain_grey_matter  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nPatella  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_Sclera  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=1.096154, mu_r=1.000000, sigma_H=0.000000) \nTendon_Ligament  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nKidney_medulla  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nMedulla_oblongata  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nEsophagus  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nIntervertebral_disc  (Thelonious_6y_V6): dielectric (eps_r=44.418065, sigma_E=1.041108, mu_r=1.000000, sigma_H=0.000000) \nVertebrae  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_lens  (Thelonious_6y_V6): dielectric (eps_r=36.279018, sigma_E=0.435952, mu_r=1.000000, sigma_H=0.000000) \ncommissura_posterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nCornea  (Thelonious_6y_V6): dielectric (eps_r=56.275669, sigma_E=1.311407, mu_r=1.000000, sigma_H=0.000000) \nTrachea_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPharynx  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nLiver  (Thelonious_6y_V6): dielectric (eps_r=47.963211, sigma_E=0.773986, mu_r=1.000000, sigma_H=0.000000) \nThalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nHeart_lumen  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine  (Thelonious_6y_V6): dielectric (eps_r=59.134765, sigma_E=0.989502, mu_r=1.000000, sigma_H=0.000000) \nKidney_cortex  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nStomach  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nFat  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nLung  (Thelonious_6y_V6): dielectric (eps_r=22.460437, sigma_E=0.423425, mu_r=1.000000, sigma_H=0.000000) \nConnective_tissue  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nPons  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nSpinal_cord  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nSAT  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nEar_cartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nTeeth  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nNerve  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nEar_skin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nMeniscus  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nSkull  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nProstate  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nDiaphragm  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nBone  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nMucosa  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine  (Thelonious_6y_V6): dielectric (eps_r=61.138364, sigma_E=2.062163, mu_r=1.000000, sigma_H=0.000000) \nLarynx  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nMandible  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nCartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nHippocampus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nCerebellum  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nPenis  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nUreter_Urethra  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nBronchi_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPancreas  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nEsophagus_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBronchi  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nCerebrospinal_fluid  (Thelonious_6y_V6): dielectric (eps_r=69.157589, sigma_E=2.338250, mu_r=1.000000, sigma_H=0.000000) \n\nLumped Elements: No active lumped elements in the simulation. \n\nHost OS: Microsoft Windows 10 Professional 64-bit (Build 9200) \nHost CPU: AMD EPYC 7542 32-Core Processor \nHost memory: 16379 MB \nThe following Accelerators have been detected: \nNVIDIA GeForce RTX 4090 (device ID = 0), compute capability 8.9, total memory 24563 MB \n\n\nSensors (3): \nInitializing field sensor Overall Field. \nInitializing point sensor Point Sensor Entity 1 (lower_left_bottom). \nAveraging setup for point sensor Point Sensor Entity 1 (lower_left_bottom): \nE-Field: \nX: 2 edges used for recording. \nY: 2 edges used for recording. \nZ: 2 edges used for recording. \nH-Field: \nX: 4 edges used for recording. \nY: 4 edges used for recording. \nZ: 4 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 1 (lower_left_bottom): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.86355e-11, convergence level = -15 dB. \nInitializing point sensor Point Sensor Entity 2 (top_right_up). \nAveraging setup for point sensor Point Sensor Entity 2 (top_right_up): \nE-Field: \nX: 2 edges used for recording. \nY: 2 edges used for recording. \nZ: 2 edges used for recording. \nH-Field: \nX: 4 edges used for recording. \nY: 4 edges used for recording. \nZ: 4 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 2 (top_right_up): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.86355e-11, convergence level = -15 dB. \nUsing DFT to convert to frequency domain. \n\nSources (1): \nInitializing plane wave source far_field_simulation_bbox. \nExcitation signal: Harmonic signal with frequency 700 MHz and ramp time 2.14286 ns \n\nUpdate coefficient calculation for 122086088 edges using 3 threads. \nCalculating update coefficients \n[PROGRESS]: 21% [ 25691000 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 43% [ 52638148 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 65% [ 79536244 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 84% [ 102793088 / 122086088 ] Calculating update coefficients \n\n\nEdge-Material Statistics (Electric/Magnetic): \n61165060 / 60921028      (100.00% / 100.00%) : Total \n61165060 / 60921028      (100.00% / 100.00%) : Dielectric \n\nEdge-Region Statistics (regions with more than 1% of all edges, max 20 items): \n58992181 / 58810012      ( 96.45% /  96.53%) : Background \n1084192 /  1496072   (  1.77% /   2.46%) : Other \n1088687 /   614944   (  1.78% /   1.01%) : Averaged \n\n\nUpdate coefficient database contains 2099 E-coefficient(s) and 1 H-coefficient(s). \nElapsed time for 'Calculating update coefficients' was 00:00:10 wall clock time. \nPreparing for time update \nUse hardware resource management option fastest simulation \nChecking out license feature 'AXWARE_TOKEN', version 8.2, (1). \n[PROGRESS]: 2% [ 2 / 100 ] Preparing for time update \n[PROGRESS]: 16% [ 16 / 100 ] Preparing for time update \n[PROGRESS]: 30% [ 30 / 100 ] Preparing for time update \n[PROGRESS]: 44% [ 44 / 100 ] Preparing for time update \n[PROGRESS]: 59% [ 59 / 100 ] Preparing for time update \nSimulation 1 is using device(s): [0] \nElapsed time for 'Preparing for time update' was 00:00:17 wall clock time. \nStarting solver aXware (hardware accelerated). \nTime Update \n[PROGRESS]: 0% [ 10 / 2853 ] Time Update, estimated remaining time 2 minutes 53 seconds  @ 401.19 MCells/s \n[PROGRESS]: 7% [ 207 / 2853 ] Time Update, estimated remaining time 30 seconds  @ 2140.68 MCells/s \n[PROGRESS]: 14% [ 404 / 2853 ] Time Update, estimated remaining time 27 seconds  @ 2172.46 MCells/s \n[PROGRESS]: 21% [ 601 / 2853 ] Time Update, estimated remaining time 26 seconds  @ 2148.25 MCells/s \n[PROGRESS]: 27% [ 798 / 2853 ] Time Update, estimated remaining time 23 seconds  @ 2198.39 MCells/s \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 2 to check conventional convergence. \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 4 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 2 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 4 to check conventional convergence. \n[PROGRESS]: 34% [ 995 / 2853 ] Time Update, estimated remaining time 21 seconds  @ 2188.85 MCells/s \n[PROGRESS]: 41% [ 1192 / 2853 ] Time Update, estimated remaining time 19 seconds  @ 2141.86 MCells/s \n[PROGRESS]: 48% [ 1389 / 2853 ] Time Update, estimated remaining time 16 seconds  @ 2178.71 MCells/s \n[PROGRESS]: 55% [ 1586 / 2853 ] Time Update, estimated remaining time 14 seconds  @ 2240.90 MCells/s \n[PROGRESS]: 62% [ 1783 / 2853 ] Time Update, estimated remaining time 12 seconds  @ 2221.29 MCells/s \nSensor Point Sensor Entity 1 (lower_left_bottom): conventional steady state check successful. \n[PROGRESS]: 69% [ 1980 / 2853 ] Time Update, estimated remaining time 10 seconds  @ 2175.17 MCells/s \nSensor Point Sensor Entity 2 (top_right_up): conventional steady state check successful. \nSteady state detected at iteration 2060, remaining time steps are 63. \n[PROGRESS]: 97% [ 2065 / 2123 ] Time Update, estimated remaining time 4 seconds  @ 382.27 MCells/s \nSimulation performed 2123 iterations. \nElapsed time for 'Time Update' was 00:00:35 wall clock time. \n\nPost-process Sensors \nPost-process sensor 'Overall Field' \nPost-process sensor 'Point Sensor Entity 1 (lower_left_bottom)' \n[PROGRESS]: 66% [ 2 / 3 ] Post-process Sensors \nPost-process sensor 'Point Sensor Entity 2 (top_right_up)' \nTrusted frequency is 700 MHz. Expect less accurate results outside. \nElapsed time for 'Post-process Sensors' was 00:00:06 wall clock time. \nFDTD simulation finished successfully. \n\nSimulation 'EM_FDTD_thelonious_700MHz_x_pos_theta' has ended successfully and took 00:01:19 wall clock time \nNo compression of solver files requested \nReleased license feature 'AXWARE_TOKEN'. \nReleased license feature 'FDTD_SOLVER'. \nPeak CPU memory usage:   3.6 GB (3913101312 Bytes) \niSolve ended successfully. \n      - Subtask 'run_isolve_execution' done in 79.95s [SimulationRunner._run_isolve_manual]\n      - Done in 79.95s [SimulationRunner._run_isolve_manual]\n    - Wait for results... [SimulationRunner._run_isolve_manual]\n      - Subtask 'run_wait_for_results' done in 5.00s [SimulationRunner._run_isolve_manual]\n      - Done in 5.00s [SimulationRunner._run_isolve_manual]\n    - Reload project... [SimulationRunner._run_isolve_manual]\nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash \n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\n      - Subtask 'run_reload_project' done in 11.12s [SimulationRunner._run_isolve_manual]\n      - Done in 11.12s [SimulationRunner._run_isolve_manual]\nProject reloaded and results are available. [SimulationRunner._run_isolve_manual]\n    - Subtask 'run_simulation_total' done in 100.59s [FarFieldStudy.subtask]\n    - Done in 100.59s [FarFieldStudy.subtask]\nRun deliverables verified. Updating metadata. [FarFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\n--- Finished: run (took 100.66s) --- [profile]\n--- Starting: extract --- [profile]\nRun deliverables verified. Proceeding with extraction. [FarFieldStudy._verify_run_deliverables_before_extraction]\nValidating project file: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash [ProjectManager.open]\nOpening project with Sim4Life: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash [ProjectManager.open]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash \nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nProject reloaded. [ProjectManager.reload_project]\n  - Extract results total... [FarFieldStudy.subtask]\n    - Extract input power... [PowerExtractor.extract_input_power]\n  - Far-field study: using theoretical model for input power. [PowerExtractor._extract_far_field_power]\n  - Calculated theoretical input power: 5.3099e-04 W [PowerExtractor._extract_far_field_power]\n      - Subtask 'extract_input_power' done in 0.02s [PowerExtractor.extract_input_power]\n      - Done in 0.02s [PowerExtractor.extract_input_power]\n    - Extract SAR statistics... [SarExtractor.extract_sar_statistics]\n  - Loading tissue groups for 'thelonious' from material_name_mapping.json [SarExtractor._define_tissue_groups]\n  - Extracting peak SAR details... [SarExtractor.extract_peak_sar_details]\n      - Subtask 'extract_sar_statistics' done in 28.25s [SarExtractor.extract_sar_statistics]\n      - Done in 28.25s [SarExtractor.extract_sar_statistics]\n    - Extract power balance... [PowerExtractor.extract_power_balance]\nAnalysis : [Warn]  Unable to balance the following EM sources: far_field_simulation_bbox,  are still not supported.\nAnalysis : [Warn]  Unable to balance the following EM sources: far_field_simulation_bbox,  are still not supported.\n    - Overwriting Pin with theoretical value: 5.3099e-04 W [PowerExtractor.extract_power_balance]\n    - Final Balance: 117.61% [PowerExtractor.extract_power_balance]\n      - Subtask 'extract_power_balance' done in 8.36s [PowerExtractor.extract_power_balance]\n      - Done in 8.36s [PowerExtractor.extract_power_balance]\n    - Extract point sensors... [SensorExtractor.extract_point_sensor_data]\n  - Point sensor plot saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_x_pos\\point_sensor_data.png [SensorExtractor._save_plot]\n      - Subtask 'extract_point_sensor_data' done in 0.64s [SensorExtractor.extract_point_sensor_data]\n      - Done in 0.64s [SensorExtractor.extract_point_sensor_data]\n  - Pickle report saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_x_pos\\sar_stats_all_tissues.pkl [Reporter._save_pickle_report]\n  - HTML report saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_x_pos\\sar_stats_all_tissues.html [Reporter._save_html_report]\n  - SAR results saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_x_pos\\sar_results.json [ResultsExtractor._save_json_results]\n    - Subtask 'extract_results_total' done in 37.52s [FarFieldStudy.subtask]\n    - Done in 37.52s [FarFieldStudy.subtask]\nExtract deliverables verified. Updating metadata. [FarFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n--- Finished: extract (took 57.84s) --- [profile]\n\n--- Processing Simulation 2/4: thelonious, 700MHz, x_pos, phi --- [FarFieldStudy._run_study]\n--- Starting: setup --- [profile]\nProject path set to: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash [ProjectManager.create_or_open_project]\nNo metadata file found at config.json. [ProjectManager.verify_simulation_metadata]\nExisting project is invalid or out of date. A new setup is required. [ProjectManager.create_or_open_project]\n--- Simulation-specific progress logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos\\progress.log --- \n--- Simulation-specific verbose logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos\\verbose.log --- \nCreating a new empty project in memory. [ProjectManager.create_new]\nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\nInitializing model by creating and deleting a dummy block... [ProjectManager.create_new]\nModel initialized, ready for population. [ProjectManager.create_new]\n  - Setup simulation... [FarFieldStudy.subtask]\n--- Setting up single Far-Field sim --- [FarFieldSetup.run_full_setup]\n    - Load phantom... [FarFieldSetup.run_full_setup]\n--- Running Phantom Check --- [PhantomSetup._log]\nFound 2 total entities in the project. [PhantomSetup._log]\n--- Phantom Check Result: Phantom not found in project. --- [PhantomSetup._log]\nPhantom not found in document. Importing from 'C:\\Users\\user\\repo-clean\\data\\phantoms\\thelonious.sab'... [PhantomSetup._log]\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nPhantom imported successfully. [PhantomSetup._log]\n      - Subtask 'setup_load_phantom' done in 8.83s [FarFieldSetup.run_full_setup]\n      - Done in 8.83s [FarFieldSetup.run_full_setup]\n    - Configure scene (bbox, plane wave)... [FarFieldSetup.run_full_setup]\nCreating simulation bounding box for far-field... [FarFieldSetup._create_or_get_simulation_bbox]\n  - Created far-field simulation BBox with 50mm padding. [FarFieldSetup._create_or_get_simulation_bbox]\n  - Creating simulation: EM_FDTD_thelonious_700MHz_x_pos_phi [FarFieldSetup._create_simulation_entity]\n  - Using simulation time multiplier: 3.5 [FarFieldSetup._apply_simulation_time_and_termination]\n  - Simulation time set to 11.44 periods. [FarFieldSetup._apply_simulation_time_and_termination]\n  - Setting termination criteria to: GlobalAutoTerminationUserDefined [FarFieldSetup._apply_simulation_time_and_termination]\n    - Convergence level set to: -15 dB [FarFieldSetup._apply_simulation_time_and_termination]\n      - Subtask 'setup_configure_scene' done in 0.06s [FarFieldSetup.run_full_setup]\n      - Done in 0.06s [FarFieldSetup.run_full_setup]\n    - Assign materials... [FarFieldSetup.run_full_setup]\nAssigning materials... [MaterialSetup.assign_materials]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\n[Info]  \nMass Density has changed from 1000 to 1.2050000000000001\nRelative Permittivity has changed from 1 to 0\nMass Density has changed from 1.2050000000000001 to 1.2\nSimulation : [Warn]  Unable to find any match for following settings properties: Magnetic Conductivity\nSimulation : [Warn]  Unable to find any match for following settings properties: Relative Permeability\n      - Subtask 'setup_materials' done in 6.73s [FarFieldSetup.run_full_setup]\n      - Done in 6.73s [FarFieldSetup.run_full_setup]\n    - Configure solver (gridding, boundaries, sensors)... [FarFieldSetup.run_full_setup]\nSetting up gridding... [GriddingSetup.setup_gridding]\n  - Looking for global grid bounding box: 'far_field_simulation_bbox' [GriddingSetup._setup_main_grid]\n  - Using manual gridding. [GriddingSetup._setup_main_grid]\n  - Global and added manual grid set with global resolution: 3.0 mm. [GriddingSetup._setup_main_grid]\n  - Using automatic padding. [GriddingSetup._setup_main_grid]\n  - No antenna components provided, skipping subgridding. [GriddingSetup.setup_gridding]\nSetting up boundary conditions... [BoundarySetup.setup_boundary_conditions]\n  - Setting global boundary conditions to: UpmlCpml [BoundarySetup.setup_boundary_conditions]\n    - Successfully set GlobalBoundaryType to UpmlCpml [BoundarySetup.setup_boundary_conditions]\n  - Setting PML strength to: Low [BoundarySetup.setup_boundary_conditions]\n    - Successfully set PmlStrength to Low [BoundarySetup.setup_boundary_conditions]\n  - Added point sensor at (Vec3(-231.59, -107.681, -1019.42), Vec3(-231.59, -107.681, -1019.42), Vec3(-231.59, -107.681, -1019.42)) (lower_left_bottom) [FarFieldSetup._add_point_sensors]\n  - Added point sensor at (Vec3(239.048, 205.076, 260.697), Vec3(239.048, 205.076, 260.697), Vec3(239.048, 205.076, 260.697)) (top_right_up) [FarFieldSetup._add_point_sensors]\n  - Configuring solver settings... [FarFieldSetup._setup_solver_settings]\n    - Solver kernel set to: Acceleware (AXware) [FarFieldSetup._setup_solver_settings]\n      - Subtask 'setup_solver' done in 0.27s [FarFieldSetup.run_full_setup]\n      - Done in 0.27s [FarFieldSetup.run_full_setup]\n    - Voxelize simulation... [FarFieldSetup.run_full_setup]\n    - Finalizing setup... [FarFieldSetup._finalize_setup]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tongue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Adrenal Gland\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Anterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Vitreous Humor)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Midbrain\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Testis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Air 1\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood Vessel Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Epididymis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pineal Body\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Urinary Bladder Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone Marrow (Red)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Gallbladder\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypophysis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (White Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spleen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thymus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypothalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skin\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (Grey Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone (Cortical)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Sclera)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tendon\\Ligament\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Medulla)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Medulla Oblongata\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Intervertebral Disc\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Vertebrae\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Lens)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Posterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Cornea)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pharynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Liver\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Cortex)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Fat\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Lung\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Connective Tissue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pons\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spinal Cord\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"SAT (Subcutaneous Fat)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cartilage\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tooth\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Nerve\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Meniscus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skull\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Prostate\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Diaphragm\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mucous Membrane\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Larynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mandible\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hippocampus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebellum\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Penis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Ureter\\Urethra\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pancreas\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebrospinal Fluid\" have been set to their value according to the selected database\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n[Info]  Start voxeling\n[Info]  Topological Voxeler Report: Complete Voxel Scene\n    Voxel Scene Memory Consumption: 0.002876 GB\n    Wall Clock Time: 8.55259 s\n\n[Info]  Voxeling succeeded.\n    - Finalizing setup complete. [FarFieldSetup._finalize_setup]\n      - Subtask 'setup_voxelize' done in 21.23s [FarFieldSetup.run_full_setup]\n      - Done in 21.23s [FarFieldSetup.run_full_setup]\n    - Save project... [FarFieldSetup.run_full_setup]\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\nProject saved. [ProjectManager.save]\n      - Subtask 'setup_save_project' done in 3.49s [FarFieldSetup.run_full_setup]\n      - Done in 3.49s [FarFieldSetup.run_full_setup]\nCommon settings applied. [FarFieldSetup.run_full_setup]\n    - Subtask 'setup_simulation' done in 40.89s [FarFieldStudy.subtask]\n    - Done in 40.89s [FarFieldStudy.subtask]\n  - Saved configuration metadata to config.json [ProjectManager.write_simulation_metadata]\n--- Finished: setup (took 41.41s) --- [profile]\n--- Starting: run --- [profile]\n  - Run simulation total... [FarFieldStudy.subtask]\nRunning simulation: EM_FDTD_thelonious_700MHz_x_pos_phi [SimulationRunner.run]\n    - Write input file... [SimulationRunner.run]\n[Info]  Writing solver input file(s) for EM_FDTD_thelonious_700MHz_x_pos_phi\n[Info]  Writing Rectilinear Discretization to Input File. Elapse Time: 0.485597 s\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n      - Subtask 'run_write_input_file' done in 4.83s [SimulationRunner.run]\n      - Done in 4.83s [SimulationRunner.run]\nRunning iSolve with acceleware on 04895e5e-6bf5-4bd1-8807-2fa8361581a6_Input.h5 [SimulationRunner._run_isolve_manual]\n    - Execute iSolve... [SimulationRunner._run_isolve_manual]\n\nReading command line \niSolve X, Version 8.2.0 (16876), 64Bit Windows \n\nRunning MPI version 2.0 on 1 process. \n\n\nSimulation 'EM_FDTD_thelonious_700MHz_x_pos_phi'  \n\nInstalled system RAM visible to this process:  16.0 GB \n\nSolver type: EmFdtd, SinglePrecision, Acceleware \nInput file name: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash_Results\\04895e5e-6bf5-4bd1-8807-2fa8361581a6_Input.h5 \nInput file generated by: Sim4Life, Version 8.2.0.16876 \nOutput file name: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash_Results\\04895e5e-6bf5-4bd1-8807-2fa8361581a6_Output.h5 \n\nUsing commercial license features. \nChecking out license feature 'FDTD_SOLVER', version 8.2, (1). \n\nRunning the EM-FDTD solver with the following settings: \nFloating Point Arithmetic: single (4 Bytes) \nHPC: Acceleware \nUsed Acceleware library is '11.4.1.13550 (x64, 64-bit)'. \nYour NVIDIA display driver is newer than the expected version. \nInstalled version: 15.7680 Expected: 15.3667 (see also http://www.acceleware.com/fdtd-11-4-1) \nReduced performance could be encountered. \n\nSimulation Time Step:   5.72711e-12 sec \nSimulation Iterations:  2853 \nMax Simulated Time: 1.63394e-08 sec \n\nGrid: \nNumber of cells: 229x177x499 = 20225967 cells = 20.2260 MCells \nNumber of cells including PML: 245x193x515 = 24351775 cells = 24.3518 MCells \nX: Range [-0.338659 ... 0.346117] with minimal 0.00297412 and maximal step 0.0029977 [m] \nY: Range [-0.21475 ... 0.312145] with minimal 0.00297412 and maximal step 0.00297865 [m] \nZ: Range [-1.12649 ... 0.367766] with minimal 0.00297403 and maximal step 0.00299799 [m] \n\nBoundaries: \nSide X-: ABC (UPML, 8 layers) \nSide X+: ABC (UPML, 8 layers) \nSide Y-: ABC (UPML, 8 layers) \nSide Y+: ABC (UPML, 8 layers) \nSide Z-: ABC (UPML, 8 layers) \nSide Z+: ABC (UPML, 8 layers) \n\nCreated unified material architecture (UMA) model \n\nMaterials (77): \nBackground: dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nTongue  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=0.865626, mu_r=1.000000, sigma_H=0.000000) \nAdrenal_gland  (Thelonious_6y_V6): dielectric (eps_r=50.989008, sigma_E=0.954350, mu_r=1.000000, sigma_H=0.000000) \nStomach_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \ncommissura_anterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nEye_vitreous_humor  (Thelonious_6y_V6): dielectric (eps_r=68.947390, sigma_E=1.583627, mu_r=1.000000, sigma_H=0.000000) \nVein  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nMidbrain  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nTestis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nAir_internal  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBlood_vessel  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nEpididymis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nPinealbody  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBladder  (Thelonious_6y_V6): dielectric (eps_r=19.149003, sigma_E=0.358399, mu_r=1.000000, sigma_H=0.000000) \nMarrow_red  (Thelonious_6y_V6): dielectric (eps_r=11.451933, sigma_E=0.207759, mu_r=1.000000, sigma_H=0.000000) \nGallbladder  (Thelonious_6y_V6): dielectric (eps_r=59.551663, sigma_E=1.202528, mu_r=1.000000, sigma_H=0.000000) \nHypophysis  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBrain_white_matter  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nSpleen  (Thelonious_6y_V6): dielectric (eps_r=58.688546, sigma_E=1.175182, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nThymus  (Thelonious_6y_V6): dielectric (eps_r=55.600852, sigma_E=1.115237, mu_r=1.000000, sigma_H=0.000000) \nTrachea  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nHeart_muscle  (Thelonious_6y_V6): dielectric (eps_r=61.478559, sigma_E=1.125021, mu_r=1.000000, sigma_H=0.000000) \nMuscle  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nHypothalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nArtery  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nSkin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nBrain_grey_matter  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nPatella  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_Sclera  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=1.096154, mu_r=1.000000, sigma_H=0.000000) \nTendon_Ligament  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nKidney_medulla  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nMedulla_oblongata  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nEsophagus  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nIntervertebral_disc  (Thelonious_6y_V6): dielectric (eps_r=44.418065, sigma_E=1.041108, mu_r=1.000000, sigma_H=0.000000) \nVertebrae  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_lens  (Thelonious_6y_V6): dielectric (eps_r=36.279018, sigma_E=0.435952, mu_r=1.000000, sigma_H=0.000000) \ncommissura_posterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nCornea  (Thelonious_6y_V6): dielectric (eps_r=56.275669, sigma_E=1.311407, mu_r=1.000000, sigma_H=0.000000) \nTrachea_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPharynx  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nLiver  (Thelonious_6y_V6): dielectric (eps_r=47.963211, sigma_E=0.773986, mu_r=1.000000, sigma_H=0.000000) \nThalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nHeart_lumen  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine  (Thelonious_6y_V6): dielectric (eps_r=59.134765, sigma_E=0.989502, mu_r=1.000000, sigma_H=0.000000) \nKidney_cortex  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nStomach  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nFat  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nLung  (Thelonious_6y_V6): dielectric (eps_r=22.460437, sigma_E=0.423425, mu_r=1.000000, sigma_H=0.000000) \nConnective_tissue  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nPons  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nSpinal_cord  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nSAT  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nEar_cartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nTeeth  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nNerve  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nEar_skin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nMeniscus  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nSkull  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nProstate  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nDiaphragm  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nBone  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nMucosa  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine  (Thelonious_6y_V6): dielectric (eps_r=61.138364, sigma_E=2.062163, mu_r=1.000000, sigma_H=0.000000) \nLarynx  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nMandible  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nCartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nHippocampus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nCerebellum  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nPenis  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nUreter_Urethra  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nBronchi_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPancreas  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nEsophagus_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBronchi  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nCerebrospinal_fluid  (Thelonious_6y_V6): dielectric (eps_r=69.157589, sigma_E=2.338250, mu_r=1.000000, sigma_H=0.000000) \n\nLumped Elements: No active lumped elements in the simulation. \n\nHost OS: Microsoft Windows 10 Professional 64-bit (Build 9200) \nHost CPU: AMD EPYC 7542 32-Core Processor \nHost memory: 16379 MB \nThe following Accelerators have been detected: \nNVIDIA GeForce RTX 4090 (device ID = 0), compute capability 8.9, total memory 24563 MB \n\n\nSensors (3): \nInitializing field sensor Overall Field. \nInitializing point sensor Point Sensor Entity 1 (lower_left_bottom). \nAveraging setup for point sensor Point Sensor Entity 1 (lower_left_bottom): \nE-Field: \nX: 2 edges used for recording. \nY: 2 edges used for recording. \nZ: 2 edges used for recording. \nH-Field: \nX: 4 edges used for recording. \nY: 4 edges used for recording. \nZ: 4 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 1 (lower_left_bottom): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.86355e-11, convergence level = -15 dB. \nInitializing point sensor Point Sensor Entity 2 (top_right_up). \nAveraging setup for point sensor Point Sensor Entity 2 (top_right_up): \nE-Field: \nX: 2 edges used for recording. \nY: 2 edges used for recording. \nZ: 2 edges used for recording. \nH-Field: \nX: 4 edges used for recording. \nY: 4 edges used for recording. \nZ: 4 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 2 (top_right_up): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.86355e-11, convergence level = -15 dB. \nUsing DFT to convert to frequency domain. \n\nSources (1): \nInitializing plane wave source far_field_simulation_bbox. \nExcitation signal: Harmonic signal with frequency 700 MHz and ramp time 2.14286 ns \n\nUpdate coefficient calculation for 122086088 edges using 3 threads. \nCalculating update coefficients \n[PROGRESS]: 21% [ 25691000 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 39% [ 47752938 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 61% [ 74678479 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 77% [ 94269718 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 97% [ 118723088 / 122086088 ] Calculating update coefficients \n\n\nEdge-Material Statistics (Electric/Magnetic): \n61165060 / 60921028      (100.00% / 100.00%) : Total \n61165060 / 60921028      (100.00% / 100.00%) : Dielectric \n\nEdge-Region Statistics (regions with more than 1% of all edges, max 20 items): \n58992181 / 58810012      ( 96.45% /  96.53%) : Background \n1084192 /  1496072   (  1.77% /   2.46%) : Other \n1088687 /   614944   (  1.78% /   1.01%) : Averaged \n\n\nUpdate coefficient database contains 2099 E-coefficient(s) and 1 H-coefficient(s). \nElapsed time for 'Calculating update coefficients' was 00:00:11 wall clock time. \nPreparing for time update \nUse hardware resource management option fastest simulation \nChecking out license feature 'AXWARE_TOKEN', version 8.2, (1). \n[PROGRESS]: 2% [ 2 / 100 ] Preparing for time update \n[PROGRESS]: 15% [ 15 / 100 ] Preparing for time update \n[PROGRESS]: 28% [ 28 / 100 ] Preparing for time update \n[PROGRESS]: 41% [ 41 / 100 ] Preparing for time update \n[PROGRESS]: 54% [ 54 / 100 ] Preparing for time update \n[PROGRESS]: 71% [ 71 / 100 ] Preparing for time update \nSimulation 1 is using device(s): [0] \nElapsed time for 'Preparing for time update' was 00:00:19 wall clock time. \nStarting solver aXware (hardware accelerated). \nTime Update \n[PROGRESS]: 0% [ 10 / 2853 ] Time Update, estimated remaining time 1 minutes 45 seconds  @ 659.61 MCells/s \n[PROGRESS]: 7% [ 207 / 2853 ] Time Update, estimated remaining time 30 seconds  @ 2156.30 MCells/s \n[PROGRESS]: 13% [ 376 / 2853 ] Time Update, estimated remaining time 31 seconds  @ 1945.88 MCells/s \n[PROGRESS]: 19% [ 545 / 2853 ] Time Update, estimated remaining time 27 seconds  @ 2052.72 MCells/s \n[PROGRESS]: 25% [ 714 / 2853 ] Time Update, estimated remaining time 26 seconds  @ 2039.80 MCells/s \n[PROGRESS]: 30% [ 883 / 2853 ] Time Update, estimated remaining time 24 seconds  @ 2013.39 MCells/s \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 1 to check conventional convergence. \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 5 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 1 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 5 to check conventional convergence. \n[PROGRESS]: 36% [ 1052 / 2853 ] Time Update, estimated remaining time 22 seconds  @ 1964.48 MCells/s \n[PROGRESS]: 43% [ 1249 / 2853 ] Time Update, estimated remaining time 19 seconds  @ 2088.56 MCells/s \n[PROGRESS]: 49% [ 1418 / 2853 ] Time Update, estimated remaining time 18 seconds  @ 1947.75 MCells/s \n[PROGRESS]: 53% [ 1531 / 2853 ] Time Update, estimated remaining time 23 seconds  @ 1374.60 MCells/s \n[PROGRESS]: 57% [ 1644 / 2853 ] Time Update, estimated remaining time 24 seconds  @ 1233.78 MCells/s \n[PROGRESS]: 62% [ 1785 / 2853 ] Time Update, estimated remaining time 18 seconds  @ 1479.86 MCells/s \nSensor Point Sensor Entity 2 (top_right_up): conventional steady state check successful. \n[PROGRESS]: 69% [ 1982 / 2853 ] Time Update, estimated remaining time 10 seconds  @ 2099.29 MCells/s \nSensor Point Sensor Entity 1 (lower_left_bottom): conventional steady state check successful. \nSteady state detected at iteration 2060, remaining time steps are 63. \n[PROGRESS]: 97% [ 2067 / 2123 ] Time Update, estimated remaining time 4 seconds  @ 355.92 MCells/s \nSimulation performed 2123 iterations. \nElapsed time for 'Time Update' was 00:00:41 wall clock time. \n\nPost-process Sensors \nPost-process sensor 'Overall Field' \nPost-process sensor 'Point Sensor Entity 1 (lower_left_bottom)' \n[PROGRESS]: 66% [ 2 / 3 ] Post-process Sensors \nPost-process sensor 'Point Sensor Entity 2 (top_right_up)' \nTrusted frequency is 700 MHz. Expect less accurate results outside. \nElapsed time for 'Post-process Sensors' was 00:00:08 wall clock time. \nFDTD simulation finished successfully. \n\nSimulation 'EM_FDTD_thelonious_700MHz_x_pos_phi' has ended successfully and took 00:01:31 wall clock time \nNo compression of solver files requested \nReleased license feature 'AXWARE_TOKEN'. \nReleased license feature 'FDTD_SOLVER'. \nPeak CPU memory usage:   3.6 GB (3912392704 Bytes) \niSolve ended successfully. \n      - Subtask 'run_isolve_execution' done in 92.53s [SimulationRunner._run_isolve_manual]\n      - Done in 92.53s [SimulationRunner._run_isolve_manual]\n    - Wait for results... [SimulationRunner._run_isolve_manual]\n      - Subtask 'run_wait_for_results' done in 5.03s [SimulationRunner._run_isolve_manual]\n      - Done in 5.03s [SimulationRunner._run_isolve_manual]\n    - Reload project... [SimulationRunner._run_isolve_manual]\nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash \n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\n      - Subtask 'run_reload_project' done in 12.19s [SimulationRunner._run_isolve_manual]\n      - Done in 12.19s [SimulationRunner._run_isolve_manual]\nProject reloaded and results are available. [SimulationRunner._run_isolve_manual]\n    - Subtask 'run_simulation_total' done in 114.72s [FarFieldStudy.subtask]\n    - Done in 114.72s [FarFieldStudy.subtask]\nRun deliverables verified. Updating metadata. [FarFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\n--- Finished: run (took 114.88s) --- [profile]\n--- Starting: extract --- [profile]\nRun deliverables verified. Proceeding with extraction. [FarFieldStudy._verify_run_deliverables_before_extraction]\nValidating project file: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash [ProjectManager.open]\nOpening project with Sim4Life: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash [ProjectManager.open]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash \nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nProject reloaded. [ProjectManager.reload_project]\n  - Extract results total... [FarFieldStudy.subtask]\n    - Extract input power... [PowerExtractor.extract_input_power]\n  - Far-field study: using theoretical model for input power. [PowerExtractor._extract_far_field_power]\n  - Calculated theoretical input power: 5.3099e-04 W [PowerExtractor._extract_far_field_power]\n      - Subtask 'extract_input_power' done in 0.00s [PowerExtractor.extract_input_power]\n      - Done in 0.00s [PowerExtractor.extract_input_power]\n    - Extract SAR statistics... [SarExtractor.extract_sar_statistics]\n  - Loading tissue groups for 'thelonious' from material_name_mapping.json [SarExtractor._define_tissue_groups]\n  - Extracting peak SAR details... [SarExtractor.extract_peak_sar_details]\n      - Subtask 'extract_sar_statistics' done in 29.34s [SarExtractor.extract_sar_statistics]\n      - Done in 29.34s [SarExtractor.extract_sar_statistics]\n    - Extract power balance... [PowerExtractor.extract_power_balance]\nAnalysis : [Warn]  Unable to balance the following EM sources: far_field_simulation_bbox,  are still not supported.\nAnalysis : [Warn]  Unable to balance the following EM sources: far_field_simulation_bbox,  are still not supported.\n    - Overwriting Pin with theoretical value: 5.3099e-04 W [PowerExtractor.extract_power_balance]\n    - Final Balance: 91.85% [PowerExtractor.extract_power_balance]\n      - Subtask 'extract_power_balance' done in 10.55s [PowerExtractor.extract_power_balance]\n      - Done in 10.55s [PowerExtractor.extract_power_balance]\n    - Extract point sensors... [SensorExtractor.extract_point_sensor_data]\n  - Point sensor plot saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_phi_x_pos\\point_sensor_data.png [SensorExtractor._save_plot]\n      - Subtask 'extract_point_sensor_data' done in 0.48s [SensorExtractor.extract_point_sensor_data]\n      - Done in 0.48s [SensorExtractor.extract_point_sensor_data]\n  - Pickle report saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_phi_x_pos\\sar_stats_all_tissues.pkl [Reporter._save_pickle_report]\n  - HTML report saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_phi_x_pos\\sar_stats_all_tissues.html [Reporter._save_html_report]\n  - SAR results saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_phi_x_pos\\sar_results.json [ResultsExtractor._save_json_results]\n    - Subtask 'extract_results_total' done in 41.25s [FarFieldStudy.subtask]\n    - Done in 41.25s [FarFieldStudy.subtask]\nExtract deliverables verified. Updating metadata. [FarFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\nProject saved. [ProjectManager.save]\n--- Finished: extract (took 57.66s) --- [profile]\n\n--- Processing Simulation 3/4: thelonious, 700MHz, z_neg, theta --- [FarFieldStudy._run_study]\n--- Starting: setup --- [profile]\nProject path set to: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash [ProjectManager.create_or_open_project]\nNo metadata file found at config.json. [ProjectManager.verify_simulation_metadata]\nExisting project is invalid or out of date. A new setup is required. [ProjectManager.create_or_open_project]\n--- Simulation-specific progress logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg\\progress.log --- \n--- Simulation-specific verbose logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg\\verbose.log --- \nCreating a new empty project in memory. [ProjectManager.create_new]\nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\nInitializing model by creating and deleting a dummy block... [ProjectManager.create_new]\nModel initialized, ready for population. [ProjectManager.create_new]\n  - Setup simulation... [FarFieldStudy.subtask]\n--- Setting up single Far-Field sim --- [FarFieldSetup.run_full_setup]\n    - Load phantom... [FarFieldSetup.run_full_setup]\n--- Running Phantom Check --- [PhantomSetup._log]\nFound 2 total entities in the project. [PhantomSetup._log]\n--- Phantom Check Result: Phantom not found in project. --- [PhantomSetup._log]\nPhantom not found in document. Importing from 'C:\\Users\\user\\repo-clean\\data\\phantoms\\thelonious.sab'... [PhantomSetup._log]\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nPhantom imported successfully. [PhantomSetup._log]\n      - Subtask 'setup_load_phantom' done in 8.47s [FarFieldSetup.run_full_setup]\n      - Done in 8.47s [FarFieldSetup.run_full_setup]\n    - Configure scene (bbox, plane wave)... [FarFieldSetup.run_full_setup]\nCreating simulation bounding box for far-field... [FarFieldSetup._create_or_get_simulation_bbox]\n  - Created far-field simulation BBox with 50mm padding. [FarFieldSetup._create_or_get_simulation_bbox]\n  - Creating simulation: EM_FDTD_thelonious_700MHz_z_neg_theta [FarFieldSetup._create_simulation_entity]\n  - Using simulation time multiplier: 3.5 [FarFieldSetup._apply_simulation_time_and_termination]\n  - Simulation time set to 11.44 periods. [FarFieldSetup._apply_simulation_time_and_termination]\n  - Setting termination criteria to: GlobalAutoTerminationUserDefined [FarFieldSetup._apply_simulation_time_and_termination]\n    - Convergence level set to: -15 dB [FarFieldSetup._apply_simulation_time_and_termination]\n      - Subtask 'setup_configure_scene' done in 1.84s [FarFieldSetup.run_full_setup]\n      - Done in 1.84s [FarFieldSetup.run_full_setup]\n    - Assign materials... [FarFieldSetup.run_full_setup]\nAssigning materials... [MaterialSetup.assign_materials]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\n[Info]  \nMass Density has changed from 1000 to 1.2050000000000001\nMass Density has changed from 1.2050000000000001 to 1.2\nRelative Permittivity has changed from 1 to 0\nSimulation : [Warn]  Unable to find any match for following settings properties: Magnetic Conductivity\nSimulation : [Warn]  Unable to find any match for following settings properties: Relative Permeability\n      - Subtask 'setup_materials' done in 5.33s [FarFieldSetup.run_full_setup]\n      - Done in 5.33s [FarFieldSetup.run_full_setup]\n    - Configure solver (gridding, boundaries, sensors)... [FarFieldSetup.run_full_setup]\nSetting up gridding... [GriddingSetup.setup_gridding]\n  - Looking for global grid bounding box: 'far_field_simulation_bbox' [GriddingSetup._setup_main_grid]\n  - Using manual gridding. [GriddingSetup._setup_main_grid]\n  - Global and added manual grid set with global resolution: 3.0 mm. [GriddingSetup._setup_main_grid]\n  - Using automatic padding. [GriddingSetup._setup_main_grid]\n  - No antenna components provided, skipping subgridding. [GriddingSetup.setup_gridding]\nSetting up boundary conditions... [BoundarySetup.setup_boundary_conditions]\n  - Setting global boundary conditions to: UpmlCpml [BoundarySetup.setup_boundary_conditions]\n    - Successfully set GlobalBoundaryType to UpmlCpml [BoundarySetup.setup_boundary_conditions]\n  - Setting PML strength to: Low [BoundarySetup.setup_boundary_conditions]\n    - Successfully set PmlStrength to Low [BoundarySetup.setup_boundary_conditions]\n  - Added point sensor at (Vec3(-231.59, -107.681, -1019.42), Vec3(-231.59, -107.681, -1019.42), Vec3(-231.59, -107.681, -1019.42)) (lower_left_bottom) [FarFieldSetup._add_point_sensors]\n  - Added point sensor at (Vec3(239.048, 205.076, 260.697), Vec3(239.048, 205.076, 260.697), Vec3(239.048, 205.076, 260.697)) (top_right_up) [FarFieldSetup._add_point_sensors]\n  - Configuring solver settings... [FarFieldSetup._setup_solver_settings]\n    - Solver kernel set to: Acceleware (AXware) [FarFieldSetup._setup_solver_settings]\n      - Subtask 'setup_solver' done in 0.23s [FarFieldSetup.run_full_setup]\n      - Done in 0.23s [FarFieldSetup.run_full_setup]\n    - Voxelize simulation... [FarFieldSetup.run_full_setup]\n    - Finalizing setup... [FarFieldSetup._finalize_setup]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tongue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Adrenal Gland\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Anterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Vitreous Humor)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Midbrain\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Testis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Air 1\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood Vessel Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Epididymis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pineal Body\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Urinary Bladder Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone Marrow (Red)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Gallbladder\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypophysis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (White Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spleen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thymus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypothalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skin\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (Grey Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone (Cortical)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Sclera)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tendon\\Ligament\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Medulla)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Medulla Oblongata\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Intervertebral Disc\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Vertebrae\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Lens)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Posterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Cornea)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pharynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Liver\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Cortex)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Fat\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Lung\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Connective Tissue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pons\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spinal Cord\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"SAT (Subcutaneous Fat)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cartilage\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tooth\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Nerve\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Meniscus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skull\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Prostate\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Diaphragm\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mucous Membrane\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Larynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mandible\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hippocampus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebellum\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Penis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Ureter\\Urethra\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pancreas\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebrospinal Fluid\" have been set to their value according to the selected database\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n[Info]  Start voxeling\n[Info]  Topological Voxeler Report: Complete Voxel Scene\n    Voxel Scene Memory Consumption: 0.002876 GB\n    Wall Clock Time: 7.68067 s\n\n[Info]  Voxeling succeeded.\n    - Finalizing setup complete. [FarFieldSetup._finalize_setup]\n      - Subtask 'setup_voxelize' done in 19.81s [FarFieldSetup.run_full_setup]\n      - Done in 19.81s [FarFieldSetup.run_full_setup]\n    - Save project... [FarFieldSetup.run_full_setup]\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\nProject saved. [ProjectManager.save]\n      - Subtask 'setup_save_project' done in 3.83s [FarFieldSetup.run_full_setup]\n      - Done in 3.83s [FarFieldSetup.run_full_setup]\nCommon settings applied. [FarFieldSetup.run_full_setup]\n    - Subtask 'setup_simulation' done in 39.77s [FarFieldStudy.subtask]\n    - Done in 39.77s [FarFieldStudy.subtask]\n  - Saved configuration metadata to config.json [ProjectManager.write_simulation_metadata]\n--- Finished: setup (took 40.39s) --- [profile]\n--- Starting: run --- [profile]\n  - Run simulation total... [FarFieldStudy.subtask]\nRunning simulation: EM_FDTD_thelonious_700MHz_z_neg_theta [SimulationRunner.run]\n    - Write input file... [SimulationRunner.run]\n[Info]  Writing solver input file(s) for EM_FDTD_thelonious_700MHz_z_neg_theta\n[Info]  Writing Rectilinear Discretization to Input File. Elapse Time: 0.488646 s\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n      - Subtask 'run_write_input_file' done in 4.89s [SimulationRunner.run]\n      - Done in 4.89s [SimulationRunner.run]\nRunning iSolve with acceleware on 820cac89-ce7c-4720-91b0-34eaecb818bd_Input.h5 [SimulationRunner._run_isolve_manual]\n    - Execute iSolve... [SimulationRunner._run_isolve_manual]\n\nReading command line \niSolve X, Version 8.2.0 (16876), 64Bit Windows \n\nRunning MPI version 2.0 on 1 process. \n\n\nSimulation 'EM_FDTD_thelonious_700MHz_z_neg_theta'  \n\nInstalled system RAM visible to this process:  16.0 GB \n\nSolver type: EmFdtd, SinglePrecision, Acceleware \nInput file name: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash_Results\\820cac89-ce7c-4720-91b0-34eaecb818bd_Input.h5 \nInput file generated by: Sim4Life, Version 8.2.0.16876 \nOutput file name: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash_Results\\820cac89-ce7c-4720-91b0-34eaecb818bd_Output.h5 \n\nUsing commercial license features. \nChecking out license feature 'FDTD_SOLVER', version 8.2, (1). \n\nRunning the EM-FDTD solver with the following settings: \nFloating Point Arithmetic: single (4 Bytes) \nHPC: Acceleware \nUsed Acceleware library is '11.4.1.13550 (x64, 64-bit)'. \nYour NVIDIA display driver is newer than the expected version. \nInstalled version: 15.7680 Expected: 15.3667 (see also http://www.acceleware.com/fdtd-11-4-1) \nReduced performance could be encountered. \n\nSimulation Time Step:   5.72711e-12 sec \nSimulation Iterations:  2853 \nMax Simulated Time: 1.63394e-08 sec \n\nGrid: \nNumber of cells: 229x177x499 = 20225967 cells = 20.2260 MCells \nNumber of cells including PML: 245x193x515 = 24351775 cells = 24.3518 MCells \nX: Range [-0.338659 ... 0.346117] with minimal 0.00297412 and maximal step 0.0029977 [m] \nY: Range [-0.21475 ... 0.312145] with minimal 0.00297412 and maximal step 0.00297865 [m] \nZ: Range [-1.12649 ... 0.367766] with minimal 0.00297403 and maximal step 0.00299799 [m] \n\nBoundaries: \nSide X-: ABC (UPML, 8 layers) \nSide X+: ABC (UPML, 8 layers) \nSide Y-: ABC (UPML, 8 layers) \nSide Y+: ABC (UPML, 8 layers) \nSide Z-: ABC (UPML, 8 layers) \nSide Z+: ABC (UPML, 8 layers) \n\nCreated unified material architecture (UMA) model \n\nMaterials (77): \nBackground: dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nTongue  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=0.865626, mu_r=1.000000, sigma_H=0.000000) \nAdrenal_gland  (Thelonious_6y_V6): dielectric (eps_r=50.989008, sigma_E=0.954350, mu_r=1.000000, sigma_H=0.000000) \nStomach_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \ncommissura_anterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nEye_vitreous_humor  (Thelonious_6y_V6): dielectric (eps_r=68.947390, sigma_E=1.583627, mu_r=1.000000, sigma_H=0.000000) \nVein  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nMidbrain  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nTestis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nAir_internal  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBlood_vessel  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nEpididymis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nPinealbody  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBladder  (Thelonious_6y_V6): dielectric (eps_r=19.149003, sigma_E=0.358399, mu_r=1.000000, sigma_H=0.000000) \nMarrow_red  (Thelonious_6y_V6): dielectric (eps_r=11.451933, sigma_E=0.207759, mu_r=1.000000, sigma_H=0.000000) \nGallbladder  (Thelonious_6y_V6): dielectric (eps_r=59.551663, sigma_E=1.202528, mu_r=1.000000, sigma_H=0.000000) \nHypophysis  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBrain_white_matter  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nSpleen  (Thelonious_6y_V6): dielectric (eps_r=58.688546, sigma_E=1.175182, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nThymus  (Thelonious_6y_V6): dielectric (eps_r=55.600852, sigma_E=1.115237, mu_r=1.000000, sigma_H=0.000000) \nTrachea  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nHeart_muscle  (Thelonious_6y_V6): dielectric (eps_r=61.478559, sigma_E=1.125021, mu_r=1.000000, sigma_H=0.000000) \nMuscle  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nHypothalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nArtery  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nSkin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nBrain_grey_matter  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nPatella  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_Sclera  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=1.096154, mu_r=1.000000, sigma_H=0.000000) \nTendon_Ligament  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nKidney_medulla  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nMedulla_oblongata  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nEsophagus  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nIntervertebral_disc  (Thelonious_6y_V6): dielectric (eps_r=44.418065, sigma_E=1.041108, mu_r=1.000000, sigma_H=0.000000) \nVertebrae  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_lens  (Thelonious_6y_V6): dielectric (eps_r=36.279018, sigma_E=0.435952, mu_r=1.000000, sigma_H=0.000000) \ncommissura_posterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nCornea  (Thelonious_6y_V6): dielectric (eps_r=56.275669, sigma_E=1.311407, mu_r=1.000000, sigma_H=0.000000) \nTrachea_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPharynx  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nLiver  (Thelonious_6y_V6): dielectric (eps_r=47.963211, sigma_E=0.773986, mu_r=1.000000, sigma_H=0.000000) \nThalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nHeart_lumen  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine  (Thelonious_6y_V6): dielectric (eps_r=59.134765, sigma_E=0.989502, mu_r=1.000000, sigma_H=0.000000) \nKidney_cortex  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nStomach  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nFat  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nLung  (Thelonious_6y_V6): dielectric (eps_r=22.460437, sigma_E=0.423425, mu_r=1.000000, sigma_H=0.000000) \nConnective_tissue  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nPons  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nSpinal_cord  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nSAT  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nEar_cartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nTeeth  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nNerve  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nEar_skin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nMeniscus  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nSkull  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nProstate  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nDiaphragm  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nBone  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nMucosa  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine  (Thelonious_6y_V6): dielectric (eps_r=61.138364, sigma_E=2.062163, mu_r=1.000000, sigma_H=0.000000) \nLarynx  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nMandible  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nCartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nHippocampus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nCerebellum  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nPenis  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nUreter_Urethra  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nBronchi_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPancreas  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nEsophagus_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBronchi  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nCerebrospinal_fluid  (Thelonious_6y_V6): dielectric (eps_r=69.157589, sigma_E=2.338250, mu_r=1.000000, sigma_H=0.000000) \n\nLumped Elements: No active lumped elements in the simulation. \n\nHost OS: Microsoft Windows 10 Professional 64-bit (Build 9200) \nHost CPU: AMD EPYC 7542 32-Core Processor \nHost memory: 16379 MB \nThe following Accelerators have been detected: \nNVIDIA GeForce RTX 4090 (device ID = 0), compute capability 8.9, total memory 24563 MB \n\n\nSensors (3): \nInitializing field sensor Overall Field. \nInitializing point sensor Point Sensor Entity 1 (lower_left_bottom). \nAveraging setup for point sensor Point Sensor Entity 1 (lower_left_bottom): \nE-Field: \nX: 2 edges used for recording. \nY: 2 edges used for recording. \nZ: 2 edges used for recording. \nH-Field: \nX: 4 edges used for recording. \nY: 4 edges used for recording. \nZ: 4 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 1 (lower_left_bottom): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.86355e-11, convergence level = -15 dB. \nInitializing point sensor Point Sensor Entity 2 (top_right_up). \nAveraging setup for point sensor Point Sensor Entity 2 (top_right_up): \nE-Field: \nX: 2 edges used for recording. \nY: 2 edges used for recording. \nZ: 2 edges used for recording. \nH-Field: \nX: 4 edges used for recording. \nY: 4 edges used for recording. \nZ: 4 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 2 (top_right_up): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.86355e-11, convergence level = -15 dB. \nUsing DFT to convert to frequency domain. \n\nSources (1): \nInitializing plane wave source far_field_simulation_bbox. \nExcitation signal: Harmonic signal with frequency 700 MHz and ramp time 2.14286 ns \n\nUpdate coefficient calculation for 122086088 edges using 3 threads. \nCalculating update coefficients \n[PROGRESS]: 23% [ 28080500 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 41% [ 50062310 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 61% [ 74501833 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 84% [ 102616088 / 122086088 ] Calculating update coefficients \n\n\nEdge-Material Statistics (Electric/Magnetic): \n61165060 / 60921028      (100.00% / 100.00%) : Total \n61165060 / 60921028      (100.00% / 100.00%) : Dielectric \n\nEdge-Region Statistics (regions with more than 1% of all edges, max 20 items): \n58992181 / 58810012      ( 96.45% /  96.53%) : Background \n1084192 /  1496072   (  1.77% /   2.46%) : Other \n1088687 /   614944   (  1.78% /   1.01%) : Averaged \n\n\nUpdate coefficient database contains 2099 E-coefficient(s) and 1 H-coefficient(s). \nElapsed time for 'Calculating update coefficients' was 00:00:11 wall clock time. \nPreparing for time update \nUse hardware resource management option fastest simulation \nChecking out license feature 'AXWARE_TOKEN', version 8.2, (1). \n[PROGRESS]: 2% [ 2 / 100 ] Preparing for time update \n[PROGRESS]: 15% [ 15 / 100 ] Preparing for time update \n[PROGRESS]: 28% [ 28 / 100 ] Preparing for time update \n[PROGRESS]: 41% [ 41 / 100 ] Preparing for time update \n[PROGRESS]: 55% [ 55 / 100 ] Preparing for time update \n[PROGRESS]: 73% [ 73 / 100 ] Preparing for time update \nSimulation 1 is using device(s): [0] \nElapsed time for 'Preparing for time update' was 00:00:17 wall clock time. \nStarting solver aXware (hardware accelerated). \nTime Update \n[PROGRESS]: 0% [ 10 / 2853 ] Time Update, estimated remaining time 1 minutes 25 seconds  @ 813.94 MCells/s \n[PROGRESS]: 6% [ 179 / 2853 ] Time Update, estimated remaining time 32 seconds  @ 2040.03 MCells/s \n[PROGRESS]: 13% [ 376 / 2853 ] Time Update, estimated remaining time 28 seconds  @ 2164.92 MCells/s \n[PROGRESS]: 20% [ 573 / 2853 ] Time Update, estimated remaining time 26 seconds  @ 2163.82 MCells/s \n[PROGRESS]: 26% [ 742 / 2853 ] Time Update, estimated remaining time 26 seconds  @ 2015.32 MCells/s \n[PROGRESS]: 32% [ 939 / 2853 ] Time Update, estimated remaining time 21 seconds  @ 2204.32 MCells/s \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 0 to check conventional convergence. \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 4 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 0 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 4 to check conventional convergence. \n[PROGRESS]: 38% [ 1108 / 2853 ] Time Update, estimated remaining time 21 seconds  @ 2048.81 MCells/s \n[PROGRESS]: 45% [ 1305 / 2853 ] Time Update, estimated remaining time 17 seconds  @ 2182.51 MCells/s \n[PROGRESS]: 52% [ 1502 / 2853 ] Time Update, estimated remaining time 16 seconds  @ 2077.08 MCells/s \n[PROGRESS]: 59% [ 1699 / 2853 ] Time Update, estimated remaining time 13 seconds  @ 2165.40 MCells/s \n[PROGRESS]: 65% [ 1868 / 2853 ] Time Update, estimated remaining time 12 seconds  @ 2027.75 MCells/s \n[PROGRESS]: 72% [ 2065 / 2853 ] Time Update, estimated remaining time 9 seconds  @ 2140.35 MCells/s \nSensor Point Sensor Entity 2 (top_right_up): conventional steady state check successful. \n[PROGRESS]: 78% [ 2234 / 2853 ] Time Update, estimated remaining time 8 seconds  @ 1915.74 MCells/s \nSensor Point Sensor Entity 1 (lower_left_bottom): conventional steady state check successful. \nSteady state detected at iteration 2420, remaining time steps are 63. \n[PROGRESS]: 97% [ 2431 / 2483 ] Time Update, estimated remaining time 2 seconds  @ 714.69 MCells/s \nSimulation performed 2483 iterations. \nElapsed time for 'Time Update' was 00:00:40 wall clock time. \n\nPost-process Sensors \nPost-process sensor 'Overall Field' \nPost-process sensor 'Point Sensor Entity 1 (lower_left_bottom)' \n[PROGRESS]: 66% [ 2 / 3 ] Post-process Sensors \nPost-process sensor 'Point Sensor Entity 2 (top_right_up)' \nTrusted frequency is 700 MHz. Expect less accurate results outside. \nElapsed time for 'Post-process Sensors' was 00:00:06 wall clock time. \nFDTD simulation finished successfully. \n\nSimulation 'EM_FDTD_thelonious_700MHz_z_neg_theta' has ended successfully and took 00:01:24 wall clock time \nNo compression of solver files requested \nReleased license feature 'AXWARE_TOKEN'. \nReleased license feature 'FDTD_SOLVER'. \nPeak CPU memory usage:   3.6 GB (3910258688 Bytes) \niSolve ended successfully. \n      - Subtask 'run_isolve_execution' done in 85.66s [SimulationRunner._run_isolve_manual]\n      - Done in 85.66s [SimulationRunner._run_isolve_manual]\n    - Wait for results... [SimulationRunner._run_isolve_manual]\n      - Subtask 'run_wait_for_results' done in 5.03s [SimulationRunner._run_isolve_manual]\n      - Done in 5.03s [SimulationRunner._run_isolve_manual]\n    - Reload project... [SimulationRunner._run_isolve_manual]\nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash \n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\n      - Subtask 'run_reload_project' done in 12.14s [SimulationRunner._run_isolve_manual]\n      - Done in 12.14s [SimulationRunner._run_isolve_manual]\nProject reloaded and results are available. [SimulationRunner._run_isolve_manual]\n    - Subtask 'run_simulation_total' done in 107.81s [FarFieldStudy.subtask]\n    - Done in 107.81s [FarFieldStudy.subtask]\nRun deliverables verified. Updating metadata. [FarFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\n--- Finished: run (took 107.88s) --- [profile]\n--- Starting: extract --- [profile]\nRun deliverables verified. Proceeding with extraction. [FarFieldStudy._verify_run_deliverables_before_extraction]\nValidating project file: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash [ProjectManager.open]\nOpening project with Sim4Life: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash [ProjectManager.open]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash \nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nProject reloaded. [ProjectManager.reload_project]\n  - Extract results total... [FarFieldStudy.subtask]\n    - Extract input power... [PowerExtractor.extract_input_power]\n  - Far-field study: using theoretical model for input power. [PowerExtractor._extract_far_field_power]\n  - Calculated theoretical input power: 1.9522e-04 W [PowerExtractor._extract_far_field_power]\n      - Subtask 'extract_input_power' done in 0.00s [PowerExtractor.extract_input_power]\n      - Done in 0.00s [PowerExtractor.extract_input_power]\n    - Extract SAR statistics... [SarExtractor.extract_sar_statistics]\n  - Loading tissue groups for 'thelonious' from material_name_mapping.json [SarExtractor._define_tissue_groups]\n  - Extracting peak SAR details... [SarExtractor.extract_peak_sar_details]\n      - Subtask 'extract_sar_statistics' done in 28.34s [SarExtractor.extract_sar_statistics]\n      - Done in 28.34s [SarExtractor.extract_sar_statistics]\n    - Extract power balance... [PowerExtractor.extract_power_balance]\nAnalysis : [Warn]  Unable to balance the following EM sources: far_field_simulation_bbox,  are still not supported.\nAnalysis : [Warn]  Unable to balance the following EM sources: far_field_simulation_bbox,  are still not supported.\n    - Overwriting Pin with theoretical value: 1.9522e-04 W [PowerExtractor.extract_power_balance]\n    - Final Balance: 221.47% [PowerExtractor.extract_power_balance]\n      - Subtask 'extract_power_balance' done in 10.88s [PowerExtractor.extract_power_balance]\n      - Done in 10.88s [PowerExtractor.extract_power_balance]\n    - Extract point sensors... [SensorExtractor.extract_point_sensor_data]\n  - Point sensor plot saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_z_neg\\point_sensor_data.png [SensorExtractor._save_plot]\n      - Subtask 'extract_point_sensor_data' done in 0.50s [SensorExtractor.extract_point_sensor_data]\n      - Done in 0.50s [SensorExtractor.extract_point_sensor_data]\n  - Pickle report saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_z_neg\\sar_stats_all_tissues.pkl [Reporter._save_pickle_report]\n  - HTML report saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_z_neg\\sar_stats_all_tissues.html [Reporter._save_html_report]\n  - SAR results saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_z_neg\\sar_results.json [ResultsExtractor._save_json_results]\n    - Subtask 'extract_results_total' done in 39.95s [FarFieldStudy.subtask]\n    - Done in 39.95s [FarFieldStudy.subtask]\nExtract deliverables verified. Updating metadata. [FarFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n--- Finished: extract (took 59.44s) --- [profile]\n\n--- Processing Simulation 4/4: thelonious, 700MHz, z_neg, phi --- [FarFieldStudy._run_study]\n--- Starting: setup --- [profile]\nProject path set to: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash [ProjectManager.create_or_open_project]\nNo metadata file found at config.json. [ProjectManager.verify_simulation_metadata]\nExisting project is invalid or out of date. A new setup is required. [ProjectManager.create_or_open_project]\n--- Simulation-specific progress logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg\\progress.log --- \n--- Simulation-specific verbose logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg\\verbose.log --- \nCreating a new empty project in memory. [ProjectManager.create_new]\nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\nInitializing model by creating and deleting a dummy block... [ProjectManager.create_new]\nModel initialized, ready for population. [ProjectManager.create_new]\n  - Setup simulation... [FarFieldStudy.subtask]\n--- Setting up single Far-Field sim --- [FarFieldSetup.run_full_setup]\n    - Load phantom... [FarFieldSetup.run_full_setup]\n--- Running Phantom Check --- [PhantomSetup._log]\nFound 2 total entities in the project. [PhantomSetup._log]\n--- Phantom Check Result: Phantom not found in project. --- [PhantomSetup._log]\nPhantom not found in document. Importing from 'C:\\Users\\user\\repo-clean\\data\\phantoms\\thelonious.sab'... [PhantomSetup._log]\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nPhantom imported successfully. [PhantomSetup._log]\n      - Subtask 'setup_load_phantom' done in 8.78s [FarFieldSetup.run_full_setup]\n      - Done in 8.78s [FarFieldSetup.run_full_setup]\n    - Configure scene (bbox, plane wave)... [FarFieldSetup.run_full_setup]\nCreating simulation bounding box for far-field... [FarFieldSetup._create_or_get_simulation_bbox]\n  - Created far-field simulation BBox with 50mm padding. [FarFieldSetup._create_or_get_simulation_bbox]\n  - Creating simulation: EM_FDTD_thelonious_700MHz_z_neg_phi [FarFieldSetup._create_simulation_entity]\n  - Using simulation time multiplier: 3.5 [FarFieldSetup._apply_simulation_time_and_termination]\n  - Simulation time set to 11.44 periods. [FarFieldSetup._apply_simulation_time_and_termination]\n  - Setting termination criteria to: GlobalAutoTerminationUserDefined [FarFieldSetup._apply_simulation_time_and_termination]\n    - Convergence level set to: -15 dB [FarFieldSetup._apply_simulation_time_and_termination]\n      - Subtask 'setup_configure_scene' done in 1.50s [FarFieldSetup.run_full_setup]\n      - Done in 1.50s [FarFieldSetup.run_full_setup]\n    - Assign materials... [FarFieldSetup.run_full_setup]\nAssigning materials... [MaterialSetup.assign_materials]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\n[Info]  \nMass Density has changed from 1000 to 1.2050000000000001\nMass Density has changed from 1.2050000000000001 to 1.2\nRelative Permittivity has changed from 1 to 0\nSimulation : [Warn]  Unable to find any match for following settings properties: Magnetic Conductivity\nSimulation : [Warn]  Unable to find any match for following settings properties: Relative Permeability\n      - Subtask 'setup_materials' done in 5.30s [FarFieldSetup.run_full_setup]\n      - Done in 5.30s [FarFieldSetup.run_full_setup]\n    - Configure solver (gridding, boundaries, sensors)... [FarFieldSetup.run_full_setup]\nSetting up gridding... [GriddingSetup.setup_gridding]\n  - Looking for global grid bounding box: 'far_field_simulation_bbox' [GriddingSetup._setup_main_grid]\n  - Using manual gridding. [GriddingSetup._setup_main_grid]\n  - Global and added manual grid set with global resolution: 3.0 mm. [GriddingSetup._setup_main_grid]\n  - Using automatic padding. [GriddingSetup._setup_main_grid]\n  - No antenna components provided, skipping subgridding. [GriddingSetup.setup_gridding]\nSetting up boundary conditions... [BoundarySetup.setup_boundary_conditions]\n  - Setting global boundary conditions to: UpmlCpml [BoundarySetup.setup_boundary_conditions]\n    - Successfully set GlobalBoundaryType to UpmlCpml [BoundarySetup.setup_boundary_conditions]\n  - Setting PML strength to: Low [BoundarySetup.setup_boundary_conditions]\n    - Successfully set PmlStrength to Low [BoundarySetup.setup_boundary_conditions]\n  - Added point sensor at (Vec3(-231.59, -107.681, -1019.42), Vec3(-231.59, -107.681, -1019.42), Vec3(-231.59, -107.681, -1019.42)) (lower_left_bottom) [FarFieldSetup._add_point_sensors]\n  - Added point sensor at (Vec3(239.048, 205.076, 260.697), Vec3(239.048, 205.076, 260.697), Vec3(239.048, 205.076, 260.697)) (top_right_up) [FarFieldSetup._add_point_sensors]\n  - Configuring solver settings... [FarFieldSetup._setup_solver_settings]\n    - Solver kernel set to: Acceleware (AXware) [FarFieldSetup._setup_solver_settings]\n      - Subtask 'setup_solver' done in 0.22s [FarFieldSetup.run_full_setup]\n      - Done in 0.22s [FarFieldSetup.run_full_setup]\n    - Voxelize simulation... [FarFieldSetup.run_full_setup]\n    - Finalizing setup... [FarFieldSetup._finalize_setup]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tongue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Adrenal Gland\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Anterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Vitreous Humor)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Midbrain\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Testis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Air 1\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood Vessel Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Epididymis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pineal Body\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Urinary Bladder Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone Marrow (Red)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Gallbladder\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypophysis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (White Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spleen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thymus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypothalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skin\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (Grey Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone (Cortical)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Sclera)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tendon\\Ligament\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Medulla)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Medulla Oblongata\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Intervertebral Disc\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Vertebrae\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Lens)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Posterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Cornea)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pharynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Liver\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Cortex)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Fat\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Lung\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Connective Tissue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pons\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spinal Cord\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"SAT (Subcutaneous Fat)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cartilage\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tooth\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Nerve\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Meniscus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skull\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Prostate\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Diaphragm\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mucous Membrane\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Larynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mandible\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hippocampus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebellum\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Penis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Ureter\\Urethra\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pancreas\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebrospinal Fluid\" have been set to their value according to the selected database\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n[Info]  Start voxeling\n[Info]  Topological Voxeler Report: Complete Voxel Scene\n    Voxel Scene Memory Consumption: 0.002876 GB\n    Wall Clock Time: 7.6676 s\n\n[Info]  Voxeling succeeded.\n    - Finalizing setup complete. [FarFieldSetup._finalize_setup]\n      - Subtask 'setup_voxelize' done in 20.77s [FarFieldSetup.run_full_setup]\n      - Done in 20.77s [FarFieldSetup.run_full_setup]\n    - Save project... [FarFieldSetup.run_full_setup]\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\nProject saved. [ProjectManager.save]\n      - Subtask 'setup_save_project' done in 3.98s [FarFieldSetup.run_full_setup]\n      - Done in 3.98s [FarFieldSetup.run_full_setup]\nCommon settings applied. [FarFieldSetup.run_full_setup]\n    - Subtask 'setup_simulation' done in 40.80s [FarFieldStudy.subtask]\n    - Done in 40.80s [FarFieldStudy.subtask]\n  - Saved configuration metadata to config.json [ProjectManager.write_simulation_metadata]\n--- Finished: setup (took 41.45s) --- [profile]\n--- Starting: run --- [profile]\n  - Run simulation total... [FarFieldStudy.subtask]\nRunning simulation: EM_FDTD_thelonious_700MHz_z_neg_phi [SimulationRunner.run]\n    - Write input file... [SimulationRunner.run]\n[Info]  Writing solver input file(s) for EM_FDTD_thelonious_700MHz_z_neg_phi\n[Info]  Writing Rectilinear Discretization to Input File. Elapse Time: 0.48039 s\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n      - Subtask 'run_write_input_file' done in 5.33s [SimulationRunner.run]\n      - Done in 5.33s [SimulationRunner.run]\nRunning iSolve with acceleware on b74e244e-d81d-4ea9-bd70-2bad50688c5d_Input.h5 [SimulationRunner._run_isolve_manual]\n    - Execute iSolve... [SimulationRunner._run_isolve_manual]\n\nReading command line \niSolve X, Version 8.2.0 (16876), 64Bit Windows \n\nRunning MPI version 2.0 on 1 process. \n\n\nSimulation 'EM_FDTD_thelonious_700MHz_z_neg_phi'  \n\nInstalled system RAM visible to this process:  16.0 GB \n\nSolver type: EmFdtd, SinglePrecision, Acceleware \nInput file name: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash_Results\\b74e244e-d81d-4ea9-bd70-2bad50688c5d_Input.h5 \nInput file generated by: Sim4Life, Version 8.2.0.16876 \nOutput file name: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash_Results\\b74e244e-d81d-4ea9-bd70-2bad50688c5d_Output.h5 \n\nUsing commercial license features. \nChecking out license feature 'FDTD_SOLVER', version 8.2, (1). \n\nRunning the EM-FDTD solver with the following settings: \nFloating Point Arithmetic: single (4 Bytes) \nHPC: Acceleware \nUsed Acceleware library is '11.4.1.13550 (x64, 64-bit)'. \nYour NVIDIA display driver is newer than the expected version. \nInstalled version: 15.7680 Expected: 15.3667 (see also http://www.acceleware.com/fdtd-11-4-1) \nReduced performance could be encountered. \n\nSimulation Time Step:   5.72711e-12 sec \nSimulation Iterations:  2853 \nMax Simulated Time: 1.63394e-08 sec \n\nGrid: \nNumber of cells: 229x177x499 = 20225967 cells = 20.2260 MCells \nNumber of cells including PML: 245x193x515 = 24351775 cells = 24.3518 MCells \nX: Range [-0.338659 ... 0.346117] with minimal 0.00297412 and maximal step 0.0029977 [m] \nY: Range [-0.21475 ... 0.312145] with minimal 0.00297412 and maximal step 0.00297865 [m] \nZ: Range [-1.12649 ... 0.367766] with minimal 0.00297403 and maximal step 0.00299799 [m] \n\nBoundaries: \nSide X-: ABC (UPML, 8 layers) \nSide X+: ABC (UPML, 8 layers) \nSide Y-: ABC (UPML, 8 layers) \nSide Y+: ABC (UPML, 8 layers) \nSide Z-: ABC (UPML, 8 layers) \nSide Z+: ABC (UPML, 8 layers) \n\nCreated unified material architecture (UMA) model \n\nMaterials (77): \nBackground: dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nTongue  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=0.865626, mu_r=1.000000, sigma_H=0.000000) \nAdrenal_gland  (Thelonious_6y_V6): dielectric (eps_r=50.989008, sigma_E=0.954350, mu_r=1.000000, sigma_H=0.000000) \nStomach_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \ncommissura_anterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nEye_vitreous_humor  (Thelonious_6y_V6): dielectric (eps_r=68.947390, sigma_E=1.583627, mu_r=1.000000, sigma_H=0.000000) \nVein  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nMidbrain  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nTestis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nAir_internal  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBlood_vessel  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nEpididymis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nPinealbody  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBladder  (Thelonious_6y_V6): dielectric (eps_r=19.149003, sigma_E=0.358399, mu_r=1.000000, sigma_H=0.000000) \nMarrow_red  (Thelonious_6y_V6): dielectric (eps_r=11.451933, sigma_E=0.207759, mu_r=1.000000, sigma_H=0.000000) \nGallbladder  (Thelonious_6y_V6): dielectric (eps_r=59.551663, sigma_E=1.202528, mu_r=1.000000, sigma_H=0.000000) \nHypophysis  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBrain_white_matter  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nSpleen  (Thelonious_6y_V6): dielectric (eps_r=58.688546, sigma_E=1.175182, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nThymus  (Thelonious_6y_V6): dielectric (eps_r=55.600852, sigma_E=1.115237, mu_r=1.000000, sigma_H=0.000000) \nTrachea  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nHeart_muscle  (Thelonious_6y_V6): dielectric (eps_r=61.478559, sigma_E=1.125021, mu_r=1.000000, sigma_H=0.000000) \nMuscle  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nHypothalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nArtery  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nSkin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nBrain_grey_matter  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nPatella  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_Sclera  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=1.096154, mu_r=1.000000, sigma_H=0.000000) \nTendon_Ligament  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nKidney_medulla  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nMedulla_oblongata  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nEsophagus  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nIntervertebral_disc  (Thelonious_6y_V6): dielectric (eps_r=44.418065, sigma_E=1.041108, mu_r=1.000000, sigma_H=0.000000) \nVertebrae  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_lens  (Thelonious_6y_V6): dielectric (eps_r=36.279018, sigma_E=0.435952, mu_r=1.000000, sigma_H=0.000000) \ncommissura_posterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nCornea  (Thelonious_6y_V6): dielectric (eps_r=56.275669, sigma_E=1.311407, mu_r=1.000000, sigma_H=0.000000) \nTrachea_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPharynx  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nLiver  (Thelonious_6y_V6): dielectric (eps_r=47.963211, sigma_E=0.773986, mu_r=1.000000, sigma_H=0.000000) \nThalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nHeart_lumen  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine  (Thelonious_6y_V6): dielectric (eps_r=59.134765, sigma_E=0.989502, mu_r=1.000000, sigma_H=0.000000) \nKidney_cortex  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nStomach  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nFat  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nLung  (Thelonious_6y_V6): dielectric (eps_r=22.460437, sigma_E=0.423425, mu_r=1.000000, sigma_H=0.000000) \nConnective_tissue  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nPons  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nSpinal_cord  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nSAT  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nEar_cartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nTeeth  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nNerve  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nEar_skin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nMeniscus  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nSkull  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nProstate  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nDiaphragm  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nBone  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nMucosa  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine  (Thelonious_6y_V6): dielectric (eps_r=61.138364, sigma_E=2.062163, mu_r=1.000000, sigma_H=0.000000) \nLarynx  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nMandible  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nCartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nHippocampus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nCerebellum  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nPenis  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nUreter_Urethra  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nBronchi_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPancreas  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nEsophagus_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBronchi  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nCerebrospinal_fluid  (Thelonious_6y_V6): dielectric (eps_r=69.157589, sigma_E=2.338250, mu_r=1.000000, sigma_H=0.000000) \n\nLumped Elements: No active lumped elements in the simulation. \n\nHost OS: Microsoft Windows 10 Professional 64-bit (Build 9200) \nHost CPU: AMD EPYC 7542 32-Core Processor \nHost memory: 16379 MB \nThe following Accelerators have been detected: \nNVIDIA GeForce RTX 4090 (device ID = 0), compute capability 8.9, total memory 24563 MB \n\n\nSensors (3): \nInitializing field sensor Overall Field. \nInitializing point sensor Point Sensor Entity 1 (lower_left_bottom). \nAveraging setup for point sensor Point Sensor Entity 1 (lower_left_bottom): \nE-Field: \nX: 2 edges used for recording. \nY: 2 edges used for recording. \nZ: 2 edges used for recording. \nH-Field: \nX: 4 edges used for recording. \nY: 4 edges used for recording. \nZ: 4 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 1 (lower_left_bottom): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.86355e-11, convergence level = -15 dB. \nInitializing point sensor Point Sensor Entity 2 (top_right_up). \nAveraging setup for point sensor Point Sensor Entity 2 (top_right_up): \nE-Field: \nX: 2 edges used for recording. \nY: 2 edges used for recording. \nZ: 2 edges used for recording. \nH-Field: \nX: 4 edges used for recording. \nY: 4 edges used for recording. \nZ: 4 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 2 (top_right_up): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.86355e-11, convergence level = -15 dB. \nUsing DFT to convert to frequency domain. \n\nSources (1): \nInitializing plane wave source far_field_simulation_bbox. \nExcitation signal: Harmonic signal with frequency 700 MHz and ramp time 2.14286 ns \n\nUpdate coefficient calculation for 122086088 edges using 3 threads. \nCalculating update coefficients \n[PROGRESS]: 20% [ 24452000 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 41% [ 50151132 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 60% [ 73353634 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 81% [ 99066106 / 122086088 ] Calculating update coefficients \n\n\nEdge-Material Statistics (Electric/Magnetic): \n61165060 / 60921028      (100.00% / 100.00%) : Total \n61165060 / 60921028      (100.00% / 100.00%) : Dielectric \n\nEdge-Region Statistics (regions with more than 1% of all edges, max 20 items): \n58992181 / 58810012      ( 96.45% /  96.53%) : Background \n1084192 /  1496072   (  1.77% /   2.46%) : Other \n1088687 /   614944   (  1.78% /   1.01%) : Averaged \n\n\nUpdate coefficient database contains 2099 E-coefficient(s) and 1 H-coefficient(s). \nElapsed time for 'Calculating update coefficients' was 00:00:10 wall clock time. \nPreparing for time update \nUse hardware resource management option fastest simulation \nChecking out license feature 'AXWARE_TOKEN', version 8.2, (1). \n[PROGRESS]: 2% [ 2 / 100 ] Preparing for time update \n[PROGRESS]: 14% [ 14 / 100 ] Preparing for time update \n[PROGRESS]: 25% [ 25 / 100 ] Preparing for time update \n[PROGRESS]: 36% [ 36 / 100 ] Preparing for time update \n[PROGRESS]: 46% [ 46 / 100 ] Preparing for time update \n[PROGRESS]: 63% [ 63 / 100 ] Preparing for time update \nSimulation 1 is using device(s): [0] \nElapsed time for 'Preparing for time update' was 00:00:19 wall clock time. \nStarting solver aXware (hardware accelerated). \nTime Update \n[PROGRESS]: 0% [ 10 / 2853 ] Time Update, estimated remaining time 2 minutes 1 seconds  @ 572.41 MCells/s \n[PROGRESS]: 7% [ 207 / 2853 ] Time Update, estimated remaining time 31 seconds  @ 2108.85 MCells/s \n[PROGRESS]: 14% [ 404 / 2853 ] Time Update, estimated remaining time 28 seconds  @ 2119.56 MCells/s \n[PROGRESS]: 20% [ 573 / 2853 ] Time Update, estimated remaining time 27 seconds  @ 2044.40 MCells/s \n[PROGRESS]: 26% [ 742 / 2853 ] Time Update, estimated remaining time 25 seconds  @ 2016.98 MCells/s \n[PROGRESS]: 32% [ 939 / 2853 ] Time Update, estimated remaining time 21 seconds  @ 2194.26 MCells/s \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 1 to check conventional convergence. \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 3 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 1 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 3 to check conventional convergence. \n[PROGRESS]: 38% [ 1108 / 2853 ] Time Update, estimated remaining time 23 seconds  @ 1840.54 MCells/s \n[PROGRESS]: 45% [ 1305 / 2853 ] Time Update, estimated remaining time 18 seconds  @ 2087.87 MCells/s \n[PROGRESS]: 51% [ 1474 / 2853 ] Time Update, estimated remaining time 17 seconds  @ 2004.94 MCells/s \n[PROGRESS]: 58% [ 1671 / 2853 ] Time Update, estimated remaining time 14 seconds  @ 2082.69 MCells/s \n[PROGRESS]: 65% [ 1868 / 2853 ] Time Update, estimated remaining time 11 seconds  @ 2137.34 MCells/s \n[PROGRESS]: 71% [ 2037 / 2853 ] Time Update, estimated remaining time 10 seconds  @ 2041.22 MCells/s \nSensor Point Sensor Entity 2 (top_right_up): conventional steady state check successful. \n[PROGRESS]: 78% [ 2234 / 2853 ] Time Update, estimated remaining time 7 seconds  @ 2074.97 MCells/s \n[PROGRESS]: 84% [ 2403 / 2853 ] Time Update, estimated remaining time 5 seconds  @ 1997.43 MCells/s \nSensor Point Sensor Entity 1 (lower_left_bottom): conventional steady state check successful. \nSteady state detected at iteration 2420, remaining time steps are 63. \n[PROGRESS]: 97% [ 2432 / 2483 ] Time Update, estimated remaining time 8 seconds  @ 150.20 MCells/s \nSimulation performed 2483 iterations. \nElapsed time for 'Time Update' was 00:00:40 wall clock time. \n\nPost-process Sensors \nPost-process sensor 'Overall Field' \nPost-process sensor 'Point Sensor Entity 1 (lower_left_bottom)' \n[PROGRESS]: 66% [ 2 / 3 ] Post-process Sensors \nPost-process sensor 'Point Sensor Entity 2 (top_right_up)' \nTrusted frequency is 700 MHz. Expect less accurate results outside. \nElapsed time for 'Post-process Sensors' was 00:00:05 wall clock time. \nFDTD simulation finished successfully. \n\nSimulation 'EM_FDTD_thelonious_700MHz_z_neg_phi' has ended successfully and took 00:01:27 wall clock time \nNo compression of solver files requested \nReleased license feature 'AXWARE_TOKEN'. \nReleased license feature 'FDTD_SOLVER'. \nPeak CPU memory usage:   3.6 GB (3909775360 Bytes) \niSolve ended successfully. \n      - Subtask 'run_isolve_execution' done in 88.14s [SimulationRunner._run_isolve_manual]\n      - Done in 88.14s [SimulationRunner._run_isolve_manual]\n    - Wait for results... [SimulationRunner._run_isolve_manual]\n      - Subtask 'run_wait_for_results' done in 5.00s [SimulationRunner._run_isolve_manual]\n      - Done in 5.00s [SimulationRunner._run_isolve_manual]\n    - Reload project... [SimulationRunner._run_isolve_manual]\nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash \n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\n      - Subtask 'run_reload_project' done in 11.30s [SimulationRunner._run_isolve_manual]\n      - Done in 11.30s [SimulationRunner._run_isolve_manual]\nProject reloaded and results are available. [SimulationRunner._run_isolve_manual]\n    - Subtask 'run_simulation_total' done in 109.88s [FarFieldStudy.subtask]\n    - Done in 109.88s [FarFieldStudy.subtask]\nRun deliverables verified. Updating metadata. [FarFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\n--- Finished: run (took 109.92s) --- [profile]\n--- Starting: extract --- [profile]\nRun deliverables verified. Proceeding with extraction. [FarFieldStudy._verify_run_deliverables_before_extraction]\nValidating project file: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash [ProjectManager.open]\nOpening project with Sim4Life: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash [ProjectManager.open]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash \nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nProject reloaded. [ProjectManager.reload_project]\n  - Extract results total... [FarFieldStudy.subtask]\n    - Extract input power... [PowerExtractor.extract_input_power]\n  - Far-field study: using theoretical model for input power. [PowerExtractor._extract_far_field_power]\n  - Calculated theoretical input power: 1.9522e-04 W [PowerExtractor._extract_far_field_power]\n      - Subtask 'extract_input_power' done in 0.02s [PowerExtractor.extract_input_power]\n      - Done in 0.02s [PowerExtractor.extract_input_power]\n    - Extract SAR statistics... [SarExtractor.extract_sar_statistics]\n  - Loading tissue groups for 'thelonious' from material_name_mapping.json [SarExtractor._define_tissue_groups]\n  - Extracting peak SAR details... [SarExtractor.extract_peak_sar_details]\n      - Subtask 'extract_sar_statistics' done in 27.91s [SarExtractor.extract_sar_statistics]\n      - Done in 27.91s [SarExtractor.extract_sar_statistics]\n    - Extract power balance... [PowerExtractor.extract_power_balance]\nAnalysis : [Warn]  Unable to balance the following EM sources: far_field_simulation_bbox,  are still not supported.\nAnalysis : [Warn]  Unable to balance the following EM sources: far_field_simulation_bbox,  are still not supported.\n    - Overwriting Pin with theoretical value: 1.9522e-04 W [PowerExtractor.extract_power_balance]\n    - Final Balance: 201.45% [PowerExtractor.extract_power_balance]\n      - Subtask 'extract_power_balance' done in 10.84s [PowerExtractor.extract_power_balance]\n      - Done in 10.84s [PowerExtractor.extract_power_balance]\n    - Extract point sensors... [SensorExtractor.extract_point_sensor_data]\n  - Point sensor plot saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_phi_z_neg\\point_sensor_data.png [SensorExtractor._save_plot]\n      - Subtask 'extract_point_sensor_data' done in 1.16s [SensorExtractor.extract_point_sensor_data]\n      - Done in 1.16s [SensorExtractor.extract_point_sensor_data]\n  - Pickle report saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_phi_z_neg\\sar_stats_all_tissues.pkl [Reporter._save_pickle_report]\n  - HTML report saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_phi_z_neg\\sar_stats_all_tissues.html [Reporter._save_html_report]\n  - SAR results saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_phi_z_neg\\sar_results.json [ResultsExtractor._save_json_results]\n    - Subtask 'extract_results_total' done in 40.22s [FarFieldStudy.subtask]\n    - Done in 40.22s [FarFieldStudy.subtask]\nExtract deliverables verified. Updating metadata. [FarFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n--- Finished: extract (took 60.38s) --- [profile]\n\n--- FarFieldStudy Finished --- [FarFieldStudy.run]\n--- Logging shutdown --- \n--- Logging shutdown --- \nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\n[Info]  Topological Voxeler Report: Muscle\n    Target Grid: Primary\n    Duration: 2250.92 ms\n    Priority: 0\n    Edges: None\n    Voxels: 225848\n    Memory Consumption: 0.329872 kB\n\n[Info]  Topological Voxeler Report: Skin\n    Target Grid: Primary\n    Duration: 2382.99 ms\n    Priority: 0\n    Edges: None\n    Voxels: 50274\n    Memory Consumption: 0.409142 kB\n\n[Info]  Topological Voxeler Report: Fat\n    Target Grid: Primary\n    Duration: 1984.38 ms\n    Priority: 0\n    Edges: None\n    Voxels: 77275\n    Memory Consumption: 0.334229 kB\n\n[Info]  Topological Voxeler Report: SAT\n    Target Grid: Primary\n    Duration: 2126.31 ms\n    Priority: 0\n    Edges: None\n    Voxels: 70055\n    Memory Consumption: 0.408096 kB\n\n[Info]  Topological Voxeler Report: Brain_grey_matter\n    Target Grid: Primary\n    Duration: 565.155 ms\n    Priority: 0\n    Edges: None\n    Voxels: 26240\n    Memory Consumption: 0.011757 kB\n\n[Info]  Topological Voxeler Report: Connective_tissue\n    Target Grid: Primary\n    Duration: 776.406 ms\n    Priority: 0\n    Edges: None\n    Voxels: 10750\n    Memory Consumption: 0.340309 kB\n\n[Info]  Topological Voxeler Report: Cerebrospinal_fluid\n    Target Grid: Primary\n    Duration: 501.267 ms\n    Priority: 0\n    Edges: None\n    Voxels: 7731\n    Memory Consumption: 0.067123 kB\n\n[Info]  Topological Voxeler Report: Bone\n    Target Grid: Primary\n    Duration: 671.983 ms\n    Priority: 0\n    Edges: None\n    Voxels: 26810\n    Memory Consumption: 0.263748 kB\n\n[Info]  Topological Voxeler Report: Skull\n    Target Grid: Primary\n    Duration: 423.726 ms\n    Priority: 0\n    Edges: None\n    Voxels: 10030\n    Memory Consumption: 0.017731 kB\n\n[Info]  Topological Voxeler Report: Brain_white_matter\n    Target Grid: Primary\n    Duration: 290.855 ms\n    Priority: 0\n    Edges: None\n    Voxels: 13777\n    Memory Consumption: 0.009506 kB\n\n[Info]  Topological Voxeler Report: Tendon_Ligament\n    Target Grid: Primary\n    Duration: 365.255 ms\n    Priority: 0\n    Edges: None\n    Voxels: 7601\n    Memory Consumption: 0.264679 kB\n\n[Info]  Topological Voxeler Report: Large_intestine\n    Target Grid: Primary\n    Duration: 199.23 ms\n    Priority: 0\n    Edges: None\n    Voxels: 8087\n    Memory Consumption: 0.018135 kB\n\n[Info]  Topological Voxeler Report: Vertebrae\n    Target Grid: Primary\n    Duration: 175.431 ms\n    Priority: 0\n    Edges: None\n    Voxels: 8635\n    Memory Consumption: 0.016899 kB\n\n[Info]  Topological Voxeler Report: Lung\n    Target Grid: Primary\n    Duration: 133.629 ms\n    Priority: 0\n    Edges: None\n    Voxels: 33854\n    Memory Consumption: 0.013893 kB\n\n[Info]  Topological Voxeler Report: Marrow_red\n    Target Grid: Primary\n    Duration: 213.692 ms\n    Priority: 0\n    Edges: None\n    Voxels: 4051\n    Memory Consumption: 0.136726 kB\n\n[Info]  Topological Voxeler Report: Artery\n    Target Grid: Primary\n    Duration: 199.554 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2634\n    Memory Consumption: 0.164230 kB\n\n[Info]  Topological Voxeler Report: Large_intestine_lumen\n    Target Grid: Primary\n    Duration: 95.4279 ms\n    Priority: 0\n    Edges: None\n    Voxels: 17862\n    Memory Consumption: 0.016106 kB\n\n[Info]  Topological Voxeler Report: Air_internal\n    Target Grid: Primary\n    Duration: 67.0564 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1818\n    Memory Consumption: 0.003288 kB\n\n[Info]  Topological Voxeler Report: Vein\n    Target Grid: Primary\n    Duration: 151.312 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2365\n    Memory Consumption: 0.107765 kB\n\n[Info]  Topological Voxeler Report: Diaphragm\n    Target Grid: Primary\n    Duration: 68.3746 ms\n    Priority: 0\n    Edges: None\n    Voxels: 4149\n    Memory Consumption: 0.004707 kB\n\n[Info]  Topological Voxeler Report: Liver\n    Target Grid: Primary\n    Duration: 75.0861 ms\n    Priority: 0\n    Edges: None\n    Voxels: 20784\n    Memory Consumption: 0.008614 kB\n\n[Info]  Topological Voxeler Report: Stomach\n    Target Grid: Primary\n    Duration: 69.0303 ms\n    Priority: 0\n    Edges: None\n    Voxels: 5088\n    Memory Consumption: 0.004791 kB\n\n[Info]  Topological Voxeler Report: Nerve\n    Target Grid: Primary\n    Duration: 79.7387 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2150\n    Memory Consumption: 0.021904 kB\n\n[Info]  Topological Voxeler Report: Mucosa\n    Target Grid: Primary\n    Duration: 54.7631 ms\n    Priority: 0\n    Edges: None\n    Voxels: 229\n    Memory Consumption: 0.001251 kB\n\n[Info]  Topological Voxeler Report: Cerebellum\n    Target Grid: Primary\n    Duration: 40.9566 ms\n    Priority: 0\n    Edges: None\n    Voxels: 5681\n    Memory Consumption: 0.001984 kB\n\n[Info]  Topological Voxeler Report: Cartilage\n    Target Grid: Primary\n    Duration: 128.095 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1660\n    Memory Consumption: 0.126228 kB\n\n[Info]  Topological Voxeler Report: Blood_vessel\n    Target Grid: Primary\n    Duration: 76.5561 ms\n    Priority: 0\n    Edges: None\n    Voxels: 342\n    Memory Consumption: 0.054993 kB\n\n[Info]  Topological Voxeler Report: Intervertebral_disc\n    Target Grid: Primary\n    Duration: 46.2176 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2778\n    Memory Consumption: 0.005638 kB\n\n[Info]  Topological Voxeler Report: Kidney_cortex\n    Target Grid: Primary\n    Duration: 47.2658 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2999\n    Memory Consumption: 0.002182 kB\n\n[Info]  Topological Voxeler Report: Small_intestine\n    Target Grid: Primary\n    Duration: 35.3025 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2106\n    Memory Consumption: 0.001465 kB\n\n[Info]  Topological Voxeler Report: Heart_muscle\n    Target Grid: Primary\n    Duration: 40.2477 ms\n    Priority: 0\n    Edges: None\n    Voxels: 8775\n    Memory Consumption: 0.003059 kB\n\n[Info]  Topological Voxeler Report: Mandible\n    Target Grid: Primary\n    Duration: 28.3011 ms\n    Priority: 0\n    Edges: None\n    Voxels: 630\n    Memory Consumption: 0.001495 kB\n\n[Info]  Topological Voxeler Report: Stomach_lumen\n    Target Grid: Primary\n    Duration: 26.5157 ms\n    Priority: 0\n    Edges: None\n    Voxels: 4872\n    Memory Consumption: 0.002899 kB\n\n[Info]  Topological Voxeler Report: Ear_skin\n    Target Grid: Primary\n    Duration: 21.6652 ms\n    Priority: 0\n    Edges: None\n    Voxels: 456\n    Memory Consumption: 0.001396 kB\n\n[Info]  Topological Voxeler Report: Spleen\n    Target Grid: Primary\n    Duration: 24.8047 ms\n    Priority: 0\n    Edges: None\n    Voxels: 4554\n    Memory Consumption: 0.002548 kB\n\n[Info]  Topological Voxeler Report: Kidney_medulla\n    Target Grid: Primary\n    Duration: 19.4083 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1878\n    Memory Consumption: 0.001274 kB\n\n[Info]  Topological Voxeler Report: Esophagus\n    Target Grid: Primary\n    Duration: 17.2748 ms\n    Priority: 0\n    Edges: None\n    Voxels: 289\n    Memory Consumption: 0.001564 kB\n\n[Info]  Topological Voxeler Report: Tongue\n    Target Grid: Primary\n    Duration: 12.1429 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1389\n    Memory Consumption: 344 bytes\n\n[Info]  Topological Voxeler Report: Spinal_cord\n    Target Grid: Primary\n    Duration: 14.897 ms\n    Priority: 0\n    Edges: None\n    Voxels: 959\n    Memory Consumption: 0.001770 kB\n\n[Info]  Topological Voxeler Report: Thymus\n    Target Grid: Primary\n    Duration: 12.3944 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1083\n    Memory Consumption: 800 bytes\n\n[Info]  Topological Voxeler Report: Teeth\n    Target Grid: Primary\n    Duration: 12.2592 ms\n    Priority: 0\n    Edges: None\n    Voxels: 209\n    Memory Consumption: 440 bytes\n\n[Info]  Topological Voxeler Report: Trachea\n    Target Grid: Primary\n    Duration: 12.1505 ms\n    Priority: 0\n    Edges: None\n    Voxels: 148\n    Memory Consumption: 512 bytes\n\n[Info]  Topological Voxeler Report: Eye_Sclera\n    Target Grid: Primary\n    Duration: 9.8237 ms\n    Priority: 0\n    Edges: None\n    Voxels: 159\n    Memory Consumption: 224 bytes\n\n[Info]  Topological Voxeler Report: Ear_cartilage\n    Target Grid: Primary\n    Duration: 10.6314 ms\n    Priority: 0\n    Edges: None\n    Voxels: 144\n    Memory Consumption: 0.001251 kB\n\n[Info]  Topological Voxeler Report: Small_intestine_lumen\n    Target Grid: Primary\n    Duration: 10.1897 ms\n    Priority: 0\n    Edges: None\n    Voxels: 845\n    Memory Consumption: 560 bytes\n\n[Info]  Topological Voxeler Report: Thalamus\n    Target Grid: Primary\n    Duration: 7.9699 ms\n    Priority: 0\n    Edges: None\n    Voxels: 699\n    Memory Consumption: 192 bytes\n\n[Info]  Topological Voxeler Report: Bladder\n    Target Grid: Primary\n    Duration: 9.8187 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1120\n    Memory Consumption: 256 bytes\n\n[Info]  Topological Voxeler Report: Pancreas\n    Target Grid: Primary\n    Duration: 9.4287 ms\n    Priority: 0\n    Edges: None\n    Voxels: 406\n    Memory Consumption: 568 bytes\n\n[Info]  Topological Voxeler Report: Esophagus_lumen\n    Target Grid: Primary\n    Duration: 8.0396 ms\n    Priority: 0\n    Edges: None\n    Voxels: 133\n    Memory Consumption: 0.000984 kB\n\n[Info]  Topological Voxeler Report: Penis\n    Target Grid: Primary\n    Duration: 7.4725 ms\n    Priority: 0\n    Edges: None\n    Voxels: 333\n    Memory Consumption: 296 bytes\n\n[Info]  Topological Voxeler Report: Meniscus\n    Target Grid: Primary\n    Duration: 10.995 ms\n    Priority: 0\n    Edges: None\n    Voxels: 349\n    Memory Consumption: 288 bytes\n\n[Info]  Topological Voxeler Report: Trachea_lumen\n    Target Grid: Primary\n    Duration: 5.8468 ms\n    Priority: 0\n    Edges: None\n    Voxels: 223\n    Memory Consumption: 512 bytes\n\n[Info]  Topological Voxeler Report: Pons\n    Target Grid: Primary\n    Duration: 4.6231 ms\n    Priority: 0\n    Edges: None\n    Voxels: 461\n    Memory Consumption: 152 bytes\n\n[Info]  Topological Voxeler Report: Eye_vitreous_humor\n    Target Grid: Primary\n    Duration: 4.7601 ms\n    Priority: 0\n    Edges: None\n    Voxels: 336\n    Memory Consumption: 160 bytes\n\n[Info]  Topological Voxeler Report: Midbrain\n    Target Grid: Primary\n    Duration: 4.2621 ms\n    Priority: 0\n    Edges: None\n    Voxels: 284\n    Memory Consumption: 112 bytes\n\n[Info]  Topological Voxeler Report: Heart_lumen\n    Target Grid: Primary\n    Duration: 4.3962 ms\n    Priority: 0\n    Edges: None\n    Voxels: 254\n    Memory Consumption: 152 bytes\n\n[Info]  Topological Voxeler Report: Gallbladder\n    Target Grid: Primary\n    Duration: 5.5849 ms\n    Priority: 0\n    Edges: None\n    Voxels: 282\n    Memory Consumption: 376 bytes\n\n[Info]  Topological Voxeler Report: Pharynx\n    Target Grid: Primary\n    Duration: 3.5617 ms\n    Priority: 0\n    Edges: None\n    Voxels: 56\n    Memory Consumption: 40 bytes\n\n[Info]  Topological Voxeler Report: Hippocampus\n    Target Grid: Primary\n    Duration: 3.908 ms\n    Priority: 0\n    Edges: None\n    Voxels: 77\n    Memory Consumption: 72 bytes\n\n[Info]  Topological Voxeler Report: Medulla_oblongata\n    Target Grid: Primary\n    Duration: 2.7125 ms\n    Priority: 0\n    Edges: None\n    Voxels: 209\n    Memory Consumption: 96 bytes\n\n[Info]  Topological Voxeler Report: Prostate\n    Target Grid: Primary\n    Duration: 3.8348 ms\n    Priority: 0\n    Edges: None\n    Voxels: 119\n    Memory Consumption: 56 bytes\n\n[Info]  Topological Voxeler Report: Adrenal_gland\n    Target Grid: Primary\n    Duration: 3.3601 ms\n    Priority: 0\n    Edges: None\n    Voxels: 107\n    Memory Consumption: 152 bytes\n\n[Info]  Topological Voxeler Report: Bronchi\n    Target Grid: Primary\n    Duration: 2.5249 ms\n    Priority: 0\n    Edges: None\n    Voxels: 42\n    Memory Consumption: 32 bytes\n\n[Info]  Topological Voxeler Report: Testis\n    Target Grid: Primary\n    Duration: 3.0588 ms\n    Priority: 0\n    Edges: None\n    Voxels: 124\n    Memory Consumption: 40 bytes\n\n[Info]  Topological Voxeler Report: Patella\n    Target Grid: Primary\n    Duration: 5.8734 ms\n    Priority: 0\n    Edges: None\n    Voxels: 124\n    Memory Consumption: 136 bytes\n\n[Info]  Topological Voxeler Report: Ureter_Urethra\n    Target Grid: Primary\n    Duration: 4.5461 ms\n    Priority: 0\n    Edges: None\n    Voxels: 30\n    Memory Consumption: 384 bytes\n\n[Info]  Topological Voxeler Report: Bronchi_lumen\n    Target Grid: Primary\n    Duration: 1.4139 ms\n    Priority: 0\n    Edges: None\n    Voxels: 27\n    Memory Consumption: 24 bytes\n\n[Info]  Topological Voxeler Report: Cornea\n    Target Grid: Primary\n    Duration: 1.1398 ms\n    Priority: 0\n    Edges: None\n    Voxels: 11\n    Memory Consumption: 32 bytes\n\n[Info]  Topological Voxeler Report: Hypothalamus\n    Target Grid: Primary\n    Duration: 0.9341 ms\n    Priority: 0\n    Edges: None\n    Voxels: 25\n    Memory Consumption: 16 bytes\n\n[Info]  Topological Voxeler Report: Epididymis\n    Target Grid: Primary\n    Duration: 1.8855 ms\n    Priority: 0\n    Edges: None\n    Voxels: 22\n    Memory Consumption: 24 bytes\n\n[Info]  Topological Voxeler Report: Eye_lens\n    Target Grid: Primary\n    Duration: 0.6108 ms\n    Priority: 0\n    Edges: None\n    Voxels: 10\n    Memory Consumption: 16 bytes\n\n[Info]  Topological Voxeler Report: Hypophysis\n    Target Grid: Primary\n    Duration: 0.4382 ms\n    Priority: 0\n    Edges: None\n    Voxels: 11\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: Pinealbody\n    Target Grid: Primary\n    Duration: 0.4026 ms\n    Priority: 0\n    Edges: None\n    Voxels: 9\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: Larynx\n    Target Grid: Primary\n    Duration: 0.262 ms\n    Priority: 0\n    Edges: None\n    Voxels: 3\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: commissura_posterior\n    Target Grid: Primary\n    Duration: 0.0718 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: commissura_anterior\n    Target Grid: Primary\n    Duration: 0.1757 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: Complete Voxel Scene\n    Voxel Scene Memory Consumption: 0.002876 GB\n    Wall Clock Time: 7.6676 s\n\n[Info]  Visualization Data Memory Consumption: 0.036381 GB\n     Elapsed Time: 0.615359 s\n[Info]  Time step: 5.72711e-12 s\nTerminating study process... \n--- Logging shutdown --- \n--- Logging shutdown --- \n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <pre><code>run_bash(\"ls -R results/far_field/thelonious/700MHz/\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; ls -R results/far_field/thelonious/700MHz/\n\n------------------------------------------------------------\nresults/far_field/thelonious/700MHz/:\nenvironmental_phi_x_pos\nenvironmental_phi_z_neg\nenvironmental_theta_x_pos\nenvironmental_theta_z_neg\n\nresults/far_field/thelonious/700MHz/environmental_phi_x_pos:\nconfig.json\nfar_field_thelonious_700MHz_environmental_phi_x_pos.smash\nfar_field_thelonious_700MHz_environmental_phi_x_pos.smash_Results\npoint_sensor_data.png\nprogress.log\nsar_results.json\nsar_stats_all_tissues.html\nsar_stats_all_tissues.pkl\nverbose.log\n\nresults/far_field/thelonious/700MHz/environmental_phi_x_pos/far_field_thelonious_700MHz_environmental_phi_x_pos.smash_Results:\n04895e5e-6bf5-4bd1-8807-2fa8361581a6_AxLog.log\n04895e5e-6bf5-4bd1-8807-2fa8361581a6_AxLog.logAxSimSummary1.html\n04895e5e-6bf5-4bd1-8807-2fa8361581a6_Input.h5\n04895e5e-6bf5-4bd1-8807-2fa8361581a6_Input.log\n04895e5e-6bf5-4bd1-8807-2fa8361581a6_Output.h5\n04895e5e-6bf5-4bd1-8807-2fa8361581a6_Output.log\n04895e5e-6bf5-4bd1-8807-2fa8361581a6_Voxeler.log5\n\nresults/far_field/thelonious/700MHz/environmental_phi_z_neg:\nconfig.json\nfar_field_thelonious_700MHz_environmental_phi_z_neg.smash\nfar_field_thelonious_700MHz_environmental_phi_z_neg.smash_Results\npoint_sensor_data.png\nprogress.log\nsar_results.json\nsar_stats_all_tissues.html\nsar_stats_all_tissues.pkl\nverbose.log\n\nresults/far_field/thelonious/700MHz/environmental_phi_z_neg/far_field_thelonious_700MHz_environmental_phi_z_neg.smash_Results:\nb74e244e-d81d-4ea9-bd70-2bad50688c5d_AxLog.log\nb74e244e-d81d-4ea9-bd70-2bad50688c5d_AxLog.logAxSimSummary1.html\nb74e244e-d81d-4ea9-bd70-2bad50688c5d_Input.h5\nb74e244e-d81d-4ea9-bd70-2bad50688c5d_Input.log\nb74e244e-d81d-4ea9-bd70-2bad50688c5d_Output.h5\nb74e244e-d81d-4ea9-bd70-2bad50688c5d_Output.log\nb74e244e-d81d-4ea9-bd70-2bad50688c5d_Voxeler.log5\n\nresults/far_field/thelonious/700MHz/environmental_theta_x_pos:\nconfig.json\nfar_field_thelonious_700MHz_environmental_theta_x_pos.smash\nfar_field_thelonious_700MHz_environmental_theta_x_pos.smash_Results\npoint_sensor_data.png\nprogress.log\nsar_results.json\nsar_stats_all_tissues.html\nsar_stats_all_tissues.pkl\nverbose.log\n\nresults/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash_Results:\nff4ed249-3a58-4fcc-b6a0-f9e1f28b1fbd_AxLog.log\nff4ed249-3a58-4fcc-b6a0-f9e1f28b1fbd_AxLog.logAxSimSummary1.html\nff4ed249-3a58-4fcc-b6a0-f9e1f28b1fbd_Input.h5\nff4ed249-3a58-4fcc-b6a0-f9e1f28b1fbd_Input.log\nff4ed249-3a58-4fcc-b6a0-f9e1f28b1fbd_Output.h5\nff4ed249-3a58-4fcc-b6a0-f9e1f28b1fbd_Output.log\nff4ed249-3a58-4fcc-b6a0-f9e1f28b1fbd_Voxeler.log5\n\nresults/far_field/thelonious/700MHz/environmental_theta_z_neg:\nconfig.json\nfar_field_thelonious_700MHz_environmental_theta_z_neg.smash\nfar_field_thelonious_700MHz_environmental_theta_z_neg.smash_Results\npoint_sensor_data.png\nprogress.log\nsar_results.json\nsar_stats_all_tissues.html\nsar_stats_all_tissues.pkl\nverbose.log\n\nresults/far_field/thelonious/700MHz/environmental_theta_z_neg/far_field_thelonious_700MHz_environmental_theta_z_neg.smash_Results:\n820cac89-ce7c-4720-91b0-34eaecb818bd_AxLog.log\n820cac89-ce7c-4720-91b0-34eaecb818bd_AxLog.logAxSimSummary1.html\n820cac89-ce7c-4720-91b0-34eaecb818bd_Input.h5\n820cac89-ce7c-4720-91b0-34eaecb818bd_Input.log\n820cac89-ce7c-4720-91b0-34eaecb818bd_Output.h5\n820cac89-ce7c-4720-91b0-34eaecb818bd_Output.log\n820cac89-ce7c-4720-91b0-34eaecb818bd_Voxeler.log5\n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p>You'll see 4 directories (one per simulation):</p> <pre><code>results/far_field/thelonious/700MHz/\n\u251c\u2500\u2500 environmental_theta_x_pos/\n\u251c\u2500\u2500 environmental_phi_x_pos/\n\u251c\u2500\u2500 environmental_theta_z_neg/\n\u2514\u2500\u2500 environmental_phi_z_neg/\n</code></pre> <p>Note: Directory names use the format <code>environmental_{polarization}_{direction}</code> (e.g., <code>theta_x_pos</code> means theta polarization, x_pos direction).</p> <p>Each contains: - <code>*.smash</code> (Sim4Life project file) - <code>*.smash_Results/*_Input.h5</code> (simulation input settings file) - <code>*.smash_Results/*_Output.h5</code> (simulation results with EM fields) - <code>sar_results.json</code> (extracted SAR values) - <code>sar_stats_all_tissues.pkl</code> (detailed tissue data) - <code>sar_stats_all_tissues.html</code> (HTML report of tissue SAR) - <code>point_sensor_data.png</code> (field convergence plot) - <code>config.json</code> (metadata with config hash, completion status) - <code>verbose.log</code> a log file with everything printed (including Sim4Life) - <code>progress.log</code> a log file with only high-level progress prints (as seen in the GUI also)</p> <p>Note that the two log files are for that specific simulation, and if you want to see the full log file, you can find it under <code>logs/*.log</code> with a timestamp as filename.</p> <p></p> <pre><code>run_bash(\"cat results/far_field/thelonious/700MHz/environmental_theta_x_pos/sar_results.json\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; cat results/far_field/thelonious/700MHz/environmental_theta_x_pos/sar_results.json\n\n------------------------------------------------------------\n{\n    \"input_power_W\": 0.0005309910780076142,\n    \"input_power_frequency_MHz\": 700.0,\n    \"eyes_group_weighted_avg_sar\": 1.282829580112987e-05,\n    \"eyes_group_peak_sar\": 1.6668154785293154e-05,\n    \"skin_group_weighted_avg_sar\": 1.734516314368961e-05,\n    \"skin_group_peak_sar\": 0.0001515590847702697,\n    \"brain_group_weighted_avg_sar\": 1.109098380334678e-05,\n    \"brain_group_peak_sar\": 3.142984496662393e-05,\n    \"genitals_group_weighted_avg_sar\": 3.8027582534518573e-06,\n    \"genitals_group_peak_sar\": 7.225423360068817e-06,\n    \"whole_body_sar\": 1.0254515500239604e-05,\n    \"peak_sar_10g_W_kg\": 0.00015270481526385993,\n    \"peak_sar_details\": {\n        \"PeakValue\": 0.00015270481526385993,\n        \"PeakLocation\": [\n            -0.13716261088848114,\n            0.0010393965058028698,\n            -0.18749523162841797\n        ],\n        \"PeakCell\": [\n            67,\n            72,\n            313\n        ],\n        \"PeakCubeSideLength\": 0.020847758278250694\n    },\n    \"power_balance\": {\n        \"Pin\": 0.0005309910780076142,\n        \"LumpedLoss\": 0.0,\n        \"DielLoss\": 0.00019936609570743381,\n        \"SIBCLoss\": 0.0,\n        \"RadPower\": 0.0004251346321493339,\n        \"Balance\": 117.61039944400207\n    },\n    \"point_sensor_data\": {\n        \"Lower Left Bottom\": {\n            \"time_s\": [\n                5.727106722891451e-12,\n                3.436264120471044e-11,\n                6.29981691813164e-11,\n                0.3444145619869232\n            ]\n        }\n    }\n}------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p>Key metrics</p> <ul> <li>Whole-body SAR: Average absorption across entire phantom (here 1.02e-5 mW/kg per 1W input power)</li> <li>SAR of groups: The weighted average SAR for a number of groups (brain, genitals, skin, eyes), which are defined under <code>data/material_name_mapping.json</code></li> <li>Peak 10g SAR: Maximum SAR averaged over 10g tissue cube (as defined in the 62704-1 IEC/IEEE standard), in both the whole body as in the groups</li> <li>Power balance: Energy conservation check (should be close to 100%). Note that the input power comes from a theoretical calculation as Sim4Life does not (yet) support input power of a far-field source.</li> </ul> <p>All values are normalized to 1W input power. Scale them based on actual exposure levels.</p> <pre><code>run_bash(\"goliat study tutorial_1_far_field.json\")\n</code></pre> <p>Watch the GUI progress through more simulations.</p>"},{"location":"tutorials/01_far_field_basics/#tutorial-1-far-field-basics","title":"Tutorial 1: Far-field basics","text":"<p>Learn environmental exposure simulations using plane waves.</p>"},{"location":"tutorials/01_far_field_basics/#what-youll-learn","title":"What you'll learn","text":"<ul> <li>How far-field simulations work (plane waves from different directions)</li> <li>Reading and understanding config files</li> <li>Running your first GOLIAT study</li> <li>Finding and interpreting results</li> </ul> <p>Related documentation: User guide (far-field workflow)</p>"},{"location":"tutorials/01_far_field_basics/#prerequisites-and-setup","title":"Prerequisites and setup","text":"<p>Before starting this tutorial, you need:</p>"},{"location":"tutorials/01_far_field_basics/#required-software","title":"Required software","text":"<p>Sim4Life 8.2.0: GOLIAT requires Sim4Life version 8.2.0 with a valid license for the software and the Duke, Ella, Thelonious and Eartha phantoms. Sim4Life is commercial software from ZMT website. Other versions are untested and may not work correctly. Since Sim4Life only runs on Windows, only Windows is supported, although Linux is supported experimentally on Sim4Life web.</p> <p>Git Bash: GOLIAT commands run in a Bash shell. On Windows, use Git Bash (included with Git for Windows). Other shells may still work though but are not tested and not shown in these tutorials.</p> <p>Install Git from https://git-scm.com/downloads if needed.</p>"},{"location":"tutorials/01_far_field_basics/#initial-setup","title":"Initial setup","text":"<p>If this is your first time using GOLIAT, run these commands from the repository root:</p> <pre><code>cd /path/to/goliat\n\n# 1. Add Sim4Life Python to PATH\nsource .bashrc\n\n# 2. Install GOLIAT in editable mode\npython -m pip install -e .\n\n# 3. Run initialization (downloads models, sets up directories)\ngoliat init\n</code></pre> <p>This one-time setup: - Installs Python dependencies from <code>pyproject.toml</code> - Installs GOLIAT package (makes <code>goliat</code> command available) - Downloads phantom models (Duke, Thelonious, Eartha, Ella) - Downloads antenna CAD models - Creates required directories (<code>data/</code>, <code>configs/</code>, <code>results/</code>, <code>logs/</code>)</p> <p>The initialization takes 5-10 minutes depending on your internet speed. If you accidentally delete parts of this setup, <code>goliat init</code> can repair it. A <code>.setup_done</code> file is created under <code>data/</code>.</p> <p>Already initialized? Just run <code>source .bashrc</code> when opening a new terminal, then skip to the next section.</p> <p>For detailed setup instructions, see the quick start guide.</p>"},{"location":"tutorials/01_far_field_basics/#hardware-recommendations","title":"Hardware recommendations","text":"<p>GPU (recommended): GOLIAT uses the FDTD solver (iSolve), which runs much faster on GPU.</p> <p>The solver kernel is configured in <code>base_config.json</code>:</p> <pre><code>\"solver_settings\": {\n  \"kernel\": \"acceleware\"  // or \"cuda\" or \"software\"\n}\n</code></pre> <p>Use <code>\"acceleware\"</code> if you have an AMD or NVIDIA GPU. Use <code>\"cuda\"</code> for NVIDIA GPUs only. Use <code>\"software\"</code> if you don't have a GPU (much slower).</p>"},{"location":"tutorials/01_far_field_basics/#running-commands","title":"Running commands","text":"<p>GOLIAT commands should be run from the repository root directory where you have:</p> <pre><code>goliat/\n\u2014\u2014 configs/          # Configuration files\n\u2014\u2014 data/             # Downloaded models\n\u2014\u2014 goliat/           # Source code\n\u2014\u2014 results/          # Simulation outputs\n\u2014\u2014 logs/             # Log files\n\u2014\u2014 .bashrc           # Shell setup\n</code></pre> <p>All tutorial commands assume you're in this root directory.</p>"},{"location":"tutorials/01_far_field_basics/#about-the-notebook-code-blocks","title":"About the notebook code blocks","text":"<p>This tutorial includes Python code blocks for running commands. These are designed for Jupyter notebooks if you prefer that workflow.</p> <p>If you're running these in VS Code, make sure you set <code>C:\\Program Files\\Sim4Life_8.2.0.16876\\Python\\python.exe</code> as your VS Code Python (with <code>&amp;gt;Python: Select interpreter</code>) and that you have Jupyter IPython installed.</p> <p>If you're using notebooks, run this setup once per session:</p>"},{"location":"tutorials/01_far_field_basics/#understanding-far-field-exposure","title":"Understanding far-field exposure","text":"<p>Far-field simulations model environmental EMF exposure. The RF source is distant from the person (broadcast antennas, base stations, ambient fields).</p> <p>Instead of placing an antenna near the body, we illuminate the phantom with plane waves from different directions. This builds transfer functions that relate measured E-field strength to absorbed power.</p>"},{"location":"tutorials/01_far_field_basics/#key-concepts","title":"Key concepts","text":"<p>Incident directions</p> <p>Plane waves can come from 6 orthogonal directions: - <code>x_pos</code>, <code>x_neg</code> (front/back) - <code>y_pos</code>, <code>y_neg</code> (left/right) - <code>z_pos</code>, <code>z_neg</code> (top/bottom)</p> <p>Polarizations</p> <p>For each direction, the E-field has two orientations: - <code>theta</code> polarization - <code>phi</code> polarization</p> <p>This tutorial runs 4 simulations (2 directions \u00d7 2 polarizations).</p> <p></p>"},{"location":"tutorials/01_far_field_basics/#the-configuration-file","title":"The configuration file","text":"<p>Here's our config for this tutorial. It runs 4 simulations with minimal settings.</p>"},{"location":"tutorials/01_far_field_basics/#breaking-down-the-config","title":"Breaking down the config","text":"<p>Inheritance</p> <pre><code>{\"extends\": \"base_config.json\"\n</code></pre> <p>This config builds on <code>base_config.json</code>, which has common settings (solver parameters, gridding defaults, convergence criteria). We only override study-specific settings.</p> <p>The base config includes many parameters you don't need to understand yet. Most will be explained throughout these tutorials as they become relevant. For now, just know it provides sensible defaults for: - FDTD solver settings (boundary conditions, kernel) - Convergence detection (auto-termination levels) - Grid generation (automatic mode, refinement) - Point sensors for field monitoring - Execution control flags</p> <p>You can check it later with <code>cat configs/base_config.json</code>, but there's no need to modify it for standard studies.</p> <p>Study type</p> <pre><code>\"study_type\": \"far_field\"\n</code></pre> <p>Tells GOLIAT this is a far-field study (plane waves), not near-field (antennas).</p> <p>Phantom selection</p> <pre><code>\"phantoms\": [\"thelonious\"]\n</code></pre> <p>We use Thelonious (male child) for this tutorial. If you don't have a license for Thelonious, feel free to use another phantoms, like Duke.</p> <p>Frequency</p> <pre><code>\"frequencies_mhz\": [700]\n</code></pre> <p>Single frequency at 700 MHz (common cellular band).</p> <p>Far-field parameters</p> <pre><code>\"far_field_setup\": {\n  \"type\": \"environmental\",\n  \"environmental\": {\n    \"incident_directions\": [\"x_pos\", \"z_neg\"],\n    \"polarizations\": [\"theta\", \"phi\"]\n  }\n}\n</code></pre> <ul> <li>Type: \"environmental\" (standard approach, there's also \"auto_induced\" for future use)</li> <li>Directions: Testing x_pos (front) and z_neg (from below)</li> <li>Polarizations: Both theta and phi for each direction</li> <li>Total simulations: 2 directions * 2 polarizations = 4 simulations</li> </ul> <p>Execution control</p> <pre><code>\"execution_control\": {\n  \"do_setup\": true,\n  \"do_run\": true,\n  \"do_extract\": true\n}\n</code></pre> <p>Run all three phases: 1. Setup: Build the Sim4Life scene (phantom, plane wave, grid) 2. Run: Execute the EM simulation 3. Extract: Pull SAR data from outputs</p> <p>For full config reference: configuration guide</p> <p></p>"},{"location":"tutorials/01_far_field_basics/#running-the-study","title":"Running the study","text":"<p>This will launch the GUI, run 4 simulations (a few minutes each depending on hardware), and extract SAR results.</p>"},{"location":"tutorials/01_far_field_basics/#what-happened","title":"What happened","text":"<p>The GOLIAT GUI opened and ran everything automatically, while your Bash shell logged a more verbose output, including the one from Sim4Life.</p> <p></p> <p>You can click around the various tab which are explained in another tutorial. The 'time remaining' is computed based on live timing results and improves as profiling data becomes available in your study.</p> <p>Phase breakdown</p> <p>Setup phase:     - Created <code>.smash</code> project in Sim4Life     - Placed phantom in scene     - Configured plane wave source (E-field = 1 V/m)     - Set up computational grid and various settings     - Assigned tissue materials from IT'IS database     - Voxelized the grid and saved the project.</p> <p>Run phase:     - Executed FDTD solver via iSolve using AXWare GPU acceleration     - Monitored convergence     - Saved EM fields to <code>*_Output.h5</code></p> <p>Extract phase:     - Calculated whole-body average SAR     - Extracted tissue-specific SAR values     - Computed peak spatial-average SAR (psSAR10g)     - Generated JSON, pickle, and HTML reports</p> <p>This happened 4 times (once per direction/polarization).</p>"},{"location":"tutorials/01_far_field_basics/#what-happened-in-sim4life","title":"What happened in Sim4Life","text":"<p>GOLIAT automatically built scenes in Sim4Life while running.</p> <p> </p>"},{"location":"tutorials/01_far_field_basics/#direction","title":"Direction","text":"<p>Each incident direction creates different exposure: - x_pos: Wave travels in +X direction (front of phantom) - z_neg: Wave travels in -Z direction (from below)</p>"},{"location":"tutorials/01_far_field_basics/#polarization","title":"Polarization","text":"<p>For each direction, the E-field orientation differs: - theta: E-field in one plane - phi: E-field perpendicular to theta</p>"},{"location":"tutorials/01_far_field_basics/#exploring-results","title":"Exploring results","text":"<p>GOLIAT organizes results in a structured directory tree.</p>"},{"location":"tutorials/01_far_field_basics/#looking-at-sar-results","title":"Looking at SAR results","text":"<p>Check the JSON from one simulation:</p>"},{"location":"tutorials/01_far_field_basics/#html-report","title":"HTML report","text":"<p>Open <code>sar_stats_all_tissues.html</code> in a browser. It shows a detailed table of SAR values for every tissue type present in the phantom, the group data, and more details </p> <p></p> <p>This helps identify which tissues absorb the most energy.</p>"},{"location":"tutorials/01_far_field_basics/#point-sensor-convergence-plots","title":"Point sensor convergence plots","text":"<p>Each simulation includes a plot showing E-field magnitude over time at monitoring points.</p> <p></p> <p>These plots verify that the simulation ran long enough. You should see: - Initial oscillations as fields build up - Gradual decay as steady state is reached - Stable final values (convergence)</p> <p>If fields are still changing rapidly at the end, the simulation may need more time. You can look in the detailed logs to examine if <code>iSolve</code> detected convergence for a specific point sensor.</p>"},{"location":"tutorials/01_far_field_basics/#simulation-time","title":"Simulation time","text":"<p>The simulation time is controlled primarily by the following settings:</p> <pre><code>\"simulation_parameters\": {\n  \"global_auto_termination\": \"GlobalAutoTerminationUserDefined\",\n  \"convergence_level_dB\": -15,\n  \"simulation_time_multiplier\": 3.5,\n  \"number_of_point_sensors\": 2\n}\n</code></pre> <p>Key parameters:</p> <ul> <li><code>global_auto_termination</code>: As defined in the Sim4Life manual, one can pick how stringent the convergence detection algo is.</li> <li><code>convergence_level_dB</code>: For user-defined termination, you can control the field decay threshold here.</li> <li><code>simulation_time_multiplier</code>: This controls the total time the simulation can maximally take. It starts from the theoretical time to cross the bounding box's diagonal at the speed of light in a vacuum, then multiplies this amount by the multiplier.</li> <li><code>number_of_point_sensors</code>: How many monitoring points to place (default 2). You can control where these are placed with <code>point_source_order</code> and pick up to 8 points (for each corner).</li> </ul> <p>Sim4Life includes built-in convergence detection that automatically stops simulations when fields reach steady state. This prevents wasting computation time after the solution has converged.</p> <p>Sim4Life offers several preset termination criteria:</p> <ul> <li><code>GlobalAutoTerminationNone</code>: No automatic termination (runs full specified time)</li> <li><code>GlobalAutoTerminationWeak</code></li> <li><code>GlobalAutoTerminationMedium</code></li> <li><code>GlobalAutoTerminationStrict</code></li> <li><code>GlobalAutoTerminationUserDefined</code>: Custom threshold (what we used)</li> </ul> <p>The details can be found in the Sim4Life manual. The field sensor convergence as a whole is taken into account.</p> <p>GOLIAT configuration:</p> <p>The base config uses <code>GlobalAutoTerminationUserDefined</code> with a -15 dB threshold:</p> <pre><code>\"global_auto_termination\": \"GlobalAutoTerminationUserDefined\",\n\"convergence_level_dB\": -15\n</code></pre> <p>This means the simulation stops when transient energy decays to 1/1000 (10^(-15/10)) of its initial value, which provides sufficient accuracy for SAR studies.</p>"},{"location":"tutorials/01_far_field_basics/#what-you-learned","title":"What you learned","text":"<ol> <li>Far-field studies use plane waves to model environmental exposure</li> <li>Config files control everything (phantoms, frequencies, directions, polarizations)</li> <li>GOLIAT automates the entire workflow (setup, run, extract)</li> <li>Results are organized by study type, phantom, frequency, and scenario</li> <li>SAR metrics quantify absorption (whole-body, localized, peak 10g)</li> </ol>"},{"location":"tutorials/01_far_field_basics/#try-this","title":"Try this","text":"<p>Edit <code>tutorial_1_far_field.json</code> and: - Add more directions (<code>y_pos</code> and <code>y_neg</code>) - Add another phantom (<code>eartha</code> for adult female) - Add another frequency (<code>835</code>)</p> <p>Then rerun:</p>"},{"location":"tutorials/01_far_field_basics/#next-steps","title":"Next steps","text":"<ul> <li>Tutorial 2: Configuration and caching (how configs work, avoiding redundant runs)</li> <li>Configuration guide: Full parameter reference at ../developer_guide/configuration.md</li> <li>User guide: Far-field workflows at user_guide.md</li> <li>Features: See what else GOLIAT does at Full List of Features</li> </ul> <p>Ready for tutorial 2? Learn how configs extend each other and how GOLIAT avoids redundant work.</p>"},{"location":"tutorials/02_configuration_and_caching/","title":"2. Configuration and Caching","text":"<pre><code>from pathlib import Path\nimport importlib.util\n\np = Path.cwd()\nwhile not (p / \"scripts\" / \"notebook_helpers.py\").exists():\n    p = p.parent\nspec = importlib.util.spec_from_file_location(\"_\", p / \"scripts\" / \"notebook_helpers.py\")\nm = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(m)\nrun_bash = m.get_run_bash()\n\nimport IPython\n\nIPython.core.display.max_output_size = None\n</code></pre> <p>This helper function lets you run bash commands from Python cells using <code>run_bash('command')</code>. The setup also disables output truncation so you can see all command output.</p> <p>If you're using bash directly (recommended), ignore the Python code blocks and just run the commands directly. Make sure to always run <code>source .bashrc</code> first.</p> <pre><code>run_bash(\"cat configs/base_config.json\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; cat configs/base_config.json\n\n------------------------------------------------------------\n{\n    \"use_gui\": true,\n    \"execution_control\": {\n        \"do_setup\": true,\n        \"do_run\": true,\n        \"do_extract\": true,\n        \"only_write_input_file\": false,\n        \"auto_cleanup_previous_results\": []\n    },\n    \"simulation_parameters\": {\n        \"global_auto_termination\": \"GlobalAutoTerminationUserDefined\",\n        \"convergence_level_dB\": -15,\n        \"simulation_time_multiplier\": 3.5,\n        \"number_of_point_sensors\": 2,\n        \"point_source_order\": [\n            \"lower_left_bottom\",\n            \"top_right_up\",\n            \"lower_right_bottom\",\n            \"top_left_up\",\n            \"lower_left_up\",\n            \"top_right_bottom\",\n            \"lower_right_up\",\n            \"top_left_bottom\"\n        ]\n    },\n    \"gridding_parameters\": {\n        \"global_gridding\": {\n            \"grid_mode\": \"manual\",\n            \"manual_fallback_max_step_mm\": 3.0\n        },\n        \"padding\": {\n            \"padding_mode\": \"automatic\",\n            \"manual_bottom_padding_mm\": [0, 0, 0],\n            \"manual_top_padding_mm\": [0, 0, 0]\n        }\n    },\n    \"solver_settings\": {\n        \"kernel\": \"acceleware\",\n        \"server\": \"localhost\",\n        \"boundary_conditions\": {\n            \"type\": \"UpmlCpml\",\n            \"strength\": \"Low\"\n        }\n    },\n    \"verbose\": false,\n    \"manual_isolve\": true,\n    \"data_setup\": {\n        \"gdrive_url\": \"https://drive.google.com/drive/folders/1Ps0ilW6yx4Z5VoWRZKrkhP225m8lBQOV?usp=sharing&amp;confirm=t\",\n        \"gdrive_url_aws\": \"https://drive.google.com/uc?id=1etS9uyi0Ns-vOtG2q0G1hU0LLw0M_dq7\",\n        \"data_dir\": \"data\"\n    }\n}\n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p>It contains settings shared across all studies: - <code>use_gui</code>: whether to use the GUI - <code>simulation_parameters</code>: which we covered last tutorial - <code>gridding_parameters</code>: the default gridding settings. If you forgot to set your specific gridding settings, this is where it will default to. - <code>solver_settings</code>: settings for <code>iSolve</code>. We already covered the kernel, but here you can also enter the name of a remote ARES server here if you want. You can set the strength of the boundary condition too.</p> <p>These apply to every study unless overridden. It recursively merges nested dictionaries: child values override parent values for matching keys, while preserving all parent keys not specified in the child.</p> <pre><code>run_bash(\"cat configs/far_field_config.json\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; cat configs/far_field_config.json\n\n------------------------------------------------------------\n{\n    \"extends\": \"base_config.json\",\n    \"study_type\": \"far_field\",\n    \"execution_control\": {\n        \"do_setup\": true,\n        \"only_write_input_file\": false,\n        \"do_run\": true,\n        \"do_extract\": true,\n        \"batch_run\": false\n    },\n    \"phantoms\": [\n        \"duke\",\n        \"ella\",\n        \"eartha\",\n        \"thelonious\"\n    ],\n    \"frequencies_mhz\": [\n        450,\n        700,\n        835,\n        1450,\n        2140,\n        2450,\n        3500,\n        5200,\n        5800\n    ],\n    \"far_field_setup\": {\n        \"type\": \"environmental\",\n        \"environmental\": {\n            \"incident_directions\": [\n                \"x_pos\",\n                \"x_neg\",\n                \"y_pos\",\n                \"y_neg\",\n                \"z_pos\",\n                \"z_neg\"\n            ],\n            \"polarizations\": [\n                \"theta\",\n                \"phi\"\n            ]\n        },\n        \"auto_induced\": {\n            \"grid_resolution_deg\": 15\n        }\n    },\n    \"simulation_parameters\": {\n        \"bbox_padding_mm\": 0,\n        \"simulation_bbox_points\": 8,\n        \"number_of_point_sensors\": 2\n    },\n    \"gridding_parameters\": {\n        \"global_gridding\": {\n            \"grid_mode\": \"manual\",\n            \"manual_fallback_max_step_mm\": 3.0\n        },\n        \"global_gridding_per_frequency\": {\n            \"450\": 2.5,\n            \"700\": 2.5,\n            \"835\": 2.5,\n            \"1450\": 2.5,\n            \"2140\": 1.694,\n            \"2450\": 1.482,\n            \"3500\": 1.0,\n            \"5200\": 1.0,\n            \"5800\": 1.0\n        },\n        \"padding\": {\n            \"padding_mode\": \"manual\",\n            \"manual_bottom_padding_mm\": [0, 0, 0],\n            \"manual_top_padding_mm\": [0, 0, 0]\n        }\n    }\n}\n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p>It starts with:</p> <pre><code>{\n  \"extends\": \"base_config.json\",\n  \"study_type\": \"far_field\",\n  ...\n}\n</code></pre> <p>This inherits everything from <code>base_config.json</code>, then adds or overrides: - <code>study_type</code> (specifies this is far-field) - <code>phantoms</code> (lists which phantoms to use) - <code>frequencies_mhz</code> (which frequencies to simulate) - <code>far_field_setup</code> (far-field specific settings like directions, polarizations)</p> <p>The result is a complete config (base settings + far-field overrides).</p> <pre><code>graph TD\n    base[base_config.jsonShared settings]\n    nf[near_field_config.jsonNear-field specifics]\n    ff[far_field_config.jsonFar-field specifics]\n    \n    base --&gt;|extends| nf\n    base --&gt;|extends| ff\n    \n    style base fill:#4CAF50\n    style nf fill:#2196F3\n    style ff fill:#2196F3\n</code></pre>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom  <pre><code>run_bash(\"cat configs/tutorial_2_custom.json\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; cat configs/tutorial_2_custom.json\n\n------------------------------------------------------------\n{\n  \"extends\": \"far_field_config.json\",\n  \"phantoms\": [\"thelonious\", \"eartha\"],\n  \"frequencies_mhz\": [700, 835]\n}\n\n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <pre><code>{\n  \"extends\": \"far_field_config.json\",\n  \"phantoms\": [\"thelonious\", \"eartha\"],\n  \"frequencies_mhz\": [700, 835]\n}\n</code></pre> <p>This inherits from <code>far_field_config.json</code> (which already inherits from <code>base_config.json</code>), then overrides only the phantoms and frequencies.</p> <p>The inheritance chain: <code>base_config.json</code> \u2192 <code>far_field_config.json</code> \u2192 <code>tutorial_2_custom.json</code></p> <p>Everything else (directions, polarizations, solver settings, gridding) comes from the parent configs.</p> <pre><code>run_bash(\"goliat validate tutorial_2_custom.json\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; goliat validate tutorial_2_custom.json\n\n------------------------------------------------------------\nValidating config: tutorial_2_custom.json\n  \u2713 Study type: far_field\n  \u2713 Phantoms: thelonious, eartha\n  \u2713 Frequencies: 700, 835 MHz\n  \u2713 Config is valid!\n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p>Let's intentionally break the config to see validation catch it. Edit <code>tutorial_2_custom.json</code> and change <code>study_type</code> to <code>invalid_type</code>:</p> <pre><code>{\n  \"extends\": \"far_field_config.json\",\n  \"study_type\": \"invalid_type\",\n  ...\n}\n</code></pre> <p>Run validation again:</p> <pre><code>run_bash(\"goliat validate tutorial_2_custom.json\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; goliat validate tutorial_2_custom.json\n\n------------------------------------------------------------\nValidating config: tutorial_2_custom.json\n  \u2713 Study type: far_field\n  \u2713 Phantoms: thelonious, eartha\n  \u2713 Frequencies: 700, 835 MHz\n  \u2713 Config is valid!\n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p>The validator checks: - Required fields are present (<code>study_type</code>, <code>phantoms</code>) - Near-field configs have <code>antenna_config</code>; far-field configs have <code>frequencies_mhz</code> - Config file loads successfully (will error if files referenced in <code>extends</code> don't exist)</p> <p>Note: The validator checks that required fields exist, but doesn't validate that <code>study_type</code> values are valid. When you run a study, GOLIAT will error if <code>study_type</code> is not \"near_field\" or \"far_field\".</p> <p>For full parameter reference: configuration guide</p> <pre><code>run_bash(\"goliat study tutorial_2_caching.json --no-cache\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; goliat study tutorial_2_caching.json --no-cache\n\n------------------------------------------------------------\nStarting Sim4Life application... \nInitializing Application [stdout]\nInitializing Application [stderr]\n[Warn]  Unable to load module 'C:\\Program Files\\Sim4Life_8.2.0.16876\\MusaikInterface.xdll'\nJosua    : [Info]  Sync\nJosua    : [Info]  Sync\nJosua    : [Info]  Command [Query Handshake] &lt;ef6545cd-b438-4118-91aa-db8ea355525a;127.0.0.1;WIN10-NEW&gt;\nJosua    : [Info]  Property [CAresSettings]\n[Info]  Connection to local Ares successfully established.\nSim4Life application started. \n--- Starting Far-Field Study: tutorial_2_caching.json --- [FarFieldStudy._run_study]\n\n--- Processing Simulation 1/1: thelonious, 700MHz, x_pos, theta --- [FarFieldStudy._run_study]\n--- Starting: setup --- [profile]\nProject path set to: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash [ProjectManager.create_or_open_project]\n`--no-cache` flag is active. Forcing a new setup by skipping verification. [ProjectManager.create_or_open_project]\n--- Simulation-specific progress logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos\\progress.log --- \n--- Simulation-specific verbose logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos\\verbose.log --- \nDeleting existing project file at C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash [ProjectManager.create_new]\nCreating a new empty project in memory. [ProjectManager.create_new]\nInitializing model by creating and deleting a dummy block... [ProjectManager.create_new]\nModel initialized, ready for population. [ProjectManager.create_new]\n  - Setup simulation... [FarFieldStudy.subtask]\n--- Setting up single Far-Field sim --- [FarFieldSetup.run_full_setup]\n    - Load phantom... [FarFieldSetup.run_full_setup]\n--- Running Phantom Check --- [PhantomSetup._log]\nFound 2 total entities in the project. [PhantomSetup._log]\n--- Phantom Check Result: Phantom not found in project. --- [PhantomSetup._log]\nPhantom not found in document. Importing from 'C:\\Users\\user\\repo-clean\\data\\phantoms\\thelonious.sab'... [PhantomSetup._log]\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nPhantom imported successfully. [PhantomSetup._log]\n      - Subtask 'setup_load_phantom' done in 8.88s [FarFieldSetup.run_full_setup]\n      - Done in 8.88s [FarFieldSetup.run_full_setup]\n    - Configure scene (bbox, plane wave)... [FarFieldSetup.run_full_setup]\nCreating simulation bounding box for far-field... [FarFieldSetup._create_or_get_simulation_bbox]\n  - Created far-field simulation BBox with 50mm padding. [FarFieldSetup._create_or_get_simulation_bbox]\n  - Creating simulation: EM_FDTD_thelonious_700MHz_x_pos_theta [FarFieldSetup._create_simulation_entity]\n  - Using simulation time multiplier: 3.5 [FarFieldSetup._apply_simulation_time_and_termination]\n  - Simulation time set to 11.44 periods. [FarFieldSetup._apply_simulation_time_and_termination]\n  - Setting termination criteria to: GlobalAutoTerminationUserDefined [FarFieldSetup._apply_simulation_time_and_termination]\n    - Convergence level set to: -15 dB [FarFieldSetup._apply_simulation_time_and_termination]\n      - Subtask 'setup_configure_scene' done in 0.33s [FarFieldSetup.run_full_setup]\n      - Done in 0.33s [FarFieldSetup.run_full_setup]\n    - Assign materials... [FarFieldSetup.run_full_setup]\nAssigning materials... [MaterialSetup.assign_materials]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\n[Info]  \nMass Density has changed from 1000 to 1.2050000000000001\nMass Density has changed from 1.2050000000000001 to 1.2\nRelative Permittivity has changed from 1 to 0\nSimulation : [Warn]  Unable to find any match for following settings properties: Magnetic Conductivity\nSimulation : [Warn]  Unable to find any match for following settings properties: Relative Permeability\n      - Subtask 'setup_materials' done in 5.84s [FarFieldSetup.run_full_setup]\n      - Done in 5.84s [FarFieldSetup.run_full_setup]\n    - Configure solver (gridding, boundaries, sensors)... [FarFieldSetup.run_full_setup]\nSetting up gridding... [GriddingSetup.setup_gridding]\n  - Looking for global grid bounding box: 'far_field_simulation_bbox' [GriddingSetup._setup_main_grid]\n  - Using manual gridding. [GriddingSetup._setup_main_grid]\n  - Global and added manual grid set with global resolution: 3.0 mm. [GriddingSetup._setup_main_grid]\n  - Using automatic padding. [GriddingSetup._setup_main_grid]\n  - No antenna components provided, skipping subgridding. [GriddingSetup.setup_gridding]\nSetting up boundary conditions... [BoundarySetup.setup_boundary_conditions]\n  - Setting global boundary conditions to: UpmlCpml [BoundarySetup.setup_boundary_conditions]\n    - Successfully set GlobalBoundaryType to UpmlCpml [BoundarySetup.setup_boundary_conditions]\n  - Setting PML strength to: Low [BoundarySetup.setup_boundary_conditions]\n    - Successfully set PmlStrength to Low [BoundarySetup.setup_boundary_conditions]\n  - Added point sensor at (Vec3(-231.59, -107.681, -1019.42), Vec3(-231.59, -107.681, -1019.42), Vec3(-231.59, -107.681, -1019.42)) (lower_left_bottom) [FarFieldSetup._add_point_sensors]\n  - Added point sensor at (Vec3(239.048, 205.076, 260.697), Vec3(239.048, 205.076, 260.697), Vec3(239.048, 205.076, 260.697)) (top_right_up) [FarFieldSetup._add_point_sensors]\n  - Configuring solver settings... [FarFieldSetup._setup_solver_settings]\n    - Solver kernel set to: Acceleware (AXware) [FarFieldSetup._setup_solver_settings]\n      - Subtask 'setup_solver' done in 0.27s [FarFieldSetup.run_full_setup]\n      - Done in 0.27s [FarFieldSetup.run_full_setup]\n    - Voxelize simulation... [FarFieldSetup.run_full_setup]\n    - Finalizing setup... [FarFieldSetup._finalize_setup]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tongue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Adrenal Gland\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Anterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Vitreous Humor)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Midbrain\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Testis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Air 1\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood Vessel Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Epididymis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pineal Body\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Urinary Bladder Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone Marrow (Red)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Gallbladder\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypophysis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (White Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spleen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thymus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypothalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skin\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (Grey Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone (Cortical)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Sclera)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tendon\\Ligament\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Medulla)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Medulla Oblongata\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Intervertebral Disc\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Vertebrae\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Lens)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Posterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Cornea)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pharynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Liver\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Cortex)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Fat\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Lung\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Connective Tissue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pons\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spinal Cord\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"SAT (Subcutaneous Fat)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cartilage\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tooth\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Nerve\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Meniscus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skull\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Prostate\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Diaphragm\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mucous Membrane\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Larynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mandible\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hippocampus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebellum\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Penis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Ureter\\Urethra\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pancreas\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebrospinal Fluid\" have been set to their value according to the selected database\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n[Info]  Start voxeling\n[Info]  Topological Voxeler Report: Complete Voxel Scene\n    Voxel Scene Memory Consumption: 0.002876 GB\n    Wall Clock Time: 7.68246 s\n\n[Info]  Voxeling succeeded.\n    - Finalizing setup complete. [FarFieldSetup._finalize_setup]\n      - Subtask 'setup_voxelize' done in 21.92s [FarFieldSetup.run_full_setup]\n      - Done in 21.92s [FarFieldSetup.run_full_setup]\n    - Save project... [FarFieldSetup.run_full_setup]\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\nProject saved. [ProjectManager.save]\n      - Subtask 'setup_save_project' done in 4.52s [FarFieldSetup.run_full_setup]\n      - Done in 4.52s [FarFieldSetup.run_full_setup]\nCommon settings applied. [FarFieldSetup.run_full_setup]\n    - Subtask 'setup_simulation' done in 41.91s [FarFieldStudy.subtask]\n    - Done in 41.91s [FarFieldStudy.subtask]\n  - Saved configuration metadata to config.json [ProjectManager.write_simulation_metadata]\n--- Finished: setup (took 41.97s) --- [profile]\n--- Starting: run --- [profile]\n  - Run simulation total... [FarFieldStudy.subtask]\nRunning simulation: EM_FDTD_thelonious_700MHz_x_pos_theta [SimulationRunner.run]\n    - Write input file... [SimulationRunner.run]\n[Info]  Writing solver input file(s) for EM_FDTD_thelonious_700MHz_x_pos_theta\n[Info]  Writing Rectilinear Discretization to Input File. Elapse Time: 0.473051 s\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n      - Subtask 'run_write_input_file' done in 4.86s [SimulationRunner.run]\n      - Done in 4.86s [SimulationRunner.run]\nRunning iSolve with acceleware on 096a3ef5-4bd1-4778-b893-dbc6c809377c_Input.h5 [SimulationRunner._run_isolve_manual]\n    - Execute iSolve... [SimulationRunner._run_isolve_manual]\n\nReading command line \niSolve X, Version 8.2.0 (16876), 64Bit Windows \n\nRunning MPI version 2.0 on 1 process. \n\n\nSimulation 'EM_FDTD_thelonious_700MHz_x_pos_theta'  \n\nInstalled system RAM visible to this process:  16.0 GB \n\nSolver type: EmFdtd, SinglePrecision, Acceleware \nInput file name: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash_Results\\096a3ef5-4bd1-4778-b893-dbc6c809377c_Input.h5 \nInput file generated by: Sim4Life, Version 8.2.0.16876 \nOutput file name: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash_Results\\096a3ef5-4bd1-4778-b893-dbc6c809377c_Output.h5 \n\nUsing commercial license features. \nChecking out license feature 'FDTD_SOLVER', version 8.2, (1). \n\nRunning the EM-FDTD solver with the following settings: \nFloating Point Arithmetic: single (4 Bytes) \nHPC: Acceleware \nUsed Acceleware library is '11.4.1.13550 (x64, 64-bit)'. \nYour NVIDIA display driver is newer than the expected version. \nInstalled version: 15.7680 Expected: 15.3667 (see also http://www.acceleware.com/fdtd-11-4-1) \nReduced performance could be encountered. \n\nSimulation Time Step:   5.72711e-12 sec \nSimulation Iterations:  2853 \nMax Simulated Time: 1.63394e-08 sec \n\nGrid: \nNumber of cells: 229x177x499 = 20225967 cells = 20.2260 MCells \nNumber of cells including PML: 245x193x515 = 24351775 cells = 24.3518 MCells \nX: Range [-0.338659 ... 0.346117] with minimal 0.00297412 and maximal step 0.0029977 [m] \nY: Range [-0.21475 ... 0.312145] with minimal 0.00297412 and maximal step 0.00297865 [m] \nZ: Range [-1.12649 ... 0.367766] with minimal 0.00297403 and maximal step 0.00299799 [m] \n\nBoundaries: \nSide X-: ABC (UPML, 8 layers) \nSide X+: ABC (UPML, 8 layers) \nSide Y-: ABC (UPML, 8 layers) \nSide Y+: ABC (UPML, 8 layers) \nSide Z-: ABC (UPML, 8 layers) \nSide Z+: ABC (UPML, 8 layers) \n\nCreated unified material architecture (UMA) model \n\nMaterials (77): \nBackground: dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nTongue  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=0.865626, mu_r=1.000000, sigma_H=0.000000) \nAdrenal_gland  (Thelonious_6y_V6): dielectric (eps_r=50.989008, sigma_E=0.954350, mu_r=1.000000, sigma_H=0.000000) \nStomach_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \ncommissura_anterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nEye_vitreous_humor  (Thelonious_6y_V6): dielectric (eps_r=68.947390, sigma_E=1.583627, mu_r=1.000000, sigma_H=0.000000) \nVein  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nMidbrain  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nTestis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nAir_internal  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBlood_vessel  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nEpididymis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nPinealbody  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBladder  (Thelonious_6y_V6): dielectric (eps_r=19.149003, sigma_E=0.358399, mu_r=1.000000, sigma_H=0.000000) \nMarrow_red  (Thelonious_6y_V6): dielectric (eps_r=11.451933, sigma_E=0.207759, mu_r=1.000000, sigma_H=0.000000) \nGallbladder  (Thelonious_6y_V6): dielectric (eps_r=59.551663, sigma_E=1.202528, mu_r=1.000000, sigma_H=0.000000) \nHypophysis  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBrain_white_matter  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nSpleen  (Thelonious_6y_V6): dielectric (eps_r=58.688546, sigma_E=1.175182, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nThymus  (Thelonious_6y_V6): dielectric (eps_r=55.600852, sigma_E=1.115237, mu_r=1.000000, sigma_H=0.000000) \nTrachea  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nHeart_muscle  (Thelonious_6y_V6): dielectric (eps_r=61.478559, sigma_E=1.125021, mu_r=1.000000, sigma_H=0.000000) \nMuscle  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nHypothalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nArtery  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nSkin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nBrain_grey_matter  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nPatella  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_Sclera  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=1.096154, mu_r=1.000000, sigma_H=0.000000) \nTendon_Ligament  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nKidney_medulla  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nMedulla_oblongata  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nEsophagus  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nIntervertebral_disc  (Thelonious_6y_V6): dielectric (eps_r=44.418065, sigma_E=1.041108, mu_r=1.000000, sigma_H=0.000000) \nVertebrae  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_lens  (Thelonious_6y_V6): dielectric (eps_r=36.279018, sigma_E=0.435952, mu_r=1.000000, sigma_H=0.000000) \ncommissura_posterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nCornea  (Thelonious_6y_V6): dielectric (eps_r=56.275669, sigma_E=1.311407, mu_r=1.000000, sigma_H=0.000000) \nTrachea_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPharynx  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nLiver  (Thelonious_6y_V6): dielectric (eps_r=47.963211, sigma_E=0.773986, mu_r=1.000000, sigma_H=0.000000) \nThalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nHeart_lumen  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine  (Thelonious_6y_V6): dielectric (eps_r=59.134765, sigma_E=0.989502, mu_r=1.000000, sigma_H=0.000000) \nKidney_cortex  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nStomach  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nFat  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nLung  (Thelonious_6y_V6): dielectric (eps_r=22.460437, sigma_E=0.423425, mu_r=1.000000, sigma_H=0.000000) \nConnective_tissue  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nPons  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nSpinal_cord  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nSAT  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nEar_cartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nTeeth  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nNerve  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nEar_skin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nMeniscus  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nSkull  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nProstate  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nDiaphragm  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nBone  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nMucosa  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine  (Thelonious_6y_V6): dielectric (eps_r=61.138364, sigma_E=2.062163, mu_r=1.000000, sigma_H=0.000000) \nLarynx  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nMandible  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nCartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nHippocampus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nCerebellum  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nPenis  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nUreter_Urethra  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nBronchi_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPancreas  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nEsophagus_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBronchi  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nCerebrospinal_fluid  (Thelonious_6y_V6): dielectric (eps_r=69.157589, sigma_E=2.338250, mu_r=1.000000, sigma_H=0.000000) \n\nLumped Elements: No active lumped elements in the simulation. \n\nHost OS: Microsoft Windows 10 Professional 64-bit (Build 9200) \nHost CPU: AMD EPYC 7542 32-Core Processor \nHost memory: 16379 MB \nThe following Accelerators have been detected: \nNVIDIA GeForce RTX 4090 (device ID = 0), compute capability 8.9, total memory 24563 MB \n\n\nSensors (3): \nInitializing field sensor Overall Field. \nInitializing point sensor Point Sensor Entity 1 (lower_left_bottom). \nAveraging setup for point sensor Point Sensor Entity 1 (lower_left_bottom): \nE-Field: \nX: 2 edges used for recording. \nY: 2 edges used for recording. \nZ: 2 edges used for recording. \nH-Field: \nX: 4 edges used for recording. \nY: 4 edges used for recording. \nZ: 4 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 1 (lower_left_bottom): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.86355e-11, convergence level = -15 dB. \nInitializing point sensor Point Sensor Entity 2 (top_right_up). \nAveraging setup for point sensor Point Sensor Entity 2 (top_right_up): \nE-Field: \nX: 2 edges used for recording. \nY: 2 edges used for recording. \nZ: 2 edges used for recording. \nH-Field: \nX: 4 edges used for recording. \nY: 4 edges used for recording. \nZ: 4 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 2 (top_right_up): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.86355e-11, convergence level = -15 dB. \nUsing DFT to convert to frequency domain. \n\nSources (1): \nInitializing plane wave source far_field_simulation_bbox. \nExcitation signal: Harmonic signal with frequency 700 MHz and ramp time 2.14286 ns \n\nUpdate coefficient calculation for 122086088 edges using 3 threads. \nCalculating update coefficients \n[PROGRESS]: 21% [ 25691000 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 42% [ 51394640 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 63% [ 77063200 / 122086088 ] Calculating update coefficients \n[PROGRESS]: 84% [ 102704588 / 122086088 ] Calculating update coefficients \n\n\nEdge-Material Statistics (Electric/Magnetic): \n61165060 / 60921028      (100.00% / 100.00%) : Total \n61165060 / 60921028      (100.00% / 100.00%) : Dielectric \n\nEdge-Region Statistics (regions with more than 1% of all edges, max 20 items): \n58992181 / 58810012      ( 96.45% /  96.53%) : Background \n1084192 /  1496072   (  1.77% /   2.46%) : Other \n1088687 /   614944   (  1.78% /   1.01%) : Averaged \n\n\nUpdate coefficient database contains 2099 E-coefficient(s) and 1 H-coefficient(s). \nElapsed time for 'Calculating update coefficients' was 00:00:10 wall clock time. \nPreparing for time update \nUse hardware resource management option fastest simulation \nChecking out license feature 'AXWARE_TOKEN', version 8.2, (1). \n[PROGRESS]: 2% [ 2 / 100 ] Preparing for time update \n[PROGRESS]: 16% [ 16 / 100 ] Preparing for time update \n[PROGRESS]: 30% [ 30 / 100 ] Preparing for time update \n[PROGRESS]: 44% [ 44 / 100 ] Preparing for time update \n[PROGRESS]: 60% [ 60 / 100 ] Preparing for time update \nSimulation 1 is using device(s): [0] \nElapsed time for 'Preparing for time update' was 00:00:17 wall clock time. \nStarting solver aXware (hardware accelerated). \nTime Update \n[PROGRESS]: 0% [ 10 / 2853 ] Time Update, estimated remaining time 1 minutes 43 seconds  @ 674.70 MCells/s \n[PROGRESS]: 7% [ 207 / 2853 ] Time Update, estimated remaining time 28 seconds  @ 2284.02 MCells/s \n[PROGRESS]: 14% [ 404 / 2853 ] Time Update, estimated remaining time 28 seconds  @ 2162.07 MCells/s \n[PROGRESS]: 21% [ 601 / 2853 ] Time Update, estimated remaining time 24 seconds  @ 2311.73 MCells/s \n[PROGRESS]: 27% [ 798 / 2853 ] Time Update, estimated remaining time 22 seconds  @ 2290.44 MCells/s \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 2 to check conventional convergence. \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 4 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 2 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 4 to check conventional convergence. \n[PROGRESS]: 34% [ 995 / 2853 ] Time Update, estimated remaining time 20 seconds  @ 2283.90 MCells/s \n[PROGRESS]: 41% [ 1192 / 2853 ] Time Update, estimated remaining time 18 seconds  @ 2259.95 MCells/s \n[PROGRESS]: 48% [ 1389 / 2853 ] Time Update, estimated remaining time 16 seconds  @ 2255.44 MCells/s \n[PROGRESS]: 55% [ 1586 / 2853 ] Time Update, estimated remaining time 14 seconds  @ 2200.96 MCells/s \n[PROGRESS]: 61% [ 1755 / 2853 ] Time Update, estimated remaining time 15 seconds  @ 1816.07 MCells/s \nSensor Point Sensor Entity 1 (lower_left_bottom): conventional steady state check successful. \n[PROGRESS]: 68% [ 1952 / 2853 ] Time Update, estimated remaining time 11 seconds  @ 2088.30 MCells/s \nSensor Point Sensor Entity 2 (top_right_up): conventional steady state check successful. \nSteady state detected at iteration 2060, remaining time steps are 63. \n[PROGRESS]: 97% [ 2065 / 2123 ] Time Update, estimated remaining time 3 seconds  @ 477.96 MCells/s \nSimulation performed 2123 iterations. \nElapsed time for 'Time Update' was 00:00:35 wall clock time. \n\nPost-process Sensors \nPost-process sensor 'Overall Field' \nPost-process sensor 'Point Sensor Entity 1 (lower_left_bottom)' \n[PROGRESS]: 66% [ 2 / 3 ] Post-process Sensors \nPost-process sensor 'Point Sensor Entity 2 (top_right_up)' \nTrusted frequency is 700 MHz. Expect less accurate results outside. \nElapsed time for 'Post-process Sensors' was 00:00:05 wall clock time. \nFDTD simulation finished successfully. \n\nSimulation 'EM_FDTD_thelonious_700MHz_x_pos_theta' has ended successfully and took 00:01:18 wall clock time \nNo compression of solver files requested \nReleased license feature 'AXWARE_TOKEN'. \nReleased license feature 'FDTD_SOLVER'. \nPeak CPU memory usage:   3.6 GB (3911561216 Bytes) \niSolve ended successfully. \n      - Subtask 'run_isolve_execution' done in 79.26s [SimulationRunner._run_isolve_manual]\n      - Done in 79.26s [SimulationRunner._run_isolve_manual]\n    - Wait for results... [SimulationRunner._run_isolve_manual]\n      - Subtask 'run_wait_for_results' done in 5.03s [SimulationRunner._run_isolve_manual]\n      - Done in 5.03s [SimulationRunner._run_isolve_manual]\n    - Reload project... [SimulationRunner._run_isolve_manual]\nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash \n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\n      - Subtask 'run_reload_project' done in 11.14s [SimulationRunner._run_isolve_manual]\n      - Done in 11.14s [SimulationRunner._run_isolve_manual]\nProject reloaded and results are available. [SimulationRunner._run_isolve_manual]\n    - Subtask 'run_simulation_total' done in 100.38s [FarFieldStudy.subtask]\n    - Done in 100.38s [FarFieldStudy.subtask]\nRun deliverables verified. Updating metadata. [FarFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\n--- Finished: run (took 100.42s) --- [profile]\n--- Starting: extract --- [profile]\nRun deliverables verified. Proceeding with extraction. [FarFieldStudy._verify_run_deliverables_before_extraction]\nValidating project file: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash [ProjectManager.open]\nOpening project with Sim4Life: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash [ProjectManager.open]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash \nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nProject reloaded. [ProjectManager.reload_project]\n  - Extract results total... [FarFieldStudy.subtask]\n    - Extract input power... [PowerExtractor.extract_input_power]\n  - Far-field study: using theoretical model for input power. [PowerExtractor._extract_far_field_power]\n  - Calculated theoretical input power: 5.3099e-04 W [PowerExtractor._extract_far_field_power]\n      - Subtask 'extract_input_power' done in 0.00s [PowerExtractor.extract_input_power]\n      - Done in 0.00s [PowerExtractor.extract_input_power]\n    - Extract SAR statistics... [SarExtractor.extract_sar_statistics]\n  - Loading tissue groups for 'thelonious' from material_name_mapping.json [SarExtractor._define_tissue_groups]\n  - Extracting peak SAR details... [SarExtractor.extract_peak_sar_details]\n      - Subtask 'extract_sar_statistics' done in 26.59s [SarExtractor.extract_sar_statistics]\n      - Done in 26.59s [SarExtractor.extract_sar_statistics]\n    - Extract power balance... [PowerExtractor.extract_power_balance]\nAnalysis : [Warn]  Unable to balance the following EM sources: far_field_simulation_bbox,  are still not supported.\nAnalysis : [Warn]  Unable to balance the following EM sources: far_field_simulation_bbox,  are still not supported.\n    - Overwriting Pin with theoretical value: 5.3099e-04 W [PowerExtractor.extract_power_balance]\n    - Final Balance: 117.61% [PowerExtractor.extract_power_balance]\n      - Subtask 'extract_power_balance' done in 8.75s [PowerExtractor.extract_power_balance]\n      - Done in 8.75s [PowerExtractor.extract_power_balance]\n    - Extract point sensors... [SensorExtractor.extract_point_sensor_data]\n  - Point sensor plot saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_x_pos\\point_sensor_data.png [SensorExtractor._save_plot]\n      - Subtask 'extract_point_sensor_data' done in 0.74s [SensorExtractor.extract_point_sensor_data]\n      - Done in 0.74s [SensorExtractor.extract_point_sensor_data]\n  - Pickle report saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_x_pos\\sar_stats_all_tissues.pkl [Reporter._save_pickle_report]\n  - HTML report saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_x_pos\\sar_stats_all_tissues.html [Reporter._save_html_report]\n  - SAR results saved to: C:\\Users\\user\\repo-clean\\results\\far_field\\thelonious\\700MHz\\environmental_theta_x_pos\\sar_results.json [ResultsExtractor._save_json_results]\n    - Subtask 'extract_results_total' done in 36.25s [FarFieldStudy.subtask]\n    - Done in 36.25s [FarFieldStudy.subtask]\nExtract deliverables verified. Updating metadata. [FarFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\nSaving project to C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n--- Finished: extract (took 55.12s) --- [profile]\n\n--- FarFieldStudy Finished --- [FarFieldStudy.run]\n--- Logging shutdown --- \n--- Logging shutdown --- \nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\n[Info]  Topological Voxeler Report: Muscle\n    Target Grid: Primary\n    Duration: 2232.9 ms\n    Priority: 0\n    Edges: None\n    Voxels: 225848\n    Memory Consumption: 0.329872 kB\n\n[Info]  Topological Voxeler Report: Skin\n    Target Grid: Primary\n    Duration: 2404.2 ms\n    Priority: 0\n    Edges: None\n    Voxels: 50274\n    Memory Consumption: 0.409142 kB\n\n[Info]  Topological Voxeler Report: SAT\n    Target Grid: Primary\n    Duration: 2152.18 ms\n    Priority: 0\n    Edges: None\n    Voxels: 70055\n    Memory Consumption: 0.408096 kB\n\n[Info]  Topological Voxeler Report: Fat\n    Target Grid: Primary\n    Duration: 2018.07 ms\n    Priority: 0\n    Edges: None\n    Voxels: 77275\n    Memory Consumption: 0.334229 kB\n\n[Info]  Topological Voxeler Report: Brain_grey_matter\n    Target Grid: Primary\n    Duration: 556.883 ms\n    Priority: 0\n    Edges: None\n    Voxels: 26240\n    Memory Consumption: 0.011757 kB\n\n[Info]  Topological Voxeler Report: Connective_tissue\n    Target Grid: Primary\n    Duration: 770.832 ms\n    Priority: 0\n    Edges: None\n    Voxels: 10750\n    Memory Consumption: 0.340309 kB\n\n[Info]  Topological Voxeler Report: Cerebrospinal_fluid\n    Target Grid: Primary\n    Duration: 502.342 ms\n    Priority: 0\n    Edges: None\n    Voxels: 7731\n    Memory Consumption: 0.067123 kB\n\n[Info]  Topological Voxeler Report: Skull\n    Target Grid: Primary\n    Duration: 411.995 ms\n    Priority: 0\n    Edges: None\n    Voxels: 10030\n    Memory Consumption: 0.017731 kB\n\n[Info]  Topological Voxeler Report: Bone\n    Target Grid: Primary\n    Duration: 666.94 ms\n    Priority: 0\n    Edges: None\n    Voxels: 26810\n    Memory Consumption: 0.263748 kB\n\n[Info]  Topological Voxeler Report: Brain_white_matter\n    Target Grid: Primary\n    Duration: 296.787 ms\n    Priority: 0\n    Edges: None\n    Voxels: 13777\n    Memory Consumption: 0.009506 kB\n\n[Info]  Topological Voxeler Report: Tendon_Ligament\n    Target Grid: Primary\n    Duration: 368.01 ms\n    Priority: 0\n    Edges: None\n    Voxels: 7601\n    Memory Consumption: 0.264679 kB\n\n[Info]  Topological Voxeler Report: Large_intestine\n    Target Grid: Primary\n    Duration: 202.156 ms\n    Priority: 0\n    Edges: None\n    Voxels: 8087\n    Memory Consumption: 0.018135 kB\n\n[Info]  Topological Voxeler Report: Vertebrae\n    Target Grid: Primary\n    Duration: 173.763 ms\n    Priority: 0\n    Edges: None\n    Voxels: 8635\n    Memory Consumption: 0.016899 kB\n\n[Info]  Topological Voxeler Report: Lung\n    Target Grid: Primary\n    Duration: 132.165 ms\n    Priority: 0\n    Edges: None\n    Voxels: 33854\n    Memory Consumption: 0.013893 kB\n\n[Info]  Topological Voxeler Report: Marrow_red\n    Target Grid: Primary\n    Duration: 211.622 ms\n    Priority: 0\n    Edges: None\n    Voxels: 4051\n    Memory Consumption: 0.136726 kB\n\n[Info]  Topological Voxeler Report: Artery\n    Target Grid: Primary\n    Duration: 193.992 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2634\n    Memory Consumption: 0.164230 kB\n\n[Info]  Topological Voxeler Report: Large_intestine_lumen\n    Target Grid: Primary\n    Duration: 93.3677 ms\n    Priority: 0\n    Edges: None\n    Voxels: 17862\n    Memory Consumption: 0.016106 kB\n\n[Info]  Topological Voxeler Report: Air_internal\n    Target Grid: Primary\n    Duration: 66.3069 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1818\n    Memory Consumption: 0.003288 kB\n\n[Info]  Topological Voxeler Report: Vein\n    Target Grid: Primary\n    Duration: 154.376 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2365\n    Memory Consumption: 0.107765 kB\n\n[Info]  Topological Voxeler Report: Diaphragm\n    Target Grid: Primary\n    Duration: 70.5643 ms\n    Priority: 0\n    Edges: None\n    Voxels: 4149\n    Memory Consumption: 0.004707 kB\n\n[Info]  Topological Voxeler Report: Liver\n    Target Grid: Primary\n    Duration: 72.7156 ms\n    Priority: 0\n    Edges: None\n    Voxels: 20784\n    Memory Consumption: 0.008614 kB\n\n[Info]  Topological Voxeler Report: Stomach\n    Target Grid: Primary\n    Duration: 65.2019 ms\n    Priority: 0\n    Edges: None\n    Voxels: 5088\n    Memory Consumption: 0.004791 kB\n\n[Info]  Topological Voxeler Report: Mucosa\n    Target Grid: Primary\n    Duration: 57.4033 ms\n    Priority: 0\n    Edges: None\n    Voxels: 229\n    Memory Consumption: 0.001251 kB\n\n[Info]  Topological Voxeler Report: Nerve\n    Target Grid: Primary\n    Duration: 79.9097 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2150\n    Memory Consumption: 0.021904 kB\n\n[Info]  Topological Voxeler Report: Cerebellum\n    Target Grid: Primary\n    Duration: 42.4557 ms\n    Priority: 0\n    Edges: None\n    Voxels: 5681\n    Memory Consumption: 0.001984 kB\n\n[Info]  Topological Voxeler Report: Cartilage\n    Target Grid: Primary\n    Duration: 128.655 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1660\n    Memory Consumption: 0.126228 kB\n\n[Info]  Topological Voxeler Report: Blood_vessel\n    Target Grid: Primary\n    Duration: 76.9545 ms\n    Priority: 0\n    Edges: None\n    Voxels: 342\n    Memory Consumption: 0.054993 kB\n\n[Info]  Topological Voxeler Report: Intervertebral_disc\n    Target Grid: Primary\n    Duration: 46.7462 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2778\n    Memory Consumption: 0.005638 kB\n\n[Info]  Topological Voxeler Report: Kidney_cortex\n    Target Grid: Primary\n    Duration: 45.488 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2999\n    Memory Consumption: 0.002182 kB\n\n[Info]  Topological Voxeler Report: Heart_muscle\n    Target Grid: Primary\n    Duration: 40.0194 ms\n    Priority: 0\n    Edges: None\n    Voxels: 8775\n    Memory Consumption: 0.003059 kB\n\n[Info]  Topological Voxeler Report: Small_intestine\n    Target Grid: Primary\n    Duration: 34.9721 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2106\n    Memory Consumption: 0.001465 kB\n\n[Info]  Topological Voxeler Report: Mandible\n    Target Grid: Primary\n    Duration: 29.0763 ms\n    Priority: 0\n    Edges: None\n    Voxels: 630\n    Memory Consumption: 0.001495 kB\n\n[Info]  Topological Voxeler Report: Stomach_lumen\n    Target Grid: Primary\n    Duration: 26.511 ms\n    Priority: 0\n    Edges: None\n    Voxels: 4872\n    Memory Consumption: 0.002899 kB\n\n[Info]  Topological Voxeler Report: Spleen\n    Target Grid: Primary\n    Duration: 24.7537 ms\n    Priority: 0\n    Edges: None\n    Voxels: 4554\n    Memory Consumption: 0.002548 kB\n\n[Info]  Topological Voxeler Report: Ear_skin\n    Target Grid: Primary\n    Duration: 20.8579 ms\n    Priority: 0\n    Edges: None\n    Voxels: 456\n    Memory Consumption: 0.001396 kB\n\n[Info]  Topological Voxeler Report: Esophagus\n    Target Grid: Primary\n    Duration: 16.0094 ms\n    Priority: 0\n    Edges: None\n    Voxels: 289\n    Memory Consumption: 0.001564 kB\n\n[Info]  Topological Voxeler Report: Kidney_medulla\n    Target Grid: Primary\n    Duration: 18.4089 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1878\n    Memory Consumption: 0.001274 kB\n\n[Info]  Topological Voxeler Report: Tongue\n    Target Grid: Primary\n    Duration: 11.8625 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1389\n    Memory Consumption: 344 bytes\n\n[Info]  Topological Voxeler Report: Spinal_cord\n    Target Grid: Primary\n    Duration: 14.2112 ms\n    Priority: 0\n    Edges: None\n    Voxels: 959\n    Memory Consumption: 0.001770 kB\n\n[Info]  Topological Voxeler Report: Thymus\n    Target Grid: Primary\n    Duration: 12.9939 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1083\n    Memory Consumption: 800 bytes\n\n[Info]  Topological Voxeler Report: Teeth\n    Target Grid: Primary\n    Duration: 11.3177 ms\n    Priority: 0\n    Edges: None\n    Voxels: 209\n    Memory Consumption: 440 bytes\n\n[Info]  Topological Voxeler Report: Trachea\n    Target Grid: Primary\n    Duration: 11.0667 ms\n    Priority: 0\n    Edges: None\n    Voxels: 148\n    Memory Consumption: 512 bytes\n\n[Info]  Topological Voxeler Report: Eye_Sclera\n    Target Grid: Primary\n    Duration: 9.6963 ms\n    Priority: 0\n    Edges: None\n    Voxels: 159\n    Memory Consumption: 224 bytes\n\n[Info]  Topological Voxeler Report: Ear_cartilage\n    Target Grid: Primary\n    Duration: 10.7904 ms\n    Priority: 0\n    Edges: None\n    Voxels: 144\n    Memory Consumption: 0.001251 kB\n\n[Info]  Topological Voxeler Report: Small_intestine_lumen\n    Target Grid: Primary\n    Duration: 9.9477 ms\n    Priority: 0\n    Edges: None\n    Voxels: 845\n    Memory Consumption: 560 bytes\n\n[Info]  Topological Voxeler Report: Thalamus\n    Target Grid: Primary\n    Duration: 8.2518 ms\n    Priority: 0\n    Edges: None\n    Voxels: 699\n    Memory Consumption: 192 bytes\n\n[Info]  Topological Voxeler Report: Bladder\n    Target Grid: Primary\n    Duration: 10.055 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1120\n    Memory Consumption: 256 bytes\n\n[Info]  Topological Voxeler Report: Pancreas\n    Target Grid: Primary\n    Duration: 8.4381 ms\n    Priority: 0\n    Edges: None\n    Voxels: 406\n    Memory Consumption: 568 bytes\n\n[Info]  Topological Voxeler Report: Esophagus_lumen\n    Target Grid: Primary\n    Duration: 6.9652 ms\n    Priority: 0\n    Edges: None\n    Voxels: 133\n    Memory Consumption: 0.000984 kB\n\n[Info]  Topological Voxeler Report: Penis\n    Target Grid: Primary\n    Duration: 7.4221 ms\n    Priority: 0\n    Edges: None\n    Voxels: 333\n    Memory Consumption: 296 bytes\n\n[Info]  Topological Voxeler Report: Meniscus\n    Target Grid: Primary\n    Duration: 11.6235 ms\n    Priority: 0\n    Edges: None\n    Voxels: 349\n    Memory Consumption: 288 bytes\n\n[Info]  Topological Voxeler Report: Trachea_lumen\n    Target Grid: Primary\n    Duration: 5.7454 ms\n    Priority: 0\n    Edges: None\n    Voxels: 223\n    Memory Consumption: 512 bytes\n\n[Info]  Topological Voxeler Report: Pons\n    Target Grid: Primary\n    Duration: 4.7081 ms\n    Priority: 0\n    Edges: None\n    Voxels: 461\n    Memory Consumption: 152 bytes\n\n[Info]  Topological Voxeler Report: Eye_vitreous_humor\n    Target Grid: Primary\n    Duration: 4.7098 ms\n    Priority: 0\n    Edges: None\n    Voxels: 336\n    Memory Consumption: 160 bytes\n\n[Info]  Topological Voxeler Report: Midbrain\n    Target Grid: Primary\n    Duration: 4.4479 ms\n    Priority: 0\n    Edges: None\n    Voxels: 284\n    Memory Consumption: 112 bytes\n\n[Info]  Topological Voxeler Report: Gallbladder\n    Target Grid: Primary\n    Duration: 6.0739 ms\n    Priority: 0\n    Edges: None\n    Voxels: 282\n    Memory Consumption: 376 bytes\n\n[Info]  Topological Voxeler Report: Heart_lumen\n    Target Grid: Primary\n    Duration: 4.6322 ms\n    Priority: 0\n    Edges: None\n    Voxels: 254\n    Memory Consumption: 152 bytes\n\n[Info]  Topological Voxeler Report: Pharynx\n    Target Grid: Primary\n    Duration: 2.8749 ms\n    Priority: 0\n    Edges: None\n    Voxels: 56\n    Memory Consumption: 40 bytes\n\n[Info]  Topological Voxeler Report: Hippocampus\n    Target Grid: Primary\n    Duration: 2.5894 ms\n    Priority: 0\n    Edges: None\n    Voxels: 77\n    Memory Consumption: 72 bytes\n\n[Info]  Topological Voxeler Report: Medulla_oblongata\n    Target Grid: Primary\n    Duration: 2.6254 ms\n    Priority: 0\n    Edges: None\n    Voxels: 209\n    Memory Consumption: 96 bytes\n\n[Info]  Topological Voxeler Report: Prostate\n    Target Grid: Primary\n    Duration: 3.6346 ms\n    Priority: 0\n    Edges: None\n    Voxels: 119\n    Memory Consumption: 56 bytes\n\n[Info]  Topological Voxeler Report: Adrenal_gland\n    Target Grid: Primary\n    Duration: 3.3348 ms\n    Priority: 0\n    Edges: None\n    Voxels: 107\n    Memory Consumption: 152 bytes\n\n[Info]  Topological Voxeler Report: Bronchi\n    Target Grid: Primary\n    Duration: 2.6002 ms\n    Priority: 0\n    Edges: None\n    Voxels: 42\n    Memory Consumption: 32 bytes\n\n[Info]  Topological Voxeler Report: Testis\n    Target Grid: Primary\n    Duration: 3.1952 ms\n    Priority: 0\n    Edges: None\n    Voxels: 124\n    Memory Consumption: 40 bytes\n\n[Info]  Topological Voxeler Report: Patella\n    Target Grid: Primary\n    Duration: 6.0684 ms\n    Priority: 0\n    Edges: None\n    Voxels: 124\n    Memory Consumption: 136 bytes\n\n[Info]  Topological Voxeler Report: Ureter_Urethra\n    Target Grid: Primary\n    Duration: 4.4848 ms\n    Priority: 0\n    Edges: None\n    Voxels: 30\n    Memory Consumption: 384 bytes\n\n[Info]  Topological Voxeler Report: Bronchi_lumen\n    Target Grid: Primary\n    Duration: 1.358 ms\n    Priority: 0\n    Edges: None\n    Voxels: 27\n    Memory Consumption: 24 bytes\n\n[Info]  Topological Voxeler Report: Cornea\n    Target Grid: Primary\n    Duration: 1.8124 ms\n    Priority: 0\n    Edges: None\n    Voxels: 11\n    Memory Consumption: 32 bytes\n\n[Info]  Topological Voxeler Report: Hypothalamus\n    Target Grid: Primary\n    Duration: 0.9416 ms\n    Priority: 0\n    Edges: None\n    Voxels: 25\n    Memory Consumption: 16 bytes\n\n[Info]  Topological Voxeler Report: Epididymis\n    Target Grid: Primary\n    Duration: 1.9835 ms\n    Priority: 0\n    Edges: None\n    Voxels: 22\n    Memory Consumption: 24 bytes\n\n[Info]  Topological Voxeler Report: Hypophysis\n    Target Grid: Primary\n    Duration: 0.4471 ms\n    Priority: 0\n    Edges: None\n    Voxels: 11\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: Eye_lens\n    Target Grid: Primary\n    Duration: 0.618 ms\n    Priority: 0\n    Edges: None\n    Voxels: 10\n    Memory Consumption: 16 bytes\n\n[Info]  Topological Voxeler Report: Pinealbody\n    Target Grid: Primary\n    Duration: 0.4223 ms\n    Priority: 0\n    Edges: None\n    Voxels: 9\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: Larynx\n    Target Grid: Primary\n    Duration: 0.3953 ms\n    Priority: 0\n    Edges: None\n    Voxels: 3\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: commissura_anterior\n    Target Grid: Primary\n    Duration: 0.1809 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: commissura_posterior\n    Target Grid: Primary\n    Duration: 0.0752 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Complete Voxel Scene\n    Voxel Scene Memory Consumption: 0.002876 GB\n    Wall Clock Time: 7.68246 s\n\n[Info]  Visualization Data Memory Consumption: 0.036381 GB\n     Elapsed Time: 0.653698 s\n[Info]  Time step: 5.72711e-12 s\nTerminating study process... \n--- Logging shutdown --- \n--- Logging shutdown --- \n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p>This runs through setup, run, and extract phases regardless if the simulation was already done. If you ran tutorial 1, you'll see a warning for this, as this specific simulation has already been run:</p> <p></p> <p>Now check the metadata file:</p> <pre><code>run_bash(\"cat results/far_field/thelonious/700MHz/environmental_theta_x_pos/config.json\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; cat results/far_field/thelonious/700MHz/environmental_theta_x_pos/config.json\n\n------------------------------------------------------------\n{\n    \"config_hash\": \"4e7840473519f3922962f66b3dc12238937f371428330eb1c65f20cb8e869a9c\",\n    \"config_snapshot\": {\n        \"study_type\": \"far_field\",\n        \"simulation_parameters\": {\n            \"global_auto_termination\": \"GlobalAutoTerminationUserDefined\",\n            \"convergence_level_dB\": -15,\n            \"simulation_time_multiplier\": 3.5,\n            \"number_of_point_sensors\": 2,\n            \"point_source_order\": [\n                \"lower_left_bottom\",\n                \"top_right_up\",\n                \"lower_right_bottom\",\n                \"top_left_up\",\n                \"lower_left_up\",\n                \"top_right_bottom\",\n                \"lower_right_up\",\n                \"top_left_bottom\"\n            ]\n        },\n        \"solver_settings\": {\n            \"kernel\": \"acceleware\",\n            \"server\": \"localhost\",\n            \"boundary_conditions\": {\n                \"type\": \"UpmlCpml\",\n                \"strength\": \"Low\"\n            }\n        },\n        \"manual_isolve\": true,\n        \"gridding_parameters\": {\n            \"global_gridding\": {\n                \"grid_mode\": \"manual\",\n                \"manual_fallback_max_step_mm\": 3.0\n            },\n            \"padding\": {\n                \"padding_mode\": \"automatic\",\n                \"manual_bottom_padding_mm\": [\n                    0,\n                    0,\n                    0\n                ],\n                \"manual_top_padding_mm\": [\n                    0,\n                    0,\n                    0\n                ]\n            }\n        },\n        \"phantom\": \"thelonious\",\n        \"frequency_mhz\": 700,\n        \"far_field_setup\": {\n            \"type\": \"environmental\",\n            \"environmental\": {\n                \"incident_directions\": [\n                    \"x_pos\"\n                ],\n                \"polarizations\": [\n                    \"theta\"\n                ]\n            }\n        }\n    },\n    \"run_done\": true,\n    \"extract_done\": true\n}------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p>You'll see:</p> <pre><code>{\n  \"config_hash\": \"a3f2c9d8b1e4...\",\n  \"config_snapshot\": {...},\n  \"run_done\": true,\n  \"extract_done\": true\n}\n</code></pre> <p>Run the same study again. The cache mechanism is on by default.</p> <pre><code>run_bash(\"goliat study tutorial_2_caching.json\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; goliat study tutorial_2_caching.json\n\n------------------------------------------------------------\nStarting Sim4Life application... \nInitializing Application [stdout]\nInitializing Application [stderr]\n[Warn]  Unable to load module 'C:\\Program Files\\Sim4Life_8.2.0.16876\\MusaikInterface.xdll'\nJosua    : [Info]  Sync\nJosua    : [Info]  Sync\nJosua    : [Info]  Command [Query Handshake] &lt;019781c1-92e8-457c-9020-287f3c637111;127.0.0.1;WIN10-NEW&gt;\nJosua    : [Info]  Property [CAresSettings]\n[Info]  Connection to local Ares successfully established.\nSim4Life application started. \n--- Starting Far-Field Study: tutorial_2_caching.json --- [FarFieldStudy._run_study]\n\n--- Processing Simulation 1/1: thelonious, 700MHz, x_pos, theta --- [FarFieldStudy._run_study]\n--- Starting: setup --- [profile]\nProject path set to: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash [ProjectManager.create_or_open_project]\nVerified existing project. Status: Setup done, Run done, Extract done [ProjectManager.verify_simulation_metadata]\nProject already done, skipping. [ProjectManager.verify_simulation_metadata]\nVerified existing project. Opening. [ProjectManager.create_or_open_project]\nValidating project file: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash [ProjectManager.open]\nOpening project with Sim4Life: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash [ProjectManager.open]\nOpening project: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos/far_field_thelonious_700MHz_environmental_theta_x_pos.smash \n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\n--- Simulation-specific progress logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos\\progress.log --- \n--- Simulation-specific verbose logging started: C:/Users/user/repo-clean/results/far_field/thelonious/700MHz/environmental_theta_x_pos\\verbose.log --- \n  - Saved configuration metadata to config.json [ProjectManager.write_simulation_metadata]\nSkipping run phase, deliverables found. [FarFieldStudy._run_single_simulation]\nSkipping extract phase, deliverables found. [FarFieldStudy._run_single_simulation]\n--- Finished: setup (took 12.08s) --- [profile]\n\n--- FarFieldStudy Finished --- [FarFieldStudy.run]\n--- Logging shutdown --- \n--- Logging shutdown --- \nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\n--- Logging shutdown --- \n--- Logging shutdown --- \n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p></p> <p>GOLIAT checks the hash, finds a match, verifies deliverables exist, and skips the simulation. Instant completion.</p> <pre><code>run_bash(\"goliat study tutorial_2_caching.json\")\n</code></pre> <p>New hash, new simulation. The cache only applies to identical configs.</p> <pre><code>run_bash(\"goliat study tutorial_2_caching.json --no-cache\")\n</code></pre>"},{"location":"tutorials/02_configuration_and_caching/#tutorial-2-configuration-and-caching","title":"Tutorial 2: Configuration and caching","text":"<p>Learn how configs work and how GOLIAT avoids redundant simulations.</p>"},{"location":"tutorials/02_configuration_and_caching/#what-youll-learn","title":"What you'll learn","text":"<ul> <li>How config files extend each other (inheritance)</li> <li>Overriding specific parameters</li> <li>Validating configs before running</li> <li>How GOLIAT knows when to skip completed simulations</li> <li>Using the <code>--no-cache</code> flag</li> </ul> <p>Related documentation: Configuration guide</p>"},{"location":"tutorials/02_configuration_and_caching/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed tutorial 1 (far-field basics)</li> <li>Basic understanding of JSON files</li> </ul>"},{"location":"tutorials/02_configuration_and_caching/#bash-setup","title":"Bash setup","text":""},{"location":"tutorials/02_configuration_and_caching/#config-inheritance","title":"Config inheritance","text":"<p>GOLIAT uses hierarchical configs. A study-specific config extends a base config, overriding only what's different.</p> <p>This avoids duplicating common settings across every study.</p>"},{"location":"tutorials/02_configuration_and_caching/#the-base-config","title":"The base config","text":"<p>Look at <code>base_config.json</code>:</p>"},{"location":"tutorials/02_configuration_and_caching/#study-configs","title":"Study configs","text":"<p>Now look at <code>far_field_config.json</code>:</p>"},{"location":"tutorials/02_configuration_and_caching/#creating-custom-configs","title":"Creating custom configs","text":"<p>Let's create a custom far-field config that changes just a few things:</p>"},{"location":"tutorials/02_configuration_and_caching/#config-validation","title":"Config validation","text":"<p>Before running a study, validate the config file to catch errors early.</p>"},{"location":"tutorials/02_configuration_and_caching/#the-caching-system","title":"The caching system","text":"<p>GOLIAT tracks completed simulations and skips them on reruns. This saves time when you run a study multiple times (common during development or parameter tuning).</p>"},{"location":"tutorials/02_configuration_and_caching/#how-it-works","title":"How it works","text":"<p>When a simulation completes, GOLIAT writes a <code>config.json</code> metadata file in the results directory. This file contains: - Config hash (SHA256 hash of the simulation-specific config) - Config snapshot (the full simulation-specific config used for this simulation) - Setup timestamp (when setup completed) - Completion flags (which phases finished: run_done, extract_done)</p> <p>Note: The <code>setup_done</code> flag is not stored in the metadata file. Instead, GOLIAT computes it during verification by checking if the <code>.smash</code> project file exists and is valid. The metadata file stores <code>setup_timestamp</code> to track when setup completed.</p> <p>On the next run, GOLIAT: 1. Generates a hash of the current config 2. Checks if a <code>config.json</code> exists in the results directory 3. Compares hashes 4. If they match and deliverables exist, skips the simulation</p> <p>Deliverables for the run phase are <code>_Output.h5</code> file younger than the creation of the setup, and for the extract phase, these are the SAR results files. If these are not present after the phase, something must have gone wrong. Next time you run this simulation, GOLIAT will try again.</p>"},{"location":"tutorials/02_configuration_and_caching/#seeing-it-in-action","title":"Seeing it in action","text":"<p>Run a simple simulation:</p>"},{"location":"tutorials/02_configuration_and_caching/#when-cache-is-invalidated","title":"When cache is invalidated","text":"<p>Change something in the config (add a phantom, change frequency, modify grid settings). The hash changes, so GOLIAT reruns the simulation.</p> <p>Edit <code>tutorial_2_caching.json</code> and change the frequency:</p> <pre><code>{\n  \"frequencies_mhz\": [835]\n}\n</code></pre> <p>Run again:</p>"},{"location":"tutorials/02_configuration_and_caching/#forcing-a-rerun","title":"Forcing a rerun","text":"<p>Sometimes you want to rerun even if the cache says it's done (testing, debugging, or if you suspect bad results). This will redo all three phases.</p> <p>Use the <code>--no-cache</code> flag:</p>"},{"location":"tutorials/02_configuration_and_caching/#what-you-learned","title":"What you learned","text":"<ol> <li>Configs extend parent configs (base \u2192 study \u2192 custom)</li> <li>Override only what's different, inherit the rest</li> <li>Validate configs before running to catch errors</li> <li>GOLIAT uses config hashing to skip completed simulations</li> <li>Metadata tracks what's done (setup, run, extract)</li> <li>Use <code>--no-cache</code> to force reruns when needed</li> </ol>"},{"location":"tutorials/02_configuration_and_caching/#common-config-patterns","title":"Common config patterns","text":"<p>Add more phantoms</p> <pre><code>{\n  \"extends\": \"far_field_config.json\",\n  \"phantoms\": [\"duke\", \"eartha\", \"thelonious\"]\n}\n</code></pre> <p>Change solver kernel to CPU</p> <pre><code>{\n  \"extends\": \"base_config.json\",\n  \"solver_settings\": {\n    \"kernel\": \"software\"\n  }\n}\n</code></pre> <p>Disable GUI for headless runs</p> <pre><code>{\n  \"use_gui\": false\n}\n</code></pre> <p>Run only extract phase (reprocess existing results)</p> <pre><code>{\n  \"execution_control\": {\n    \"do_setup\": false,\n    \"do_run\": false,\n    \"do_extract\": true\n  }\n}\n</code></pre>"},{"location":"tutorials/02_configuration_and_caching/#try-this","title":"Try this","text":"<ol> <li>Create a custom config that extends <code>tutorial_1_far_field.json</code></li> <li>Add 2 more directions (<code>y_pos</code> and <code>y_neg</code>)</li> <li>Validate it</li> <li>Run it</li> <li>Run it again and watch it skip completed sims</li> <li>Change one direction and watch it rerun only new combinations</li> </ol>"},{"location":"tutorials/02_configuration_and_caching/#next-steps","title":"Next steps","text":"<ul> <li>Tutorial 3: Near-field basics (antennas, placements, localized SAR)</li> <li>Configuration guide: All parameters at ../developer_guide/configuration.md</li> <li>Features: Verify and resume details at Full List of Features</li> </ul> <p>Ready for tutorial 3? Learn near-field simulations with antennas.</p>"},{"location":"tutorials/03_near_field_basics/","title":"3. Near-Field Basics","text":"<pre><code>from pathlib import Path\nimport importlib.util\n\np = Path.cwd()\nwhile not (p / \"scripts\" / \"notebook_helpers.py\").exists():\n    p = p.parent\nspec = importlib.util.spec_from_file_location(\"_\", p / \"scripts\" / \"notebook_helpers.py\")\nm = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(m)\nrun_bash = m.get_run_bash()\n\nimport IPython\n\nIPython.core.display.max_output_size = None\n</code></pre> <p>This helper function lets you run bash commands from Python cells using <code>run_bash('command')</code>. The setup also disables output truncation so you can see all command output.</p> <p>If you're using bash directly (recommended), ignore the Python code blocks and just run the commands directly. Make sure to always run <code>source .bashrc</code> first.</p> <pre><code>run_bash(\"cat configs/tutorial_3_near_field.json\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; cat configs/tutorial_3_near_field.json\n\n------------------------------------------------------------\n{\n  \"extends\": \"base_config.json\",\n  \"study_type\": \"near_field\",\n  \"phantoms\": [\"thelonious\"],\n  \"execution_control\": {\n    \"do_setup\": true,\n    \"do_run\": true,\n    \"do_extract\": true\n  },\n  \"simulation_parameters\": {\n    \"number_of_point_sensors\": 2\n  },\n  \"gridding_parameters\": {\n    \"global_gridding\": {\n      \"grid_mode\": \"manual\",\n      \"manual_fallback_max_step_mm\": 3.0\n    },\n    \"global_gridding_per_frequency\": {\n      \"700\": 2.5\n    },\n    \"padding\": {\n      \"padding_mode\": \"manual\",\n      \"manual_bottom_padding_mm\": [0, 0, 0],\n      \"manual_top_padding_mm\": [0, 0, 0]\n    }\n  },\n  \"antenna_config\": {\n    \"700\": {\n      \"center_frequency\": 700,\n      \"target_power_mW\": 267,\n      \"model_type\": \"PIFA\",\n      \"source_name\": \"Lines 1\",\n      \"materials\": {\n        \"Extrude 1\": \"Copper\",\n        \"component1:Battery\": \"Copper\",\n        \"component1:Patch\": \"Copper\",\n        \"component1:ShortingPin\": \"Copper\",\n        \"component1:Substrate\": \"Rogers RT/duroid 5880\"\n      },\n      \"gridding\": {\n        \"automatic\": [\"component1:Substrate\", \"Lines 1\"]\n      }\n    }\n  },\n  \"placement_scenarios\": {\n    \"front_of_eyes\": {\n      \"bounding_box\": \"default\",\n      \"positions\": {\n        \"center\": [0, 0, -100]\n      },\n      \"orientations\": {\n        \"vertical\": []\n      },\n      \"antenna_reference\": {\n        \"distance_from_top\": 10\n      },\n      \"phantom_reference\": \"nasion\"\n    }\n  },\n  \"phantom_definitions\": {\n    \"thelonious\": {\n      \"nasion\": [-1, 0, 0],\n      \"placements\": {\n        \"do_front_of_eyes\": true,\n        \"do_by_belly\": false,\n        \"do_by_cheek\": false,\n        \"distance_from_eye\": 200\n      }\n    }\n  }\n}\n\n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <pre><code>run_bash(\"goliat study tutorial_3_near_field\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; goliat study tutorial_3_near_field\n\n------------------------------------------------------------\nStarting Sim4Life application... \nInitializing Application [stdout]\nInitializing Application [stderr]\n[Warn]  Unable to load module 'C:\\Program Files\\Sim4Life_8.2.0.16876\\MusaikInterface.xdll'\n[Info]  Connection to local Ares successfully established.\nSim4Life application started. \n--- Starting Near-Field Study: tutorial_3_near_field.json --- [NearFieldStudy._run_study]\n\n--- Processing Simulation 1/1: thelonious, 700MHz, front_of_eyes_center_vertical --- [NearFieldStudy._run_study]\n--- Starting: setup --- [profile]\nProject path set to: C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/near_field_thelonious_700MHz_front_of_eyes_center_vertical.smash [ProjectManager.create_or_open_project]\nNo metadata file found at config.json. [ProjectManager.verify_simulation_metadata]\nExisting project is invalid or out of date. A new setup is required. [ProjectManager.create_or_open_project]\n--- Simulation-specific progress logging started: C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical\\progress.log --- \n--- Simulation-specific verbose logging started: C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical\\verbose.log --- \nCreating a new empty project in memory. [ProjectManager.create_new]\nInitializing model by creating and deleting a dummy block... [ProjectManager.create_new]\nModel initialized, ready for population. [ProjectManager.create_new]\n  - Setup simulation... [NearFieldStudy.subtask]\nRunning full simulation setup... [NearFieldSetup.run_full_setup]\n    - Load phantom... [NearFieldSetup.run_full_setup]\n--- Running Phantom Check --- [PhantomSetup._log]\nFound 2 total entities in the project. [PhantomSetup._log]\n--- Phantom Check Result: Phantom not found in project. --- [PhantomSetup._log]\nPhantom not found in document. Importing from 'C:\\Users\\user\\repo-clean\\data\\phantoms\\thelonious.sab'... [PhantomSetup._log]\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nPhantom imported successfully. [PhantomSetup._log]\n      - Subtask 'setup_load_phantom' done in 8.41s [NearFieldSetup.run_full_setup]\n      - Done in 8.41s [NearFieldSetup.run_full_setup]\n    - Configure scene (bboxes, placement, simulation, sensors)... [NearFieldSetup.run_full_setup]\nSetting up bounding boxes... [NearFieldSetup._setup_bounding_boxes]\n  - Head BBox created. [NearFieldSetup._setup_bounding_boxes]\n  - Trunk BBox created. [NearFieldSetup._setup_bounding_boxes]\n--- Starting Placement: front_of_eyes - center - vertical --- [PlacementSetup.place_antenna]\nComposing final transformation... [PlacementSetup.place_antenna]\nApplying final composed transform. [PlacementSetup.place_antenna]\n--- Transformation Sequence Complete --- [PlacementSetup.place_antenna]\n  - Bounding box setting: 'default' [NearFieldSetup._create_simulation_bbox]\n  - Combined BBox created for front_of_eyes_center_vertical. [NearFieldSetup._create_simulation_bbox]\nSetting up simulation entity... [NearFieldSetup._setup_simulation_entity]\n  - Configuring solver settings... [NearFieldSetup._setup_solver_settings]\n    - Solver kernel set to: Acceleware (AXware) [NearFieldSetup._setup_solver_settings]\n  - Using simulation time multiplier: 3.5 [NearFieldSetup._apply_simulation_time_and_termination]\n  - Simulation time set to 4.63 periods. [NearFieldSetup._apply_simulation_time_and_termination]\n  - Setting termination criteria to: GlobalAutoTerminationUserDefined [NearFieldSetup._apply_simulation_time_and_termination]\n    - Convergence level set to: -15 dB [NearFieldSetup._apply_simulation_time_and_termination]\n  - Added point sensor at (-81.86, -50.79, -159.99) (lower_left_bottom) [NearFieldSetup._add_point_sensors]\n  - Added point sensor at (73.39, 325.47, 204.03) (top_right_up) [NearFieldSetup._add_point_sensors]\n      - Subtask 'setup_configure_scene' done in 0.33s [NearFieldSetup.run_full_setup]\n      - Done in 0.33s [NearFieldSetup.run_full_setup]\n    - Assign materials... [NearFieldSetup.run_full_setup]\nAssigning materials... [MaterialSetup.assign_materials]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\n[Info]  \nMass Density has changed from 1000 to 1.2050000000000001\nMass Density has changed from 1.2050000000000001 to 1.2\nRelative Permittivity has changed from 1 to 0\nSimulation : [Warn]  Unable to find any match for following settings properties: Magnetic Conductivity\nSimulation : [Warn]  Unable to find any match for following settings properties: Relative Permeability\nSimulation : [Warn]  Unable to find any match for following settings properties: Mass Density\n  - Assigned 'Copper' to 'Extrude 1'. [MaterialSetup._assign_antenna_materials]\nSimulation : [Warn]  Unable to find any match for following settings properties: Mass Density\n  - Assigned 'Copper' to 'component1:Battery'. [MaterialSetup._assign_antenna_materials]\nSimulation : [Warn]  Unable to find any match for following settings properties: Mass Density\n  - Assigned 'Copper' to 'component1:Patch'. [MaterialSetup._assign_antenna_materials]\nSimulation : [Warn]  Unable to find any match for following settings properties: Mass Density\n  - Assigned 'Copper' to 'component1:ShortingPin'. [MaterialSetup._assign_antenna_materials]\n  - Assigned 'Rogers RT/duroid 5880' to 'component1:Substrate'. [MaterialSetup._assign_antenna_materials]\n      - Subtask 'setup_materials' done in 5.76s [NearFieldSetup.run_full_setup]\n      - Done in 5.76s [NearFieldSetup.run_full_setup]\n    - Configure solver (gridding, boundaries, sources)... [NearFieldSetup.run_full_setup]\nSetting up gridding... [GriddingSetup.setup_gridding]\n  - Looking for global grid bounding box: 'front_of_eyes_center_vertical_simulation_bbox' [GriddingSetup._setup_main_grid]\n  - Using manual gridding. [GriddingSetup._setup_main_grid]\n  - Global and added manual grid set with frequency-specific (700MHz) resolution: 2.5 mm. [GriddingSetup._setup_main_grid]\n  - Using manual padding. [GriddingSetup._setup_main_grid]\n    - Manual padding set: Bottom=[0 0 0]mm, Top=[0 0 0]mm [GriddingSetup._setup_main_grid]\nSetting up boundary conditions... [BoundarySetup.setup_boundary_conditions]\n  - Setting global boundary conditions to: UpmlCpml [BoundarySetup.setup_boundary_conditions]\n    - Successfully set GlobalBoundaryType to UpmlCpml [BoundarySetup.setup_boundary_conditions]\n  - Setting PML strength to: Low [BoundarySetup.setup_boundary_conditions]\n    - Successfully set PmlStrength to Low [BoundarySetup.setup_boundary_conditions]\nSetting up source and sensors... [SourceSetup.setup_source_and_sensors]\n  - Using Harmonic source for phantom simulation. [SourceSetup.setup_source_and_sensors]\n      - Subtask 'setup_solver' done in 0.09s [NearFieldSetup.run_full_setup]\n      - Done in 0.09s [NearFieldSetup.run_full_setup]\n    - Voxelize simulation... [NearFieldSetup.run_full_setup]\n    - Finalizing setup... [NearFieldSetup._finalize_setup]\nSimulation : [Warn]  Some properties for material \"Air\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tongue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Adrenal Gland\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Anterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Vitreous Humor)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Midbrain\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Testis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Air 1\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Blood Vessel Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Epididymis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pineal Body\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Urinary Bladder Wall\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone Marrow (Red)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Gallbladder\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypophysis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (White Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spleen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thymus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Muscle\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hypothalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skin\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Brain (Grey Matter)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bone (Cortical)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Sclera)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tendon\\Ligament\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Medulla)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Medulla Oblongata\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Intervertebral Disc\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Vertebrae\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Lens)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Commissura Posterior\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Eye (Cornea)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Trachea Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pharynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Liver\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Thalamus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Heart Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Large Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Kidney (Cortex)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Stomach\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Fat\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Lung\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Connective Tissue\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pons\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Spinal Cord\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"SAT (Subcutaneous Fat)\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cartilage\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Tooth\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Nerve\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Meniscus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Skull\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Prostate\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Diaphragm\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mucous Membrane\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Larynx\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Mandible\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Small Intestine Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Hippocampus\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebellum\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Penis\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Ureter\\Urethra\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Pancreas\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Esophagus Lumen\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Bronchi\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Cerebrospinal Fluid\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Copper\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Copper 2\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Copper 3\" have been set to their value according to the selected database\nSimulation : [Warn]  Some properties for material \"Copper 4\" have been set to their value according to the selected database\nSaving project to C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/near_field_thelonious_700MHz_front_of_eyes_center_vertical.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\n[Info]  Start voxeling\n[Info]  Topological Voxeler Report: Complete Voxel Scene\n    Voxel Scene Memory Consumption: 0.003806 GB\n    Wall Clock Time: 7.09322 s\n\n[Info]  Voxeling succeeded.\n    - Finalizing setup complete. [NearFieldSetup._finalize_setup]\n      - Subtask 'setup_voxelize' done in 19.31s [NearFieldSetup.run_full_setup]\n      - Done in 19.31s [NearFieldSetup.run_full_setup]\n    - Save project... [NearFieldSetup.run_full_setup]\nSaving project to C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/near_field_thelonious_700MHz_front_of_eyes_center_vertical.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\nProject saved. [ProjectManager.save]\n      - Subtask 'setup_save_project' done in 7.94s [NearFieldSetup.run_full_setup]\n      - Done in 7.94s [NearFieldSetup.run_full_setup]\nFull simulation setup complete. [NearFieldSetup.run_full_setup]\n    - Subtask 'setup_simulation' done in 42.02s [NearFieldStudy.subtask]\n    - Done in 42.02s [NearFieldStudy.subtask]\n  - Saved configuration metadata to config.json [ProjectManager.write_simulation_metadata]\n--- Finished: setup (took 42.06s) --- [profile]\n--- Starting: run --- [profile]\n  - Run simulation total... [NearFieldStudy.subtask]\nRunning simulation: EM_FDTD_thelonious_700MHz_front_of_eyes_center_vertical [SimulationRunner.run]\n    - Write input file... [SimulationRunner.run]\n[Info]  Writing solver input file(s) for EM_FDTD_thelonious_700MHz_front_of_eyes_center_vertical\n[Info]  Writing Rectilinear Discretization to Input File. Elapse Time: 0.373037 s\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved.\n\n      - Subtask 'run_write_input_file' done in 4.95s [SimulationRunner.run]\n      - Done in 4.95s [SimulationRunner.run]\nRunning iSolve with acceleware on 9077bf1a-0b90-4f6d-8181-ed239422c3b6_Input.h5 [SimulationRunner._run_isolve_manual]\n    - Execute iSolve... [SimulationRunner._run_isolve_manual]\n\nReading command line \niSolve X, Version 8.2.0 (16876), 64Bit Windows \n\nRunning MPI version 2.0 on 1 process. \n\n\nSimulation 'EM_FDTD_thelonious_700MHz_front_of_eyes_center_vertical'  \n\nInstalled system RAM visible to this process:  16.0 GB \n\nSolver type: EmFdtd, SinglePrecision, Acceleware \nInput file name: C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/near_field_thelonious_700MHz_front_of_eyes_center_vertical.smash_Results\\9077bf1a-0b90-4f6d-8181-ed239422c3b6_Input.h5 \nInput file generated by: Sim4Life, Version 8.2.0.16876 \nOutput file name: C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/near_field_thelonious_700MHz_front_of_eyes_center_vertical.smash_Results\\9077bf1a-0b90-4f6d-8181-ed239422c3b6_Output.h5 \n\nUsing commercial license features. \nChecking out license feature 'FDTD_SOLVER', version 8.2, (1). \n\nRunning the EM-FDTD solver with the following settings: \nFloating Point Arithmetic: single (4 Bytes) \nHPC: Acceleware \nUsed Acceleware library is '11.4.1.13550 (x64, 64-bit)'. \nYour NVIDIA display driver is newer than the expected version. \nInstalled version: 15.7680 Expected: 15.3667 (see also http://www.acceleware.com/fdtd-11-4-1) \nReduced performance could be encountered. \n\nSimulation Time Step:   8.16961e-13 sec \nSimulation Iterations:  8090 \nMax Simulated Time: 6.60921e-09 sec \n\nGrid: \nNumber of cells: 76x166x160 = 2018560 cells = 2.0186 MCells \nNumber of cells including PML: 92x185x176 = 2995520 cells = 2.9955 MCells \nX: Range [-0.0846985 ... 0.0762301] with minimal 0.000600006 and maximal step 0.00244118 [m] \nY: Range [-0.0576809 ... 0.332357] with minimal 0.00029999 and maximal step 0.00249848 [m] \nZ: Range [-0.166654 ... 0.210697] with minimal 0.000600006 and maximal step 0.00249726 [m] \n\nBoundaries: \nSide X-: ABC (UPML, 8 layers) \nSide X+: ABC (UPML, 8 layers) \nSide Y-: ABC (UPML, 8 layers) \nSide Y+: ABC (UPML, 11 layers) \nSide Z-: ABC (UPML, 8 layers) \nSide Z+: ABC (UPML, 8 layers) \n\nCreated unified material architecture (UMA) model \n\nMaterials (82): \nBackground: dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nTongue  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=0.865626, mu_r=1.000000, sigma_H=0.000000) \nAdrenal_gland  (Thelonious_6y_V6): dielectric (eps_r=50.989008, sigma_E=0.954350, mu_r=1.000000, sigma_H=0.000000) \ncomponent1:Patch  (Antenna 700 MHz (front_of_eyes_center_vertical)): lossy metal (eps_r=1.000000, sigma_E=58130000.000000, mu_r=1.000000, sigma_H=0.000000) \nStomach_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \ncommissura_anterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nEye_vitreous_humor  (Thelonious_6y_V6): dielectric (eps_r=68.947390, sigma_E=1.583627, mu_r=1.000000, sigma_H=0.000000) \nVein  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nMidbrain  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nTestis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nAir_internal  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBlood_vessel  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nEpididymis  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nPinealbody  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBladder  (Thelonious_6y_V6): dielectric (eps_r=19.149003, sigma_E=0.358399, mu_r=1.000000, sigma_H=0.000000) \nMarrow_red  (Thelonious_6y_V6): dielectric (eps_r=11.451933, sigma_E=0.207759, mu_r=1.000000, sigma_H=0.000000) \nGallbladder  (Thelonious_6y_V6): dielectric (eps_r=59.551663, sigma_E=1.202528, mu_r=1.000000, sigma_H=0.000000) \nHypophysis  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nBrain_white_matter  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nSpleen  (Thelonious_6y_V6): dielectric (eps_r=58.688546, sigma_E=1.175182, mu_r=1.000000, sigma_H=0.000000) \nExtrude 1  (Antenna 700 MHz (front_of_eyes_center_vertical)): lossy metal (eps_r=1.000000, sigma_E=58130000.000000, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nThymus  (Thelonious_6y_V6): dielectric (eps_r=55.600852, sigma_E=1.115237, mu_r=1.000000, sigma_H=0.000000) \nTrachea  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nHeart_muscle  (Thelonious_6y_V6): dielectric (eps_r=61.478559, sigma_E=1.125021, mu_r=1.000000, sigma_H=0.000000) \nMuscle  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nHypothalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nArtery  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nSkin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nBrain_grey_matter  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nPatella  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_Sclera  (Thelonious_6y_V6): dielectric (eps_r=55.907533, sigma_E=1.096154, mu_r=1.000000, sigma_H=0.000000) \nTendon_Ligament  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \nKidney_medulla  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \ncomponent1:Battery  (Antenna 700 MHz (front_of_eyes_center_vertical)): lossy metal (eps_r=1.000000, sigma_E=58130000.000000, mu_r=1.000000, sigma_H=0.000000) \nMedulla_oblongata  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nEsophagus  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nIntervertebral_disc  (Thelonious_6y_V6): dielectric (eps_r=44.418065, sigma_E=1.041108, mu_r=1.000000, sigma_H=0.000000) \nVertebrae  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nEye_lens  (Thelonious_6y_V6): dielectric (eps_r=36.279018, sigma_E=0.435952, mu_r=1.000000, sigma_H=0.000000) \ncommissura_posterior  (Thelonious_6y_V6): dielectric (eps_r=39.695046, sigma_E=0.531363, mu_r=1.000000, sigma_H=0.000000) \nCornea  (Thelonious_6y_V6): dielectric (eps_r=56.275669, sigma_E=1.311407, mu_r=1.000000, sigma_H=0.000000) \nTrachea_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPharynx  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nLiver  (Thelonious_6y_V6): dielectric (eps_r=47.963211, sigma_E=0.773986, mu_r=1.000000, sigma_H=0.000000) \nThalamus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nHeart_lumen  (Thelonious_6y_V6): dielectric (eps_r=62.103070, sigma_E=1.455938, mu_r=1.000000, sigma_H=0.000000) \nLarge_intestine  (Thelonious_6y_V6): dielectric (eps_r=59.134765, sigma_E=0.989502, mu_r=1.000000, sigma_H=0.000000) \nKidney_cortex  (Thelonious_6y_V6): dielectric (eps_r=60.631926, sigma_E=1.277659, mu_r=1.000000, sigma_H=0.000000) \nStomach  (Thelonious_6y_V6): dielectric (eps_r=65.714765, sigma_E=1.105511, mu_r=1.000000, sigma_H=0.000000) \nFat  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nLung  (Thelonious_6y_V6): dielectric (eps_r=22.460437, sigma_E=0.423425, mu_r=1.000000, sigma_H=0.000000) \nConnective_tissue  (Thelonious_6y_V6): dielectric (eps_r=46.258918, sigma_E=0.645211, mu_r=1.000000, sigma_H=0.000000) \ncomponent1:Substrate  (Antenna 700 MHz (front_of_eyes_center_vertical)): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPons  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nSpinal_cord  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nSAT  (Thelonious_6y_V6): dielectric (eps_r=11.423242, sigma_E=0.096238, mu_r=1.000000, sigma_H=0.000000) \nEar_cartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nTeeth  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nNerve  (Thelonious_6y_V6): dielectric (eps_r=33.263358, sigma_E=0.522929, mu_r=1.000000, sigma_H=0.000000) \nEar_skin  (Thelonious_6y_V6): dielectric (eps_r=42.697659, sigma_E=0.799975, mu_r=1.000000, sigma_H=0.000000) \nMeniscus  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nSkull  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nProstate  (Thelonious_6y_V6): dielectric (eps_r=61.295609, sigma_E=1.130577, mu_r=1.000000, sigma_H=0.000000) \nDiaphragm  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nBone  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nMucosa  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine  (Thelonious_6y_V6): dielectric (eps_r=61.138364, sigma_E=2.062163, mu_r=1.000000, sigma_H=0.000000) \nLarynx  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nMandible  (Thelonious_6y_V6): dielectric (eps_r=12.662775, sigma_E=0.120578, mu_r=1.000000, sigma_H=0.000000) \nSmall_intestine_lumen  (Thelonious_6y_V6): dielectric (eps_r=55.587038, sigma_E=0.878895, mu_r=1.000000, sigma_H=0.000000) \nCartilage  (Thelonious_6y_V6): dielectric (eps_r=43.455463, sigma_E=0.697055, mu_r=1.000000, sigma_H=0.000000) \nHippocampus  (Thelonious_6y_V6): dielectric (eps_r=53.898662, sigma_E=0.859642, mu_r=1.000000, sigma_H=0.000000) \nCerebellum  (Thelonious_6y_V6): dielectric (eps_r=51.031533, sigma_E=1.173295, mu_r=1.000000, sigma_H=0.000000) \nPenis  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \ncomponent1:ShortingPin  (Antenna 700 MHz (front_of_eyes_center_vertical)): lossy metal (eps_r=1.000000, sigma_E=58130000.000000, mu_r=1.000000, sigma_H=0.000000) \nUreter_Urethra  (Thelonious_6y_V6): dielectric (eps_r=45.325498, sigma_E=0.637236, mu_r=1.000000, sigma_H=0.000000) \nBronchi_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nPancreas  (Thelonious_6y_V6): dielectric (eps_r=60.201963, sigma_E=0.966322, mu_r=1.000000, sigma_H=0.000000) \nEsophagus_lumen  (Thelonious_6y_V6): dielectric (eps_r=1.000000, sigma_E=0.000000, mu_r=1.000000, sigma_H=0.000000) \nBronchi  (Thelonious_6y_V6): dielectric (eps_r=42.588287, sigma_E=0.713502, mu_r=1.000000, sigma_H=0.000000) \nCerebrospinal_fluid  (Thelonious_6y_V6): dielectric (eps_r=69.157589, sigma_E=2.338250, mu_r=1.000000, sigma_H=0.000000) \n\nLumped Elements (1): \nInitializing lumped element Lines 1  (Antenna 700 MHz (front_of_eyes_center_vertical)) (1 edge(s)) (Resistor, 50 ohm) \n\nHost OS: Microsoft Windows 10 Professional 64-bit (Build 9200) \nHost CPU: AMD EPYC 7542 32-Core Processor \nHost memory: 16379 MB \nThe following Accelerators have been detected: \nNVIDIA GeForce RTX 4090 (device ID = 0), compute capability 8.9, total memory 24563 MB \n\n\nSensors (4): \nInitializing path sensor Lines 1  (Antenna 700 MHz (front_of_eyes_center_vertical)). \nHarmonic steady state settings for Lines 1  (Antenna 700 MHz (front_of_eyes_center_vertical)): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.85936e-11, convergence level = -15 dB. \nInitializing field sensor Overall Field. \nInitializing point sensor Point Sensor Entity 1 (lower_left_bottom). \nAveraging setup for point sensor Point Sensor Entity 1 (lower_left_bottom): \nE-Field: \nX: 8 edges used for recording. \nY: 8 edges used for recording. \nZ: 8 edges used for recording. \nH-Field: \nX: 8 edges used for recording. \nY: 8 edges used for recording. \nZ: 8 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 1 (lower_left_bottom): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.85936e-11, convergence level = -15 dB. \nInitializing point sensor Point Sensor Entity 2 (top_right_up). \nAveraging setup for point sensor Point Sensor Entity 2 (top_right_up): \nE-Field: \nX: 8 edges used for recording. \nY: 8 edges used for recording. \nZ: 8 edges used for recording. \nH-Field: \nX: 8 edges used for recording. \nY: 8 edges used for recording. \nZ: 8 edges used for recording. \nHarmonic steady state settings for Point Sensor Entity 2 (top_right_up): ema-factor-per-period = 0.8, ema factor across check point 0.894427, frequency = 7e+08, recording time step = 2.85936e-11, convergence level = -15 dB. \nUsing DFT to convert to frequency domain. \n\nSources (1): \nInitializing edge source Lines 1  (Antenna 700 MHz (front_of_eyes_center_vertical)) (amplitude 1, time shift0, type voltage, excitation id e2220022-6e80-44a2-a40e-20de7c605e77). \nExcitation signal: Harmonic signal with frequency 700 MHz and ramp time 2.14286 ns \n\nUpdate coefficient calculation for 12265770 edges using 3 threads. \nCalculating update coefficients \n\n\nEdge-Material Statistics (Electric/Magnetic): \n6158750 / 6107016    (100.00% / 100.00%) : Total \n6141150 / 6083739    ( 99.71% /  99.62%) : Dielectric \n17600 /   23277      (  0.29% /   0.38%) : Lossy Metal \n\nEdge-Region Statistics (regions with more than 1% of all edges, max 20 items): \n4571553 / 4548441    ( 74.23% /  74.48%) : Background \n202588 /  240362     (  3.29% /   3.94%) : Muscle  (Thelonious_6y_V6) \n193767 /  203606     (  3.15% /   3.33%) : Lung  (Thelonious_6y_V6) \n96336 /  132166      (  1.56% /   2.16%) : Brain_grey_matter  (Thelonious_6y_V6) \n52688 /   70953      (  0.86% /   1.16%) : Brain_white_matter  (Thelonious_6y_V6) \n372840 /  527412     (  6.05% /   8.64%) : Other \n668978 /  384076     ( 10.86% /   6.29%) : Averaged \n\n\nUpdate coefficient database contains 10798 E-coefficient(s) and 23 H-coefficient(s). \nElapsed time for 'Calculating update coefficients' was 00:00:02 wall clock time. \nPreparing for time update \nUse hardware resource management option fastest simulation \nChecking out license feature 'AXWARE_TOKEN', version 8.2, (1). \n[PROGRESS]: 25% [ 25 / 100 ] Preparing for time update \nSimulation 1 is using device(s): [0] \nElapsed time for 'Preparing for time update' was 00:00:03 wall clock time. \nStarting solver aXware (hardware accelerated). \nTime Update \n[PROGRESS]: 0% [ 10 / 8090 ] Time Update, estimated remaining time 3 minutes  @ 134.68 MCells/s \n[PROGRESS]: 13% [ 1131 / 8090 ] Time Update, estimated remaining time 13 seconds  @ 1610.56 MCells/s \n[PROGRESS]: 27% [ 2252 / 8090 ] Time Update, estimated remaining time 11 seconds  @ 1650.20 MCells/s \n[PROGRESS]: 41% [ 3373 / 8090 ] Time Update, estimated remaining time 9 seconds  @ 1652.52 MCells/s \n[PROGRESS]: 55% [ 4494 / 8090 ] Time Update, estimated remaining time 7 seconds  @ 1656.56 MCells/s \n[PROGRESS]: 69% [ 5615 / 8090 ] Time Update, estimated remaining time 5 seconds  @ 1632.63 MCells/s \n[PROGRESS]: 83% [ 6736 / 8090 ] Time Update, estimated remaining time 2 seconds  @ 1656.96 MCells/s \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 1 to check conventional convergence. \nPoint Sensor Entity 1 (lower_left_bottom): Choosing component 4 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 1 to check conventional convergence. \nPoint Sensor Entity 2 (top_right_up): Choosing component 5 to check conventional convergence. \n[PROGRESS]: 95% [ 7697 / 8090 ] Time Update, estimated remaining time 1 seconds  @ 1174.38 MCells/s \nSimulation performed 8090 iterations. \nElapsed time for 'Time Update' was 00:00:17 wall clock time. \n\nPost-process Sensors \nPost-process sensor 'Lines 1  (Antenna 700 MHz (front_of_eyes_center_vertical))' \nPost-process sensor 'Overall Field' \nPost-process sensor 'Point Sensor Entity 1 (lower_left_bottom)' \nPost-process sensor 'Point Sensor Entity 2 (top_right_up)' \nTrusted frequency is 700 MHz. Expect less accurate results outside. \nElapsed time for 'Post-process Sensors' was 00:00:00 wall clock time. \nFDTD simulation finished successfully. \n\nSimulation 'EM_FDTD_thelonious_700MHz_front_of_eyes_center_vertical' has ended successfully and took 00:00:32 wall clock time \nNo compression of solver files requested \nReleased license feature 'AXWARE_TOKEN'. \nReleased license feature 'FDTD_SOLVER'. \nPeak CPU memory usage: 971.7 MB (1018908672 Bytes) \niSolve ended successfully. \n      - Subtask 'run_isolve_execution' done in 32.67s [SimulationRunner._run_isolve_manual]\n      - Done in 32.67s [SimulationRunner._run_isolve_manual]\n    - Wait for results... [SimulationRunner._run_isolve_manual]\n      - Subtask 'run_wait_for_results' done in 5.03s [SimulationRunner._run_isolve_manual]\n      - Done in 5.03s [SimulationRunner._run_isolve_manual]\n    - Reload project... [SimulationRunner._run_isolve_manual]\nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\nOpening project: C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/near_field_thelonious_700MHz_front_of_eyes_center_vertical.smash \n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\n      - Subtask 'run_reload_project' done in 11.88s [SimulationRunner._run_isolve_manual]\n      - Done in 11.88s [SimulationRunner._run_isolve_manual]\nProject reloaded and results are available. [SimulationRunner._run_isolve_manual]\n    - Subtask 'run_simulation_total' done in 54.61s [NearFieldStudy.subtask]\n    - Done in 54.61s [NearFieldStudy.subtask]\nRun deliverables verified. Updating metadata. [NearFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\n--- Finished: run (took 54.69s) --- [profile]\n--- Starting: extract --- [profile]\nRun deliverables verified. Proceeding with extraction. [NearFieldStudy._verify_run_deliverables_before_extraction]\nValidating project file: C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/near_field_thelonious_700MHz_front_of_eyes_center_vertical.smash [ProjectManager.open]\nOpening project with Sim4Life: C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/near_field_thelonious_700MHz_front_of_eyes_center_vertical.smash [ProjectManager.open]\nOpening project: C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/near_field_thelonious_700MHz_front_of_eyes_center_vertical.smash \nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  Checking out license feature 'MODEL_THELONIOUS', version 1.0, (1).\nLicense  : [Info]  Acquired [ MODEL_THELONIOUS 1.0 ]\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nModeler  : [Warn]  No exact match found for SkullNot changing colors.\nProject reloaded. [ProjectManager.reload_project]\n  - Extract results total... [NearFieldStudy.subtask]\n    - Extract input power... [PowerExtractor.extract_input_power]\n  - GetPower() not available, falling back to manual extraction. [PowerExtractor._extract_near_field_power]\n      - Subtask 'extract_input_power' done in 3.78s [PowerExtractor.extract_input_power]\n      - Done in 3.78s [PowerExtractor.extract_input_power]\n    - Extract SAR statistics... [SarExtractor.extract_sar_statistics]\n  - Loading tissue groups for 'thelonious' from material_name_mapping.json [SarExtractor._define_tissue_groups]\n  - Extracting peak SAR details... [SarExtractor.extract_peak_sar_details]\n      - Subtask 'extract_sar_statistics' done in 7.03s [SarExtractor.extract_sar_statistics]\n      - Done in 7.03s [SarExtractor.extract_sar_statistics]\n    - Extract power balance... [PowerExtractor.extract_power_balance]\n    - Final Balance: 22.90% [PowerExtractor.extract_power_balance]\n      - Subtask 'extract_power_balance' done in 2.23s [PowerExtractor.extract_power_balance]\n      - Done in 2.23s [PowerExtractor.extract_power_balance]\n    - Extract point sensors... [SensorExtractor.extract_point_sensor_data]\n  - Point sensor plot saved to: C:\\Users\\user\\repo-clean\\results\\near_field\\thelonious\\700MHz\\front_of_eyes_center_vertical\\point_sensor_data.png [SensorExtractor._save_plot]\n      - Subtask 'extract_point_sensor_data' done in 0.55s [SensorExtractor.extract_point_sensor_data]\n      - Done in 0.55s [SensorExtractor.extract_point_sensor_data]\n  - Pickle report saved to: C:\\Users\\user\\repo-clean\\results\\near_field\\thelonious\\700MHz\\front_of_eyes_center_vertical\\sar_stats_all_tissues.pkl [Reporter._save_pickle_report]\n  - HTML report saved to: C:\\Users\\user\\repo-clean\\results\\near_field\\thelonious\\700MHz\\front_of_eyes_center_vertical\\sar_stats_all_tissues.html [Reporter._save_html_report]\n  - SAR results saved to: C:\\Users\\user\\repo-clean\\results\\near_field\\thelonious\\700MHz\\front_of_eyes_center_vertical\\sar_results.json [ResultsExtractor._save_json_results]\n    - Subtask 'extract_results_total' done in 13.80s [NearFieldStudy.subtask]\n    - Done in 13.80s [NearFieldStudy.subtask]\nExtract deliverables verified. Updating metadata. [NearFieldStudy._verify_and_update_metadata]\nUpdated metadata in config.json [ProjectManager.update_simulation_metadata]\nSaving project to C:/Users/user/repo-clean/results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/near_field_thelonious_700MHz_front_of_eyes_center_vertical.smash... [ProjectManager.save]\n[Info]  Document produced by Sim4Life version 8.2.0.16876\n[Info]  There have been no model changes since the last time was saved. \n\nProject saved. [ProjectManager.save]\n--- Finished: extract (took 30.59s) --- [profile]\n\n--- NearFieldStudy Finished --- [NearFieldStudy.run]\n--- Logging shutdown --- \n--- Logging shutdown --- \nLicense  : [Info]  Released [ MODEL_THELONIOUS 1.0 ]\n[Info]  Topological Voxeler Report: Muscle\n    Target Grid: Primary\n    Duration: 2038.02 ms\n    Priority: 0\n    Edges: None\n    Voxels: 96103\n    Memory Consumption: 0.084938 kB\n\n[Info]  Topological Voxeler Report: Skin\n    Target Grid: Primary\n    Duration: 2043.38 ms\n    Priority: 0\n    Edges: None\n    Voxels: 21508\n    Memory Consumption: 0.123222 kB\n\n[Info]  Topological Voxeler Report: SAT\n    Target Grid: Primary\n    Duration: 1909.36 ms\n    Priority: 0\n    Edges: None\n    Voxels: 24985\n    Memory Consumption: 0.121010 kB\n\n[Info]  Topological Voxeler Report: Fat\n    Target Grid: Primary\n    Duration: 1916.99 ms\n    Priority: 0\n    Edges: None\n    Voxels: 23715\n    Memory Consumption: 0.083389 kB\n\n[Info]  Topological Voxeler Report: Brain_grey_matter\n    Target Grid: Primary\n    Duration: 660.133 ms\n    Priority: 0\n    Edges: None\n    Voxels: 55992\n    Memory Consumption: 0.024544 kB\n\n[Info]  Topological Voxeler Report: Connective_tissue\n    Target Grid: Primary\n    Duration: 677.102 ms\n    Priority: 0\n    Edges: None\n    Voxels: 12933\n    Memory Consumption: 0.046371 kB\n\n[Info]  Topological Voxeler Report: Bone\n    Target Grid: Primary\n    Duration: 529.629 ms\n    Priority: 0\n    Edges: None\n    Voxels: 9017\n    Memory Consumption: 0.044350 kB\n\n[Info]  Topological Voxeler Report: Cerebrospinal_fluid\n    Target Grid: Primary\n    Duration: 585.837 ms\n    Priority: 0\n    Edges: None\n    Voxels: 14690\n    Memory Consumption: 0.088646 kB\n\n[Info]  Topological Voxeler Report: Brain_white_matter\n    Target Grid: Primary\n    Duration: 347.053 ms\n    Priority: 0\n    Edges: None\n    Voxels: 30817\n    Memory Consumption: 0.019691 kB\n\n[Info]  Topological Voxeler Report: Skull\n    Target Grid: Primary\n    Duration: 490.03 ms\n    Priority: 0\n    Edges: None\n    Voxels: 20263\n    Memory Consumption: 0.036324 kB\n\n[Info]  Topological Voxeler Report: Tendon_Ligament\n    Target Grid: Primary\n    Duration: 228.936 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2012\n    Memory Consumption: 0.021988 kB\n\n[Info]  Topological Voxeler Report: Large_intestine\n    Target Grid: Primary\n    Duration: 237.051 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Vertebrae\n    Target Grid: Primary\n    Duration: 223.899 ms\n    Priority: 0\n    Edges: None\n    Voxels: 7548\n    Memory Consumption: 0.012505 kB\n\n[Info]  Topological Voxeler Report: Lung\n    Target Grid: Primary\n    Duration: 181.668 ms\n    Priority: 0\n    Edges: None\n    Voxels: 71680\n    Memory Consumption: 0.026184 kB\n\n[Info]  Topological Voxeler Report: Marrow_red\n    Target Grid: Primary\n    Duration: 155.288 ms\n    Priority: 0\n    Edges: None\n    Voxels: 4559\n    Memory Consumption: 0.029617 kB\n\n[Info]  Topological Voxeler Report: Artery\n    Target Grid: Primary\n    Duration: 119.946 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2101\n    Memory Consumption: 0.043495 kB\n\n[Info]  Topological Voxeler Report: Large_intestine_lumen\n    Target Grid: Primary\n    Duration: 102.014 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Vein\n    Target Grid: Primary\n    Duration: 98.1659 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1338\n    Memory Consumption: 0.020744 kB\n\n[Info]  Topological Voxeler Report: Air_internal\n    Target Grid: Primary\n    Duration: 79.1533 ms\n    Priority: 0\n    Edges: None\n    Voxels: 3390\n    Memory Consumption: 0.007278 kB\n\n[Info]  Topological Voxeler Report: Diaphragm\n    Target Grid: Primary\n    Duration: 88.8875 ms\n    Priority: 0\n    Edges: None\n    Voxels: 8314\n    Memory Consumption: 0.008522 kB\n\n[Info]  Topological Voxeler Report: Liver\n    Target Grid: Primary\n    Duration: 78.388 ms\n    Priority: 0\n    Edges: None\n    Voxels: 18313\n    Memory Consumption: 0.005272 kB\n\n[Info]  Topological Voxeler Report: Stomach\n    Target Grid: Primary\n    Duration: 87.828 ms\n    Priority: 0\n    Edges: None\n    Voxels: 5411\n    Memory Consumption: 0.002693 kB\n\n[Info]  Topological Voxeler Report: Nerve\n    Target Grid: Primary\n    Duration: 87.9098 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1451\n    Memory Consumption: 0.023468 kB\n\n[Info]  Topological Voxeler Report: Mucosa\n    Target Grid: Primary\n    Duration: 60.5404 ms\n    Priority: 0\n    Edges: None\n    Voxels: 329\n    Memory Consumption: 0.003487 kB\n\n[Info]  Topological Voxeler Report: Cartilage\n    Target Grid: Primary\n    Duration: 80.1576 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2561\n    Memory Consumption: 0.037788 kB\n\n[Info]  Topological Voxeler Report: Cerebellum\n    Target Grid: Primary\n    Duration: 53.6068 ms\n    Priority: 0\n    Edges: None\n    Voxels: 12280\n    Memory Consumption: 0.004150 kB\n\n[Info]  Topological Voxeler Report: Intervertebral_disc\n    Target Grid: Primary\n    Duration: 57.954 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1606\n    Memory Consumption: 0.003365 kB\n\n[Info]  Topological Voxeler Report: Blood_vessel\n    Target Grid: Primary\n    Duration: 78.8028 ms\n    Priority: 0\n    Edges: None\n    Voxels: 558\n    Memory Consumption: 0.036507 kB\n\n[Info]  Topological Voxeler Report: Kidney_cortex\n    Target Grid: Primary\n    Duration: 56.6828 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Heart_muscle\n    Target Grid: Primary\n    Duration: 50.9975 ms\n    Priority: 0\n    Edges: None\n    Voxels: 18049\n    Memory Consumption: 0.006874 kB\n\n[Info]  Topological Voxeler Report: Mandible\n    Target Grid: Primary\n    Duration: 36.7393 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1424\n    Memory Consumption: 0.003334 kB\n\n[Info]  Topological Voxeler Report: Small_intestine\n    Target Grid: Primary\n    Duration: 46.2618 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Spleen\n    Target Grid: Primary\n    Duration: 31.4035 ms\n    Priority: 0\n    Edges: None\n    Voxels: 4755\n    Memory Consumption: 0.002098 kB\n\n[Info]  Topological Voxeler Report: Stomach_lumen\n    Target Grid: Primary\n    Duration: 35.5623 ms\n    Priority: 0\n    Edges: None\n    Voxels: 6396\n    Memory Consumption: 0.001488 kB\n\n[Info]  Topological Voxeler Report: Kidney_medulla\n    Target Grid: Primary\n    Duration: 23.0735 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Ear_skin\n    Target Grid: Primary\n    Duration: 25.8537 ms\n    Priority: 0\n    Edges: None\n    Voxels: 745\n    Memory Consumption: 0.003128 kB\n\n[Info]  Topological Voxeler Report: Tongue\n    Target Grid: Primary\n    Duration: 13.7742 ms\n    Priority: 0\n    Edges: None\n    Voxels: 2533\n    Memory Consumption: 688 bytes\n\n[Info]  Topological Voxeler Report: Esophagus\n    Target Grid: Primary\n    Duration: 21.3608 ms\n    Priority: 0\n    Edges: None\n    Voxels: 540\n    Memory Consumption: 0.003250 kB\n\n[Info]  Topological Voxeler Report: Thymus\n    Target Grid: Primary\n    Duration: 15.869 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1942\n    Memory Consumption: 0.001389 kB\n\n[Info]  Topological Voxeler Report: Spinal_cord\n    Target Grid: Primary\n    Duration: 22.8303 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1522\n    Memory Consumption: 0.002632 kB\n\n[Info]  Topological Voxeler Report: Trachea\n    Target Grid: Primary\n    Duration: 23.102 ms\n    Priority: 0\n    Edges: None\n    Voxels: 376\n    Memory Consumption: 0.001137 kB\n\n[Info]  Topological Voxeler Report: Teeth\n    Target Grid: Primary\n    Duration: 26.1998 ms\n    Priority: 0\n    Edges: None\n    Voxels: 371\n    Memory Consumption: 760 bytes\n\n[Info]  Topological Voxeler Report: Eye_Sclera\n    Target Grid: Primary\n    Duration: 11.7457 ms\n    Priority: 0\n    Edges: None\n    Voxels: 377\n    Memory Consumption: 520 bytes\n\n[Info]  Topological Voxeler Report: Ear_cartilage\n    Target Grid: Primary\n    Duration: 12.4414 ms\n    Priority: 0\n    Edges: None\n    Voxels: 262\n    Memory Consumption: 0.002754 kB\n\n[Info]  Topological Voxeler Report: Thalamus\n    Target Grid: Primary\n    Duration: 8.8514 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1208\n    Memory Consumption: 368 bytes\n\n[Info]  Topological Voxeler Report: Small_intestine_lumen\n    Target Grid: Primary\n    Duration: 13.6083 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Bladder\n    Target Grid: Primary\n    Duration: 10.797 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Pancreas\n    Target Grid: Primary\n    Duration: 9.436 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Esophagus_lumen\n    Target Grid: Primary\n    Duration: 8.4816 ms\n    Priority: 0\n    Edges: None\n    Voxels: 243\n    Memory Consumption: 0.001625 kB\n\n[Info]  Topological Voxeler Report: Meniscus\n    Target Grid: Primary\n    Duration: 8.7346 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Penis\n    Target Grid: Primary\n    Duration: 7.9636 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Trachea_lumen\n    Target Grid: Primary\n    Duration: 7.7146 ms\n    Priority: 0\n    Edges: None\n    Voxels: 544\n    Memory Consumption: 1016 bytes\n\n[Info]  Topological Voxeler Report: Pons\n    Target Grid: Primary\n    Duration: 5.1731 ms\n    Priority: 0\n    Edges: None\n    Voxels: 824\n    Memory Consumption: 248 bytes\n\n[Info]  Topological Voxeler Report: Eye_vitreous_humor\n    Target Grid: Primary\n    Duration: 6.2173 ms\n    Priority: 0\n    Edges: None\n    Voxels: 939\n    Memory Consumption: 384 bytes\n\n[Info]  Topological Voxeler Report: Midbrain\n    Target Grid: Primary\n    Duration: 5.4243 ms\n    Priority: 0\n    Edges: None\n    Voxels: 510\n    Memory Consumption: 176 bytes\n\n[Info]  Topological Voxeler Report: Gallbladder\n    Target Grid: Primary\n    Duration: 6.1489 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Heart_lumen\n    Target Grid: Primary\n    Duration: 5.5531 ms\n    Priority: 0\n    Edges: None\n    Voxels: 526\n    Memory Consumption: 280 bytes\n\n[Info]  Topological Voxeler Report: Pharynx\n    Target Grid: Primary\n    Duration: 3.1245 ms\n    Priority: 0\n    Edges: None\n    Voxels: 97\n    Memory Consumption: 80 bytes\n\n[Info]  Topological Voxeler Report: Medulla_oblongata\n    Target Grid: Primary\n    Duration: 2.9105 ms\n    Priority: 0\n    Edges: None\n    Voxels: 359\n    Memory Consumption: 168 bytes\n\n[Info]  Topological Voxeler Report: Hippocampus\n    Target Grid: Primary\n    Duration: 3.1725 ms\n    Priority: 0\n    Edges: None\n    Voxels: 178\n    Memory Consumption: 120 bytes\n\n[Info]  Topological Voxeler Report: Prostate\n    Target Grid: Primary\n    Duration: 3.582 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Adrenal_gland\n    Target Grid: Primary\n    Duration: 3.8691 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Bronchi\n    Target Grid: Primary\n    Duration: 2.881 ms\n    Priority: 0\n    Edges: None\n    Voxels: 68\n    Memory Consumption: 64 bytes\n\n[Info]  Topological Voxeler Report: Testis\n    Target Grid: Primary\n    Duration: 2.9861 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Patella\n    Target Grid: Primary\n    Duration: 4.0883 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Ureter_Urethra\n    Target Grid: Primary\n    Duration: 3.7368 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: component1:Substrate\n    Target Grid: Primary\n    Duration: 9.8476 ms\n    Priority: 0\n    Edges: None\n    Voxels: 8412\n    Memory Consumption: 0.001396 kB\n\n[Info]  Topological Voxeler Report: Extrude 1\n    Target Grid: Primary\n    Duration: 17.8383 ms\n    Priority: 0\n    Edges: 4319\n    Voxels: None\n    Memory Consumption: 752 bytes\n\n[Info]  Topological Voxeler Report: Bronchi_lumen\n    Target Grid: Primary\n    Duration: 1.5447 ms\n    Priority: 0\n    Edges: None\n    Voxels: 40\n    Memory Consumption: 40 bytes\n\n[Info]  Topological Voxeler Report: component1:Battery\n    Target Grid: Primary\n    Duration: 11.3133 ms\n    Priority: 0\n    Edges: 12000\n    Voxels: 3268\n    Memory Consumption: 0.001846 kB\n\n[Info]  Topological Voxeler Report: Cornea\n    Target Grid: Primary\n    Duration: 1.454 ms\n    Priority: 0\n    Edges: None\n    Voxels: 33\n    Memory Consumption: 56 bytes\n\n[Info]  Topological Voxeler Report: Hypothalamus\n    Target Grid: Primary\n    Duration: 1.0686 ms\n    Priority: 0\n    Edges: None\n    Voxels: 45\n    Memory Consumption: 24 bytes\n\n[Info]  Topological Voxeler Report: Epididymis\n    Target Grid: Primary\n    Duration: 1.5807 ms\n    Priority: 0\n    Edges: None\n    Voxels: None\n    Memory Consumption: 0 bytes\n\n[Info]  Topological Voxeler Report: Eye_lens\n    Target Grid: Primary\n    Duration: 0.7881 ms\n    Priority: 0\n    Edges: None\n    Voxels: 28\n    Memory Consumption: 40 bytes\n\n[Info]  Topological Voxeler Report: Hypophysis\n    Target Grid: Primary\n    Duration: 0.496 ms\n    Priority: 0\n    Edges: None\n    Voxels: 18\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: Pinealbody\n    Target Grid: Primary\n    Duration: 0.473 ms\n    Priority: 0\n    Edges: None\n    Voxels: 16\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: component1:ShortingPin\n    Target Grid: Primary\n    Duration: 0.9927 ms\n    Priority: 0\n    Edges: 59\n    Voxels: 8\n    Memory Consumption: 32 bytes\n\n[Info]  Topological Voxeler Report: Larynx\n    Target Grid: Primary\n    Duration: 0.2878 ms\n    Priority: 0\n    Edges: None\n    Voxels: 7\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: commissura_anterior\n    Target Grid: Primary\n    Duration: 0.1882 ms\n    Priority: 0\n    Edges: None\n    Voxels: 3\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: commissura_posterior\n    Target Grid: Primary\n    Duration: 0.0682 ms\n    Priority: 0\n    Edges: None\n    Voxels: 1\n    Memory Consumption: 8 bytes\n\n[Info]  Topological Voxeler Report: component1:Patch\n    Target Grid: Primary\n    Duration: 5.3291 ms\n    Priority: 0\n    Edges: 1298\n    Voxels: None\n    Memory Consumption: 176 bytes\n\n[Info]  Topological Voxeler Report: Complete Voxel Scene\n    Voxel Scene Memory Consumption: 0.003806 GB\n    Wall Clock Time: 7.09322 s\n\n[Info]  Visualization Data Memory Consumption: 0.023711 GB\n     Elapsed Time: 0.446288 s\n[Info]  Time step: 8.16961e-13 s\n--- Logging shutdown --- \n--- Logging shutdown --- \n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p>The GUI opens and shows progress through three phases:</p> <p>Setup phase (1-2 minutes): - Create project directory - Import phantom model (thelonious) - Import antenna CAD model - Place antenna at nasion landmark, and lower this by 100 mm. - Apply material properties - Configure simulation boundaries - Set up gridding</p> <p>Run phase (anwyhere between 1 minute and 5 hours depending on simulation settings): - Writes the input file - Launch iSolve and executes the FDTD simulation - Monitors convergence</p> <p>Extract phase (1-2 minutes): - Open completed project - Extract SAR data from sensors - Generate statistics reports - Save deliverables</p> <p>Watch the GUI status log to see each subtask complete with its timing.</p> <pre><code>run_bash(\"ls results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/\")\n</code></pre> <pre>\n<code>Running: source .bashrc &amp;&amp; ls results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/\n\n------------------------------------------------------------\nconfig.json\nnear_field_thelonious_700MHz_front_of_eyes_center_vertical.smash\nnear_field_thelonious_700MHz_front_of_eyes_center_vertical.smash_Results\npoint_sensor_data.png\nprogress.log\nsar_results.json\nsar_stats_all_tissues.html\nsar_stats_all_tissues.pkl\nverbose.log\n------------------------------------------------------------\n\nCommand completed with return code: 0\n</code>\n</pre> <pre>\n<code>0</code>\n</pre> <p>You can open this <code>.smash</code> file in Sim4Life to see: - Phantom geometry with tissue materials - Antenna positioned in front of eyes - Simulation bounding box (head region) - FDTD grid resolution - Point sensors for SAR measurement</p>"},{"location":"tutorials/03_near_field_basics/#tutorial-3-near-field-basics","title":"Tutorial 3: Near-field basics","text":"<p>Learn device exposure simulations with phone antennas near the body.</p>"},{"location":"tutorials/03_near_field_basics/#what-youll-learn","title":"What you'll learn","text":"<ul> <li>How near-field simulations work (antennas near the body)</li> <li>Antenna configuration basics</li> <li>Placement scenarios and anatomical landmarks</li> <li>Understanding the GUI and logging system</li> <li>Localized SAR extraction</li> </ul> <p>Related documentation: User guide (near-field workflow)</p>"},{"location":"tutorials/03_near_field_basics/#prerequisites","title":"Prerequisites","text":"<ul> <li>Tutorial 1 completed (far-field basics)</li> <li>Tutorial 2 completed (config system, caching)</li> <li>Antenna CAD models available in <code>antenna_models/</code> directory</li> </ul> <p>If you need antenna models, see the Quick Start guide (antenna models are auto-downloaded as needed).</p>"},{"location":"tutorials/03_near_field_basics/#about-the-notebook-code-blocks","title":"About the notebook code blocks","text":"<p>This tutorial includes Python code blocks for running commands. These are designed for Jupyter notebooks if you prefer that workflow.</p> <p>If you're using notebooks, run this setup once per session:</p>"},{"location":"tutorials/03_near_field_basics/#near-field-vs-far-field","title":"Near-field vs far-field","text":"<p>Far-field simulations model environmental exposure where the source is distant. Near-field simulations model device exposure where the antenna is close to the body.</p> <p>The differences matter:</p> Aspect Far-field Near-field Source Plane waves (distant) Antenna model (near body) SAR pattern Distributed Localized hotspots Configuration Directions + polarizations Antenna + placement Typical use Base stations, broadcast Phones, wearables, implants <p>In near-field studies, GOLIAT: 1. Imports the antenna CAD model 2. Positions it relative to anatomical landmarks 3. Applies material properties and power settings 4. Runs the FDTD simulation 5. Extracts localized SAR values</p> <p></p>"},{"location":"tutorials/03_near_field_basics/#the-configuration-file","title":"The configuration file","text":"<p>This tutorial uses a single phantom (Thelonious), one frequency (700 MHz), and the front_of_eyes placement.</p>"},{"location":"tutorials/03_near_field_basics/#study-type","title":"Study type","text":"<pre><code>\"study_type\": \"near_field\"\n</code></pre> <p>This tells GOLIAT to run a near-field study, which requires <code>antenna_config</code> and <code>placement_scenarios</code> instead of <code>far_field_setup</code>.</p>"},{"location":"tutorials/03_near_field_basics/#phantom-selection","title":"Phantom selection","text":"<pre><code>\"phantoms\": [\"thelonious\"]\n</code></pre> <p>We use Thelonious (male child) for this tutorial. If you don't have a license for Thelonious, feel free to use another phantoms, like Duke.</p>"},{"location":"tutorials/03_near_field_basics/#antenna-configuration","title":"Antenna configuration","text":"<p>The <code>antenna_config</code> section defines antenna properties for each frequency.</p> <pre><code>\"antenna_config\": {\n  \"700\": {\n    \"center_frequency\": 700,\n    \"target_power_mW\": 267,\n    \"model_type\": \"PIFA\",\n    \"source_name\": \"Lines 1\",\n    \"materials\": {...},\n    \"gridding\": {...}\n  }\n}\n</code></pre> <p>Key parameters:</p> <ul> <li><code>center_frequency</code>: Antenna operating frequency in MHz</li> <li><code>target_power_mW</code>: The necessary power such that the 10g-SAR in a flat phantom is 1 W/kg. This is for a 300 x 300 mm x 5 skin depth region with tissue parameters from IEC/IEEE 62209-01 at a distance of 5 mm.</li> <li><code>model_type</code>: Antenna type (PIFA or IFA), used to select setup logic</li> <li><code>source_name</code>: Name of the excitation entity in the CAD file</li> <li><code>materials</code>: Maps CAD component names to Sim4Life materials</li> <li><code>gridding</code>: Defines the details of specific sub-meshes in the antenna, per entity group.</li> </ul> <p>Material mapping</p> <p>The <code>materials</code> object tells GOLIAT which material to assign to each antenna component:</p> <pre><code>\"materials\": {\n  \"Extrude 1\": \"Copper\",\n  \"component1:Battery\": \"Copper\",\n  \"component1:Patch\": \"Copper\",\n  \"component1:ShortingPin\": \"Copper\",\n  \"component1:Substrate\": \"Rogers RT/duroid 5880\"\n}\n</code></pre> <p>These names must match entities in the CAD file. The substrate uses a specific dielectric material (Rogers RT/duroid 5880) while conductive parts use Copper.</p> <p></p> <p>PIFA antenna components grided with an automatic default grid. The antenna is below the top right circle. One can distinguish a battery, a substrate, ... This is a mock-up phone as is common in very general dosimetric studies.</p>"},{"location":"tutorials/03_near_field_basics/#placement-scenarios","title":"Placement scenarios","text":"<p>The <code>placement_scenarios</code> section defines where and how the antenna is positioned relative to the phantom.</p> <pre><code>\"placement_scenarios\": {\n  \"front_of_eyes\": {\n    \"bounding_box\": \"default\",\n    \"positions\": {\n      \"center\": [0, 0, -100]\n    },\n    \"orientations\": {\n      \"vertical\": []\n    },\n    \"antenna_reference\": {\n      \"distance_from_top\": 10\n    },\n    \"phantom_reference\": \"nasion\"\n  }\n}\n</code></pre> <p>Key parameters:</p> <ul> <li><code>bounding_box</code>: Which part of phantom to include (default, head, trunk, whole_body). Default means head for <code>front_of_eyes</code> and trunk for <code>by_belly</code>.</li> <li><code>positions</code>: Named position offsets in [x, y, z] mm relative to the reference point. GOLIAT will loop through all of these.</li> <li><code>orientations</code>: Named rotation sequences applied to the antenna. GOLIAT will loop through all of these, for each position.</li> <li><code>antenna_reference</code>: Point on antenna used for placement (distance from top of the phone, by the earpiece speaker).</li> <li><code>phantom_reference</code>: Anatomical landmark used as placement origin.</li> </ul> <p>Anatomical landmarks</p> <p>The <code>phantom_reference</code> parameter points to a coordinate defined in <code>phantom_definitions</code>:</p> <pre><code>\"phantom_definitions\": {\n  \"thelonious\": {\n    \"head_y_separation\": 0,\n    \"trunk_z_separation\": -300,\n    \"chest_extension\": 100,\n    \"nasion\": [-1, 0, 0],\n    ...\n    \"placements\": {\n      \"do_front_of_eyes\": true,\n      ...\n      \"distance_from_eye\": 200\n    }\n  }\n}\n</code></pre> <p>For front_of_eyes placement: - GOLIAT finds the eye entities in the phantom - Calculates their bounding box center - Applies the nasion offset - Adds the position offset (here [0, 0, -100]) for the <code>center</code> scenario pacement. - Places the antenna at the calculated point - Orients the antenna according to any rotations specified for the scenario.</p> <p>The <code>distance_from_eye</code> parameter (200 mm) sets the separation between the phantom and antenna along the Y axis (pointing out of the face).</p> <p>The three parameters <code>head_y_separation</code>, <code>trunk_z_separation</code> and <code>chest_extension</code> define how the <code>head</code> and <code>trunk</code> bounding boxes are defined. Some dimensions of these bounding boxes are defined intelligently, others unfortuneatly require some manual parameters like these. For example, the <code>head_y_separation</code> determines where the back of the head stops for the Thelonious phantom. The next two determine the z and y dimensions of the trunk bounding box.</p> <p></p> <p>Nasion point used as reference point for front_of_eyes placement. This aligns with a point on the antenna 10 mm below the top, by the earpiece speaker.</p> <p></p> <p>Setup for the near-field simulation. Note that the head and trunk bounding boxes are present. The simulation bounding box wraps around the phone and the bounding box of interest (here 'default', i.e., the head). The phone is placed 100 mm below its initial position, where the naison aligns 200 mm from the antenna reference point, 10 mm below the top of the phone.</p>"},{"location":"tutorials/03_near_field_basics/#understanding-the-gui","title":"Understanding the GUI","text":"<p>Before running the simulation, let's tour the GOLIAT GUI. It shows real-time progress, logs, timings, and system utilization.</p> <p>When you run a study, a window opens automatically. Here's what each section does:</p> <p></p>"},{"location":"tutorials/03_near_field_basics/#main-tab","title":"Main tab","text":"<p>The main tab shows overall progress and current activity.</p> <p>Progress bars: - Overall progress: Total completion across all simulations - Stage progress: Current phase (setup, run, extract) within one simulation</p> <p>Simulation info: - Current simulation count (e.g., Simulation: 1 / 1000) - Case details (phantom, frequency, placement)</p> <p>Timing info: - Elapsed time since study started - Time remaining (estimated from profiler data)</p> <p>Status log: - Color-coded messages showing what GOLIAT is doing - Green for success, yellow for warnings, red for errors</p> <p>System utilization: - CPU percentage across all cores - RAM usage (used/total GB) - GPU percentage (if <code>nvidia-smi</code> available)</p> <p>Buttons: - Hitting Stop will try to stop the simulations gracefully. - Closing the window will instantly stop GOLIAT. This may corrupt your <code>.smash</code> files. - You can minimize the GUI to the Windows system tray.</p>"},{"location":"tutorials/03_near_field_basics/#timings-and-timings-piecharts-tabs","title":"Timings and Timings Piecharts tabs","text":"<p>Shows execution statistics for phases and subtasks.</p> <p>For each task, you see: - Mean, median, min, max duration - 10<sup>th</sup>, 25<sup>th</sup>, 75<sup>th</sup>, 90<sup>th</sup> percentiles</p> <p>This data comes from the profiler and improves ETA accuracy as more simulations complete. The piecharts give a visual depiction of the average timings.</p>"},{"location":"tutorials/03_near_field_basics/#time-remaining-and-overall-progress-tabs","title":"Time Remaining and Overall Progress tabs.","text":"<p>Shows progress and ETA trends over time.</p> <p>Time remaining plot: - Hours remaining vs time - Should converge to zero as work completes</p> <p>Overall progress plot: - Percentage complete vs time - Should show smooth upward trend</p> <p>These plots update every 5 seconds during execution.</p>"},{"location":"tutorials/03_near_field_basics/#the-logging-system","title":"The logging system","text":"<p>GOLIAT uses two separate log streams with different purposes.</p>"},{"location":"tutorials/03_near_field_basics/#log-destinations","title":"Log destinations","text":"<p>Logs go to three places:</p> <ol> <li>Console (shell): Real-time output while study runs</li> <li><code>logs/</code> directory: Session logs with timestamps (e.g., <code>logs/10_31_25-20-55-16.progress.log</code>)</li> <li>Simulation directories: Simulation-specific logs in each project folder</li> </ol>"},{"location":"tutorials/03_near_field_basics/#progress-vs-verbose-logs","title":"Progress vs verbose logs","text":"<p>Progress log: - High-level, user-facing messages - Shown in GUI status box - Saved to <code>*.progress.log</code> files - Tracks phases and subtasks</p> <p>Verbose log: - Detailed internal messages - Not shown in GUI (console and file only) - Saved to main <code>*.log</code> files - Includes everything, including the Sim4Life and <code>iSolve</code> logs, useful for debugging</p> <p>Both logs write to the console, but only progress logs appear in the GUI.</p>"},{"location":"tutorials/03_near_field_basics/#phases-and-subtasks","title":"Phases and subtasks","text":"<p>GOLIAT organizes work into three phases, each containing multiple subtasks.</p> <p>The three phases:</p> <ol> <li>Setup: Creates Sim4Life project, imports models, configures simulation</li> <li>Run: Executes FDTD solver (longest phase)</li> <li>Extract: Processes SAR data, generates reports</li> </ol> <p>Subtask logging:</p> <p>When a subtask starts, you see: <pre><code>  - Loading phantom model...\n</code></pre></p> <p>When it finishes, you see: <pre><code>    - Done in 3.2s\n</code></pre></p> <p>The timing line is indented to align with the subtask name. This format applies to console, GUI, and log files. A phase (containing subtasks) is also timed and aligned one tab less.</p> <p></p> <p>Console output showing subtask progression with timings.</p>"},{"location":"tutorials/03_near_field_basics/#simulation-specific-logs","title":"Simulation-specific logs","text":"<p>Each simulation writes logs to its project directory:</p> <pre><code>results/near_field/thelonious/700MHz/front_of_eyes_center_vertical/\n    progress.log        # High-level progress\n    verbose.log         # Detailed logs\n    config.json         # Metadata for caching\n    simulation.smash    # Sim4Life project\n</code></pre> <p>The <code>progress.log</code> file is a subset of <code>verbose.log</code>, containing only user-facing messages. This is the log shown in the GUI.</p>"},{"location":"tutorials/03_near_field_basics/#running-the-simulation","title":"Running the simulation","text":"<p>Now that we finally understand all the above, it's time to run the near-field study:</p>"},{"location":"tutorials/03_near_field_basics/#understanding-the-results","title":"Understanding the results","text":"<p>After the simulation completes, find the results in:</p> <pre><code>results/near_field/thelonious/700MHz/\n  front_of_eyes_center_vertical/\n</code></pre>"},{"location":"tutorials/03_near_field_basics/#output-files","title":"Output files","text":"<p>Simulation project: - <code>simulation.smash</code>: Complete Sim4Life project with fields and SAR</p> <p>SAR data: - <code>sar_results.json</code>: Raw SAR values for all tissues - <code>sar_stats_all_tissues.pkl</code>: Statistical summaries (pickle format) - <code>sar_stats_all_tissues.html</code>: Human-readable HTML report</p> <p>Metadata: - <code>config.json</code>: Config snapshot and caching flags</p> <p>Analysis and visualization sections will be added in a future tutorial.</p>"},{"location":"tutorials/03_near_field_basics/#checking-the-sim4life-project","title":"Checking the Sim4Life project","text":"<p>Open the project to inspect the simulation setup:</p>"},{"location":"tutorials/03_near_field_basics/#whats-next","title":"What's next","text":"<p>You've completed your first near-field simulation. Next steps:</p> <p>Tutorial 4: Gridding and phantom rotation - Manual vs automatic gridding - Subgridding for antenna components - By_cheek placement with phantom rotation - Scene alignment optimization</p> <p>Tutorial 5: Parallel and cloud execution - Running multiple simulations simultaneously - Config splitting strategies - Using oSPARC for cloud compute</p>"},{"location":"tutorials/03_near_field_basics/#summary","title":"Summary","text":"<p>You learned: - Near-field simulations model device exposure with antennas near the body - Antenna configuration includes materials, power, and gridding settings - Placement scenarios use anatomical landmarks for positioning - The GUI shows real-time progress, logs, timings, and system utilization - GOLIAT uses two log streams (progress and verbose) with different purposes - Simulations progress through setup, run, and extract phases - Results include SAR data, statistics, and complete Sim4Life projects</p> <p>In Tutorial 4, we'll explore computational gridding strategies and more complex placements requiring phantom rotation.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/","title":"4. Gridding and Phantom Rotation","text":"<pre><code>from pathlib import Path\nimport importlib.util\n\np = Path.cwd()\nwhile not (p / \"scripts\" / \"notebook_helpers.py\").exists():\n    p = p.parent\nspec = importlib.util.spec_from_file_location(\"_\", p / \"scripts\" / \"notebook_helpers.py\")\nm = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(m)\nrun_bash = m.get_run_bash()\n\nimport IPython\n\nIPython.core.display.max_output_size = None\n</code></pre> <p>This helper function lets you run bash commands from Python cells using <code>run_bash('command')</code>.</p> <p>If you're using bash directly (recommended), ignore the Python code blocks and just run the commands directly. Make sure to always run <code>source .bashrc</code> first.</p> <pre><code>run_bash(\"cat configs/tutorial_4_advanced.json\")\n</code></pre> <pre><code>run_bash(\"goliat study tutorial_4_advanced\")\n</code></pre> <p>This runs 4 simulations: 1. 700 MHz, by_cheek, tragus position, cheek_base orientation (with rotation, with subgrid) 2. 700 MHz, by_cheek, tragus position, tilt_base orientation (no rotation, with subgrid) 3. 835 MHz, by_cheek, tragus position, cheek_base orientation (with rotation, no subgrid) 4. 835 MHz, by_cheek, tragus position, tilt_base orientation (no rotation, no subgrid)</p> <p>Watch for these key steps in the logs:</p> <p>For cheek_base orientation: <pre><code>  - Calculating placement details...\n  - Calculated base rotation for cheek alignment: 84.23 degrees around X-axis.\n  - Handling phantom rotation...\n  - Finding touching angle via binary search...\n  - Determined touching angle: 13.50 deg\n  - Aligning simulation scene with phone...\n</code></pre></p> <p>For tilt_base orientation: <pre><code>  - Calculating placement details...\n  - Calculated base rotation for cheek alignment: 84.23 degrees around X-axis.\n  - Handling phantom rotation...\n  - Phantom rotation not enabled for this orientation.\n  - Aligning simulation scene with phone...\n</code></pre></p> <p>The setup phase takes longer for cheek_base due to the binary search (extra 5-8 seconds).</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#tutorial-4-gridding-and-phantom-rotation","title":"Tutorial 4: Gridding and phantom rotation","text":"<p>Learn computational mesh strategies and advanced near-field placement techniques.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#what-youll-learn","title":"What you'll learn","text":"<ul> <li>Automatic vs manual gridding</li> <li>Subgridding for antenna components</li> <li>Per-frequency grid settings</li> <li>By_cheek placement with phantom rotation</li> <li>Binary search for touching angle detection</li> <li>Scene alignment optimization</li> </ul> <p>Related documentation: Configuration (gridding parameters), Advanced features (phantom rotation)</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Tutorial 3 completed (near-field basics)</li> <li>Understanding of FDTD grid concepts</li> <li>Antenna models available</li> </ul>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#bash-setup","title":"Bash setup","text":"<p>Run this once per notebook session:</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#computational-gridding-basics","title":"Computational gridding basics","text":"<p>The FDTD solver discretizes space into a rectangular mesh. Cell size affects both accuracy and computation time.</p> <p>Key tradeoffs:</p> <ul> <li>Smaller cells: More accurate, longer simulation time</li> <li>Larger cells: Faster simulation, potential artifacts</li> <li>Optimal size: 10-20 cells per wavelength minimum</li> </ul> <p>For a 700 MHz signal: - Wavelength in tissue: ~40-60 mm (depends on tissue type) - Recommended cell size: 2-3 mm (GOLIAT enforces a 3 mm maximum for manual grids)</p> <p>GOLIAT supports three gridding strategies:</p> Strategy When to use Configuration Automatic Quick tests, uniform materials <code>grid_mode: \"automatic\"</code> Manual Production runs, precise control <code>grid_mode: \"manual\"</code> + per-frequency settings Subgridding Fine details (antenna parts) Defined in <code>antenna_config</code> <p>The GOLIAT EU Project uses manual gridding with per-frequency settings for all production simulations.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#the-configuration-file","title":"The configuration file","text":"<p>This tutorial uses the Thelonious phantom with two frequencies (700 MHz and 835 MHz) to demonstrate gridding configurations. The 700 MHz antenna uses subgridding, while 835 MHz does not.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#gridding-parameters","title":"Gridding parameters","text":"<p>The <code>gridding_parameters</code> section defines global mesh settings.</p> <pre><code>\"gridding_parameters\": {\n  \"global_gridding\": {\n    \"grid_mode\": \"manual\",\n    \"manual_fallback_max_step_mm\": 5.0\n  },\n  \"global_gridding_per_frequency\": {\n    \"700\": 2.5,\n    \"835\": 2.5\n  },\n  \"padding\": {\n    \"padding_mode\": \"manual\",\n    \"manual_bottom_padding_mm\": [0, 0, 0],\n    \"manual_top_padding_mm\": [0, 0, 0]\n  }\n}\n</code></pre> <p>Key parameters:</p> <ul> <li><code>grid_mode</code>: Use <code>\"manual\"</code> for explicit control, <code>\"automatic\"</code> for Sim4Life defaults</li> <li><code>manual_fallback_max_step_mm</code>: Maximum cell size if no per-frequency value is defined</li> <li><code>global_gridding_per_frequency</code>: Cell size in mm for each frequency</li> <li><code>padding</code>: Extra space around simulation boundaries</li> </ul> <p>The per-frequency settings let you use finer grids for higher frequencies where wavelengths are shorter.</p> <p></p> <p>Left: Coarse 5 mm grid. Right: Fine 2.5 mm grid. Finer grids resolve more details.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#subgridding-for-antennas","title":"Subgridding for antennas","text":"<p>Subgridding applies a finer mesh to specific components without affecting the global grid. This is useful for small antenna features that need high resolution.</p> <p>Here's the 700 MHz antenna config with subgridding:</p> <pre><code>\"700\": {\n  \"center_frequency\": 700,\n  \"target_power_mW\": 267,\n  \"model_type\": \"PIFA\",\n  \"source_name\": \"Lines 1\",\n  \"materials\": {...},\n  \"gridding\": {\n    \"automatic\": [\"component1:Substrate\", \"Lines 1\"],\n    \"subgridding\": {\n      \"components\": [\"component1:Battery\", \"component1:Patch\", \"Extrude 1\", \"component1:ShortingPin\"],\n      \"SubGridMode\": \"Box\",\n      \"SubGridLevel\": \"x9\",\n      \"AutoRefinement\": \"AutoRefinementVeryFine\"\n    }\n  }\n}\n</code></pre> <p>Subgridding parameters:</p> <ul> <li><code>components</code>: List of CAD entities to apply subgrid to</li> <li><code>SubGridMode</code>: Subgrid shape (<code>\"Box\"</code> is standard)</li> <li><code>SubGridLevel</code>: Resolution multiplier relative to global grid</li> <li><code>\"x3\"</code>: 3x finer (cell size divided by 3)</li> <li><code>\"x9\"</code>: 9x finer (cell size divided by 9)</li> <li>Higher values give better accuracy but increase computation time</li> <li><code>AutoRefinement</code>: Additional refinement level</li> <li><code>\"AutoRefinementVeryFine\"</code>: Highest quality</li> <li><code>\"AutoRefinementFine\"</code>: Moderate quality</li> <li><code>\"AutoRefinementDefault\"</code>: Standard quality</li> </ul> <p>For 700 MHz with global grid 2.5 mm and SubGridLevel x9: - Global cell size: 2.5 mm - Subgrid cell size: 2.5 / 9 \u2248 0.28 mm</p> <p>This resolves fine antenna features without making the entire domain expensive.</p> <p></p> <p>Subgrid region around antenna components (shown in red). Global grid is coarser (blue).</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#comparing-with-and-without-subgridding","title":"Comparing with and without subgridding","text":"<p>The 835 MHz antenna does not use subgridding:</p> <pre><code>\"835\": {\n  \"center_frequency\": 835,\n  \"target_power_mW\": 228,\n  \"model_type\": \"PIFA\",\n  \"source_name\": \"Lines 1\",\n  \"materials\": {...},\n  \"gridding\": {\n    \"automatic\": [\"component1:Substrate\", \"Lines 1\"]\n  }\n}\n</code></pre> <p>This antenna uses only the global 2.5 mm grid. You can compare results to see if subgridding makes a difference for your specific antenna geometry.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#by_cheek-placement","title":"By_cheek placement","text":"<p>The <code>by_cheek</code> placement positions the phone at the ear, using the tragus (ear cartilage protrusion) as an anatomical landmark.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#configuration","title":"Configuration","text":"<pre><code>\"placement_scenarios\": {\n  \"by_cheek\": {\n    \"bounding_box\": \"default\",\n    \"positions\": {\n      \"tragus\": [0, 0, 0]\n    },\n    \"orientations\": {\n      \"cheek_base\": {\n        \"rotate_phantom_to_cheek\": true,\n        \"angle_offset_deg\": 0\n      },\n      \"tilt_base\": []\n    },\n    \"antenna_reference\": {\n      \"distance_from_top\": 10\n    },\n    \"phantom_reference\": \"tragus\"\n  }\n}\n</code></pre> <p>Key differences from front_of_eyes:</p> <ul> <li>Uses <code>tragus</code> instead of <code>nasion</code> as reference point</li> <li>Distance from cheek is 8 mm (vs 200 mm from eyes)</li> <li>Includes base alignment calculation (ear-to-mouth vector)</li> <li>Supports phantom rotation option</li> </ul>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#tragus-landmark","title":"Tragus landmark","text":"<p>The <code>phantom_reference: \"tragus\"</code> parameter points to coordinates defined in <code>phantom_definitions</code>:</p> <pre><code>\"phantom_definitions\": {\n  \"thelonious\": {\n    \"tragus\": [0, 7, -5],\n    \"lips\": [0, 122, 31],\n    ...\n    \"placements\": {\n      \"do_by_cheek\": true,\n      \"distance_from_cheek\": 8\n    }\n  }\n}\n</code></pre> <p>GOLIAT finds the ear skin entity, calculates its center, applies the tragus offset, then positions the phone 8 mm away.</p> <p></p> <p>Tragus anatomical landmark used as reference for by_cheek placement.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#phantom-rotation","title":"Phantom rotation","text":"<p>For some by_cheek orientations, the phantom needs to rotate toward the phone to create realistic contact. This is configured using a dictionary format in the orientations section.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#configuration_1","title":"Configuration","text":"<pre><code>\"orientations\": {\n  \"cheek_base\": {\n    \"rotate_phantom_to_cheek\": true,\n    \"angle_offset_deg\": 0\n  }\n}\n</code></pre> <p>Parameters:</p> <ul> <li><code>rotate_phantom_to_cheek</code>: Enable automatic rotation (boolean)</li> <li><code>angle_offset_deg</code>: Additional angle to rotate phantom away from phone after contact (number)</li> </ul> <p>When this is enabled, GOLIAT: 1. Places phone and phantom in initial positions 2. Runs binary search to find touching angle 3. Applies the angle + offset 4. Rotates phantom, bounding boxes, and sensors 5. Continues with scene alignment</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#binary-search-for-touching-angle","title":"Binary search for touching angle","text":"<p>GOLIAT uses binary search to find the exact angle where the phantom's skin touches the phone's ground plane.</p> <p>The search: - Searches between 0 and 30 degrees rotation around Z axis - Uses 0.5 degree precision - Checks for overlap at each iteration - Stops when touching distance is minimized</p> <p>Watch the console output during setup to see the search progress:</p> <pre><code>  - Handling phantom rotation...\n  - Finding touching angle via binary search...\n    - Testing angle: 15.00 deg (distance: 2.35 mm)\n    - Testing angle: 7.50 deg (distance: 5.82 mm)\n    - Testing angle: 11.25 deg (distance: 3.47 mm)\n    - Testing angle: 13.12 deg (distance: 2.89 mm)\n    ...\n    - Determined touching angle: 13.50 deg\n    - Applying offset: 0.00 deg\n    - Final rotation: 13.50 deg\n    - Done in 4.8s\n</code></pre> <p></p> <p>Console output showing binary search iterations converging to optimal angle.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#before-and-after-rotation","title":"Before and after rotation","text":"<p>Before rotation: Gap between phantom and phone.</p> <p></p> <p>After rotation: Phantom skin touches phone ground plane.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#angle-offset","title":"Angle offset","text":"<p>The <code>angle_offset_deg</code> parameter lets you fine-tune the final position. Positive values rotate the phantom away from the phone (increasing gap), negative values rotate toward it (increasing overlap).</p> <p>Examples: - <code>angle_offset_deg: 0</code>: Phantom just touches phone (default) - <code>angle_offset_deg: 2</code>: 2 degree separation (small gap) - <code>angle_offset_deg: -1</code>: 1 degree overlap (slight compression)</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#scene-alignment","title":"Scene alignment","text":"<p>For by_cheek placements, GOLIAT automatically aligns the entire scene with the phone's upright orientation. This optimizes the computational grid and can reduce simulation time.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#how-it-works","title":"How it works","text":"<p>After phantom rotation (if enabled), GOLIAT:</p> <ol> <li>Identifies reference entities on phone:</li> <li>PIFA: <code>component1:Substrate</code> and <code>component1:Battery</code></li> <li>IFA: <code>Ground</code> and <code>Battery</code></li> <li>Calculates transformation matrix to make phone upright</li> <li>Applies transformation to all scene entities:</li> <li>Phantom group</li> <li>Antenna group</li> <li>Simulation bounding box</li> <li>Antenna bounding box</li> <li>Head and trunk bounding boxes</li> <li>Point sensors</li> </ol> <p>Only parent groups and bounding boxes are transformed, not individual tissues. This keeps relative geometry correct while aligning the grid with the phone.</p> <p></p> <p>Scene after alignment: Phone is upright, grid aligns with phone orientation.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#why-this-matters","title":"Why this matters","text":"<p>FDTD grids are always axis-aligned rectangular meshes. When the phone is tilted relative to the axes, the grid must use smaller cells to resolve edges accurately. Aligning the phone with the axes lets the grid use larger cells while maintaining accuracy.</p> <p>This can reduce: - Number of grid cells (by 10-30%) - Memory usage - Simulation time</p> <p>The alignment happens automatically for all by_cheek placements. No configuration is needed.</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#running-the-simulations","title":"Running the simulations","text":"<p>Run the study:</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#comparing-results","title":"Comparing results","text":"<p>After simulations complete, compare the four cases:</p> <p>Subgridding comparison: - 700 MHz (with subgrid) vs 835 MHz (no subgrid) - Check if SAR hotspot patterns differ - Compare peak 10g SAR values</p> <p>Rotation comparison: - cheek_base (with rotation) vs tilt_base (no rotation) - Check contact region SAR values - Compare field penetration depth</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#todo-analysis-and-visualization-tools-will-be-covered-in-a-future-tutorial","title":"TODO: Analysis and visualization tools will be covered in a future tutorial.","text":"<p>Find results in:</p> <pre><code>results/near_field/thelonious/700MHz/\n  by_cheek_tragus_cheek_base/     # With rotation, with subgrid\n  by_cheek_tragus_tilt_base/      # No rotation, with subgrid\n\nresults/near_field/thelonious/835MHz/\n  by_cheek_tragus_cheek_base/     # With rotation, no subgrid\n  by_cheek_tragus_tilt_base/      # No rotation, no subgrid\n</code></pre>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#gridding-recommendations","title":"Gridding recommendations","text":"<p>Based on GOLIAT EU Project experience:</p> <p>For production simulations: - Use manual gridding with per-frequency settings - 2.5 mm cells for frequencies below 1000 MHz - 1.5-2.0 mm cells for frequencies 1000-3000 MHz - 1.0 mm cells for frequencies above 3000 MHz</p> <p>For subgridding: - Apply to small antenna components (patches, pins, batteries) - Use SubGridLevel x9 for fine metallic features - Use AutoRefinementVeryFine for best accuracy - Skip subgridding for quick test runs</p> <p>For phantom rotation: - Enable for by_cheek placements where contact matters - Use <code>angle_offset_deg: 0</code> for realistic contact - Test without rotation first to verify basic setup</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#whats-next","title":"What's next","text":"<p>You've learned advanced near-field techniques. Next steps:</p> <p>Tutorial 5: Parallel and cloud execution - Running multiple simulations simultaneously - Config splitting strategies - Using oSPARC for cloud compute</p>"},{"location":"tutorials/04_gridding_and_phantom_rotation/#summary","title":"Summary","text":"<p>You learned: - FDTD grids discretize space into rectangular meshes with tradeoffs between accuracy and speed - Manual gridding with per-frequency settings provides precise control - Subgridding applies finer resolution to antenna components without affecting global grid - By_cheek placement uses tragus landmark and includes automatic base alignment - Phantom rotation uses binary search to find optimal touching angle - Scene alignment optimizes grid orientation for by_cheek placements automatically - The GOLIAT EU Project uses manual 2.5 mm grids with x9 subgridding for production</p> <p>In Tutorial 5, we'll explore running multiple simulations in parallel to use multi-core systems and cloud compute resources.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/","title":"5. Parallel and Cloud Execution","text":"<pre><code>from pathlib import Path\nimport importlib.util\n\np = Path.cwd()\nwhile not (p / \"scripts\" / \"notebook_helpers.py\").exists():\n    p = p.parent\nspec = importlib.util.spec_from_file_location(\"_\", p / \"scripts\" / \"notebook_helpers.py\")\nm = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(m)\nrun_bash = m.get_run_bash()\n\nimport IPython\n\nIPython.core.display.max_output_size = None\n</code></pre> <p>This helper function lets you run bash commands from Python cells using <code>run_bash('command')</code>. The setup also disables output truncation so you can see all command output.</p> <p>If you're using bash directly (recommended), ignore the Python code blocks and just run the commands directly. Make sure to always run <code>source .bashrc</code> first.</p> <pre><code>run_bash(\"cat configs/tutorial_5_parallel.json\")\n</code></pre> <pre><code>run_bash(\"goliat parallel tutorial_5_parallel --num-splits 4\")\n</code></pre> <p>Output:</p> <pre><code>Creating parallel configs in: configs/tutorial_5_parallel_parallel\n  - Copied: base_config.json\nSmart split strategy: 4 phantom group(s) \u00d7 1 frequencies group(s) = 4 total configs\nPhantom groups: [1, 1, 1, 1]\nFrequencies groups: [2]\n  - Created: tutorial_5_parallel_0.json (phantoms: ['duke'], frequencies: 2)\n  - Created: tutorial_5_parallel_1.json (phantoms: ['thelonious'], frequencies: 2)\n  - Created: tutorial_5_parallel_2.json (phantoms: ['eartha'], frequencies: 2)\n  - Created: tutorial_5_parallel_3.json (phantoms: ['ella'], frequencies: 2)\nConfig splitting complete.\nFound 4 configs to run in parallel.\nRemoved stale lock file: goliat.lock\n--- Study 1/4 started ---\n--- Study 2/4 started ---\n--- Study 3/4 started ---\n--- Study 4/4 started ---\n</code></pre> <p></p> <p>Terminal showing config split details.</p> <pre><code>run_bash(\"ls configs/tutorial_5_parallel_parallel/\")\n</code></pre> <p>Output:</p> <pre><code>base_config.json\ntutorial_5_parallel_0.json\ntutorial_5_parallel_1.json\ntutorial_5_parallel_2.json\ntutorial_5_parallel_3.json\n</code></pre> <p>Each config is a complete, runnable configuration with a subset of the original work.</p> <p>Check one split:</p> <pre><code>run_bash(\"cat configs/tutorial_5_parallel_parallel/tutorial_5_parallel_0.json\")\n</code></pre> <p>You'll see it contains only <code>duke</code> in the phantoms list, while keeping both frequencies.</p> <p></p> <p>Directory showing split config files.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#tutorial-5-parallel-and-cloud-execution","title":"Tutorial 5: Parallel and cloud execution","text":"<p>Learn to run multiple simulations simultaneously on local hardware or cloud resources.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#what-youll-learn","title":"What you'll learn","text":"<ul> <li>Local parallel execution with <code>goliat parallel</code></li> <li>Config splitting strategies</li> <li>Managing multiple GUI instances</li> <li>Results merging</li> <li>oSPARC batch execution overview</li> </ul> <p>Related documentation: Cloud setup</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#prerequisites","title":"Prerequisites","text":"<ul> <li>Tutorial 1-4 completed</li> <li>Multi-core CPU (4+ cores recommended)</li> <li>For oSPARC: API credentials in <code>.env</code> file</li> </ul>"},{"location":"tutorials/05_parallel_and_cloud_execution/#bash-setup","title":"Bash setup","text":"<p>Run this once per notebook session:</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#why-parallel-execution-matters","title":"Why parallel execution matters","text":"<p>A single simulation can take 15-40 minutes depending on complexity. A study with 4 phantoms and 2 frequencies requires 8 simulations, which would take 2-5 hours sequentially.</p> <p>With parallel execution: - 4-core machine: Run 4 simulations simultaneously (cut time by 4x) - Cloud resources: Run dozens simultaneously (finish large studies in hours)</p> <p>GOLIAT supports two parallel strategies:</p> Strategy When to use Resources needed Local parallel 10-50 simulations, multi-core machine CPU cores, RAM oSPARC batch 50+ simulations, limited local resources API credentials, credits <p>This tutorial focuses on local parallel execution. oSPARC batch is covered briefly with links to detailed documentation.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#important-limitation-gpu-and-isolve-execution","title":"Important limitation: GPU and iSolve execution","text":"<p>Important: When running parallel simulations on a single machine with one GPU, iSolve will only execute one simulation at a time. This is a fundamental limitation of Sim4Life's GPU-based solver.</p> <p>What this means: - Setup and extract phases can run in parallel (no GPU required) - Run phase (iSolve) cannot run in parallel on a single GPU machine - Multiple parallel processes will queue for GPU access, effectively running sequentially</p> <p>Impact: Running <code>goliat parallel</code> with <code>--num-splits 4</code> on a single-GPU machine will: - Speed up setup phases (4x faster) - Speed up extract phases (4x faster) - NOT speed up run phases (still sequential, same total time as running individually)</p> <p>Solutions for true parallel iSolve execution: 1. oSPARC batch: Submit simulations to cloud platform where each job gets its own GPU 2. Multiple Windows PCs: Set up GOLIAT on multiple machines as described in Cloud Setup</p> <p>For large studies requiring many simulations, oSPARC batch is the recommended approach.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#understanding-config-splitting","title":"Understanding config splitting","text":"<p>The <code>goliat parallel</code> command splits a large config into smaller configs, each handling a subset of the work.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#splitting-strategies","title":"Splitting strategies","text":"<p>GOLIAT uses a smart algorithm that considers: - Number of phantoms - Number of frequencies (far-field) or antennas (near-field) - Target number of splits</p> <p>The algorithm finds the best factorization to distribute work evenly.</p> <p>Example 1: 4 phantoms, 2 frequencies, 4 splits - Split phantoms into 4 groups (1 phantom each) - Keep all frequencies in each config - Result: 4 configs, each with 1 phantom and 2 frequencies</p> <p>Example 2: 2 phantoms, 8 frequencies, 4 splits - Keep all phantoms in each config - Split frequencies into 4 groups (2 frequencies each) - Result: 4 configs, each with 2 phantoms and 2 frequencies</p> <p>Example 3: 4 phantoms, 4 frequencies, 4 splits - Split phantoms into 2 groups (2 phantoms each) - Split frequencies into 2 groups (2 frequencies each) - Result: 4 configs (2 phantom groups \u00d7 2 frequency groups)</p> <p>The algorithm balances work across splits to minimize idle time.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#the-configuration-file","title":"The configuration file","text":"<p>This tutorial uses a far-field config with 4 phantoms and 2 frequencies, totaling 16 simulations (4 phantoms \u00d7 2 frequencies \u00d7 2 directions \u00d7 1 polarization).</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#key-parameters","title":"Key parameters","text":"<pre><code>{\n  \"study_type\": \"far_field\",\n  \"phantoms\": [\"duke\", \"thelonious\", \"eartha\", \"ella\"],\n  \"frequencies_mhz\": [700, 900],\n  \"far_field_setup\": {\n    \"type\": \"environmental\",\n    \"environmental\": {\n      \"incident_directions\": [\"x_pos\", \"z_neg\"],\n      \"polarizations\": [\"theta\"]\n    }\n  }\n}\n</code></pre> <p>This config generates: - 4 phantoms - 2 frequencies - 2 incident directions - 1 polarization - Total: 4 \u00d7 2 \u00d7 2 \u00d7 1 = 16 simulations</p> <p>Running sequentially would take 4-8 hours. Running in parallel on 4 cores takes 1-2 hours.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#running-parallel-studies","title":"Running parallel studies","text":"<p>The <code>goliat parallel</code> command handles splitting, launching, and coordinating multiple studies.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#step-1-split-the-config","title":"Step 1: Split the config","text":"<p>Run:</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#step-2-inspect-split-configs","title":"Step 2: Inspect split configs","text":"<p>The split configs are in <code>configs/tutorial_5_parallel_parallel/</code>:</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#step-3-multiple-guis","title":"Step 3: Multiple GUIs","text":"<p>After splitting, GOLIAT launches one <code>goliat study</code> process per config. Each process opens its own GUI window.</p> <p>You'll see 4 GUI windows, each tracking one phantom's simulations.</p> <p></p> <p>Four GOLIAT GUIs running in parallel, one per phantom.</p> <p>Each GUI shows: - Its subset of simulations (e.g., duke at 700 MHz and 900 MHz) - Progress through setup, run, extract phases - Independent ETA calculations - System utilization (shared across all processes)</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#step-4-monitor-system-resources","title":"Step 4: Monitor system resources","text":"<p>With 4 parallel processes, CPU usage should be high across multiple cores.</p> <p>Open Task Manager (Windows) or Activity Monitor (Mac) to verify: - CPU usage: 80-100% (varies based on FDTD vs setup work) - RAM usage: Increases per simulation (2-8 GB each) - Disk I/O: Moderate (reading/writing project files)</p> <p></p> <p>Task Manager showing high CPU usage across multiple cores.</p> <p>If any process idles while others work, the split may be unbalanced. Adjust split strategy or reduce number of splits.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#step-5-results-merging","title":"Step 5: Results merging","text":"<p>When all processes complete, results are in the standard directory structure:</p> <pre><code>results/far_field/duke/700MHz/...\nresults/far_field/duke/900MHz/...\nresults/far_field/thelonious/700MHz/...\nresults/far_field/thelonious/900MHz/...\nresults/far_field/eartha/700MHz/...\nresults/far_field/eartha/900MHz/...\nresults/far_field/ella/700MHz/...\nresults/far_field/ella/900MHz/...\n</code></pre> <p>No manual merging is needed. Each process writes to its own phantom/frequency subdirectories, and the results structure is identical to running sequentially.</p> <p></p> <p>Single results directory containing outputs from all parallel processes.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#command-options","title":"Command options","text":"<p>The <code>goliat parallel</code> command supports several options.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#number-of-splits","title":"Number of splits","text":"<pre><code>goliat parallel my_config --num-splits N\n</code></pre> <p>Choose N based on: - Number of CPU cores (N \u2264 cores for best performance) - Available RAM (each simulation needs 2-8 GB) - Number of phantoms and frequencies (N must factor evenly)</p> <p>Valid splits: - 4 phantoms, 2 frequencies: 1, 2, 4, 8 splits work - 2 phantoms, 3 frequencies: 1, 2, 3, 6 splits work - 1 phantom, 8 frequencies: 1, 2, 4, 8 splits work</p> <p>If you request an invalid split, GOLIAT reports the closest achievable factorization.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#skip-split","title":"Skip split","text":"<p>If you already split a config and want to re-run:</p> <pre><code>goliat parallel my_config --skip-split\n</code></pre> <p>This reuses the existing split directory without regenerating configs. Useful for: - Re-running after errors - Tweaking execution control settings - Testing with <code>--no-cache</code></p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#no-cache","title":"No cache","text":"<p>Force all simulations to re-run:</p> <pre><code>goliat parallel my_config --no-cache\n</code></pre> <p>This disables the caching system, ignoring any existing <code>config.json</code> metadata. Useful for: - Testing config changes - Debugging setup issues - Regenerating results after code updates</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#when-to-use-parallel-execution","title":"When to use parallel execution","text":"<p>Good cases: - 10-50 simulations - Multi-core machine (4+ cores) - Enough RAM (8-32 GB) - Local compute sufficient for timeline</p> <p>Avoid when: - Only 2-5 simulations (overhead not worth it) - Low RAM (causes thrashing) - 50+ simulations (use oSPARC batch instead)</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#osparc-cloud-execution-overview","title":"oSPARC cloud execution overview","text":"<p>For large studies (50+ simulations), oSPARC provides cloud compute resources. This is a brief overview; see the oSPARC cloud execution for complete instructions.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#workflow","title":"Workflow","text":"<ol> <li>Generate input files locally:</li> <li>Set <code>only_write_input_file: true</code></li> <li> <p>Run <code>goliat study</code> to create <code>.h5</code> solver files</p> </li> <li> <p>Submit batch to oSPARC:</p> </li> <li>Set <code>batch_run: true</code></li> <li>Run <code>goliat study</code> again</li> <li> <p>GOLIAT uploads files and monitors job status</p> </li> <li> <p>Download and extract:</p> </li> <li>When jobs complete, GOLIAT downloads results</li> <li>Set <code>do_extract: true</code> to process SAR data</li> </ol>"},{"location":"tutorials/05_parallel_and_cloud_execution/#credentials-setup","title":"Credentials setup","text":"<p>oSPARC requires API credentials in a <code>.env</code> file:</p> <pre><code>OSPARC_API_KEY=your_api_key_here\nOSPARC_API_SECRET=your_api_secret_here\n</code></pre> <p>Get credentials from https://api.sim4life.science</p> <p></p> <p>Example .env file with oSPARC credentials (redacted).</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#batch-configuration","title":"Batch configuration","text":"<p>Enable batch mode in your config:</p> <pre><code>{\n  \"execution_control\": {\n    \"do_setup\": true,\n    \"only_write_input_file\": true,\n    \"do_run\": false,\n    \"do_extract\": false,\n    \"batch_run\": true\n  }\n}\n</code></pre> <p></p> <p>Config section enabling batch mode.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#monitoring","title":"Monitoring","text":"<p>During batch execution, the GUI shows job status:</p> <pre><code>--- Submitting Jobs to oSPARC in Parallel ---\n  - Submitted job 1/50: duke_700_x_pos_theta\n  - Submitted job 2/50: duke_700_x_neg_theta\n  ...\n  - Job 1/50: PENDING\n  - Job 2/50: SUCCESS (downloaded)\n  - Job 3/50: RUNNING\n</code></pre> <p>Jobs progress through states: - PENDING: Queued, waiting for resources - RUNNING: Executing on oSPARC compute node - SUCCESS: Completed, results downloaded - FAILED: Error occurred (check logs)</p> <p></p> <p>GUI showing oSPARC job status monitoring.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#osparc-dashboard","title":"oSPARC dashboard","text":"<p>You can also monitor jobs at https://api.sim4life.science</p> <p></p> <p>oSPARC web interface showing running jobs.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#costs-and-limits","title":"Costs and limits","text":"<p>oSPARC charges based on: - Compute time (per hour per core) - Storage (per GB)</p> <p>The GOLIAT EU Project has access to dedicated resources. For individual use, check pricing and quotas.</p> <p>oSPARC limits: - ~61 parallel jobs per user - Storage quotas (varies by plan) - API rate limits (handled by GOLIAT)</p> <p>For more details, see: - oSPARC cloud execution</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#choosing-the-right-strategy","title":"Choosing the right strategy","text":"Factor Local parallel oSPARC batch Number of simulations 10-50 50-500+ Timeline Hours to 1 day Hours (with resources) Cost Free (your hardware) Paid (compute credits) Setup complexity Simple Moderate (credentials) RAM requirement High (all processes) Low (only setup) <p>Hybrid approach: - Use local parallel for setup (fast) - Generate input files - Submit batch to oSPARC for run phase - Extract locally</p> <p>This balances speed, cost, and resource usage.</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#whats-next","title":"What's next","text":"<p>You've completed the GOLIAT tutorial series. Next steps:</p> <p>Explore advanced features: - Free-space antenna validation - Custom analysis scripts - Result visualization tools - Integration with other EMF tools</p> <p>Read the documentation: - Configuration reference: All config parameters - Advanced features: Phantom rotation, profiling, custom setups - Cloud setup: VM deployment - oSPARC: Cloud batch execution</p>"},{"location":"tutorials/05_parallel_and_cloud_execution/#summary","title":"Summary","text":"<p>You learned: - Local parallel execution uses <code>goliat parallel</code> to split configs and run multiple studies simultaneously - Config splitting uses smart factorization based on phantoms and frequencies - Each split runs in its own process with its own GUI window - Results merge automatically into the standard directory structure - Choose number of splits based on CPU cores, RAM, and work distribution - oSPARC batch execution scales to hundreds of simulations on cloud resources - oSPARC requires API credentials and uses a three-step workflow (generate, submit, extract) - Hybrid approaches combine local setup with cloud execution for efficiency</p> <p>You've completed all five tutorials and can now run sophisticated EMF dosimetry studies with GOLIAT.</p>"},{"location":"tutorials/overview/","title":"GOLIAT tutorials","text":"<p>Interactive tutorials for learning GOLIAT through hands-on examples.</p>"},{"location":"tutorials/overview/#getting-started","title":"Getting started","text":"<p>Each tutorial is a Jupyter notebook that you can run interactively. They use the bash helper from <code>scripts/notebook_helpers.py</code> to execute GOLIAT commands.</p>"},{"location":"tutorials/overview/#tutorial-list","title":"Tutorial list","text":""},{"location":"tutorials/overview/#1-far-field-basics","title":"1. Far-field basics","text":"<p>Start here. Learn environmental exposure simulations with plane waves.</p> <ul> <li>Duration: 25-30 minutes</li> <li>Difficulty: Beginner</li> <li>Topics: Plane waves, directions, polarizations, config structure, running first study</li> </ul>"},{"location":"tutorials/overview/#2-configuration-and-caching","title":"2. Configuration and caching","text":"<p>Learn how configs extend each other and how GOLIAT avoids redundant work.</p> <ul> <li>Duration: 30-35 minutes</li> <li>Difficulty: Beginner to Intermediate</li> <li>Topics: Config inheritance, validation, config hashing, metadata, <code>--no-cache</code> flag</li> </ul>"},{"location":"tutorials/overview/#3-near-field-basics","title":"3. Near-field basics","text":"<p>Device exposure scenarios with antennas.</p> <ul> <li>Duration: 30-35 minutes</li> <li>Difficulty: Intermediate</li> <li>Topics: Antennas, placements, anatomical landmarks, localized SAR, SAPD extraction</li> </ul>"},{"location":"tutorials/overview/#4-gridding-and-phantom-rotation","title":"4. Gridding and phantom rotation","text":"<p>Computational grids and advanced near-field techniques.</p> <ul> <li>Duration: 35-40 minutes</li> <li>Difficulty: Intermediate to Advanced</li> <li>Topics: Automatic/manual gridding, subgridding, phantom rotation, scene alignment</li> </ul>"},{"location":"tutorials/overview/#5-parallel-and-cloud-execution","title":"5. Parallel and cloud execution","text":"<p>Running multiple simulations (local parallel and oSPARC).</p> <ul> <li>Duration: 30-35 minutes</li> <li>Difficulty: Intermediate to Advanced</li> <li>Topics: Config splitting, multiple GUIs, oSPARC setup, batch runs, job monitoring</li> </ul>"},{"location":"tutorials/overview/#contributing","title":"Contributing","text":"<p>Found an issue or want to improve a tutorial? See the Technical Guide for developer information.</p>"},{"location":"tutorials/overview/#see-also","title":"See also","text":"<ul> <li>Quick start guide (get GOLIAT running in minutes)</li> <li>User guide (comprehensive workflow explanations)</li> <li>Configuration reference (full config parameter documentation)</li> <li>Full List of Features (everything GOLIAT can do)</li> </ul>"},{"location":"user_guide/ai_assistant/","title":"AI assistant","text":"<p>GOLIAT has an integrated AI assistant for querying the codebase and documentation in natural language. It uses Retrieval-Augmented Generation (RAG), indexing all Python files, Markdown docs, and JSON configs.</p>"},{"location":"user_guide/ai_assistant/#usage","title":"Usage","text":"<pre><code>goliat ai \"Your question here\"\n</code></pre> <p>For multi-turn conversation:</p> <pre><code>goliat ai --interactive\n</code></pre>"},{"location":"user_guide/ai_assistant/#model-selection","title":"Model selection","text":"<p>By default, the assistant classifies query complexity and picks a model automatically. Override this with:</p> <ul> <li><code>--simple</code>: Force the simpler (cheaper) model</li> <li><code>--complex</code>: Force the more capable model</li> </ul>"},{"location":"user_guide/ai_assistant/#example-queries","title":"Example queries","text":"<ul> <li>\"How does phantom rotation work?\"</li> <li>\"Where is the heatmap generation logic?\"</li> <li>\"How do I configure subgridding?\"</li> <li>\"Why am I getting a CUDA error?\"</li> </ul>"},{"location":"user_guide/ai_assistant/#features","title":"Features","text":"<ul> <li>Context-aware: Understands project structure and retrieves relevant code snippets.</li> <li>Code citations: Points to specific files and line numbers.</li> <li>Cost tracking: Shows token usage and estimated cost after each query.</li> <li>Markdown output: Responses are formatted with syntax highlighting.</li> </ul>"},{"location":"user_guide/ai_assistant/#setup","title":"Setup","text":"<p>Requires an OpenAI API key in your environment:</p> <pre><code>export OPENAI_API_KEY=your_key_here\n</code></pre> <p>Optional: Install with <code>pip install goliat[ai]</code> for the <code>rich</code> library (better terminal formatting).</p>"},{"location":"user_guide/quick_start/","title":"Quick start: Your first GOLIAT simulation","text":"<p>Welcome to GOLIAT! This guide will get you up and running with your first automated EMF dosimetry simulation in minutes. GOLIAT streamlines the entire process using Sim4Life, handling scene setup, execution, and results analysis. We'll walk through a simple \"Hello World\" near-field simulation to calculate Specific Absorption Rate (SAR) and Surface Absorbed Power Density (SAPD) in a digital human phantom.</p>"},{"location":"user_guide/quick_start/#what-youll-achieve","title":"What you'll achieve","text":"<p>By the end of this guide, you will have:</p> <ul> <li>Installed GOLIAT on your system</li> <li>Set up your Python environment with Sim4Life integration</li> <li>Created and configured a basic near-field simulation</li> <li>Run your first GOLIAT study</li> <li>Located and understood your simulation results</li> </ul>"},{"location":"user_guide/quick_start/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, please ensure you have the following:</p> <ul> <li>Sim4Life: Version 8.2 or 9.2 with a valid license. Download from ZMT Zurich if needed. Version 9.2 is recommended for new installations.</li> <li>Python: Version 3.11. GOLIAT uses the Python distribution bundled with Sim4Life, so you typically don't need a separate Python installation.</li> <li>Digital Phantom Models: GOLIAT automatically downloads phantom models (e.g., \"thelonious\" for a child, \"eartha\" for an adult) when you first run a simulation. You may be prompted to provide your email for licensing purposes.</li> <li>Antenna Models: Antenna models for various frequencies are downloaded automatically as needed.</li> </ul> <p>\ud83d\udca1 Pro Tip: If you're new to EMF dosimetry or Sim4Life, familiarize yourself with core concepts. See the User Guide for background on SAR and digital human phantoms.</p>"},{"location":"user_guide/quick_start/#step-1-install-goliat","title":"Step 1: Install GOLIAT","text":"<p>GOLIAT supports two installation methods. Choose based on your needs:</p> <p>For users: Install from PyPI and run from any directory. See installation guide for details.</p> <p>For developers: Clone the repository and install in editable mode. See installation guide for details.</p>"},{"location":"user_guide/quick_start/#quick-pypi-install-users","title":"Quick PyPI install (users)","text":"<p>Most users (i.e., those that just want to get simulating ASAP) should create a virtual environment with Sim4Life Python:</p> <pre><code>C:\\Program Files\\Sim4Life_9.2.0.xxxxx\\Python\\python.exe -m venv venv --system-site-packages\nsource venv/Scripts/activate\npython -m pip install goliat\n</code></pre> <p>The <code>--system-site-packages</code> flag allows the venv to access Sim4Life's packages (like <code>s4l_v1</code>). You can find your Sim4Life Python interpreter in your Sim4Life installation directory (e.g., <code>C:\\Program Files\\Sim4Life_9.2.0.xxxxx\\Python\\python.exe</code>).</p> <p>Note: PyPI installation gives you the latest released version. For unreleased features or bug fixes, use editable installation.</p> <p>Then navigate to your project directory and initialize:</p> <pre><code>cd /path/to/your/project\ngoliat init\n</code></pre> <p>This creates <code>configs/</code> and <code>data/</code> directories and downloads required models.</p> <p>Changing Sim4Life Versions</p> <p>GOLIAT will prompt you to select a Sim4Life version on first run. You can change this anytime:</p> <pre><code>goliat config set-version    # Interactive version picker\ngoliat config show           # View current settings\n</code></pre> <p>Your choice is saved in <code>data/.goliat_preferences.json</code>.</p>"},{"location":"user_guide/quick_start/#developer-install-editable","title":"Developer install (editable)","text":"<p>If you need to modify code or access repository tools:</p> <pre><code># Clone repository\ngit clone https://github.com/rwydaegh/goliat.git\ncd goliat\n\n# Set up Sim4Life Python environment\nsource .bashrc\n\n# Install in editable mode (or in a venv)\npython -m pip install -e .\n\n# Initialize GOLIAT\ngoliat init\n</code></pre> <p>Note: The <code>.bashrc</code> file adds Sim4Life Python to your PATH. GOLIAT will prompt you to copy it to your home directory for convenience.</p>"},{"location":"user_guide/quick_start/#step-2-configure-your-first-study","title":"Step 2: Configure your first study","text":"<p>GOLIAT uses JSON configuration files to define your simulations. These files are located in the <code>configs/</code> directory that was created during initialization.</p> <ol> <li> <p>Choose a template:</p> <ul> <li>For Near-Field simulations (device close to the body), copy <code>configs/near_field_config.json</code> to <code>configs/my_first_near_field_study.json</code>.</li> <li>For Far-Field simulations (whole-body plane wave exposure), copy <code>configs/far_field_config.json</code> to <code>configs/my_first_far_field_study.json</code>.</li> </ul> </li> <li> <p>Edit your custom config (e.g., <code>configs/my_first_near_field_study.json</code>):</p> <pre><code>```json\n{\n  \"extends\": \"base_config.json\",\n  \"study_type\": \"near_field\",\n  \"phantoms\": [\"thelonious\"],\n  \"frequencies_mhz\": [700],\n  \"execution_control\": {\n    \"do_setup\": true,\n    \"do_run\": true,\n    \"do_extract\": true\n  }\n}\n```\n</code></pre> <p>Note: In this example, we use the \"thelonious\" child phantom and a single frequency (700 MHz) for a quick test run. GOLIAT's configuration system supports inheritance. Your custom config extends <code>base_config.json</code>, allowing you to override only the settings you need. For a deep dive into all available parameters, refer to the Configuration Guide.</p> </li> <li> <p>Environment Variables (Optional): Create a <code>.env</code> file in the project root if needed:</p> <ul> <li>oSPARC Cloud Runs: Add API credentials if using cloud execution</li> <li>Phantom Downloads: Add email if prompted during phantom download</li> </ul> </li> </ol> <p>For details, see Troubleshooting.</p>"},{"location":"user_guide/quick_start/#step-3-run-your-first-simulation","title":"Step 3: Run your first simulation","text":"<p>Now you're ready to launch your first GOLIAT study! Execute the following command in your terminal:</p> <pre><code>goliat study my_first_near_field_study\n</code></pre> <p>What happens:</p> <ul> <li>GOLIAT GUI opens showing real-time progress and ETA</li> <li>Downloads phantom and antenna models (one-time)</li> <li>Builds simulation scene in Sim4Life (loads phantom, places antenna)</li> <li>Runs FDTD solver via iSolve</li> <li>Extracts SAR metrics (whole-body, head/trunk, peak 10g SAR) and optionally SAPD</li> <li>Duration: 5-10 minutes depending on hardware</li> </ul> <p> GOLIAT GUI displaying real-time progress and simulation status.</p>"},{"location":"user_guide/quick_start/#step-4-view-and-analyze-results","title":"Step 4: View and analyze results","text":"<p>Once the simulation is complete, GOLIAT will save all results in a structured directory within the <code>results/</code> folder. For our example, you'll find outputs in <code>results/near_field/thelonious/700MHz/by_cheek/</code>.</p> <p>Key output files: - <code>sar_results.json</code>: Contains normalized SAR values (e.g., mW/kg per 1W input power). May also include SAPD if extraction is enabled. - <code>sar_stats_all_tissues.pkl</code>: A detailed Python pickle file with tissue-specific data. - Plots: Various plots, such as SAR heatmaps and bar charts, visualizing the results.</p> <p>You can also run the dedicated analysis script to aggregate and further process your results. Check out the auto-generated first draft paper (only results) to see an example of compiled analysis output:</p> <p><pre><code>goliat analyze --config my_first_near_field_study\n</code></pre> This will generate additional CSV files and plots in the <code>results/</code> directory.</p> <p>Example results:</p> View Analysis Results Gallery  SAR heatmap showing distribution across tissues and frequencies.  ![Heatmap](../img/results_capita_selecta/06_heatmap.png)   More plot types  Bar chart of average SAR by frequency.  ![Bar Chart](../img/results_capita_selecta/01_bar_chart.png)  Power balance overview.  ![Power Balance](../img/results_capita_selecta/10_power_balance.png)  Top 20 tissues by SAR.  ![Ranking](../img/results_capita_selecta/11_ranking.png)   <p>Troubleshooting: Encountering issues? Refer to the Troubleshooting Guide for common problems and solutions (e.g., Sim4Life licensing, Python path errors, disk space management).</p>"},{"location":"user_guide/quick_start/#next-steps","title":"Next steps","text":"<p>You've successfully run your first GOLIAT simulation. Here's what you can do next:</p> <ul> <li>Explore all features: Check out the Full List of Features to discover everything GOLIAT can do</li> <li>Customize your studies: Experiment with configuration files to explore different frequencies, phantoms, and antenna placements</li> <li>Manage disk space: For serial workflows, enable automatic cleanup: <code>\"auto_cleanup_previous_results\": [\"output\"]</code>. See Configuration Guide</li> <li>Scale with the cloud: Use oSPARC for parallel, large-scale simulations by setting <code>\"batch_run\": true</code> in your config</li> </ul> View Cloud Monitoring Dashboard  Web dashboard for monitoring distributed studies.  ![Dashboard](../img/cloud/monitoring_dashboard.png)  Track worker status and super studies.  ![Super Studies](../img/cloud/monitoring_super_studies.png)   <ul> <li>Explore tutorials: Start with Far-Field Basics Tutorial or Parallel and Cloud Execution Tutorial</li> </ul>"},{"location":"user_guide/quick_start/#if-you-have-questions-or-encounter-issues-open-a-github-issue","title":"If you have questions or encounter issues, open a GitHub Issue.","text":""},{"location":"user_guide/user_guide/","title":"\ud83d\udcd6 User Guide: Understanding GOLIAT Workflows","text":"<p>This guide explains how GOLIAT operates, covering workflows for both near-field (device close to the body, like a mobile phone) and far-field (whole-body exposure, such as environmental plane waves) scenarios.</p> <p>GOLIAT automates the complex and often tedious aspects of EMF simulations: downloading necessary models, constructing complex scenes in Sim4Life, executing calculations, and extracting metrics like Specific Absorption Rate (SAR).</p>"},{"location":"user_guide/user_guide/#key-concepts-in-emf-dosimetry","title":"\ud83d\udca1 Key concepts in EMF dosimetry","text":"<p>Before diving into the workflows, let's clarify some fundamental terms:</p> <ul> <li>Phantoms: These are highly detailed digital human models (e.g., \"thelonious\" represents a 6-year-old boy, \"ella\" an adult female). They serve as realistic 3D representations for safe and accurate simulation of EMF interaction with biological tissues.</li> <li>Near-Field Simulations: Focus on scenarios where an EMF source (e.g., an antenna in a mobile device) is in close proximity to the body. These simulations assess localized absorption, particularly in sensitive areas like the head, eyes, or limbs.</li> <li>Far-Field Simulations: Address scenarios involving plane waves impinging on the entire body from various directions (e.g., front, back, sides). These are typically used for evaluating environmental or broadcast exposure.</li> <li>Specific Absorption Rate (SAR): The primary output metric, representing the rate at which electromagnetic energy is absorbed per unit mass of biological tissue, typically expressed in milliwatts per kilogram (mW/kg) per 1W of input power. GOLIAT provides whole-body average SAR, localized SAR (e.g., head/trunk), and peak spatial-average SAR (psSAR) over 10g tissue cubes in specific organs (e.g., brain, eyes, skin).</li> <li>Surface Absorbed Power Density (SAPD): An additional metric for high-frequency exposure (&gt; 6 GHz), measuring the power density absorbed on the skin surface. GOLIAT automatically calculates peak SAPD and its location based on the skin surface mesh.</li> <li>Configuration Files (Configs): JSON files that serve as the \"recipe\" for your simulations. They define all parameters, including phantom selection, frequencies, antenna properties, and execution controls. GOLIAT uses a hierarchical system where study-specific configs inherit from <code>base_config.json</code>, allowing for easy customization and overrides.</li> </ul>"},{"location":"user_guide/user_guide/#end-to-end-workflow-from-config-to-analysis","title":"\ud83d\ude80 End-to-end workflow: from config to analysis","text":"<p>GOLIAT's robust and modular design follows a clear, sequential flow: Load Config \u2192 Orchestrate Study \u2192 Setup Scene \u2192 Run Simulation \u2192 Extract Results \u2192 Analyze &amp; Plot.</p>"},{"location":"user_guide/user_guide/#1-load-configuration","title":"1. Load configuration","text":"<p>Your journey begins by specifying a configuration file. -   Execute your study using the command line: <pre><code>goliat study your_study_config.json\n</code></pre></p> <p>To bypass the caching system and force a fresh run, use the <code>--no-cache</code> flag:</p> <p><pre><code>goliat study your_study_config.json --no-cache\n</code></pre> -   GOLIAT intelligently merges your chosen configuration (e.g., <code>near_field_config.json</code>) with the <code>base_config.json</code>, applying overrides for specific parameters like solver settings or gridding refinements. -   A graphical user interface (GUI) will launch. Your configuration will be loaded and the study will initiate.</p> <p>\ud83d\udca1 Pro Tip: Configuration files are human-readable JSON. We recommend editing them in a code editor like VS Code. Start by copying one of the provided templates (e.g., <code>near_field_config.json</code>) and modify only the parameters relevant to your study, such as phantoms or frequencies. Refer to the Configuration Guide for a detailed breakdown of all parameters.</p>"},{"location":"user_guide/user_guide/#2-orchestrate-study","title":"2. Orchestrate study","text":"<p>The core logic of your simulation is managed by specialized Study classes (<code>NearFieldStudy</code> or <code>FarFieldStudy</code>).</p> <ul> <li>Near-Field Example: If you're running a near-field study, the <code>NearFieldStudy</code> class will systematically loop through all defined phantoms, frequencies, and antenna placements. For instance, it might process \"thelonious\" phantom at 700 MHz with an antenna placed \"by_cheek\" (e.g., 8mm from the cheek).</li> <li>Far-Field Example: For far-field studies, the <code>FarFieldStudy</code> class iterates through phantoms, frequencies, incident directions (e.g., x_pos, y_neg), and polarizations (e.g., theta, phi).</li> <li>Project Management: For each unique simulation scenario, GOLIAT creates a dedicated Sim4Life project file (<code>.smash</code>) within a structured <code>results/</code> directory. The directory structure follows the pattern <code>results/{study_type}/{phantom}/{frequency}MHz/{scenario}/</code>, where <code>scenario</code> identifies the specific simulation configuration. For a near-field study, this might be <code>results/near_field/thelonious/700MHz/by_cheek_tragus_cheek_base/</code>. For a far-field study, it would be <code>results/far_field/thelonious/700MHz/environmental_x_pos_theta/</code>. Each simulation gets its own directory and project file, providing isolation and reliability.</li> <li>Progress Tracking: The GUI provides real-time progress updates and an estimate for the Time Remaining, which becomes more accurate as the current session progresses. The GUI also tracks system resource utilization (CPU, RAM, GPU, VRAM) and displays time-series plots of these metrics. </li> </ul>"},{"location":"user_guide/user_guide/#3-setup-scene-in-sim4life","title":"3. Setup scene in Sim4Life","text":"<p>This phase involves GOLIAT automatically constructing the 3D simulation environment within Sim4Life.</p> <ul> <li>Phantom Loading: The specified digital phantom model is downloaded (if not already present) and imported into the scene, complete with its detailed tissue segmentation (e.g., skin, brain, muscle).</li> <li>Antenna/Source Placement:</li> <li>Near-Field: The CAD model of the antenna (e.g., PIFA or IFA type) is imported and precisely positioned relative to the phantom, according to the defined placement scenario (e.g., 8mm gap from the cheek, with a specific tilt).</li> <li>Far-Field: Instead of an antenna, a plane wave source is configured, specifying its electric field strength (e.g., 1 V/m), incident direction, and polarization.</li> <li>Material Assignment: Appropriate electromagnetic properties (e.g., conductivity, permittivity) are assigned to all entities in the scene (tissues, antenna components) based on the specified frequency.</li> <li>Gridding: The simulation domain is discretized into a computational grid. GOLIAT intelligently applies gridding rules, using finer cells around critical areas like the antenna or phantom surface, and coarser cells elsewhere. This can be automatic or manually controlled via millimeter steps.</li> <li>Scene Optimization: For <code>by_cheek</code> placements, GOLIAT automatically aligns the entire simulation scene (phantom, bounding boxes, sensors) with the phone's upright orientation. This alignment optimizes the computational grid orientation and can reduce simulation time. The alignment occurs after antenna placement and phantom rotation (if enabled), keeping the relative geometry correct throughout the scene.</li> <li>Boundaries and Sensors: Perfectly Matched Layer (PML) boundaries are configured to absorb outgoing electromagnetic waves, preventing reflections. Point sensors are strategically placed at the corners of the simulation bounding box to monitor field values for convergence.</li> <li>Solver Configuration: The Finite-Difference Time-Domain (FDTD) solver from <code>iSolve.exe</code> is set up, typically leveraging GPU acceleration (e.g., Acceleware or CUDA kernel) for faster computation.</li> </ul>"},{"location":"user_guide/user_guide/#4-run-simulation","title":"4. Run simulation","text":"<p>With the scene meticulously set up, GOLIAT proceeds to execute the electromagnetic simulation.</p> <ul> <li>Local Execution: For local runs, GOLIAT directly invokes the Sim4Life <code>iSolve.exe</code> solver. The GUI remains responsive, displaying logs and progress updates as the solver runs.</li> <li>Cloud Execution (oSPARC): For large-scale or parallel studies, GOLIAT can generate the necessary input files (<code>.h5</code>) and submit them as jobs to the oSPARC cloud platform. It then monitors the status of these jobs (e.g., PENDING \u2192 RUNNING \u2192 SUCCESS).</li> <li>Duration: A single simulation can take anywhere from 5 seconds to 5 hours, depending on factors like grid resolution, frequency, and computational resources. All results are normalized to a 1W input power for consistency.</li> </ul> <p>Batch mode: By setting <code>\"batch_run\": true</code> in your configuration, GOLIAT can manage multiple simulations concurrently, either locally (using <code>goliat parallel</code>) or on oSPARC. The GUI tracks the status of all jobs and automatically downloads results upon completion.</p> <p>Important limitation: When running parallel simulations locally on a single machine with one GPU, iSolve will only execute one simulation at a time. This means: - Setup and extract phases can run in parallel (CPU-based, benefits from parallelization) - Run phase (iSolve) cannot run in parallel on a single GPU machine (processes queue sequentially) - For true parallel iSolve execution, use oSPARC batch or multiple Windows PCs as described in Cloud Setup</p>"},{"location":"user_guide/user_guide/#5-extract-analyze-results","title":"5. Extract &amp; analyze results","text":"<p>After the simulation, GOLIAT's <code>ResultsExtractor</code> and <code>Analyzer</code> components take over to process and interpret the vast amount of raw data.</p> <ul> <li>SAR Extraction: The extractor pulls various SAR metrics from the simulation output:</li> <li>Whole-Body SAR: The average SAR over the entire phantom.</li> <li>Localized SAR: Average SAR in specific regions, such as the head or trunk, relevant for localized exposures.</li> <li>psSAR10g: Peak spatial-average SAR over a 10-gram tissue cube, typically reported for sensitive organs like the eyes, brain, and skin.</li> <li>SAPD: Surface Absorbed Power Density (peak value and location) on the skin surface.</li> <li>Power Balance: A check to ensure energy conservation within the simulation, ideally close to 100%.</li> <li>Normalization: All extracted SAR values are normalized to a 1W input power, providing a standardized basis for comparison.</li> <li>Output Files (located in the <code>results/</code> folder):</li> <li><code>sar_results.json</code>: A JSON file containing the primary normalized SAR values.</li> <li><code>sar_stats_all_tissues.pkl</code>: A Python pickle file with detailed, tissue-specific SAR data.</li> <li>Plots: GOLIAT automatically generates a suite of visualizations, including SAR heatmaps (showing SAR distribution by tissue and frequency), bar charts (comparing SAR in different regions), and boxplots (illustrating SAR distributions).</li> <li>Aggregated Analysis: After running multiple simulations, use <code>goliat analyze --config your_config.json</code> to aggregate results across all runs. This command:<ul> <li>Collects SAR data from all simulations in your study</li> <li>Generates statistical summaries (mean, median, percentiles) grouped by frequency and scenario</li> <li>Creates publication-ready plots (heatmaps, bar charts, boxplots, correlation matrices, and more)</li> <li>Exports formatted Excel files (<code>Final_Data_UGent.xlsx</code>) containing all data and metadata</li> <li>Exports CSV files with detailed and summary statistics</li> <li>Optionally generates a LaTeX paper with all figures organized by section This is useful for comparing results across frequencies, placements, or other parameters. Check out the auto-generated first draft paper (only results) to see an example of compiled analysis output. For details, see the Analysis Guide.</li> </ul> </li> <li>Log Files: For debugging and detailed tracking, GOLIAT generates two types of log files in the <code>logs/</code> directory for each run: a <code>.progress.log</code> for high-level updates and a <code>.log</code> for verbose, detailed information. The system automatically manages these files, keeping a maximum of 15 pairs to prevent excessive disk usage.</li> </ul> <p>Example output interpretation: For a near-field 700MHz simulation with an antenna by the cheek, you might observe: -   Head SAR: 0.5 mW/kg (per 1W input). -   Brain psSAR10g: 2.1 mW/kg peak. For far-field studies, the analysis often involves averaging results over different incident directions to determine typical exposure scenarios.</p> <p>\ud83d\udca1 If you simulate the whole-body, you get an overview of all the SAR values in each tissue (as defined by Sim4Life), their psSAR10g values and more! This is also displayed in HTML files. Moreover, we define a number of tissue groups of interest, including the eyes, head, skin and genitals which aggregate the above results for groups of tissues (as defined in <code>data/material_name_mapping.json</code>).</p>"},{"location":"user_guide/user_guide/#near-field-vs-far-field-workflows-a-comparison","title":"\ud83d\udd04 Near-field vs. far-field workflows: a comparison","text":"<p>While the core GOLIAT workflow remains consistent, the specifics of scene setup and analysis differ between near-field and far-field studies.</p>"},{"location":"user_guide/user_guide/#near-field-workflow-device-exposure","title":"Near-field workflow (device exposure)","text":"<ul> <li> <p>Primary Use Case: Assessing localized EMF exposure from devices held close to the body, such as mobile phones, wearables, or other devices. The focus is on SAR in specific tissues and organs.</p> </li> <li> <p>Key Steps:</p> </li> <li>Configuration: Set <code>\"study_type\": \"near_field\"</code> and define specific <code>placement_scenarios</code> (e.g., \"by_cheek\", \"on_wrist\").</li> <li>Scene Setup: Involves importing a detailed CAD model of the device antenna and precisely positioning it relative to the phantom, often with a small air gap (e.g., 8mm).</li> <li>Simulation Run: Typically uses a harmonic excitation (single frequency) to simulate continuous wave exposure.</li> <li> <p>Results Analysis: Concentrates on localized SAR values (e.g., head SAR, trunk SAR) and peak spatial-average SAR (psSAR10g) in sensitive tissues like the eyes, brain, and skin.</p> </li> <li> <p>Free-Space Mode: GOLIAT supports a \"freespace\" phantom option, allowing you to run simulations of the antenna in isolation (without a body). This is useful for antenna characterization and validation.</p> </li> <li> <p>Gaussian Excitation: For near-field studies, you can use Gaussian pulse excitation instead of harmonic. This enables frequency-domain analysis and antenna resonance detection. Set <code>\"excitation_type\": \"Gaussian\"</code> in your config and configure <code>bandwidth_mhz</code> (typically 50-150 MHz). Gaussian excitation requires longer simulation times due to frequency resolution requirements.</p> </li> <li> <p>Antenna Detuning Calibration: When a phone is held against the body, the antenna's resonance frequency shifts due to body loading effects. GOLIAT supports calibrated detuning: run a Gaussian calibration simulation first to measure the frequency shift, then apply the offset in subsequent harmonic runs. Enable with <code>\"detuning_enabled\": true</code> and configure <code>\"detuning_config\": {\"700\": -15}</code> (shifts 700 MHz source down 15 MHz).</p> </li> </ul>"},{"location":"user_guide/user_guide/#far-field-workflow-environmental-exposure","title":"Far-field workflow (environmental exposure)","text":"<ul> <li> <p>Primary Use Case: Evaluating whole-body EMF exposure from distant sources, such as broadcast antennas, cellular base stations, or industrial equipment. The focus is on whole-body average SAR and overall field distribution. We reduce the complexity of impinging fields to all orthogonal directions and two polarizations, and assume that by normalizing this to 1 W, we can construct a transfer functions between measured E-field values and absorption values, especially for channel scenarios where the user is not down- or uploading anything.</p> </li> <li> <p>Key Steps:</p> </li> <li>Configuration: Set <code>\"study_type\": \"far_field\"</code> and define <code>incident_directions</code> (e.g., <code>[\"x_pos\", \"y_neg\"]</code>) and <code>polarizations</code> (e.g., <code>[\"theta\", \"phi\"]</code>).</li> <li>Scene Setup: Instead of a device, plane wave sources are configured to illuminate the phantom from multiple directions, covering a full range of exposure angles.</li> <li>Simulation Run: Multiple simulations are typically run for each frequency, covering all specified directions and polarizations (e.g., 12 simulations per frequency: 6 directions \u00d7 2 polarizations).</li> <li> <p>Results Analysis: Focuses on whole-body average SAR and how SAR is distributed across the entire phantom, often aggregated over various exposure scenarios.</p> </li> <li> <p>Power Normalization: Simulations run at 1 V/m and results are scaled to 1 W/m\u00b2 power density (\u00d7754 scaling factor). This normalization is standard in dosimetry literature and matches what EMF probes measure. The <code>power_balance.input_method</code> config controls how power balance is computed: <code>bounding_box</code> (default, gives ~100% balance as a numerical sanity check) or <code>phantom_cross_section</code> (uses pre-computed body silhouette areas from <code>data/phantom_skins/</code>, gives &gt;100% balance but is physically meaningful for absorption efficiency analysis).</p> </li> <li> <p>Auto-induced mode: Simulates the worst-case scenario where a MaMIMO base station focuses its beams onto a human. After all environmental simulations complete for a (phantom, frequency) pair, GOLIAT combines the results with optimal phase weights to find the skin location with maximum constructive interference. Enable with <code>\"auto_induced\": {\"enabled\": true}</code>. The algorithm:</p> <ol> <li>Extracts skin voxel locations from <code>_Input.h5</code> (~88k voxels vs 8M total - 100\u00d7 reduction)</li> <li>For each direction's <code>_Output.h5</code>, reads E-field at skin voxels only</li> <li>Finds top-N locations where \u03a3|E_i| is maximum (worst-case focus points)</li> <li>Computes optimal phases: \u03c6_i = -arg(E_i\u00ae) for constructive interference</li> <li>Combines fields in a 100mm cube around each focus point</li> <li>Runs SAPD extraction on the combined H5 using Sim4Life (IEC-compliant)</li> </ol> <p>Results are saved to <code>results/far_field/{phantom}/{freq}MHz/auto_induced/auto_induced_summary.json</code>. See the Configuration Guide for all options.</p> </li> <li> <p>Multi-Sine Excitation: For efficiency, GOLIAT can simulate multiple frequencies in a single FDTD run. Use the <code>\"700+2450\"</code> format in your <code>frequencies_mhz</code> array (e.g., <code>[\"700+2450\", 5800]</code>). The simulation uses a UserDefined waveform with superimposed sinusoids and extracts SAR at each frequency via DFT post-processing. This provides ~4\u00d7 speedup for widely-spaced frequencies (&gt; 200 MHz apart) where beat period overhead is minimal. Frequency-dependent material dispersion is automatically handled through dispersion fitting. See Technical Docs for mathematical details.</p> <p>Example multi-sine config: <pre><code>{\n  \"frequencies_mhz\": [\"700+2450\", 5800],\n  \"far_field_setup\": {\n    \"type\": \"environmental\",\n    \"environmental\": {\n      \"incident_directions\": [\"x_pos\", \"y_neg\"],\n      \"polarizations\": [\"theta\", \"phi\"]\n    }\n  }\n}\n</code></pre> This runs two simulations per direction/polarization: one extracting SAR at 700 and 2450 MHz, another at 5800 MHz.</p> </li> </ul>"},{"location":"user_guide/user_guide/#tips-for-success","title":"\u2705 Tips for success","text":"<ul> <li>Scale Up Your Studies: For multi-core local execution, leverage <code>goliat parallel near_field_config.json --num-splits 4</code> to distribute simulations across multiple CPU cores. Note: On a single-GPU machine, this only parallelizes setup and extract phases; iSolve run phases will still execute sequentially. For true parallel run phases, use oSPARC batch or multiple Windows PCs.</li> <li>Cloud Computing with oSPARC: For hundreds or thousands of simulations, oSPARC offers a cost-effective and fast cloud solution. Remember to set up your API keys in a <code>.env</code> file.</li> <li>Manage disk space: For serial workflows on machines with limited storage, use <code>\"auto_cleanup_previous_results\": [\"output\"]</code> to automatically delete previous simulation files. See Configuration Guide for details.</li> <li>Customize with Confidence: Feel free to modify frequencies and placements in your configuration files. However, for consistency with GOLIAT's protocols, it's generally recommended to keep the core antenna models fixed.</li> <li>Effective Debugging: Always consult the <code>logs/</code> directory for detailed error messages. You can also rerun specific phases of a study (e.g., <code>\"do_setup\": false, \"do_run\": false, \"do_extract\": true</code>) to isolate and debug issues more efficiently.</li> <li>Analyze Logs: Use <code>goliat stats &lt;path&gt;</code> to parse verbose logs into a JSON summary (for a single file) or generate statistical plots (for a directory of logs). This is helpful for analyzing solver performance and timing.</li> </ul> <p>You can now navigate GOLIAT and perform EMF dosimetry simulations. For hands-on examples, proceed to the Tutorials. For a complete reference of all available features, see the Full List of Features. If you have any further questions or encounter issues, please open a GitHub Issue.</p>"}]}